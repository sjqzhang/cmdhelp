-- phpMyAdmin SQL Dump
-- version 3.3.8.1
-- http://www.phpmyadmin.net
--
-- 主机: w.rdc.sae.sina.com.cn:3307
-- 生成日期: 2016 年 03 月 08 日 12:02
-- 服务器版本: 5.6.23
-- PHP 版本: 5.3.3

SET SQL_MODE="NO_AUTO_VALUE_ON_ZERO";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;

--
-- 数据库: `app_cmdhelp`
--

-- --------------------------------------------------------

--
-- 表的结构 `cmdhelp`
--

CREATE TABLE IF NOT EXISTS `cmdhelp` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '编号',
  `cmd` varchar(255) DEFAULT NULL COMMENT '命令',
  `cmdinfo` longtext COMMENT '命令详情',
  `description` varchar(1024) DEFAULT NULL COMMENT '描述',
  PRIMARY KEY (`id`)
) ENGINE=MyISAM  DEFAULT CHARSET=utf8 AUTO_INCREMENT=167 ;

--
-- 转存表中的数据 `cmdhelp`
--

INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(4, 'cobbler', 'cobbler system add --name=network --ip=192.168.98.0/8 --profile=centos6.6 --interface eth0', ''),
(5, 'cobbler', 'cobbler system add --name=network --ip=192.168.98.0/8 --profile=centos6.6 --interface eth0 ', ''),
(110, 'cobbler', 'cobbler distro report', ''),
(12, 'cobbler', 'cobbler profile edit --name=centos6.6 --kickstart=/var/lib/cobbler/kickstarts/custom.ks --distro=images-x86_64 --repos=Centos6-UPDATES cloudera epel6-x86_64 epel6-x86_64-testing mesosphere percona --virt-auto-boot=1 --virt-cpus=8 --virt-file-size=200 --virt-disk-driver=qcow2 --virt-ram=4096 --virt-type=kvm --virt-bridge=br0 --virt-path=/data/kvm', ''),
(11, 'cobbler', 'cobbler system add --name=host-188116 --hostname=host-188116 --mac=00:50:56:3C:49:44 --interface=eth0 --ip-address=192.168.98.130 --subnet=255.255.255.0 --gateway=192.168.98.128 --static=1 --profile=centos6.6', ''),
(20, 'ci', '\nci 常用函数\r\n   \r\n  $this->table->generate() \r\n  $this->db->get(''news'') \r\n  $this->agent->accept_charset() \r\n  $this->agent->accept_charset(''utf-8'') \r\n  $this->agent->accept_lang() \r\n  $this->agent->accept_lang(''en'') \r\n  $this->agent->agent_string() \r\n  $this->agent->browser() \r\n  $this->agent->is_browser() \r\n  $this->agent->is_browser(''Safari'') \r\n  $this->agent->is_mobile() \r\n  $this->agent->is_mobile(''iphone'') \r\n  $this->agent->is_referral() \r\n  $this->agent->is_robot() \r\n  $this->agent->mobile() \r\n  $this->agent->platform() \r\n  $this->agent->referrer() \r\n  $this->agent->robot() \r\n  $this->agent->version() \r\n  $this->benchmark->elapsed_time() \r\n  $this->benchmark->elapsed_time(''cat'', ''bird'') \r\n  $this->benchmark->elapsed_time(''dog'', ''bird'') \r\n  $this->benchmark->elapsed_time(''dog'', ''cat'') \r\n  $this->benchmark->mark(''another_mark_end'') \r\n  $this->benchmark->mark(''another_mark_start'') \r\n  $this->benchmark->mark(''bird'') \r\n  $this->benchmark->mark(''cat'') \r\n  $this->benchmark->mark(''dog'') \r\n  $this->benchmark->mark(''my_mark_end'') \r\n  $this->benchmark->mark(''my_mark_start'') \r\n  $this->benchmark->memory_usage() \r\n  $this->Blog->get_last_ten_entries() \r\n  $this->cache->apc->get(''my_cache'') \r\n  $this->cache->apc->is_supported() \r\n  $this->cache->apc->save(''foo'', ''bar'', 10) \r\n  $this->cache->cache_info() \r\n  $this->cache->clean() \r\n  $this->cache->delete(''cache_item_id'') \r\n  $this->cache->file->save(''foo'', ''bar'', 10) \r\n  $this->cache->get() \r\n  $this->cache->get(''foo'') \r\n  $this->cache->get_metadata(''my_cached_item'') \r\n  $this->cache->get(''my_cached_item'') \r\n  $this->cache->memcached->save(''foo'', ''bar'', 10) \r\n  $this->cache->save(''cache_item_id'', ''data_to_cache'') \r\n  $this->cache->save(''foo'', $foo, 300) \r\n  $this->calendar->generate() \r\n  $this->calendar->generate(2006, 6) \r\n  $this->calendar->generate(2006, 6, $data) \r\n  $this->calendar->generate($this->uri->segment(3) \r\n  $this->cart->contents() \r\n  $this->cart->destroy() \r\n  $this->cart->format_number($items[''price'']) \r\n  $this->cart->format_number($items[''subtotal'']) \r\n  $this->cart->format_number($this->cart->total() \r\n  $this->cart->has_options($items[''rowid'']) \r\n  $this->cart->has_options(rowid) \r\n  $this->cart->insert() \r\n  $this->cart->insert($data) \r\n  $this->cart->product_options($items[''rowid'']) \r\n  $this->cart->product_options(rowid) \r\n  $this->cart->total() \r\n  $this->cart->total_items() \r\n  $this->cart->update() \r\n  $this->cart->update($data) \r\n  $this->CI =&amp; get_instance() \r\n  $this->CI->output->get_output() \r\n  $this->comments() \r\n  $this->config->base_url() \r\n  $this->config[''blog_settings''] = $config<br /> \r\n  $this->config->item() \r\n  $this->config->item(''blog_settings'') \r\n  $this->config->item(''item name'') \r\n  $this->config->item(''language'') \r\n  $this->config->load() \r\n  $this->config->load(''blog_settings'', TRUE) \r\n  $this->config->load(''filename'') \r\n  $this->config->load 中使用了第二个参数，你可以通过指定函数 $this->config->item() \r\n  $this->config->set_item(''item_name'', ''item_value'') \r\n  $this->config->site_url() \r\n  $this->config->system_url() \r\n  $this->conn_id was a resource instead of an object.  \r\n  $this->content = $_POST[''content''];<br /> \r\n  $this->date = time() \r\n  $this->db->affected_rows() \r\n  $this->db->cache_delete() \r\n  $this->db->cache_delete_all() \r\n  $this->db->cache_delete(''/blog'', ''comments'') \r\n  $this->db->cache_delete(''blog'', ''comments'') \r\n  $this->db->cache_off() \r\n  $this->db->cache_on() \r\n  $this->db->call_function() \r\n  $this->db->call_function(''get_client_info'') \r\n  $this->db->call_function(''some_function'', $param1, $param2, etc..) \r\n  $this->db->close() \r\n  $this->db->count_all() \r\n  $this->db->count_all(''my_table'') \r\n  $this->db->count_all_results() \r\n  $this->db->count_all_results(''my_table'') \r\n  $this->db->dbprefix() \r\n  $this->db->dbprefix(''tablename'') \r\n  $this->db->delete() \r\n  $this->db->delete(''mytable'') \r\n  $this->db->delete(''mytable'', array(''id'' => $id) \r\n  $this->db->delete($tables) \r\n  $this->db->distinct() \r\n  $this->db->empty_table() \r\n  $this->db->empty_table(''mytable'') \r\n  $this->db->escape() \r\n  $this->db->escape_like_str() \r\n  $this->db->escape_like_str($search) \r\n  $this->db->escape($name) \r\n  $this->db->escape_str() \r\n  $this->db->escape_str($title) \r\n  $this->db->escape($title) \r\n  $this->db->field_data() \r\n  $this->db->field_data(''table_name'') \r\n  $this->db->field_exists() \r\n  $this->db->field_exists(''field_name'', ''table_name'') \r\n  $this->db->field_names() \r\n  $this->db->fields() \r\n  $this->db->flush_cache() \r\n  $this->dbforge->add_column() \r\n  $this->dbforge->add_column(''table_name'', $fields) \r\n  $this->dbforge->add_field() \r\n  $this->dbforge->add_field(array( \r\n  $this->dbforge->add_field($fields) \r\n  $this->dbforge->add_field(''id'') \r\n  $this->dbforge->add_field(&quot;label varchar(100) \r\n  $this->dbforge->add_key(array(''blog_name'', ''blog_label'') \r\n  $this->dbforge->add_key(''blog_id'', TRUE) \r\n  $this->dbforge->add_key(''blog_name'') \r\n  $this->dbforge->add_key(''field'') \r\n  $this->dbforge->add_key(''site_id'', TRUE) \r\n  $this->dbforge->create_database(''db_name'') \r\n  $this->dbforge->create_database(''my_db'') \r\n  $this->dbforge->create_table(''blog'') \r\n  $this->dbforge->create_table(''table_name'') \r\n  $this->dbforge->create_table(''table_name'', TRUE) \r\n  $this->dbforge->drop_column() \r\n  $this->dbforge->drop_column(''table_name'', ''column_to_drop'') \r\n  $this->dbforge->drop_database(''db_name'') \r\n  $this->dbforge->drop_database(''my_db'') \r\n  $this->dbforge->drop_table(''blog'') \r\n  $this->dbforge->drop_table(''table_name'') \r\n  $this-> dbforge -> modify_column() \r\n  $this->dbforge->modify_column() \r\n  $this->dbforge->modify_column(''table_name'', $fields) \r\n  $this->dbforge->rename_table(''old_table_name'', ''new_table_name'') \r\n  $this->db->from() \r\n  $this->db->from(''blogs'') \r\n  $this->db->from(''my_table'') \r\n  $this->db->from(''mytable'') \r\n  $this->db->get() \r\n  $this->db->get(''entries'', 10) \r\n  $this->db->get(''members'') \r\n  $this->db->get(''mytable'') \r\n  $this->db->get(''mytable'', 10, 20) \r\n  $this->db->get(''table'') \r\n  $this->db->get(''table_name'') \r\n  $this->db->get(''tablename'') \r\n  $this->db->get_where() \r\n  $this->db->get_where(''mytable'', array(''id'' => $id) \r\n  $this->db->get_where(''news'', array(''slug'' => $slug) \r\n  $this->db->group_by() \r\n  $this->db->group_by(array("title", "date") \r\n  $this->db->group_by("title") \r\n  $this->db->having() \r\n  $this->db->having(array(''title ='' => ''My Title'', ''id &lt;'' => $id) \r\n  $this->db->having(''user_id = 45'') \r\n  $this->db->having(''user_id'',  45) \r\n  $this->db->having(''user_id'',  45, FALSE) \r\n  $this->db->insert() \r\n  $this->db->insert_batch() \r\n  $this->db->insert_batch(''mytable'', $data) \r\n  $this->db->insert(''entries'',$this) \r\n  $this->db->insert_id() \r\n  $this->db->insert(''mytable'') \r\n  $this->db->insert(''mytable'', $data) \r\n  $this->db->insert(''mytable'', $object) \r\n  $this->db->insert(''news'', $data) \r\n  $this->db->insert_string() \r\n  $this->db->insert_string(''table_name'', $data) \r\n  $this->db->insert_string(''trackbacks'', $data) \r\n  $this->db->insert_string(&#x27;captcha&#x27;, $data) \r\n  $this->db->join() \r\n  $this->db->join(''comments'', ''comments.id = blogs.id'') \r\n  $this->db->join(''comments'', ''comments.id = blogs.id'', ''left'') \r\n  $this->db->last_query() \r\n  $this->db->like() \r\n  $this->db->like($array) \r\n  $this->db->like(''body'', ''match'') \r\n  $this->db->like(''title'', ''match'') \r\n  $this->db->like(''title'', ''match'', ''after'') \r\n  $this->db->like(''title'', ''match'', ''before'') \r\n  $this->db->like(''title'', ''match'', ''both'') \r\n  $this->db->like(''title'', ''match'', ''none'') \r\n  $this->db->limit() \r\n  $this->db->limit(10) \r\n  $this->db->limit(10, 20) \r\n  $this->db->list_fields() \r\n  $this->db->list_fields(''table_name'') \r\n  $this->db->list_tables() \r\n  $this->db->not_like() \r\n  $this->db->not_like(''title'', ''match'') \r\n  $this->db->order_by() \r\n  $this->db->order_by("name", "asc") \r\n  $this->db->order_by("title", "desc") \r\n  $this->db->order_by(''title desc, name asc'') \r\n  $this->db->or_having() \r\n  $this->db->or_like() \r\n  $this->db->or_like(''body'', $match) \r\n  $this->db->or_not_like() \r\n  $this->db->or_not_like(''body'', ''match'') \r\n  $this->db->or_where() \r\n  $this->db->or_where(''id >'', $id) \r\n  $this->db->or_where_in() \r\n  $this->db->or_where_in(''username'', $names) \r\n  $this->db->or_where_not_in() \r\n  $this->db->or_where_not_in(''username'', $names) \r\n  $this->db->platform() \r\n  $this->db->protect_identifiers(''table_name'') \r\n  $this->db->protect_identifiers(''table_name'', TRUE) \r\n  $this->db->query() \r\n  $this->db->query(''AND YET ANOTHER QUERY...'') \r\n  $this->db->query(''ANOTHER QUERY...'') \r\n  $this->db->query(''AN SQL QUERY...'') \r\n  $this->db->query($query) \r\n  $this->db->query(&quot;DELETE FROM captcha WHERE captcha_time &lt; &quot;.$expiration) \r\n  $this->db->query("SELECT foo, bar, baz, foofoo, foobar AS raboof, foobaz<br />  FROM exp_pre_email_addresses<br />  WHERE foo != ''oof''<br />  AND baz != ''zab''<br />  ORDER BY foobaz<br />  LIMIT 5, 100") \r\n  $this->db->query("select foo, bar, baz, foofoo, foobar as raboof, foobaz from exp_pre_email_addresses ...where foo != ''oof'' and baz != ''zab'' order by foobaz limit 5, 100") \r\n  $this->db->query("SELECT * FROM another_table") \r\n  $this->db->query("SELECT * FROM blog") \r\n  $this->db->query("SELECT * FROM members WHERE member_id = ''$current_user''") \r\n  $this->db->query(''SELECT * FROM my_table'') \r\n  $this->db->query("SELECT * FROM my_table") \r\n  $this->db->query("SELECT * FROM mytable") \r\n  $this->db->query(''SELECT * FROM some_table'') \r\n  $this->db->query("SELECT * FROM users;") \r\n  $this->db->query("SELECT * FROM users LIMIT 1;") \r\n  $this->db->query(''SELECT name FROM my_table LIMIT 1'') \r\n  $this->db->query(''SELECT name FROM some_table'') \r\n  $this->db->query(''SELECT name, title, email FROM my_table'') \r\n  $this->db->query(''SELECT title FROM my_table'') \r\n  $this->db->query($sql) \r\n  $this->db->query($sql, array(3, ''live'', ''Rick'') \r\n  $this->db->query($sql, $binds) \r\n  $this->db->query("YOUR QUERY") \r\n  $this->db->query(''YOUR QUERY HERE'') \r\n  $this->db->query(''一条SQL查询...'') \r\n  $this->db->query(''另一条查询...'') \r\n  $this->db->query("要执行的 SQL") \r\n  $this->db->query(''还有一条查询...'') \r\n  $this->db->reconnect() \r\n  $this->db->result() \r\n  $this->db->select(''*'') \r\n  $this->db->select() \r\n  $this->db->select_avg() \r\n  $this->db->select_avg(''age'') \r\n  $this->db->select(''field1'') \r\n  $this->db->select(''field2'') \r\n  $this->db->select_max() \r\n  $this->db->select_max(''age'') \r\n  $this->db->select_max(''age'', ''member_age'') \r\n  $this->db->select_min() \r\n  $this->db->select_min(''age'') \r\n  $this->db->select("(''SELECT SUM(payments.amount) \r\n  $this->db->select_sum() \r\n  $this->db->select_sum(''age'') \r\n  $this->db->select(''title, content, date'') \r\n  $this->db->set() \r\n  $this->db->set($array) \r\n  $this->db->set_dbprefix() \r\n  $this->db->set_dbprefix(''newprefix'') \r\n  $this->db->set(''field'', ''field+1'') \r\n  $this->db->set(''field'', ''field+1'', FALSE) \r\n  $this->db->set(''name'', $name) \r\n  $this->db->set($object) \r\n  $this->db->set(''status'', $status) \r\n  $this->db->set(''title'', $title) \r\n  $this->db->simple_query() \r\n  $this->db->smart_escape_str() \r\n  $this->db->start_cache() \r\n  $this->db->stop_cache() \r\n  $this->db->table_exists() \r\n  $this->db->table_exists(''table_name'') \r\n  $this->db->trans_begin() \r\n  $this->db->trans_commit() \r\n  $this->db->trans_complete() \r\n  $this->db->trans_off() \r\n  $this->db->trans_rollback() \r\n  $this->db->trans_start() \r\n  $this->db->trans_start(TRUE) \r\n  $this->db->trans_status() \r\n  $this->db->trans_strict(FALSE) \r\n  $this->db->truncate() \r\n  $this->db->truncate(''mytable'') \r\n  $this->db->update() \r\n  $this->db->update_batch() \r\n  $this->db->update_batch(''mytable'', $data, ''title'') \r\n  $this->db->update(''entries'',$this, array(''id'' => $_POST[''id'']) \r\n  $this->db->update(''mytable'', $data) \r\n  $this->db->update(''mytable'', $data, array(''id'' => $id) \r\n  $this->db->update(''mytable'', $data, "id = 4") \r\n  $this->db->update(''mytable'', $object) \r\n  $this->db->update_string() \r\n  $this->db->update_string(''table_name'', $data, $where) \r\n  $this->db->use_table() \r\n  $this->dbutil->backup() \r\n  $this->dbutil->backup($prefs) \r\n  $this->dbutil->csv_from_result($db_result) \r\n  $this->dbutil->csv_from_result($query) \r\n  $this->dbutil->csv_from_result($query, $delimiter, $newline) \r\n  $this->dbutil->database_exists() \r\n  $this->dbutil->database_exists(''database_name'') \r\n  $this->dbutil->list_databases() \r\n  $this->dbutil->optimize_database() \r\n  $this->dbutil->optimize_table(''table_name'') \r\n  $this->dbutil->repair_table(''table_name'') \r\n  $this->dbutil->xml_from_result($db_result) \r\n  $this->dbutil->xml_from_result($query, $config) \r\n  $this->db->version() \r\n  $this->db->where() \r\n  $this->db->where($array) \r\n  $this->db->where(''id'', ''5'') \r\n  $this->db->where(''id <'', $id) \r\n  $this->db->where(''id'', $id) \r\n  $this->db->where_in() \r\n  $this->db->where_in(''username'', $names) \r\n  $this->db->where(''MATCH (field) \r\n  $this->db->where(''name !='', $name) \r\n  $this->db->where(''name'', $name) \r\n  $this->db->where_not_in() \r\n  $this->db->where_not_in(''username'', $names) \r\n  $this->db->where(''status'', $status) \r\n  $this->db->where(''title'', $title) \r\n  $this->db->where($where) \r\n  $this->email->attach() \r\n  $this->email->attach(''path/photo1.jpg'') \r\n  $this->email->attach(''path/photo2.jpg'') \r\n  $this->email->attach(''path/photo3.jpg'') \r\n  $this->email->bcc() \r\n  $this->email->bcc(''them@their-example.com'') \r\n  $this->email->cc() \r\n  $this->email->cc(''another@another-example.com'') \r\n  $this->email->clear() \r\n  $this->email->clear(TRUE) \r\n  $this->email->from() \r\n  $this->email->from(''you@example.com'', ''Your Name'') \r\n  $this->email->from(''your@example.com'') \r\n  $this->email->from(''your@example.com'', ''Your Name'') \r\n  $this->email->initialize() \r\n  $this->email->initialize($config) \r\n  $this->email->message() \r\n  $this->email->message(''Hi ''.$name.'' Here is the info you requested.'') \r\n  $this->email->message(''Testing the email class.'') \r\n  $this->email->message(''This is my message'') \r\n  $this->email->print_debugger() \r\n  $this->email->reply_to() \r\n  $this->email->reply_to(''you@example.com'', ''Your Name'') \r\n  $this->email->send() \r\n  $this->email->set_alt_message() \r\n  $this->email->set_alt_message(''This is the alternative message'') \r\n  $this->email->some_function() \r\n  $this->email->subject() \r\n  $this->email->subject(''Email Test'') \r\n  $this->email->subject(''Here is your info ''.$name) \r\n  $this->email->subject(''This is my subject'') \r\n  $this->email->to() \r\n  $this->email->to($address) \r\n  $this->email->to($list) \r\n  $this->email->to(''one@example.com, two@example.com, three@example.com'') \r\n  $this->email->to(''someone@example.com'') \r\n  $this->encrypt->set_cipher() \r\n  $this->encrypt->set_cipher(MCRYPT_BLOWFISH) \r\n  $this->encrypt->set_mode() \r\n  $this->encrypt->set_mode(MCRYPT_MODE_CFB) \r\n  $this->encrypt->sha1() \r\n  $this->encrypt->sha1(''Some string'') \r\n  $this->foo($parts) \r\n  $this->form_validation->required($string) \r\n  $this->form_validation->run() \r\n  $this->form_validation->run(''signup'') \r\n  $this->form_validation->set_error_delimiters(''&lt;div class="error">'', ''&lt;/div>'') \r\n  $this->form_validation->set_message() \r\n  $this->form_validation->set_message(''required'', ''Your custom message here'') \r\n  $this->form_validation->set_message(''rule'', ''Error Message'') \r\n  $this->form_validation->set_message(''username_check'') \r\n  $this->form_validation->set_message(''username_check'', ''The %s field can not be the word "test"'') \r\n  $this->form_validation->set_rules() \r\n  $this->form_validation->set_rules($config) \r\n  $this->form_validation->set_rules(''email'', ''Email'', ''required'') \r\n  $this->form_validation->set_rules(''email'', ''Email'', ''required|is_unique[users.email]'') \r\n  $this->form_validation->set_rules(''email'', ''Email'', ''required|valid_email|is_unique[users.email]'') \r\n  $this->form_validation->set_rules(''email'', ''Email'', ''trim|required|valid_email'') \r\n  $this->form_validation->set_rules(''first_name'', ''lang:first_name'', ''required'') \r\n  $this->form_validation->set_rules(''options[]'', ''Options'', ''required'') \r\n  $this->form_validation->set_rules(''passconf'', ''Password Confirmation'', ''required'') \r\n  $this->form_validation->set_rules(''passconf'', ''Password Confirmation'', ''trim|required'') \r\n  $this->form_validation->set_rules(''password'', ''Password'', ''required'') \r\n  $this->form_validation->set_rules(''password'', ''Password'', ''required|matches[passconf]'') \r\n  $this->form_validation->set_rules(''password'', ''Password'', ''trim|required|matches[passconf]|md5'') \r\n  $this->form_validation->set_rules(''text'', ''text'', ''required'') \r\n  $this->form_validation->set_rules(''title'', ''Title'', ''required'') \r\n  $this->form_validation->set_rules(''username'', ''Username'', ''callback_username_check'') \r\n  $this->form_validation->set_rules(''username'', ''Username'', ''required'') \r\n  $this->form_validation->set_rules(''username'', ''Username'', ''required|min_length[5]|max_length[12]|is_unique[users.username]'') \r\n  $this->form_validation->set_rules(''username'', ''Username'', ''trim|required|min_length[5]|max_length[12]|xss_clean'') \r\n  $this->form_validation.【译者注：所有使用下列函数的表单项都必须有验证规则，规则可以为''''，或者为简单的trim函数，不可为NULL】 \r\n  $this->ftp->chmod() \r\n  $this->ftp->chmod(''/public_html/foo/bar/'', DIR_WRITE_MODE) \r\n  $this->ftp->close() \r\n  $this->ftp->connect() \r\n  $this->ftp->connect($config) \r\n  $this->ftp->delete_dir() \r\n  $this->ftp->delete_dir(''/public_html/path/to/folder/'') \r\n  $this->ftp->delete_file() \r\n  $this->ftp->download() \r\n  $this->ftp->download(''/public_html/myfile.html'', ''/local/path/to/myfile.html'', ''ascii'') \r\n  $this->ftp->list_files() \r\n  $this->ftp->list_files(''/public_html/'') \r\n  $this->ftp->mirror() \r\n  $this->ftp->mirror(''/path/to/myfolder/'', ''/public_html/myfolder/'') \r\n  $this->ftp->mkdir() \r\n  $this->ftp->mkdir(''/public_html/foo/bar/'', DIR_WRITE_MODE) \r\n  $this->ftp->move() \r\n  $this->ftp->move(''/public_html/joe/blog.html'', ''/public_html/fred/blog.html'') \r\n  $this->ftp->rename() \r\n  $this->ftp->rename(''/public_html/foo/green.html'', ''/public_html/foo/blue.html'') \r\n  $this->ftp->upload() \r\n  $this->ftp->upload(''/local/path/to/myfile.html'', ''/public_html/myfile.html'', ''ascii'', 0775) \r\n  $this->fubar->function() \r\n  $this->image_lib->clear() \r\n  $this->image_lib->crop() \r\n  $this->image_lib->display_errors() \r\n  $this->image_lib->display_errors(''&lt;p>'', ''&lt;/p>'') \r\n  $this->image_lib->initialize($config) \r\n  $this->image_lib->resize() \r\n  $this->image_lib->rotate() \r\n  $this->image_lib->watermark() \r\n  $this->input->cookie() \r\n  $this->input->cookie(''some_data'', TRUE) \r\n  $this->input->get() \r\n  $this->input->get(NULL, TRUE) \r\n  $this->input->get_post() \r\n  $this->input->get_post(''some_data'', TRUE) \r\n  $this->input->get_request_header() \r\n  $this->input->get_request_header(''some-header'', TRUE) \r\n  $this->input->get(''some_data'', TRUE) \r\n  $this->input->ip_address() \r\n  $this->input->is_ajax_request() \r\n  $this->input->is_cli_request() \r\n  $this->input->post() \r\n  $this->input->post(NULL, TRUE) \r\n  $this->input->post(''some_data'') \r\n  $this->input->post(''some_data'', TRUE) \r\n  $this->input->post(''something'') \r\n  $this->input->post(''text'') \r\n  $this->input->post(''title'') \r\n  $this->input->request_headers() \r\n  $this->input->server() \r\n  $this->input->server(''some_data'') \r\n  $this->input->set_cookie() \r\n  $this->input->set_cookie($cookie) \r\n  $this->input->set_cookie($name, $value, $expire, $domain, $path, $prefix, $secure) \r\n  $this->input->user_agent() \r\n  $this->input->valid_ip($ip) \r\n  $this->jquery->animate(target, parameters, optional speed, optional extra information) \r\n  $this->jquery->click(''#trigger'', $this->jquery->animate(''#note'', $params, normal) \r\n  $this->jquery->corner(&quot;#note&quot;, &quot;cool tl br&quot;) \r\n  $this->jquery->corner(target, corner_style) \r\n  $this->jquery->effect(''bounce'') \r\n  $this->jquery->effect([optional path] plugin name) \r\n  $this->jquery->fadeIn(target,  optional speed, optional extra information) \r\n  $this->jquery->fadeOut(target,  optional speed, optional extra information) \r\n  $this->jquery->hide(target,  optional speed, optional extra information) \r\n  $this->jquery->show(target,  optional speed, optional extra information) \r\n  $this->jquery->slideDown(target,  optional speed, optional extra information) \r\n  $this->jquery->slideToggle(target,  optional speed, optional extra information) \r\n  $this->jquery->slideUp(target,  optional speed, optional extra information) \r\n  $this->jquery->toggleClass(target, class) \r\n  $this->jquery->toggle(target) \r\n  $this->lang->line() \r\n  $this->lang->line(''invalid_selection'') \r\n  $this->lang->line(''language_key'') \r\n  $this->lang->load() \r\n  $this->lang->load(''file_name'') \r\n  $this->load->add_package_path() \r\n  $this->load->add_package_path(APPPATH.''my_app'', FALSE) \r\n  $this->load->add_package_path(APPPATH.''my_app'', TRUE) \r\n  $this->load->add_package_path(APPPATH.''third_party/foo_bar/'') \r\n  $this->load->config(''file_name'') \r\n  $this->load->database() \r\n  $this->load->database($config) \r\n  $this->load->database($dsn) \r\n  $this->load->database(''group_name'') \r\n  $this->load->database(''group_one'', TRUE) \r\n  $this->load->database(''group_two'', TRUE) \r\n  $this->load->database(''options'', true/false) \r\n  $this->load->dbforge() \r\n  $this->load->dbutil() \r\n  $this->load->driver(''cache'') \r\n  $this->load->driver(''cache'', array(''adapter'' => ''apc'', ''backup'' => ''file'') \r\n  $this->load->driver(''class name'') \r\n  $this->load->driver(''some_parent'') \r\n  $this->load->file(''filepath/filename'', true/false) \r\n  $this->load->get_var() \r\n  $this->load->get_var($key) \r\n  $this->load->helper(''array'') \r\n  $this->load->helper(array(''form'', ''url'') \r\n  $this->load->helper( array(''helper1'', ''helper2'', ''helper3'') \r\n  $this->load->helper(''captcha'') \r\n  $this->load->helper(''cookie'') \r\n  $this->load->helper(''date'') \r\n  $this->load->helper(''directory'') \r\n  $this->load->helper(''download'') \r\n  $this->load->helper(''email'') \r\n  $this->load->helper(''file'') \r\n  $this->load->helper(''file_name'') \r\n  $this->load->helper(''foo'') \r\n  $this->load->helper(''form'') \r\n  $this->load->helper(''html'') \r\n  $this->load->helper(''inflector'') \r\n  $this->load->helper(''language'') \r\n  $this->load->helper(''name'') \r\n  $this->load->helper(''number'') \r\n  $this->load->helper(''path'') \r\n  $this->load->helper(''security'') \r\n  $this->load->helper(''smiley'') \r\n  $this->load->helper(''string'') \r\n  $this->load->helper(''text'') \r\n  $this->load->helper(''typography'') \r\n  $this->load->helper(''url'') \r\n  $this->load->helper(&#x27;captcha&#x27;) \r\n  $this->load->helper(''xml'') \r\n  $this->load->language (#3520) \r\n  $this->load->language(''file_name'') \r\n  $this->load->library() \r\n  $this->load->library(array(''email'', ''table'') \r\n  $this->load->library(''calendar'') \r\n  $this->load->library(''calendar'', $prefs) \r\n  $this->load->library(''class name'') \r\n  $this->load->library(''class_name'', $config, ''object name'') \r\n  $this->load->library(''email'') \r\n  $this->load->library(''email'', $config) \r\n  $this->load->library(''flavors/chocolate'') \r\n  $this->load->library(''foo_bar'') \r\n  $this->load->library(''form_validation'') \r\n  $this->load->library(''ftp'') \r\n  $this->load->library function from working in constructors.  \r\n  $this->load->library(''image_lib'', $config) \r\n  $this->load->library(''javascript'', array(''js_library_driver'' => ''scripto'', ''autoload'' => FALSE) \r\n  $this->load->library(''jquery'', FALSE) \r\n  $this->load->library(''migration'') \r\n  $this->load->library(''pagination'') \r\n  $this->load->library(''parser'') \r\n  $this->load->library(''someclass'') \r\n  $this->load->library(''Someclass'', $params) \r\n  $this->load->library(''table'') \r\n  $this->load->library(''trackback'') \r\n  $this->load->library(''typography'') \r\n  $this->load->library(''upload'', $config) \r\n  $this->load->library(''user_agent'') \r\n  $this->load->library(''validation'') \r\n  $this->load->library(''xmlrpc'') \r\n  $this->load->library(''xmlrpcs'') \r\n  $this->load->model(''Blog'') \r\n  $this->load->model(''blog/queries'') \r\n  $this->load->model(''Model_name'') \r\n  $this->load->model(''Model_name'', '''', $config) \r\n  $this->load->model(''Model_name'', ''fubar'') \r\n  $this->load->model(''Model_name'', '''', TRUE) \r\n  $this->load->model(''news_model'') \r\n  $this->load->model(''post_model'') \r\n  $this->load->plugin(''foo'') \r\n  $this->load->remove_package_path() \r\n  $this->load->remove_package_path(APPPATH.''my_app'') \r\n  $this->load->remove_package_path(APPPATH.''third_party/foo_bar/'') \r\n  $this->load->vars() \r\n  $this->load->vars($array) \r\n  $this->load->view() \r\n  $this->load->view(''blog'', $data) \r\n  $this->load->view(''blogview'') \r\n  $this->load->view(''blogview'', $data) \r\n  $this->load->view(''blogview'', $data, true) \r\n  $this->load->view(''content'') \r\n  $this->load->view(''content'', $data) \r\n  $this->load->view(''file_name'', $data, true/false) \r\n  $this->load->view(''folder_name/file_name'') \r\n  $this->load->view(''footer'') \r\n  $this->load->view(''formsuccess'') \r\n  $this->load->view(''header'') \r\n  $this->load->view(''header'',$data) \r\n  $this->load->view(''iphone/home'') \r\n  $this->load->view(''menu'') \r\n  $this->load->view(''mobile/home'') \r\n  $this->load->view(''my_app_index'') \r\n  $this->load->view(''myfile'', '''', true) \r\n  $this->load->view(''myform'') \r\n  $this->load->view(''my_view'', $object) \r\n  $this->load->view(''name'') \r\n  $this->load->view(''news/create'') \r\n  $this->load->view(''news/index'', $data) \r\n  $this->load->view(''news/success'') \r\n  $this->load->view(''news/view'', $data) \r\n  $this->load->view(''pages/''.$page, $data) \r\n  $this->load->view(''smiley_view'', $data) \r\n  $this->load->view(''templates/footer'') \r\n  $this->load->view(''templates/footer'', $data) \r\n  $this->load->view(''templates/header'', $data) \r\n  $this->load->view(''upload_form'', array(''error'' => '' '' ) \r\n  $this->load->view(''upload_form'', $error) \r\n  $this->load->view(''upload_success'', $data) \r\n  $this->load->view(''web/home'') \r\n  $this->load->view(''welcome_message'') \r\n  $this->load->view。如果有多个调用，那么他们将会被合并到一起。例如，你可能希望有一个标题视图、一个菜单视图、一个内容视图、和一个页脚视图。他们看起来应该是这样： \r\n  $this->$method() \r\n  $this->migrate->current() \r\n  $this->migration->current() \r\n  $this->migration->error_string() \r\n  $this->migration->latest() \r\n  $this->migration->version() \r\n  $this->migration->version(5) \r\n  $this->Model_name->function() \r\n  $this->my_session \r\n  $this->news_model->get_news() \r\n  $this->news_model->get_news($slug) \r\n  $this->news_model->set_news() \r\n  $this->output->append_output() \r\n  $this->output->append_output($data) \r\n  $this->output<br/> \r\n  $this->output->cache() \r\n  $this->output->cache_expiration > 0) \r\n  $this->output->cache(n) \r\n  $this->output->enable_profiler() \r\n  $this->output->enable_profiler(FALSE) \r\n  $this->output->enable_profiler(TRUE) \r\n  $this->output->get_output() \r\n  $this->output->set_content_type() \r\n  $this->output->set_header() \r\n  $this->output->set_header("Cache-Control: no-store, no-cache, must-revalidate") \r\n  $this->output->set_header("Cache-Control: post-check=0, pre-check=0") \r\n  $this->output->set_header("HTTP/1.0 200 OK") \r\n  $this->output->set_header("HTTP/1.1 200 OK") \r\n  $this->output->set_header(''Last-Modified: ''.gmdate(''D, d M Y H:i:s'', $last_update) \r\n  $this->output->set_header("Pragma: no-cache") \r\n  $this->output->set_output() \r\n  $this->output->set_output($data) \r\n  $this->output->set_profiler_sections() \r\n  $this->output->set_profiler_sections($sections) \r\n  $this->output->set_status_header(''401'') \r\n  $this->output->_write_cache($output) \r\n  $this->pagination->create_links() \r\n  $this->pagination->initialize($config) \r\n  $this->parser->parse() \r\n  $this->parser->parse(''blog_template'', $data) \r\n  $this->parser->parse(''blog_template'', $data, TRUE) \r\n  $this->parser->parse_string() \r\n  $this->post_model->update(elements(array(''id'', ''title'', ''content'') \r\n  $this->security->sanitize_filename() \r\n  $this->security->sanitize_filename($this->input->post(''filename'') \r\n  $this->security->xss_clean() \r\n  $this->security->xss_clean($data) \r\n  $this->security->xss_clean($file, TRUE) \r\n  $this->session->all_userdata() \r\n  $this->session->flashdata(''item'') \r\n  $this->session->keep_flashdata(''item'') \r\n  $this->session->sess_destroy() \r\n  $this->session->set_flashdata(''item'', ''value'') \r\n  $this->session->set_userdata($array) \r\n  $this->session->set_userdata($newdata) \r\n  $this->session->set_userdata(''some_name'', ''some_value'') \r\n  $this->session->unset_userdata($array_items) \r\n  $this->session->unset_userdata(''some_name'') \r\n  $this->session->userdata(''session_id'') \r\n  $this->someclass->some_function() \r\n  $this->some_parent->child_one->some_method() \r\n  $this->some_parent->child_two->another_method() \r\n  $this->some_parent->some_method() \r\n  $this->table->add_row() \r\n  $this->table->add_row(array(''Blue'', ''Red'', ''Green'') \r\n  $this->table->add_row(array(''Fred'', ''Blue'', ''Small'') \r\n  $this->table->add_row(array(''John'', ''Green'', ''Medium'') \r\n  $this->table->add_row(array(''Mary'', ''Red'', ''Large'') \r\n  $this->table->add_row(''Blue'', ''Red'', ''Green'') \r\n  $this->table->add_row($cell, ''Red'', ''Green'') \r\n  $this->table->add_row(''Fred'', ''Blue'', ''Small'') \r\n  $this->table->add_row(''Fred'', ''&lt;strong>Blue&lt;/strong>'', ''Small'') \r\n  $this->table->add_row(''Fred'', ''Wednesday'', ''Express'') \r\n  $this->table->add_row(''John'', ''Green'', ''Medium'') \r\n  $this->table->add_row(''John'', ''Saturday'', ''Overnight'') \r\n  $this->table->add_row(''Mary'', ''Monday'', ''Air'') \r\n  $this->table->add_row(''Mary'', ''Red'', ''Large'') \r\n  $this->table->clear() \r\n  $this->table->function \r\n  $this->table->function = ''htmlspecialchars'';<br /> \r\n  $this->table->generate() \r\n  $this->table->generate($col_array) \r\n  $this->table->generate($data) \r\n  $this->table->generate($new_list) \r\n  $this->table->generate($query) \r\n  $this->table->make_columns() \r\n  $this->table->make_columns($image_array, 8) \r\n  $this->table->make_columns($list, 3) \r\n  $this->table->set_caption() \r\n  $this->table->set_caption(''Colors'') \r\n  $this->table->set_empty() \r\n  $this->table->set_empty("&amp;nbsp;") \r\n  $this->table->set_heading() \r\n  $this->table->set_heading(array(''Name'', ''Color'', ''Size'') \r\n  $this->table->set_heading(''Name'', ''Color'', ''Size'') \r\n  $this->table->set_heading(''Name'', ''Day'', ''Delivery'') \r\n  $this->table->set_template() \r\n  $this->table->set_template($tmpl) \r\n  $this->title = $_POST[''title''];<br /> \r\n  $this->title = $_POST[''title'']; \n  $this->total_segment() \r\n  $this->total_segments() \r\n  $this->trackback->data(''blog_name'') \r\n  $this->trackback->data(''excerpt'') \r\n  $this->trackback->data(''item'') \r\n  $this->trackback->data(''title'') \r\n  $this->trackback->data(''url'') \r\n  $this->trackback->display_errors() \r\n  $this->trackback->receive() \r\n  $this->trackback->send_error("The Trackback did not contain valid data") \r\n  $this->trackback->send_error("Unable to determine the entry ID") \r\n  $this->trackback->send_success() \r\n  $this->trackback->send($tb_data) \r\n  $this->typography->auto_typography($string, FALSE) \r\n  $this->typography->format_characters($string) \r\n  $this->typography->nl2br_except_pre($string) \r\n  $this->typography->protect_braced_quotes = TRUE; \r\n  $this->unit->active(FALSE) \r\n  $this->unit->report() \r\n  $this->unit->result() \r\n  $this->unit->run(1, TRUE) \r\n  $this->unit->run(''Foo'', ''Foo'') \r\n  $this->unit->run(''Foo'', ''is_string'') \r\n  $this->unit->run($test, $expected_result) \r\n  $this->unit->run($test, $expected_result, $test_name) \r\n  $this->unit->run( test, expected result, ''test name'', ''notes'') \r\n  $this->unit->set_items() \r\n  $this->unit->set_template($str) \r\n  $this->unit->set_test_items() \r\n  $this->unit->set_test_items(array(''test_name'', ''result'') \r\n  $this->unit->use_strict(TRUE) \r\n  $this->upload->data() \r\n  $this->upload->display_errors() \r\n  $this->upload->display_errors(''&lt;p>'', ''&lt;/p>'') \r\n  $this->upload->do_upload() \r\n  $this->upload->do_upload($field_name) \r\n  $this->upload->initialize($config) \r\n  $this->uri->assoc_to_uri() \r\n  $this->uri->assoc_to_uri($array) \r\n  $this->uri->rsegment_array() \r\n  $this->uri->rsegment(n) \r\n  $this->uri->ruri_string() \r\n  $this->uri->ruri_to_assoc(n) \r\n  $this->uri->segment() \r\n  $this->uri->segment(3) \r\n  $this->uri->segment(3, 0) \r\n  $this->uri->segment(4) \r\n  $this->uri->segment_array() \r\n  $this->uri->segment(n) \r\n  $this->uri->slash_rsegment(n) \r\n  $this->uri->slash_segment(3) \r\n  $this->uri->slash_segment(3, ''both'') \r\n  $this->uri->slash_segment(3, ''leading'') \r\n  $this->uri->slash_segment(n) \r\n  $this->uri->total_rsegments() \r\n  $this->uri->total_segments() \r\n  $this->uri->uri_string() \r\n  $this->uri->uri_to_assoc(3) \r\n  $this->uri->uri_to_assoc(3, $default) \r\n  $this->uri->uri_to_assoc(n) \r\n  $this->validation->error_string; ?> \r\n  $this->validation->run() \r\n  $this->validation->set_checkbox(''mycheck'', ''1'') \r\n  $this->validation->set_error_delimiters(''&lt;div class="error">'', ''&lt;/div>'') \r\n  $this->validation->set_fields($fields) \r\n  $this->validation->set_message(''rule'', ''Error Message'') \r\n  $this->validation->set_message(''username_check'', ''The %s field can not be the word "test"'') \r\n  $this->validation->set_radio(''myradio'', ''1'') \r\n  $this->validation->set_rules($rules) \r\n  $this->validation->set_select(''myselect'', ''one'') \r\n  $this->validation->set_select(''myselect'', ''three'') \r\n  $this->validation->set_select(''myselect'', ''two'') \r\n  $this->xmlrpc->display_error() \r\n  $this->xmlrpc->display_response() \r\n  $this->xmlrpc->method() \r\n  $this->xmlrpc->method(''Greetings'') \r\n  $this->xmlrpc->method(''method'') \r\n  $this->xmlrpc->method(''weblogUpdates.ping'') \r\n  $this->xmlrpc->request() \r\n  $this->xmlrpc->request($request) \r\n  $this->xmlrpc->send_error_message() \r\n  $this->xmlrpc->send_error_message(''100'',''InvalidAccess'') \r\n  $this->xmlrpc->send_error_message(''123'', ''Requested data not available'') \r\n  $this->xmlrpc->send_request() \r\n  $this->xmlrpc->send_response() \r\n  $this->xmlrpc->send_response($response) \r\n  $this->xmlrpc->server() \r\n  $this->xmlrpc->server(''http://rpc.pingomatic.com/'', 80) \r\n  $this->xmlrpc->server(''http://www.sometimes.com/pings.php'', 80) \r\n  $this->xmlrpc->server($server_url, 80) \r\n  $this->xmlrpc->set_debug(TRUE) \r\n  $this->xmlrpcs->initialize($config) \r\n  $this->xmlrpcs->serve() \r\n  $this->xmlrpc->timeout() \r\n  $this->xmlrpc->timeout(6) \r\n  $this->zip->add_data() \r\n  $this->zip->add_data($data) \r\n  $this->zip->add_data($name, $data) \r\n  $this->zip->add_dir() \r\n  $this->zip->add_dir(''myfolder'') \r\n  $this->zip->archive() \r\n  $this->zip->archive(''/path/to/directory/my_backup.zip'') \r\n  $this->zip->archive(''/path/to/folder/myarchive.zip'') \r\n  $this->zip->clear_data() \r\n  $this->zip->download() \r\n  $this->zip->download(''latest_stuff.zip'') \r\n  $this->zip->download(''my_backup.zip'') \r\n  $this->zip->download(''myphotos.zip'') \r\n  $this->zip->get_zip() \r\n  $this->zip->read_dir() \r\n  $this->zip->read_dir($path) \r\n  $this->zip->read_dir($path, FALSE) \r\n  $this->zip->read_dir(''/path/to/directory'', FALSE) \r\n  $this->zip->read_file() \r\n  $this->zip->read_file($path); \r\n  $this->zip->read_file("/path/to/photo.jpg"); // 读取文件内容<br /> \r\n  $this->zip->read_file($path, TRUE);\n', ''),
(16, 'nginx', 'user  nginx;\r\nworker_processes 4;\r\n\r\nerror_log  /var/log/nginx/error.log warn;\r\n#error_log  /var/log/nginx/nginx_error.log debug;\r\n\r\npid        /var/run/nginx.pid;\r\n\r\n#Specifies the value for maximum file descriptors that can be opened by this process. \r\nworker_rlimit_nofile 65535;\r\n\r\nevents \r\n{\r\n  use epoll;\r\n  worker_connections 65535;\r\n}\r\n\r\nhttp \r\n{\r\n  include       /etc/nginx/mime.types;\r\n  default_type  application/octet-stream;\r\n\r\n  log_format  main  ''$remote_addr - $remote_user [$time_local] "$request" ''\r\n                      ''$status $body_bytes_sent "$http_referer" ''\r\n                      ''"$http_user_agent" "$http_x_forwarded_for"'';\r\n\r\n  access_log  /var/log/nginx/access.log  main;\r\n  #docs attack\r\n  #limit_zone one  $binary_remote_addr  10m;\r\n  #limit_req_zone  $binary_remote_addr  zone=req_one:10m rate=1r/s;\r\n  #docs attack\r\n\r\n  #charset  gb2312;\r\n  charset  utf-8;\r\n      \r\n  server_names_hash_bucket_size 128;\r\n  client_header_buffer_size 32k;\r\n  large_client_header_buffers 4 32k;\r\n  client_max_body_size 8m;\r\n      \r\n  sendfile on;\r\n  tcp_nopush     on;\r\n\r\n  keepalive_timeout 60;\r\n\r\n  tcp_nodelay on;\r\n\r\n  fastcgi_connect_timeout 400;\r\n  fastcgi_send_timeout 400;\r\n  fastcgi_read_timeout 400;\r\n  fastcgi_buffer_size 128k;\r\n  fastcgi_buffers 2 256k;\r\n  fastcgi_busy_buffers_size 256k;\r\n  fastcgi_temp_file_write_size 256k;\r\n\r\n  gzip on;\r\n  gzip_min_length  1k;\r\n  gzip_buffers     4 16k;\r\n  gzip_http_version 1.0;\r\n  gzip_comp_level 2;\r\n  gzip_types       text/plain application/x-javascript text/css application/xml;\r\n  gzip_vary on;\r\n\r\n  #limit_zone  crawler  $binary_remote_addr  10m;\r\n \r\n   include /etc/nginx/conf.d/*.conf;\r\n  \r\n}\r\n\r\n\r\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(24, 'python', '\npython 例用简介\r\n1 序言 \r\n      思路:用shell编程.(Linux通常是bash而Windows是批处理脚本).例如,在Windows上用ping ip 的命令依次测试各个机器并得到控制台输出.由于ping通的时候控制台文本通常是"Reply from ... " 而不通的时候文本是"time out ... " ,所以,在结果中进行字符串查找,即可知道该机器是否连通.  \r\n   \r\n      实现:Java代码如下: \r\n  String cmd="cmd.exe ping "; \r\n  String ipprefix="192.168.10."; \r\n  int begin=101; \r\n  int end=200; \r\n  Process p=null; \r\n   \r\n  for(int i=begin;i<end;i++){ \r\n       p= Runtime.getRuntime().exec(cmd+i); \r\n       String line = null; \r\n       BufferedReader reader = new BufferedReader(new InputStreamReader(p.getInputStream())); \r\n       while((line = reader.readLine()) != null) \r\n       { \r\n           \n       } \r\n      reader.close(); \r\n      p.destroy(); \r\n  } \r\n   \r\n      这段代码运行得很好,问题是为了运行这段代码,你还需要做一些额外的工作.这些额外的工作包括: \r\n  编写一个类文件 \r\n  编写一个main方法 \r\n  将之编译成字节代码 \r\n  由于字节代码不能直接运行,你需要再写个小小的bat或者bash脚本来运行.  \r\n      当然,用C/C++同样能完成这项工作.但C/C++不是跨平台语言.在这个足够简单的例子中也许看不出C/C++和Java实现的区别,但在一些更为复杂的场景,比如要将连通与否的信息记录到网络数据库.由于Linux和Windows的网络接口实现方式不同,你不得不写两个函数的版本.用Java就没有这样的顾虑.  \r\n   \r\n      同样的工作用Python实现如下: \r\n   \r\n   \r\n  import subprocess \r\n   \r\n  cmd="cmd.exe" \r\n  begin=101 \r\n  end=200 \r\n  while begin<end: \r\n      \r\n      p=subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE, \r\n                     stdin=subprocess.PIPE, \r\n                     stderr=subprocess.PIPE) \r\n      p.stdin.write("ping 192.168.1."+str(begin)+"\r\n") \r\n   \r\n      p.stdin.close() \r\n      p.wait() \r\n      \r\n      print "execution result: %s"%p.stdout.read() \r\n   \r\n      对比Java,Python的实现更为简洁,你编写的时间更快.你不需要写main函数,并且这个程序保存之后可以直接运行.另外,和Java一样,Python也是跨平台的.  \r\n   \r\n      有经验的C/Java程序员可能会争论说用C/Java写会比Python写得快.这个观点见仁见智.我的想法是当你同时掌握Java和Python之后,你会发现用Python写这类程序的速度会比Java快上许多.例如操作本地文件时你仅需要一行代码而不需要Java的许多流包装类.各种语言有其天然的适合的应用范围.用Python处理一些简短程序类似与操作系统的交互编程工作最省时省力.  \r\n   \r\n  Python应用场合 \r\n   \r\n      足够简单的任务,例如一些shell编程.如果你喜欢用Python设计大型商业网站或者设计复杂的游戏,悉听尊便.  \r\n   \r\n  2 快速入门 \r\n  2.1 Hello world \r\n   \r\n      安装完Python之后(我本机的版本是2.5.4),打开IDLE(Python GUI) , 该程序是Python语言解释器,你写的语句能够立即运行.我们写下一句著名的程序语句: \r\n   \r\n  print "Hello,world!" \r\n   \r\n      并按回车.你就能看到这句被K&R引入到程序世界的名言.  \r\n   \r\n      在解释器中选择"File"--"New Window" 或快捷键 Ctrl+N , 打开一个新的编辑器.写下如下语句: \r\n  print "Hello,world!" \r\n  raw_input("Press enter key to close this window"); \r\n   \r\n      保存为a.py文件.按F5,你就可以看到程序的运行结果了.这是Python的第二种运行方式.  \r\n   \r\n      找到你保存的a.py文件,双击.也可以看到程序结果.Python的程序能够直接运行,对比Java,这是一个优势.  \r\n   \r\n  2.2 国际化支持 \r\n   \r\n      我们换一种方式来问候世界.新建一个编辑器并写如下代码: \r\n  print "欢迎来到奥运中国!" \r\n  raw_input("Press enter key to close this window"); \r\n   \r\n      在你保存代码的时候,Python会提示你是否改变文件的字符集,结果如下: \r\n  # -*- coding: cp936 -*- \r\n   \r\n  print "欢迎来到奥运中国!" \r\n  raw_input("Press enter key to close this window"); \r\n   \r\n      将该字符集改为我们更熟悉的形式: \r\n  # -*- coding: GBK -*- \r\n   \r\n  print "欢迎来到奥运中国!" # 使用中文的例子 \r\n  raw_input("Press enter key to close this window"); \r\n   \r\n      程序一样运行良好.  \r\n  2.3 方便易用的计算器 \r\n   \r\n      用微软附带的计算器来计数实在太麻烦了.打开Python解释器,直接进行计算: \r\n  a=100.0 \r\n  b=201.1 \r\n  c=2343 \r\n  print (a+b+c)/c \r\n   \r\n  2.4 字符串,ASCII和UNICODE \r\n   \r\n   \r\n      可以如下打印出预定义输出格式的字符串: \r\n  print """ \r\n  Usage: thingy [OPTIONS] \r\n       -h                        Display this usage message \r\n       -H hostname               Hostname to connect to \r\n  """ \r\n   \r\n      字符串是怎么访问的?请看这个例子: \r\n  word="abcdefg" \r\n  a=word[2] \r\n  print "a is: "+a \r\n  b=word[1:3] \r\n  print "b is: "+b # index 1 and 2 elements of word.  \r\n  c=word[:2] \r\n  print "c is: "+c # index 0 and 1 elements of word.  \r\n  d=word[0:] \r\n  print "d is: "+d # All elements of word.  \r\n  e=word[:2]+word[2:] \r\n  print "e is: "+e # All elements of word.  \r\n  f=word[-1] \r\n  print "f is: "+f # The last elements of word.  \r\n  g=word[-4:-2] \r\n  print "g is: "+g # index 3 and 4 elements of word.  \r\n  h=word[-2:] \r\n  print "h is: "+h # The last two elements.  \r\n  i=word[:-2] \r\n  print "i is: "+i # Everything except the last two characters \r\n  l=len(word) \r\n  print "Length of word is: "+ str(l) \r\n   \r\n      请注意ASCII和UNICODE字符串的区别: \r\n  print "Input your Chinese name:" \r\n  s=raw_input("Press enter to be continued"); \r\n  print "Your name is  : " +s; \r\n  l=len(s) \r\n  print "Length of your Chinese name in asc codes is:"+str(l); \r\n  a=unicode(s,"GBK") \r\n  l=len(a) \r\n  print "I''m sorry we should use unicode char!Characters number of your Chinese \\ \r\n  name in unicode is:"+str(l); \r\n   \r\n  2.5 使用List \r\n   \r\n      类似Java里的List,这是一种方便易用的数据类型: \r\n   \r\n  word=[''a'',''b'',''c'',''d'',''e'',''f'',''g''] \r\n  a=word[2] \r\n  print "a is: "+a \r\n  b=word[1:3] \r\n  print "b is: " \r\n  print b # index 1 and 2 elements of word.  \r\n  c=word[:2] \r\n  print "c is: " \r\n  print c # index 0 and 1 elements of word.  \r\n  d=word[0:] \r\n  print "d is: " \r\n  print d # All elements of word.  \r\n  e=word[:2]+word[2:] \r\n  print "e is: " \r\n  print e # All elements of word.  \r\n  f=word[-1] \r\n  print "f is: " \r\n  print f # The last elements of word.  \r\n  g=word[-4:-2] \r\n  print "g is: " \r\n  print g # index 3 and 4 elements of word.  \r\n  h=word[-2:] \r\n  print "h is: " \r\n  print h # The last two elements.  \r\n  i=word[:-2] \r\n  print "i is: " \r\n  print i # Everything except the last two characters \r\n  l=len(word) \r\n  print "Length of word is: "+ str(l) \r\n  print "Adds new element" \r\n  word.append(''h'') \r\n  print word \r\n   \r\n  2.6 条件和循环语句 \r\n   \r\n  # Multi-way decision \r\n  x=int(raw_input("Please enter an integer:")) \r\n  if x<0: \r\n      x=0 \r\n      print "Negative changed to zero" \r\n   \r\n  elif x==0: \r\n      print "Zero" \r\n   \r\n  else: \r\n      print "More" \r\n   \r\n   \r\n  # Loops List \r\n  a = [''cat'', ''window'', ''defenestrate''] \r\n  for x in a: \r\n      print x, len(x) \r\n   \r\n  2.7 如何定义函数 \r\n   \r\n  # Define and invoke function.  \r\n  def sum(a,b): \r\n      return a+b \r\n   \r\n   \r\n  func = sum \r\n  r = func(5,6) \r\n  print r \r\n   \r\n  # Defines function with default argument \r\n  def add(a,b=2): \r\n      return a+b \r\n  r=add(1) \r\n  print r \r\n  r=add(1,5) \r\n  print r \r\n   \r\n      并且,介绍一个方便好用的函数: \r\n  # The range() function \r\n  a =range(5,10) \r\n  print a \r\n  a = range(-2,-7) \r\n  print a \r\n  a = range(-7,-2) \r\n  print a \r\n  a = range(-2,-11,-3) # The 3rd parameter stands for step \r\n  print a \r\n   \r\n  2.8 文件I/O \r\n   \r\n  spath="D:/download/baa.txt" \r\n  f=open(spath,"w") # Opens file for writing.Creates this file doesn''t exist.  \r\n  f.write("First line 1.\r\n") \r\n  f.writelines("First line 2.") \r\n   \r\n  f.close() \r\n   \r\n  f=open(spath,"r") # Opens file for reading \r\n   \r\n  for line in f: \r\n      print line \r\n   \r\n  f.close() \r\n   \r\n  2.9 异常处理 \r\n   \r\n   \r\n  s=raw_input("Input your age:") \r\n  if s =="": \r\n      raise Exception("Input must no be empty.") \r\n   \r\n  try: \r\n      i=int(s) \r\n  except ValueError: \r\n      print "Could not convert data to an integer." \r\n  except: \r\n      print "Unknown exception!" \r\n  else: # It is useful for code that must be executed if the try clause does not raise an exception \r\n      print "You are %d" % i," years old" \r\n  finally: # Clean up action \r\n      print "Goodbye!" \r\n   \r\n   \r\n  2.10 类和继承 \r\n   \r\n  class Base: \r\n      def __init__(self): \r\n          self.data = [] \r\n      def add(self, x): \r\n          self.data.append(x) \r\n      def addtwice(self, x): \r\n          self.add(x) \r\n          self.add(x) \r\n   \r\n  # Child extends Base \r\n  class Child(Base): \r\n      def plus(self,a,b): \r\n          return a+b \r\n   \r\n  oChild =Child() \r\n  oChild.add("str1") \r\n  print oChild.data \r\n  print oChild.plus(2,3) \r\n   \r\n   \r\n  2.11 包机制 \r\n   \r\n      每一个.py文件称为一个module,module之间可以互相导入.请参看以下例子: \r\n  # a.py \r\n  def add_func(a,b): \r\n      return a+b \r\n   \r\n  # b.py \r\n  from a import add_func # Also can be : import a \r\n   \r\n  print "Import add_func from module a" \r\n  print "Result of 1 plus 2 is: " \r\n  print add_func(1,2)    # If using "import a" , then here should be "a.add_func" \r\n   \r\n   \r\n      module可以定义在包里面.Python定义包的方式稍微有点古怪,假设我们有一个parent文件夹,该文件夹有一个child子文件夹.child中有一个module a.py . 如何让Python知道这个文件层次结构?很简单,每个目录都放一个名为_init_.py 的文件.该文件内容可以为空.这个层次结构如下所示: \r\n  parent \r\n    --__init_.py \r\n    --child \r\n      -- __init_.py \r\n      --a.py \r\n   \r\n  b.py \r\n   \r\n      那么Python如何找到我们定义的module?在标准包sys中,path属性记录了Python的包路径.你可以将之打印出来: \r\n  import sys \r\n   \r\n  print sys.path \r\n   \r\n      通常我们可以将module的包路径放到环境变量PYTHONPATH中,该环境变量会自动添加到sys.path属性.另一种方便的方法是编程中直接指定我们的module路径到sys.path 中: \r\n  import sys \r\n  sys.path.append(''D:\\\\download'') \r\n   \r\n  from parent.child.a import add_func \r\n   \r\n   \r\n  print sys.path \r\n   \r\n  print "Import add_func from module a" \r\n  print "Result of 1 plus 2 is: " \r\n  print add_func(1,2) \r\n   \r\n   \r\n  总结 \r\n      你会发现这个教程相当的简单.许多Python特性在代码中以隐含方式提出,这些特性包括:Python不需要显式声明数据类型,关键字说明,字符串函数的解释等等.我认为一个熟练的程序员应该对这些概念相当了解,这样在你挤出宝贵的一小时阅读这篇短短的教程之后,你能够通过已有知识的迁移类比尽快熟悉Python,然后尽快能用它开始编程.  \r\n   \r\n      当然,1小时学会Python颇有哗众取宠之嫌.确切的说,编程语言包括语法和标准库.语法相当于武术招式,而标准库应用实践经验则类似于内功,需要长期锻炼.Python学习了Java的长处,提供了大量极方便易用的标准库供程序员"拿来主义".(这也是Python成功的原因),在开篇我们看到了Python如何调用Windows cmd的例子,以后我会尽量写上各标准库的用法和一些应用技巧,让大家真正掌握Python.  \r\n   \r\n      但不管怎样,至少你现在会用Python代替繁琐的批处理写程序了.希望那些真的能在一小时内读完本文并开始使用Python的程序员会喜欢这篇小文章,谢谢!\npythonmodule python模块 \r\n  1）  python运行时服务 \r\n   \r\n    * copy： copy模块提供了对复合（compound）对象（list，tuple，dict，custom class）进行浅拷贝和深拷贝的功能。 \r\n   \r\n    * pickle： pickle模块被用来序列化python的对象到bytes流，从而适合存储到文件，网络传输，或数据库存储。（pickle的过程也被称serializing,marshalling或者flattening，pickle同时可以用来将bytes流反序列化为python的对象）。 \r\n   \r\n    * sys：sys模块包含了跟python解析器和环境相关的变量和函数。 \r\n   \r\n    * 其他： atexit，gc，inspect，marshal，traceback，types，warnings，weakref。 \r\n   \r\n     \r\n   \r\n  2）  数学 \r\n   \r\n    * decimal：python中的float使用双精度的二进制浮点编码来表示的，这种编码导致了小数不能被精确的表示，例如0.1实际上内存中为0.100000000000000001，还有3*0.1 == 0.3 为False. decimal就是为了解决类似的问题的，拥有更高的精确度，能表示更大范围的数字，更精确地四舍五入。 \r\n   \r\n    * math：math模块定义了标准的数学方法，例如cos(x),sin(x)等。 \r\n   \r\n    * random：random模块提供了各种方法用来产生随机数。 \r\n   \r\n    * 其他：fractions，numbers。 \r\n   \r\n     \r\n   \r\n  3）  数据结构，算法和代码简化 \r\n   \r\n    * array： array代表数组，类似与list，与list不同的是只能存储相同类型的对象。 \r\n   \r\n    * bisect： bisect是一个有序的list，其中内部使用二分法（bitsection）来实现大部分操作。 \r\n   \r\n    * collections：collections模块包含了一些有用的容器的高性能实现，各种容器的抽象基类，和创建name-tuple对象的函数。例如包含了容器deque，defaultdict，namedtuple等。 \r\n   \r\n    * heapq：heapq是一个使用heap实现的带有优先级的queue。 \r\n   \r\n    * itertools：itertools包含了函数用来创建有效的iterators。所有的函数都返回iterators或者函数包含iterators（例如generators 和generators expression）。 \r\n   \r\n    * operator： operator提供了访问python内置的操作和解析器提供的特殊方法，例如 x+y 为 add（x，y），x+=y为iadd（x，y），a % b 为mod（a，b）等等。 \r\n   \r\n    * 其他：abc，contextlib，functools。 \r\n   \r\n     \r\n   \r\n  4  ) string 和 text 处理 \r\n   \r\n    *codecs：codecs模块被用来处理不同的字符编码与unicode text io的转化。 \r\n   \r\n    * re：re模块用来对字符串进行正则表达式的匹配和替换。 \r\n   \r\n    * string：string模块包含大量有用的常量和函数用来处理字符串。也包含了新字符串格式的类。 \r\n   \r\n    * struct：struct模块被用来在python和二进制结构间实现转化。 \r\n   \r\n    * unicodedata：unicodedata模块提供访问unicode字符数据库 \r\n   \r\n   \r\n  5  ) python数据库访问 \r\n   \r\n    * 关系型数据库拥有共同的规范Python Database API Specification V2.0，MySQL，Oracle等都实现了此规范，然后增加自己的扩展。 \r\n   \r\n    * sqlite3: sqlite3 模块提供了SQLite数据库访问的接口。SQLite数据库是以一个文件或内存的形式存在的自包含的关系型数据库。 \r\n   \r\n    * DBM-style 数据库模块：python提供了打了的modules来支持UNIX DBM-style数据库文件。dbm模块用来读取标准的UNIX-dbm数据库文件，gdbm用来读取GNU dbm数据库文件，dbhash用来读取Berkeley DB数据库文件。所有的这些模块提供了一个对象实现了基于字符串的持久化的字典，他与字典dict非常相似，但是他的keys和values都必须是字符串。 \r\n   \r\n    * shelve：shelve模块使用特殊的“shelf”对象来支持持久化对象。这个对象的行为与dict相似，但是所有的他存储的对象都使用基于hashtable的数据库（dbhash，dbm，gdbm）存储在硬盘。与dbm模块的区别是所存储的对象不仅是字符串，而且可以是任意的与pickle兼容的对象。 \r\n   \r\n     \r\n   \r\n  6）  文件和目录处理 \r\n   \r\n    * bz2：bz2模块用来处理以bzip2压缩算法压缩的文件。 \r\n   \r\n    * filecmp：filecmp模块提供了函数来比较文件和目录。 \r\n   \r\n    * fnmatch：fnmatch模块提供了使用UNIX shell-style的通配符来匹配文件名。这个模块只是用来匹配，使用glob可以获得匹配的文件列表。 \r\n   \r\n    * glob：glob模块返回了某个目录下与指定的UNIX shell通配符匹配的所有文件。 \r\n   \r\n    * gzip：gzip模块提供了类GzipFile，用来执行与GNUgzip程序兼容的文件的读写。 \r\n   \r\n    * shutil： shutil模块用来执行更高级别的文件操作，例如拷贝，删除，改名。shutil操作之针对一般的文件，不支持pipes，block devices等文件类型。 \r\n   \r\n    * tarfile： tarfile模块用来维护tar存档文件。tar没有压缩的功能。 \r\n   \r\n    * tempfile：tempfile模块用来产生临时文件和文件名。 \r\n   \r\n    * zipfile： zipfile模块用来处理zip格式的文件。 \r\n   \r\n    * zlib，zlib模块提供了对zlib库的压缩功能的访问。 \r\n   \r\n     \r\n   \r\n  7）  操作系统的服务 \r\n   \r\n    * cmmands： commands模块被用来执行简单的系统命令，命令以字符串的形式传入，且同时以字符串的形式返回命令的输出。但是此模块只在UNIX系统上可用。 \r\n   \r\n    * configParser，configParser模块用来读写windows的ini格式的配置文件。 \r\n   \r\n    * datetime，datetime模块提供了各种类型来表示和处理日期和时间。 \r\n   \r\n    * errno， 定义了所有的errorcode对应的符号名字。 \r\n   \r\n    * io，io模块实现了各种IO形式和内置的open()函数。 \r\n   \r\n    * logging， logging模块灵活方便地对应用程序记录events，errors，warnings，和debuging 信息。这些log信息可以被收集，过滤，写到文件或系统log，甚至通过网络发送到远程的机器上。 \r\n   \r\n    *mmap，mmap模块提供了内存映射文件对象的支持，使用内存映射文件与使用一般的文件或byte字符串相似。 \r\n   \r\n    *msvcrt，mscrt只可以在windows系统使用，用来访问Visual C运行时库的很多有用的功能。 \r\n   \r\n    *optparse，optparse模块更高级别来处理UNIX style的命令行选项sys.argv。 \r\n   \r\n    * os，os模块对通用的操作系统服务提供了可移植的（portable）的接口。os可以认为是nt和posix的抽象。nt提供windows的服务接口，posix提供UNIX（linux，mac）的服务接口。 \r\n   \r\n    * os.path，os.path模块以可移植的方式来处理路径相关的操作。 \r\n   \r\n    * signal，signal模块用来实现信号（signal）处理，往往跟同步有关。 \r\n   \r\n    * subprocess，subprocess模块包含了函数和对象来统一创建新进程，控制新进程的输入输出流，处理进程的返回。 \r\n   \r\n    * time，time模块提供了各种时间相关的函数。常用的time.sleep().  \r\n   \r\n    * winreg, winreg模块用来操作windows注册表。 \r\n   \r\n    * 其他：fcntl。 \r\n   \r\n     \r\n   \r\n  8）  线程和并行 \r\n   \r\n    * multiprocessing，multiprocessing模块提供通过subprocess来加载多个任务，通信，共享数据，执行各种同步操作。 \r\n   \r\n    * threading，threading模块提供了thread类很很多的同步方法来实现多线程编程。 \r\n   \r\n    * queue，queue模块实现了各种多生产者，多消费者队列，被用来实现多线程程序的信息安全交换。 \r\n   \r\n    * 其他：Coroutines and Microthreading。 \r\n   \r\n     \r\n   \r\n  9）  网络编程和套接字（sockets） \r\n   \r\n    * asynchat，asynchat模块通过封装asyncore来简化了应用程序的网络异步处理。 \r\n   \r\n    * ssl，ssl模块被用来使用secure sockets layer（SSL）包装socket对象，从而使得实现数据加密和终端认证。python使用openssl来实现此模块。 \r\n   \r\n    * socketserver，socketserver模块提供了类型简化了TCP，UDP和UNIX领域的socket server的实现。 \r\n   \r\n    * 其他：asyncore，select。 \r\n   \r\n     \r\n   \r\n  10）internet应用程序编程 \r\n   \r\n    * ftplib，ftplib模块实现了ftp的client端协议。此模块很少使用，因为urllib提供了更高级的接口。 \r\n   \r\n    * http包，包含了http client和server的实现和cookies管理的模块。 \r\n   \r\n    * smtplib，smtplib包含了smtp client的底层接口，用来使用smtp协议发送邮件。 \r\n   \r\n    * urllib，urllib包提供了高级的接口来实现与http server，ftp server和本地文件交互的client。 \r\n   \r\n    * xmlrpc，xmlrpc模块被用类实现XML-RPC client。 \r\n   \r\n     \r\n   \r\n  11）  web 编程 \r\n   \r\n    * cgi，cgi模块用来实现cgi脚本，cgi程序一般地被webserver执行，用来处理用户在form中的输入，或生成一些动态的内容。当与cgi脚本有管的request被提交，webserver将cgi作为子进程执行，cgi程序通过sys.stdin或环境变量来获得输入，通过sys.stdout来输出。 \r\n   \r\n    * webbrowser，webbrowser模块提供了平台独立的工具函数来使用web browser打开文档。 \r\n   \r\n    * 其他：wsgiref/WSGI (Python Web Server Gateway Interface).  \r\n      \r\n   \r\n  12  ) internet 数据处理和编码 \r\n   \r\n    * base64，base64模块提供了base64，base32，base16编码方式，用来实现二进制与文本间的编码和解码。base64通常用来对编码二进制数据，从而嵌入到邮件或http协议中。 \r\n   \r\n    * binascii，binascii模块提供了低级的接口来实现二进制和各种ASCII编码的转化。 \r\n   \r\n    * csv，csv模块用来读写comma-separated values（CSV）文件。 \r\n   \r\n    * email，email包提供了大量的函数和对象来使用MIME标准来表示，解析和维护email消息。 \r\n   \r\n    * hashlib，hashlib模块实现了各种secure hash和message digest algorithms，例如MD5和SHA1。 \r\n   \r\n    * htmlparser（html.parser），此模块定义了HTMLParser来解析HTML和XHTML文档。使用此类，需要定义自己的类且继承于HTMLParser。 \r\n   \r\n    * json，json模块被用类序列化或饭序列化Javascript object notation（JSON）对象。 \r\n   \r\n    * xml,xml包提供了各种处理xml的方法。\npythonfunction python函数 \r\n  1.常用内置函数：(不用import就可以直接使用)  \r\n      help(obj) 在线帮助, obj可是任何类型 \r\n      callable(obj) 查看一个obj是不是可以像函数一样调用 \r\n      repr(obj) 得到obj的表示字符串，可以利用这个字符串eval重建该对象的一个拷贝 \r\n      eval_r(str) 表示合法的python表达式，返回这个表达式 \r\n      dir(obj) 查看obj的name space中可见的name \r\n      hasattr(obj,name) 查看一个obj的name space中是否有name \r\n      getattr(obj,name) 得到一个obj的name space中的一个name \r\n      setattr(obj,name,value) 为一个obj的name space中的一个name指向vale这个object \r\n      delattr(obj,name) 从obj的name space中删除一个name \r\n      vars(obj) 返回一个object的name space。用dictionary表示 \r\n      locals() 返回一个局部name space,用dictionary表示 \r\n      globals() 返回一个全局name space,用dictionary表示 \r\n      type(obj) 查看一个obj的类型 \r\n      isinstance(obj,cls) 查看obj是不是cls的instance \r\n      issubclass(subcls,supcls) 查看subcls是不是supcls的子类 \r\n      \r\n    类型转换函数 \r\n      chr(i) 把一个ASCII数值,变成字符 \r\n      ord(i) 把一个字符或者unicode字符,变成ASCII数值 \r\n      oct(x) 把整数x变成八进制表示的字符串 \r\n      hex(x) 把整数x变成十六进制表示的字符串 \r\n      str(obj) 得到obj的字符串描述 \r\n      list(seq) 把一个sequence转换成一个list \r\n      tuple(seq) 把一个sequence转换成一个tuple \r\n      dict(),dict(list) 转换成一个dictionary \r\n      int(x) 转换成一个integer \r\n      long(x) 转换成一个long interger \r\n      float(x) 转换成一个浮点数 \r\n      complex(x) 转换成复数 \r\n      max(...) 求最大值 \r\n      min(...) 求最小值 \r\n    用于执行程序的内置函数 \r\n      complie 如果一段代码经常要使用,那么先编译,再运行会更快。 \r\n      \r\n  2.和操作系统相关的调用 \r\n    系统相关的信息模块 import sys \r\n      sys.argv是一个list,包含所有的命令行参数.  \r\n      sys.stdout sys.stdin sys.stderr 分别表示标准输入输出,错误输出的文件对象.  \r\n      sys.stdin.readline() 从标准输入读一行 sys.stdout.write("a") 屏幕输出a \r\n      sys.exit(exit_code) 退出程序 \r\n      sys.modules 是一个dictionary，表示系统中所有可用的module \r\n      sys.platform 得到运行的操作系统环境 \r\n      sys.path 是一个list,指明所有查找module，package的路径.  \r\n      \r\n    操作系统相关的调用和操作 import os \r\n      os.environ 一个dictionary 包含环境变量的映射关系 os.environ["HOME"] 可以得到环境变量HOME的值 \r\n      os.chdir(dir) 改变当前目录 os.chdir(''d:\\\\outlook'') 注意windows下用到转义 \r\n      os.getcwd() 得到当前目录 \r\n      os.getegid() 得到有效组id  os.getgid() 得到组id \r\n      os.getuid() 得到用户id  os.geteuid() 得到有效用户id \r\n      os.setegid os.setegid() os.seteuid() os.setuid() \r\n      os.getgruops() 得到用户组名称列表 \r\n      os.getlogin() 得到用户登录名称 \r\n      os.getenv 得到环境变量 \r\n      os.putenv 设置环境变量 \r\n      os.umask 设置umask \r\n      os.system(cmd) 利用系统调用，运行cmd命令 \r\n      操作举例： \r\n        os.mkdir(''/tmp/xx'') os.system("echo ''hello'' > /tmp/xx/a.txt") os.listdir(''/tmp/xx'') \r\n        os.rename(''/tmp/xx/a.txt'',''/tmp/xx/b.txt'') os.remove(''/tmp/xx/b.txt'') os.rmdir(''/tmp/xx'') \r\n        用python编写一个简单的shell \r\n          #!/usr/bin/python \r\n          import os, sys \r\n          cmd = sys.stdin.readline() \r\n          while cmd: \r\n              os.system(cmd) \r\n              cmd = sys.stdin.readline() \r\n              \r\n    用os.path编写平台无关的程序 \r\n      os.path.abspath("1.txt") == os.path.join(os.getcwd(), "1.txt") \r\n      os.path.split(os.getcwd()) 用于分开一个目录名称中的目录部分和文件名称部分。 \r\n      os.path.join(os.getcwd(), os.pardir, ''a'', ''a.doc'') 全成路径名称.  \r\n        os.pardir 表示当前平台下上一级目录的字符 ..  \r\n      os.path.getctime("/root/1.txt")  返回1.txt的ctime(创建时间)时间戳 \r\n      os.path.exists(os.getcwd()) 判断文件是否存在 \r\n      os.path.expanduser(''~/dir'') 把~扩展成用户根目录 \r\n      os.path.expandvars(''$PATH'') 扩展环境变量PATH \r\n      os.path.isfile(os.getcwd()) 判断是否是文件名，1是0否 \r\n      os.path.isdir(''c:\\Python26  emp'') 判断是否是目录,1是0否 \r\n      os.path.islink(''/home/huaying/111.sql'') 是否是符号连接 windows下不可用 \r\n      os.path.ismout(os.getcwd()) 是否是文件系统安装点 windows下不可用 \r\n      os.path.samefile(os.getcwd(), ''/home/huaying'') 看看两个文件名是不是指的是同一个文件 \r\n      os.path.walk(''/home/huaying'', test_fun, "a.c")  \r\n        遍历/home/huaying下所有子目录包括本目录,对于每个目录都会调用函数test_fun.  \r\n        例：在某个目录中，和他所有的子目录中查找名称是a.c的文件或目录。 \r\n          def test_fun(filename, dirname, names): //filename即是walk中的a.c dirname是访问的目录名称 \r\n              if filename in names: //names是一个list,包含dirname目录下的所有内容 \r\n                  print os.path.join(dirname, filename) \r\n          os.path.walk(''/home/huaying'', test_fun, "a.c") \r\n          \r\n    文件操作 \r\n      打开文件 \r\n        f = open("filename", "r") r只读 w写 rw读写 rb读二进制 wb写二进制 w+写追加 \r\n      读写文件 \r\n        f.write("a") f.write(str) 写一字符串 f.writeline() f.readlines() 与下read类同 \r\n        f.read() 全读出来 f.read(size) 表示从文件中读取size个字符 \r\n        f.readline() 读一行,到文件结尾,返回空串. f.readlines() 读取全部，返回一个list. list每个元素表示一行，包含"\r\n"\\ \r\n        f.tell() 返回当前文件读取位置 \r\n        f.seek(off, where) 定位文件读写位置. off表示偏移量，正数向文件尾移动，负数表示向开头移动。 \r\n          where为0表示从开始算起,1表示从当前位置算,2表示从结尾算.  \r\n        f.flush() 刷新缓存 \r\n      关闭文件 \r\n        f.close() \r\n        \r\n  正则表达式 import re \r\n      简单的regexp \r\n        p = re.compile("abc") if p.match("abc") : print "match" \r\n        上例中首先生成一个pattern(模式),如果和某个字符串匹配，就返回一个match object \r\n        除某些特殊字符metacharacter元字符，大多数字符都和自身匹配。 \r\n        这些特殊字符是 。^ $ * + ? { [ ] \\ | ( ) \r\n      字符集合(用[]表示) \r\n        列出字符,如[abc]表示匹配a或b或c,大多数metacharacter在[]中只表示和本身匹配。例： \r\n          a = ".^$*+?{\\\\|()"  大多数metachar在[]中都和本身匹配，但"^[]\\"不同 \r\n          p = re.compile("["+a+"]") \r\n          for i in a: \r\n              if p.match(i): \r\n                  print "[%s] is match" %i \r\n              else: \r\n                  print "[%s] is not match" %i \r\n          在[]中包含[]本身，表示"["或者"]"匹配.用\\[和\\]表示.  \r\n          ^出现在[]的开头,表示取反.[^abc]表示除了a,b,c之外的所有字符。^没有出现在开头，即于身身匹配。 \r\n          -可表示范围.[a-zA-Z]匹配任何一个英文字母。[0-9]匹配任何数字。 \r\n          \\在[]中的妙用。 \r\n            \\d [0-9] \r\n            \\D [^0-9] \r\n            \\s [   \r\n\\r\\f\\v] \r\n            \\S [^   \r\n\\r\\f\\v] \r\n            \\w [a-zA-Z0-9_] \r\n            \\W [^a-zA-Z0-9_] \r\n               表示和tab匹配, 其他的都和字符串的表示法一致 \r\n            \\x20 表示和十六进制ascii 0x20匹配 \r\n            有了\\，可以在[]中表示任何字符。注：单独的一个"."如果没有出现[]中，表示出了换行\r\n以外的匹配任何字符,类似[^\r\n].  \r\n        regexp的重复          \r\n          {m,n}表示出现m个以上(含m个),n个以下(含n个).  如ab{1,3}c和abc,abbc,abbbc匹配，不会与ac,abbbc匹配。 \r\n          m是下界，n是上界。m省略表下界是0,n省略，表上界无限大。 \r\n          *表示{,} +表示{1,} ?表示{0,1} \r\n          最大匹配和最小匹配 python都是最大匹配，如果要最小匹配，在*,+,?,{m,n}后面加一个?.  \r\n          match object的end可以得到匹配的最后一个字符的位置。 \r\n            re.compile("a*").match(''aaaa'').end()     4  最大匹配 \r\n            re.compile("a*?").match(''aaaa'').end()    0  最小匹配 \r\n        使用原始字符串 \r\n          字符串表示方法中用\\\\表示字符\\.大量使用影响可读性。 \r\n          解决方法：在字符串前面加一个r表示raw格式。 \r\n          a = r"\\a" print a 结果是\\a \r\n          a = r"\\"a" print a 结果是\\"a \r\n        使用re模块 \r\n          先用re.compile得到一个RegexObject 表示一个regexp \r\n          后用pattern的match,search的方法,得到MatchObject \r\n          再用match object得到匹配的位置,匹配的字符串等信息 \r\n          RegxObject常用函数: \r\n            >>> re.compile("a").match("abab") 如果abab的开头和re.compile("a")匹配，得到MatchObject \r\n            <_sre.SRE_Match object at 0x81d43c8> \r\n            >>> print re.compile("a").match("bbab") \r\n            None 注：从str的开头开始匹配          \r\n            >>> re.compile("a").search("abab") 在abab中搜索第一个和re_obj匹配的部分 \r\n            <_sre.SRE_Match object at 0x81d43c8> \r\n            >>> print re.compile("a").search("bbab") \r\n            <_sre.SRE_Match object at 0x8184e18> 和match()不同,不必从开头匹配          \r\n            re_obj.findall(str) 返回str中搜索所有和re_obj匹配的部分.  \r\n              返回一个tuple,其中元素是匹配的字符串.  \r\n          MatchObject的常用函数 \r\n            m.start() 返回起始位置,m.end()返回结束位置(不包含该位置的字符).  \r\n            m.span() 返回一个tuple表示(m.start(), m.end()) \r\n            m.pos(), m.endpos(), m.re(), m.string() \r\n              m.re().search(m.string(), m.pos(), m.endpos()) 会得到m本身 \r\n            m.finditer()可以返回一个iterator,用来遍历所有找到的MatchObject.  \r\n              for m in re.compile("[ab]").finditer("tatbxaxb"): \r\n              print m.span() \r\n        高级regexp \r\n          | 表示联合多个regexp. A B两个regexp，A|B表示和A匹配或者跟B匹配.  \r\n          ^ 表示只匹配一行的开始行首,^只有在开头才有此特殊意义。 \r\n          $ 表示只匹配一行的结尾 \r\n          \\A 表示只匹配第一行字符串的开头 ^匹配每一行的行首 \r\n          \\Z 表示只匹配行一行字符串的结尾 $匹配第一行的行尾 \r\n          \\b 只匹配词的边界 例：\\binfo\\b 只会匹配"info" 不会匹配information \r\n          \\B 表示匹配非单词边界 \r\n          示例如下： \r\n            >>> print re.compile(r"\\binfo\\b").match("info ") #使用raw格式 \\b表示单词边界 \r\n            <_sre.SRE_Match object at 0x817aa98> \r\n            >>> print re.compile("\\binfo\\b").match("info ") #没有使用raw \\b表示退格符号 \r\n            None \r\n            >>> print re.compile("\\binfo\\b").match("\\binfo\\b ") \r\n            <_sre.SRE_Match object at 0x8174948> \r\n        分组(Group) 示例：re.compile("(a(b)c)d").match("abcd").groups()   (''abc'', ''b'')        \r\n          #!/usr/local/bin/python        \r\n          import re        \r\n          x = """ \r\n          name: Charles \r\n          Address: BUPT \r\n          \r\n          name: Ann \r\n          Address: BUPT \r\n          """        \r\n          #p = re.compile(r"^name:(.*)\r\n^Address:(.*)\r\n", re.M) \r\n          p = re.compile(r"^name:(?P.*)\r\n^Address:(?P.*)\r\n", re.M) \r\n          for m in p.finditer(x): \r\n                  print m.span() \r\n                  print "here is your friends list" \r\n                  print "%s, %s"%m.groups() \r\n        Compile Flag \r\n          用re.compile得到RegxObject时，可以有一些flag用来调整RegxObject的详细特征.  \r\n            DOTALL, S 让.匹配任意字符,包括换行符\r\n \r\n            IGNORECASE, I 忽略大小写 \r\n            LOCALES, L 让\\w \\W \\b \\B和当前的locale一致 \r\n            MULTILINE, M 多行模式，只影响^和$(参见上例) \r\n            VERBOSE, X verbose模式\npythondatetime 日期函数 \r\n   \r\n  Time模块： \r\n  －－－－－－－－－－－－－－－－－－－－－－－－－－ \r\n  time() #以浮点形式返回自Linux新世纪以来经过的秒数。在linux中，00:00:00 UTC, \r\n   \r\n  January 1, 1970是新**49**的开始。 \r\n  >>> time.time() \r\n  1150269086.6630149 \r\n  >>> time.ctime(1150269086.6630149) \r\n  >>> ''Wed Jun 14 15:11:26 2006'' \r\n   \r\n  time.ctime([sec])#把秒数转换成日期格式，如果不带参数，则显示当前的时间。 \r\n   \r\n  >>> import time \r\n  >>> time.ctime() \r\n  >>> ''Wed Jun 14 15:02:50 2006'' \r\n  >>> time.ctime(1138068452427683) \r\n  ''Sat Dec 14 04:51:44 1901'' \r\n  >>> time.ctime(os.path.getmtime(''E:\\\\untitleds.bmp'')) \r\n  ''Fri Sep 19 16:35:37 2008'' \r\n   \r\n  >>> time.gmtime(os.path.getmtime(''E:\\\\untitleds.bmp'')) \r\n  time.struct_time(tm_year=2008, tm_mon=9, tm_mday=19, tm_hour=8, tm_min=35, \r\n   \r\n  tm_sec=37, tm_wday=4, tm_yday=263, tm_isdst=0) \r\n   \r\n  将一个文件的修改时间转换为日期格式（秒 转 日期） \r\n  >>> time.strftime(''%Y-%m-%d %X'',time.localtime(os.path.getmtime \r\n   \r\n  (''E:\\\\untitleds.bmp''))) \r\n  ''2008-09-19 16:35:37'' \r\n   \r\n  #定时3秒。 \r\n  >>> time.sleep(3) \r\n   \r\n  TIME模块参考： \r\n  －－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－ \r\n  #取一个文件的修改时间 \r\n  >>> os.path.getmtime(''E:\\\\untitleds.bmp'') \r\n  1221813337.7626641 \r\n   \r\n  变量 \r\n  timezone 通用协调时间和本地标准时间的差值，以秒为单位。 \r\n  altzone 通用协调时间和本地夏令时的差值 \r\n  daylight 标志，本地时间是否反映夏令时。 \r\n  tzname (标准时区名，夏令时时区名) \r\n   \r\n  函数 \r\n  time() 以浮点数返回纪元至今以来的秒数。 \r\n  clock() 以浮点数返回CPU开始这个process的时间，(或者至上次调用这个函数的时间) \r\n  sleep() 延迟一段以浮点数表示的秒数。 \r\n  gmtime() 把以秒表示的时间转换为通用协调时序列 \r\n  localtime() 把秒时转换为本地时序列 \r\n  asctime() 将时间序列转换成文本描述 \r\n  ctime() 将秒时转换成文本描述 \r\n  mktime() 将本地时序列转换成秒时 \r\n  strftime() 以指定格式将序列时转为文本描述 \r\n  strptime() 以指定格式从文本描述中解析出时间序列 \r\n  tzset() 改变当地时区值 \r\n   \r\n  strptime(date_string, format)函数time模块中用来将日期字符串date_string按指定的格式format进行转换，format是要以date_string对应的。如果转换失败将触发一个异常。 \r\n  format转义符对应意义如下 \r\n  %a 本地简化星期名称 \r\n  %A 本地完整星期名称 \r\n  %b 本地简化的月份名称 \r\n  %B 本地完整的月份名称 \r\n  %c 本地相应的日期表示和时间表示 \r\n  %d 月内中的一天（0-31） \r\n  %H 24小时制小时数（0-23） \r\n  %I 12小时制小时数（01-12） \r\n  %j 年内的一天（001-366）#hi.baidu.com/muinlive \r\n  %m 月份（01-12） \r\n  %M 分钟数（00=59） \r\n  %p 本地A.M.或P.M.的等价符 \r\n  %S 秒（00-59） \r\n  %U 一年中的星期数（00-53）星期天为星期的开始 \r\n  %w 星期（0-6），星期天为星期的开始 \r\n  %W 一年中的星期数（00-53）星期一为星期的开始 \r\n  %x 本地相应的日期表示 \r\n  %X 本地相应的时间表示 \r\n  %y 两位数的年份表示（00-99） \r\n  %Y 四位数的年份表示（000-9999） \r\n  %Z 当前时区的名称 \r\n  %% %号本身 \r\n  #hi.baidu.com/muinlive \r\n  示例结果 \r\n  >>> d1=time.strptime(''2007/4/15'',''%Y/%m/%d'') \r\n  >>> d1 \r\n  (2007, 4, 15, 0, 0, 0, 6, 105, -1) \r\n   \r\n  你可以利用 time 模块里的 strptime（）和 strftime（）。 \r\n   \r\n  strftime（）则根据你指定的格式控制字符串输出日期。 \r\n   \r\n  比如，把 “12-Jan-06 10:06” 格式转换成 “2006-01-12 10:06:00” 格式： \r\n   \r\n  >>> from time import strptime, strftime \r\n  >>> \r\n  >>> myDate = ''12-Jan-06 10:06'' \r\n  >>> parsed = strptime( myDate, ''%d-%b-%y %H:%M'' ) \r\n  >>> converted = strftime( ''%Y-%m-%d %H:%M:00'', parsed ) \r\n  >>> \r\n  >>> converted \r\n  ''2006-01-12 10:06:00'' \r\n   \r\n  http://blog.csdn.net/moxien/archive/2008/06/04/2512343.aspx \r\n   \r\n   \r\n   \r\n  DateTime模块 \r\n  －－－－－－－－－－－－－－－－－－－－－－－－－－－－ \r\n  datetime 将日期转化为秒 \r\n  ------------------------------------- \r\n  >>> import datetime,time \r\n  >>> time.mktime(datetime.datetime(2009,1,1).timetuple()) \r\n  1230739200.0 \r\n   \r\n  >>> cc=[2000,11,3,12,43,33] #Attributes: year, month, day, hour, minute, \r\n   \r\n  second \r\n  >>> time.mktime(datetime.datetime(cc[0],cc[1],cc[2],cc[3],cc[4],cc \r\n   \r\n  [5]).timetuple()) \r\n  973226613.0 \r\n   \r\n  将秒转换为日期格式 \r\n  >>> cc = time.localtime(os.path.getmtime(''E:\\\\untitleds.bmp'')) \r\n  >>> print cc[0:3] \r\n  (2008, 9, 19) \r\n   \r\n  DateTime示例 \r\n  －－－－－－－－－－－－－－－－－ \r\n  演示计算两个日期相差天数的计算 \r\n  >>> import datetime \r\n  >>> d1 = datetime.datetime(2005, 2, 16) \r\n  >>> d2 = datetime.datetime(2004, 12, 31) \r\n  >>> (d1 - d2).days \r\n  47 \r\n   \r\n  演示计算运行时间的例子，以秒进行显示 \r\n  import datetime \r\n  starttime = datetime.datetime.now() \r\n  #long running \r\n  endtime = datetime.datetime.now() \r\n  print (endtime - starttime).seconds \r\n   \r\n  演示计算当前时间向后10小时的时间。 \r\n  >>> d1 = datetime.datetime.now() \r\n  >>> d3 = d1 + datetime.timedelta(hours=10) \r\n  >>> d3.ctime() \r\n   \r\n  其本上常用的类有：datetime和timedelta两个。它们之间可以相互加减。每个类都有一 \r\n   \r\n  些方法和属性可以查看具体的值 \r\n   \r\n  3)glob \r\n  可以使用简单的方法匹配某个目录下的所有子目录或文件，用法也很简单。 \r\n  3.1 glob.glob(regression) 返回一个列表 \r\n  3.2 glob.iglob(regression) 返回一个遍历器 \r\n  这个模块简单好用，强力推荐。\n', ''),
(25, 'tcpdump', '\ntcpdump tcp port 80 show all HTTP traffic\ntcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap \r\n  (1)tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型 \r\n  (2)-i eth1 : 只抓经过接口eth1的包 \r\n  (3)-t : 不显示时间戳 \r\n  (4)-s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包 \r\n  (5)-c 100 : 只抓取100个数据包 \r\n  (6)dst port ! 22 : 不抓取目标端口是22的数据包 \r\n  (7)src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24 \r\n  (8)-w ./target.cap : 保存成cap文件，方便用ethereal(即wireshark)分析\ntcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\)  \r\n  (1)截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信\ntcpdump 使用文档\r\n \r\n  一、监视指定主机的数据包 \r\n   \r\n    打印所有进入或离开sundown的数据包.  \r\n   \r\n    tcpdump host sundown \r\n   \r\n    也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包 \r\n   \r\n    tcpdump host 210.27.48.1 \r\n   \r\n    打印helios 与 hot 或者与 ace 之间通信的数据包 \r\n   \r\n    tcpdump host helios and \\( hot or ace \\) \r\n   \r\n    截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信 \r\n   \r\n    tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\) \r\n   \r\n    打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包.  \r\n   \r\n    tcpdump ip host ace and not helios \r\n   \r\n    如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令： \r\n   \r\n    tcpdump ip host 210.27.48.1 and ! 210.27.48.2 \r\n   \r\n    截获主机hostname发送的所有数据 \r\n   \r\n    tcpdump -i eth0 src host hostname \r\n   \r\n    监视所有送到主机hostname的数据包 \r\n   \r\n    tcpdump -i eth0 dst host hostname \r\n   \r\n   \r\n   \r\n  二、监视指定主机和端口的数据包 \r\n   \r\n    如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令 \r\n   \r\n    tcpdump tcp port 23 host 210.27.48.1 \r\n   \r\n    对本机的udp 123 端口进行监视 123 为ntp的服务端口 \r\n   \r\n    tcpdump udp port 123 \r\n   \r\n   \r\n   \r\n  三、监视指定网络的数据包 \r\n   \r\n    打印本地主机与Berkeley网络上的主机之间的所有通信数据包(nt: ucb-ether, 此处可理解为''Berkeley网络''的网络地址,此表达式最原始的含义可表达为: 打印网络地址为ucb-ether的所有数据包) \r\n   \r\n    tcpdump net ucb-ether \r\n   \r\n    打印所有通过网关snup的ftp数据包(注意, 表达式被单引号括起来了, 这可以防止shell对其中的括号进行错误解析) \r\n   \r\n    tcpdump ''gateway snup and (port ftp or ftp-data)'' \r\n   \r\n    打印所有源地址或目标地址是本地主机的IP数据包 \r\n   \r\n    (如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字) \r\n   \r\n    tcpdump ip and not net localnet \r\n   \r\n   \r\n   \r\n  四、监视指定协议的数据包 \r\n   \r\n    打印TCP会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字)) \r\n   \r\n    tcpdump ''tcp[tcpflags] & (tcp-syn|tcp-fin) != 0 and not src and dst net localnet'' \r\n   \r\n    打印所有源或目的端口是80, 网络层协议为IPv4, 并且含有数据,而不是SYN,FIN以及ACK-only等不含数据的数据包.(ipv6的版本的表达式可做练习) \r\n   \r\n    tcpdump ''tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'' \r\n   \r\n    (nt: 可理解为, ip[2:2]表示整个ip数据包的长度, (ip[0]&0xf)<<2)表示ip数据包包头的长度(ip[0]&0xf代表包中的IHL域, 而此域的单位为32bit, 要换算 \r\n   \r\n    成字节数需要乘以4,　即左移2.　(tcp[12]&0xf0)>>4 表示tcp头的长度, 此域的单位也是32bit,　换算成比特数为 ((tcp[12]&0xf0) >> 4)　<<　２,　 \r\n    即 ((tcp[12]&0xf0)>>2).　((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0　表示: 整个ip数据包的长度减去ip头的长度,再减去 \r\n    tcp头的长度不为0, 这就意味着, ip数据包中确实是有数据.对于ipv6版本只需考虑ipv6头中的''Payload Length'' 与 ''tcp头的长度''的差值, 并且其中表达方式''ip[]''需换成''ip6[]''.) \r\n   \r\n    打印长度超过576字节, 并且网关地址是snup的IP数据包 \r\n   \r\n    tcpdump ''gateway snup and ip[2:2] > 576'' \r\n   \r\n    打印所有IP层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报 \r\n   \r\n    tcpdump ''ether[0] & 1 = 0 and ip[16] >= 224'' \r\n   \r\n    打印除''echo request''或者''echo reply''类型以外的ICMP数据包( 比如,需要打印所有非ping 程序产生的数据包时可用到此表达式 .  \r\n    (nt: ''echo reuqest'' 与 ''echo reply'' 这两种类型的ICMP数据包通常由ping程序产生)) \r\n   \r\n    tcpdump ''icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply'' \r\n  \n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(26, 'php', '\nphpfunction 函数大全 \r\n  usleep() 延迟代码执行若干微秒。 \r\n  unpack() 从二进制字符串对数据进行解包。 \r\n  uniqid() 基于以微秒计的当前时间，生成一个唯一的 ID。 \r\n  time_sleep_until() 延迟代码执行直到指定的时间。 \r\n  time_nanosleep() 延迟代码执行若干秒和纳秒。 \r\n  sleep() 延迟代码执行若干秒。 \r\n  show_source() 对文件进行语法高亮显示。 \r\n  strip_whitespace() 返回已删除 PHP 注释以及空白字符的源代码文件。 \r\n  pack() 把数据装入一个二进制字符串。 \r\n  ignore_user_abort() 设置与客户机断开是否会终止脚本的执行。 \r\n  highlight_string() 对字符串进行语法高亮显示。 \r\n  highlight_file() 对文件进行语法高亮显示。 \r\n  get_browser() 返回用户浏览器的性能。 \r\n  exit() 输出一条消息，并退出当前脚本。 \r\n  eval() 把字符串按照 PHP 代码来计算。 \r\n  die() 输出一条消息，并退出当前脚本。 \r\n  defined() 检查某常量是否存在。 \r\n  define() 定义一个常量。 \r\n  constant() 返回常量的值。 \r\n  connection_status() 返回当前的连接状态。 \r\n  connection_aborted() 检查是否断开客户机。 \r\n  zip_read() 读取打开的 zip 档案中的下一个文件。 \r\n  zip_open() 打开 ZIP 文件以供读取。 \r\n  zip_entry_read() 从打开的 zip 档案项目中获取内容。 \r\n  zip_entry_open() 打开一个 ZIP 档案项目以供读取。 \r\n  zip_entry_name() 返回 zip 档案项目的名称。 \r\n  zip_entry_filesize() 返回 zip 档案项目的原始大小（在压缩之前）。 \r\n  zip_entry_compressionmethod() 返回 zip 档案项目的压缩方法。 \r\n  zip_entry_compressedsize() 返回 zip 档案项目的压缩文件尺寸。 \r\n  zip_entry_close() 关闭由 zip_entry_open() 函数打开的 zip 档案文件。 \r\n  zip_close() 关闭由 zip_open() 函数打开的 zip 档案文件。 \r\n  xml_set_unparsed_entity_decl_handler() 规定在遇到无法解析的实体名称（NDATA）声明时被调用的函数。 \r\n  xml_set_processing_instruction_handler() 规定当解析器在 XML 文档中找到处理指令时所调用的函数。 \r\n  xml_set_object() 允许在对象中使用 XML 解析器。 \r\n  xml_set_notation_decl_handler() 规定当解析器在 XML 文档中找到符号声明时被调用的函数。 \r\n  xml_set_external_entity_ref_handler() 规定当解析器在 XML 文档中找到外部实体时被调用的函数。 \r\n  xml_set_element_handler() 建立起始和终止元素处理器。 \r\n  xml_set_default_handler() 为 XML 解析器建立默认的数据处理器。 \r\n  xml_set_character_data_handler() 建立字符数据处理器。 \r\n  xml_parser_set_option() 为 XML 解析器进行选项设置。 \r\n  xml_parser_get_option() 从 XML 解析器获取选项设置信息。 \r\n  xml_parser_free() 释放 XML 解析器。 \r\n  xml_parser_create() 创建 XML 解析器。 \r\n  xml_parser_create_ns() 创建带有命名空间支持的 XML 解析器。 \r\n  xml_parse_into_struct() 把 XML 数据解析到数组中。 \r\n  xml_parse() 解析 XML 文档。 \r\n  xml_get_error_code() 获取 XML 解析器错误代码。 \r\n  xml_get_current_line_number() 获取 XML 解析器的当前行号。 \r\n  xml_get_current_column_number() 获取 XML 解析器的当前列号。 \r\n  xml_get_current_byte_index() 获取 XML 解析器的当前字节索引。 \r\n  xml_error_string() 获取 XML 解析器的错误描述。 \r\n  utf7_encode() 把 ISO-8859-1 字符串编码为 UTF-8。 \r\n  utf8_decode() 把 UTF-8 字符串解码为 ISO-8859-1。 \r\n  wordwrap() 按照指定长度对字符串进行折行处理。 \r\n  vsprintf() 把格式化字符串写入变量中。 \r\n  vprintf() 输出格式化的字符串。 \r\n  vfprintf() 把格式化的字符串写到指定的输出流。 \r\n  ucwords() 把字符串中每个单词的首字符转换为大写。 \r\n  ucfirst() 把字符串中的首字符转换为大写。 \r\n  trim() 从字符串的两端删除空白字符和其他预定义字符。 \r\n  substr_replace() 把字符串的一部分替换为另一个字符串。 \r\n  substr_count() 计算子串在字符串中出现的次数。 \r\n  substr_compare() 从指定的开始长度比较两个字符串。 \r\n  substr() 返回字符串的一部分。 \r\n  strtr() 转换字符串中特定的字符。 \r\n  strtoupper() 把字符串转换为大写。 \r\n  strtolower() 把字符串转换为小写。 \r\n  strtok() 把字符串分割为更小的字符串。 \r\n  strstr() 搜索一个字符串在另一个字符串中的第一次出现。 \r\n  strspn() 返回在字符串中包含的特定字符的数目。 \r\n  strrpos() 查找字符串在另一个字符串中最后一次出现的位置。 \r\n  strripos() 查找字符串在另一个字符串中最后一次出现的位置。 \r\n  strrev() 反转字符串。 \r\n  strrchr() 查找字符串在另一个字符串中最后一次出现的位置，并返回从该位置到字符串结尾的所有字符。 \r\n  strpos() 返回字符串在另一个字符串中第一次出现的位置。 \r\n  strpbrk() 在字符串中搜索指定字符中的任意一个。 \r\n  strncmp() 比较两个字符串。 \r\n  strncasecmp() 比较两个字符串。 \r\n  strnatcmp() 使用一种“自然”算法来比较两个字符串。 \r\n  strnatcasecmp() 使用一种“自然”算法来比较两个字符串。 \r\n  strlen() 返回字符串的长度。 \r\n  stristr() 查找字符串在另一个字符串中第一次出现的位置。 \r\n  stripos() 返回字符串在另一个字符串中第一次出现的位置。 \r\n  stripslashes() 删除由 addslashes()函数添加的反斜杠。 \r\n  stripcslashes() 删除由addcslashes()函数添加的反斜杠。 \r\n  strip_tags() 剥去 HTML、XML 以及 PHP 的标签。 \r\n  strcspn() 返回在找到任何指定的字符之前，在字符串查找的字符数。 \r\n  strcoll() 比较两个字符串。 \r\n  strcmp() 比较两个字符串。 \r\n  strchr() 搜索一个字符串在另一个字符串中的第一次出现。 \r\n  strcasecmp() 比较两个字符串。 \r\n  str_word_count() 计算字符串中的单词数。 \r\n  str_split() 把字符串分割到数组中。 \r\n  str_shuffle() 随机地打乱字符串中的所有字符。 \r\n  str_rot13() 对字符串执行 ROT13 编码。 \r\n  str_replace() 使用一个字符串替换字符串中的另一些字符。 \r\n  str_repeat() 把字符串重复指定的次数。 \r\n  str_pad() 把字符串填充为指定的长度。 \r\n  str_ireplace() 使用一个字符串替换字符串中的另一些字符。 \r\n  sscanf() 根据指定的格式解析来自一个字符串的输入。 \r\n  sprintf() 把格式化的字符串写写入一个变量中。 \r\n  soundex() 计算字符串的 soundex 键。 \r\n  similar_text() 计算两个字符串的匹配字符的数目。 \r\n  sha1_file() 计算文件的 SHA-1 散列。 \r\n  sha1() 计算字符串的 SHA-1 散列。 \r\n  setlocale() 设置地区信息（地域信息）。 \r\n  rtrim() P rtrim() 函数 \r\n  quotemeta() 在字符串中某些预定义的字符前添加反斜杠。 \r\n  quoted_printable_decode() 对经过 quoted-printable 编码后的字符串进行解码，返回 8 位的字符串。 \r\n  printf() 输出格式化的字符串。 \r\n  print() 输出一个或多个字符串。 \r\n  parse_str() 把查询字符串解析到变量中。 \r\n  ord() 返回字符串第一个字符的 ASCII 值。 \r\n  number_format() 通过千位分组来格式化数字。 \r\n  nl2br() 在字符串中的每个新行 (\r\n) 之前插入 HTML 换行符 (<br />)。 \r\n  nl_langinfo() 返回指定的本地信息。 \r\n  money_format() 把字符串格式化为货币字符串。 \r\n  metaphone() 计算字符串的 metaphone 键。 \r\n  md5_file() 计算文件的 MD5 散列。 \r\n  md5() 计算字符串的 MD5 散列。 \r\n  ltrim() 从字符串左侧删除空格或其他预定义字符。 \r\n  localeconv() 返回包含本地数字及货币信息格式的数组。 \r\n  levenshtein() 返回两个字符串之间的 Levenshtein 距离。 \r\n  join() 把数组元素组合为一个字符串。 \r\n  implode() 把数组元素组合为一个字符串。 \r\n  htmlspecialchars() 把一些预定义的字符转换为 HTML 实体。 \r\n  html_entity_decode() chars_decode() 函数 \r\n  htmlentities() 把字符转换为 HTML 实体。 \r\n  html_entity_decode() 把 HTML 实体转换为字符。 \r\n  hebrevc() 把希伯来文本从右至左的流转换为左至右的流。它也会把新行 (\r\n) 转换为 <br />。 \r\n  hebrev() 把希伯来文本从右至左的流转换为左至右的流。 \r\n  get_html_translation_table() 返回被htmlentities()和htmlspecialchars()函数使用的翻译表。 \r\n  fprintf() 把格式化的字符串写到指定的输出流（例如：文件或数据库）。 \r\n  explode() 把字符串分割为数组。 \r\n  echo() 输出一个或多个字符串。 \r\n  crypt() 返回使用 DES、Blowfish 或 MD5 加密的字符串。 \r\n  crc32() 计算一个字符串的 crc32 多项式。 \r\n  count_chars() 返回字符串所用字符的信息。 \r\n  convert_uuencode() 使用 uuencode 算法对字符串进行编码。 \r\n  convert_uudecode() 对 uuencode 编码的字符串进行解码。 \r\n  convert_cyr_string() 把字符由一种 Cyrillic 字符转换成另一种。 \r\n  chunk_split() 把字符串分割为一连串更小的部分。 \r\n  chr() 从指定的 ASCII 值返回字符。 \r\n  chop() 从字符串的末端开始删除空白字符或其他预定义字符。 \r\n  bin2hex() 把 ASCII 字符的字符串转换为十六进制值。 \r\n  addslashes() 在指定的预定义字符前添加反斜杠。 \r\n  addcslashes() 在指定的字符前添加反斜杠。 \r\n  xpath() 运行对 XML 文档的 XPath 查询。 \r\n  simplexml_load_string() 把 XML 字符串载入对象中。 \r\n  simplexml_load_file() 把 XML 文档载入对象中。 \r\n  simplexml_import_dom() 把 DOM 节点转换为 SimpleXMLElement 对象。 \r\n  registerXPathNamespace() 为下一次 XPath 查询创建命名空间语境。 \r\n  getNamespace() 获取在 XML 文档中使用的命名空间。 \r\n  getName() 从 SimpleXMLElement 对象获取 XML 元素的名称。 \r\n  getDocNamespaces() 从 SimpleXMLElement 对象返回在 XML 文档中声明的命名空间。 \r\n  children() 获取指定节点的子节点。 \r\n  attributes() 获取 SimpleXML 元素的属性。 \r\n  asXML() 以字符串的形式从 SimpleXMLElement 对象返回 XML 文档。 \r\n  addChild() 向指定的 XML 节点添加一个子节点。 \r\n  addAttribute() 给 SimpleXML 元素添加一个属性。 \r\n  __construct() 创建一个新的 SimpleXMLElement 对象。 \r\n  mysql_unbuffered_query() 向 MySQL 发送一条 SQL 查询（不获取 / 缓存结果）。 \r\n  mysql_thread_id() 返回当前线程的 ID。 \r\n  mysql_stat() 返回 MySQL 服务器的当前系统状态。 \r\n  mysql_select_db() 设置活动的 MySQL 数据库。 \r\n  mysql_result() 返回结果集中一个字段的值。 \r\n  mysql_real_escape_string() 转义 SQL 语句中使用的字符串中的特殊字符。 \r\n  mysql_query() 执行一条 MySQL 查询。 \r\n  mysql_ping() Ping 一个服务器连接，如果没有连接则重新连接。 \r\n  mysql_pconnect() 打开一个到 MySQL 服务器的持久连接。 \r\n  mysql_num_rows() 返回结果集中行的数目。 \r\n  mysql_num_fields() 返回结果集中字段的数。 \r\n  mysql_list_processes() 列出 MySQL 进程。 \r\n  mysql_list_dbs() 列出 MySQL 服务器中所有的数据库。 \r\n  mysql_insert_id() 返回上一步 INSERT 操作产生的 ID。 \r\n  mysql_info() 返回最近一条查询的信息。 \r\n  mysql_get_server_info() 返回 MySQL 服务器的信息。 \r\n  mysql_get_proto_info() 返回 MySQL 协议的信息。 \r\n  mysql_get_host_info() 返回 MySQL 主机的信息。 \r\n  mysql_get_client_info() 返回 MySQL 客户端信息。 \r\n  mysql_free_result() 释放结果内存。 \r\n  mysql_field_type() 返回结果集中指定字段的类型。 \r\n  mysql_field_table() 返回指定字段所在的表名。 \r\n  mysql_field_seek() 将结果集中的指针设定为指定的字段偏移量。 \r\n  mysql_field_name() 取得结果中指定字段的字段名。 \r\n  mysql_field_len() 返回指定字段的长度。 \r\n  mysql_field_flags() 从结果中取得和指定字段关联的标志。 \r\n  mysql_fetch_row() 从结果集中取得一行作为数字数组。 \r\n  mysql_fetch_object() 从结果集（记录集）中取得一行作为对象。 \r\n  mysql_fetch_lengths() 取得一行中每个字段的内容的长度。 \r\n  mysql_fetch_field() 从结果集中取得列信息并作为对象返回。 \r\n  mysql_fetch_assoc() 从结果集中取得一行作为关联数组。 \r\n  mysql_fetch_array() 从结果集中取得一行作为关联数组，或数字数组，或二者兼有 \r\n  mysql_error() 返回上一个 MySQL 操作产生的文本错误信息。 \r\n  mysql_errno() 返回上一个 MySQL 操作中的错误信息的数字编码。 \r\n  mysql_db_name() 取得 mysql_list_dbs() 调用所返回的数据库名。 \r\n  mysql_data_seek() 移动内部结果的指针。 \r\n  mysql_connect() 打开非持久的 MySQL 连接。 \r\n  mysql_close() 关闭非持久的 MySQL 连接。 \r\n  mysql_client_encoding() 返回当前连接的字符集的名称。 \r\n  mysql_affected_rows() 返回前一次 MySQL 操作所影响的记录行数。 \r\n  tanh() 返回双曲正切。 \r\n  tan() 返回正切。 \r\n  srand() 播下随机数发生器种子。 \r\n  sqrt() 返回一个数的平方根。 \r\n  sinh() 返回一个数的双曲正弦。 \r\n  sin() 返回一个数的正弦。 \r\n  round() 对浮点数进行四舍五入。 \r\n  rand() 返回随机整数。 \r\n  rad2deg() 把弧度数转换为角度数。 \r\n  pow() 返回 x 的 y 次方。 \r\n  pi() 返回圆周率的值。 \r\n  octdec() 把八进制转换为十进制。 \r\n  mt_srand() 播种 Mersenne Twister 随机数生成器。 \r\n  mt_rand() 使用 Mersenne Twister 算法返回随机整数。 \r\n  mt_getrandmax() 显示随机数的最大可能值。 \r\n  min() 返回最小值。 \r\n  max() 返回最大值。 \r\n  log1p() 以返回 log(1 + x)，甚至当 x 的值接近零也能计算出准确结果。 \r\n  log10() 以 10 为底的对数。 \r\n  log() 返回自然对数。 \r\n  lcg_value() 组合线性同余发生器。 \r\n  is_nan() 判断是否为合法数值。 \r\n  is_infinite() 判断是否为无限值。 \r\n  is_finite() 判断是否为有限值。 \r\n  hypot() 计算一直角三角形的斜边长度。 \r\n  hexdec() 把十六进制转换为十进制。 \r\n  fmod() 显示随机数最大的可能值。 \r\n  fmod() 返回除法的浮点数余数。 \r\n  floor() 向下舍入为最接近的整数。 \r\n  expm1() 返回 exp(x) - 1，甚至当 number 的值接近零也能计算出准确结果。 \r\n  exp() 计算 e 的指数。 \r\n  deg2rad() 将角度转换为弧度。 \r\n  decoct() 把十进制转换为八进制。 \r\n  dechex() 把十进制转换为十六进制。 \r\n  decbin() 把十进制转换为二进制。 \r\n  cosh() 返回一个数的双曲余弦。 \r\n  cos() 返回一个数的余弦。 \r\n  ceil() 向上舍入为最接近的整数。 \r\n  bindec() 把二进制转换为十进制。 \r\n  base_convert() 在任意进制之间转换数字。 \r\n  atanh() 返回一个角度的反双曲正切。 \r\n  atan() 和 atan2() 和 atan2() 函数 \r\n  atan() 和 atan2() 和 atan2() 函数 \r\n  asinh() 返回一个数的反双曲正弦。 \r\n  asin() 返回不同数值的反正弦，返回的结果是介于 -PI/2 与 PI/2 之间的弧度值。 \r\n  acosh() 返回一个数的反双曲余弦。 \r\n  acos() 返回一个数的反余弦。 \r\n  abs() 返回一个数的绝对值。 \r\n  mail() 允许您从脚本中直接发送电子邮件。 \r\n  libxml_use_internal_errors() 禁用标准的 libxml 错误，并启用用户错误处理。 \r\n  libxml_get_last_error() 从 libxml 错误缓冲中获取最后一个错误。 \r\n  libxml_get_errors() 从 libxml 错误缓冲中获取错误。 \r\n  libxml_clear_errors() 清空 libxml 错误缓冲。 \r\n  setrawcookie() 不对 cookie 值进行 URL 编码，发送一个 HTTP cookie。 \r\n  setcookie() 向客户端发送一个 HTTP cookie。 \r\n  headers_sent() 检查 HTTP 报头是否发送/已发送到何处。 \r\n  headers_list() 返回已发送的（或待发送的）响应头部的一个列表。 \r\n  header() 向客户端发送原始的 HTTP 报头。 \r\n  ftp_systype() 返回远程 FTP 服务器的系统类型标识符。 \r\n  ftp_ssl_connect() 打开一个安全的 SSL-FTP 连接。 \r\n  ftp_size() 返回指定文件的大小。 \r\n  ftp_site() 向服务器发送 SITE 命令。 \r\n  ftp_set_option() 设置各种 FTP 运行时选项。 \r\n  ftp_rmdir() 删除一个目录。 \r\n  ftp_rename() 更改 FTP 服务器上的文件或目录名。 \r\n  ftp_rawlist() 返回指定目录中文件的详细列表。 \r\n  ftp_raw() 向 FTP 服务器发送一个 raw 命令。 \r\n  ftp_quit() 关闭 FTP 连接。 \r\n  ftp_pwd() 返回当前目录名。 \r\n  ftp_put() 把文件上传到服务器。 \r\n  ftp_pasv() 把被动模式设置为打开或关闭。 \r\n  ftp_nlist() 返回指定目录的文件列表。 \r\n  ftp_nb_put() 把文件上传到服务器 (non-blocking)。 \r\n  ftp_nb_get() 从 FTP 服务器上获取文件并写入本地文件 (non-blocking)。 \r\n  ftp_nb_fput() 上传一个已打开的文件，并在 FTP 服务器上把它保存为文件 (non-blocking)。 \r\n  ftp_nb_fget() 从 FTP 服务器上下载一个文件并保存到本地已经打开的一个文件中 (non-blocking)。 \r\n  ftp_nb_continue() 连续获取 / 发送文件。 \r\n  ftp_mkdir() 在 FTP 服务器上建立新目录。 \r\n  ftp_mdtm() 返回指定文件的最后修改时间。 \r\n  ftp_login() 登录 FTP 服务器。 \r\n  ftp_get() 从 FTP 服务器上下载一个文件。 \r\n  ftp_get_option() 返回当前 FTP 连接的各种不同的选项设置。 \r\n  ftp_fput() 上传一个已经打开的文件到 FTP 服务器。 \r\n  ftp_fget() 从 FTP 服务器上下载一个文件并保存到本地一个已经打开的文件中。 \r\n  ftp_exec() 请求在 FTP 服务器上执行一个程序或命令。 \r\n  ftp_delete() 删除 FTP 服务器上的一个文件。 \r\n  ftp_connect() 建立一个新的 FTP 连接。 \r\n  ftp_close() 关闭 FTP 连接。 \r\n  ftp_chmod() 设置 FTP 服务器上指定文件的权限。 \r\n  ftp_chdir() 改变 FTP 服务器上的当前目录。 \r\n  ftp_cdup() 把当前目录改变为 FTP 服务器上的父目录。 \r\n  ftp_alloc() 为要上传到 FTP 服务器的文件分配空间。 \r\n  filter_var() 通过指定的过滤器过滤变量。 \r\n  filter_var_array() 获取多项变量，并进行过滤。 \r\n  filter_list() 返回包含所有得到支持的过滤器的一个数组。 \r\n  filter_input_array() 从脚本外部获取多项输入，并进行过滤。 \r\n  filter_input() 从脚本外部获取输入，并进行过滤。 \r\n  filter_id() 返回指定过滤器的 ID 号。 \r\n  filter_has_var() 检查是否存在指定输入类型的变量。 \r\n  unlink() 删除文件。 \r\n  umask() 改变当前的 umask。 \r\n  touch() 设置指定文件的访问和修改时间。 \r\n  tmpfile() 以读写（w+）模式建立一个具有唯一文件名的临时文件。 \r\n  tempnam() 创建一个具有唯一文件名的临时文件。 \r\n  symlink() 创建符号连接。 \r\n  stat() 返回关于文件的信息。 \r\n  set_file_buffer() 设置打开文件的缓冲大小。 \r\n  rmdir() 删除空的目录。 \r\n  rewind() 将文件指针的位置倒回文件的开头。 \r\n  rename() 重命名文件或目录。 \r\n  realpath() 返回绝对路径。 \r\n  readlink() 返回符号连接指向的目标。 \r\n  readfile() 输出一个文件。 \r\n  popen() 打开进程文件指针。 \r\n  pclose() 关闭由 popen() 打开的管道。 \r\n  pathinfo() 以数组的形式返回文件路径的信息。 \r\n  parse_ini_file() 解析一个配置文件，并以数组的形式返回其中的设置。 \r\n  move_uploaded_file() 将上传的文件移动到新位置。 \r\n  mkdir() 创建目录。 \r\n  lstat() 返回关于文件或符号连接的信息。 \r\n  linkinfo() 返回连接的信息。 \r\n  link() 建立一个硬连接。 \r\n  is_writeable() 判断指定的文件是否可写。 \r\n  is_writable() 判断指定的文件是否可写。 \r\n  is_uploaded_file() 判断指定的文件是否是通过 HTTP POST 上传的。 \r\n  is_readable() 判断指定文件名是否可读。 \r\n  is_link() 判断指定文件名是否为一个符号连接。 \r\n  is_file() 检查指定的文件名是否是正常的文件。 \r\n  is_executable() 检查指定的文件是否可执行。 \r\n  is_dir() 检查指定的文件是否是目录。 \r\n  glob() 返回匹配指定模式的文件名或目录。 \r\n  fwrite() 写入文件（可安全用于二进制文件）。 \r\n  ftruncate() 把文件截断到指定的长度。 \r\n  ftell() 在打开文件中的当前位置。 \r\n  fstat() 返回关于打开文件的信息。 \r\n  fseek() 在打开的文件中定位。 \r\n  fscanf() 根据指定的格式对来自打开的文件的输入进行解析。 \r\n  fread() 读取文件（可安全用于二进制文件）。 \r\n  fputs() 写入文件（可安全用于二进制文件）。 \r\n  fputcsv() 将行格式化为 CSV 并写入一个打开的文件。 \r\n  fpassthru() 输出文件指针处的所有剩余数据。 \r\n  fopen() 打开文件或者 URL。 \r\n  fnmatch() 根据指定的模式来匹配文件名或字符串。 \r\n  flock() 锁定或释放文件。 \r\n  filetype() 返回指定文件或目录的类型。 \r\n  filesize() 返回指定文件的大小。 \r\n  fileperms() 返回文件或目录的权限。 \r\n  fileowner() 返回文件的所有者。 \r\n  filemtime() 返回文件内容上次的修改时间。 \r\n  fileinode() 返回文件的 inode 编号。 \r\n  filegroup() 返回指定文件的组 ID。 \r\n  filectime() 返回指定文件的上次 inode 修改时间。 \r\n  fileatime() 返回指定文件的上次访问时间。 \r\n  file_put_contents() 把一个字符串写入文件中。 \r\n  file_get_contents() 把整个文件读入一个字符串中。 \r\n  file_exists() 检查文件或目录是否存在。 \r\n  file() 把整个文件读入一个数组中。 \r\n  fgetss() 从打开的文件中读取一行并过滤掉 HTML 和 PHP 标记。 \r\n  fgets() 从文件指针中读取一行。 \r\n  fgetcsv() 从文件指针中读入一行并解析 CSV 字段。 \r\n  fgetc() 从文件指针中读取一个字符。 \r\n  fflush() 将缓冲内容输出到文件。 \r\n  feof() 检测是否已到达文件末尾 (eof)。 \r\n  fclose() 关闭一个打开文件。 \r\n  diskfreespace() 返回目录中的可用空间。该函数是disk_free_space()函数的别名。 \r\n  disk_total_space() 返回指定目录的磁盘总大小。 \r\n  disk_free_space() 返回目录中的可用空间 \r\n  dirname() 返回路径中的目录部分。 \r\n  clearstatcache() 拷贝文件。 \r\n  clearstatcache() 清除文件状态缓存。 \r\n  chown() 改变指定文件的所有者。 \r\n  chmod() 改变文件模式。 \r\n  chgrp() 改变文件所属的组。 \r\n  basename() 返回路径中的文件名部分。 \r\n  set_exception_handler() handler() 函数 \r\n  set_exception_handler() 设置用户自定义的异常处理函数。 \r\n  set_error_handler() 设置用户自定义的错误处理函数。 \r\n  restore_exception_handler() 恢复之前的异常处理程序，该程序是由 set_exception_handler() 函数改变的。 \r\n  restore_error_handler() 恢复之前的错误处理程序，该程序是由 set_error_handler() 函数改变的。 \r\n  error_reporting() 设置 PHP 的报错级别并返回当前级别。 \r\n  error_log() 向服务器错误记录、文件或远程目标发送一个错误。 \r\n  error_get_last() 获取最后发生的错误。 \r\n  debug_print_backtrace() 输出 backtrace。 \r\n  debug_backtrace() cktrace() 函数 \r\n  scandir() 返回一个数组，其中包含指定路径中的文件和目录。 \r\n  rewinddir() 重置由 opendir() 打开的目录句柄。 \r\n  readdir() 返回由 opendir() 打开的目录句柄中的条目。 \r\n  opendir() 打开一个目录句柄，可由 closedir()，readdir() 和 rewinddir() 使用。 \r\n  getcwd() 返回当前目录。 \r\n  closedir() 关闭由 opendir() 函数打开的目录句柄。 \r\n  dir() 打开一个目录句柄，并返回一个对象。这个对象包含三个方法：read() , rewind() 以及 close()。 \r\n  chroot() 把当前进程的根目录改变为指定的目录。 \r\n  chdir() 把当前的目录改变为指定的目录。 \r\n  time() 返回当前时间的 Unix 时间戳。 \r\n  strtotime() 将任何英文文本的日期时间描述解析为 Unix 时间戳。 \r\n  strptime() 解析由strftime()生成的日期／时间。 \r\n  strftime() 根据区域设置格式化本地时间／日期。 \r\n  mktime() 返回一个日期的 Unix 时间戳。 \r\n  microtime() 返回当前 Unix 时间戳和微秒数。 \r\n  localtime() 返回本地时间（一个数组）。 \r\n  idate() 将本地时间/日期格式化为整数。 \r\n  gmstrftime() 根据本地区域设置格式化 GMT/UTC 时间／日期。 \r\n  gmmktime() 取得 GMT 日期的 UNIX 时间戳。 \r\n  gmdate() 格式化 GMT/UTC 日期/时间。 \r\n  gettimeofday() 返回一个包含当前时间信息的数组。 \r\n  getdate() 取得日期／时间信息。 \r\n  date() 格式化一个本地时间／日期。 \r\n  date_sunset() 返回指定的日期与地点的日落时间。 \r\n  date_sunrise() 返回指定的日期与地点的日出时间。 \r\n  date_default_timezone_set() 设置用在脚本中所有日期/时间函数的默认时区。 \r\n  date_default_timezone_get() 返回脚本中所有日期时间函数所使用的默认时区。 \r\n  checkdate() 验证一个格里高里日期。 \r\n  UnixToJD() 把 Unix 时间戳转换为儒略日计数。 \r\n  JulianToJD() 把儒略历转换为儒略日计数。 \r\n  JewishToJD() 把犹太历法转换为儒略日计数。 \r\n  JDToUnix() 把儒略日计数转换为 Unix 时间戳。 \r\n  JDToGregorian() lian() 函数 \r\n  JDToGregorian() wish() 函数 \r\n  JDToGregorian() 把儒略日计数转换为格利高里历法。 \r\n  JDToFrench() 把儒略日计数转换为法国共和国历法。 \r\n  JDMonthName() 返回指定历法的月份字符串。 \r\n  JDDayOfWeek() 返回日期在周几。 \r\n  GregorianToJD() 将格利高里历法转换成为儒略日计数。 \r\n  FrenchToJD() 将法国共和历法转换成为儒略日计数。 \r\n  easter_days() 返回指定年份的复活节与 3 月 21 日之间的天数。 \r\n  easter_date() 返回指定年份的复活节午夜的 Unix 时间戳。 \r\n  cal_to_jd() 把指定的日期转换为儒略日计数。 \r\n  cal_info() 返回一个数组，其中包含了关于给定历法的信息。 \r\n  cal_from_jd() 把儒略日计数转换为指定历法的日期。 \r\n  cal_days_in_month() 针对指定的年份和日历，返回一个月中的天数。 \r\n  usort() 使用用户自定义的函数对数组排序。 \r\n  uksort() 使用用户自定义的比较函数按照键名对数组排序，并保持索引关系。 \r\n  uasort() 使用用户自定义的比较函数对数组排序，并保持索引关联（不为元素分配新的键）。 \r\n  sort() 按升序对给定数组的值排序。 \r\n  sizeof() 计算数组中的单元数目或对象中的属性个数。 \r\n  shuffle() 把数组中的元素按随机顺序重新排列。 \r\n  rsort() 对数组的元素按照键值进行逆向排序。与arsort()的功能基本相同。 \r\n  reset() 把数组的内部指针指向第一个元素，并返回这个元素的值。 \r\n  range() 创建并返回一个包含指定范围的元素的数组。 \r\n  prev() HP prev() 函数 \r\n  pos() 是current() 函数的别名。它可返回数组中当前元素的值。 \r\n  next() 把指向当前元素的指针移动到下一个元素的位置，并返回当前元素的值。 \r\n  natsort() 用自然顺序算法对给定数组中的元素排序。 \r\n  natcasesort() 用不区分大小写的自然顺序算法对给定数组中的元素排序。 \r\n  list() 用数组中的元素为一组变量赋值。 \r\n  ksort() 按照键名对数组排序，为数组值保留原来的键。 \r\n  krsort() 将数组按照键逆向排序，为数组值保留原来的键。 \r\n  key() 返回数组内部指针当前指向元素的键名。 \r\n  in_array() 在数组中搜索给定的值。 \r\n  extract() extract() 函数 \r\n  end() 将数组内部指针指向最后一个元素，并返回该元素的值（如果成功）。 \r\n  each() 生成一个由数组当前内部指针所指向的元素的键名和键值组成的数组，并把内部指针向前移动。 \r\n  current() 返回数组中的当前元素（单元）。 \r\n  count() 计算数组中的单元数目或对象中的属性个数。 \r\n  compact() 创建一个由参数所带变量组成的数组。如果参数中存在数组，该数组中变量的值也会被获取。 \r\n  asort() 对数组进行排序并保持索引关系。主要用于对那些单元顺序很重要的结合数组进行排序。 \r\n  arsort() 对数组进行逆向排序并保持索引关系。主要用于对那些单元顺序很重要的结合数组进行排序。 \r\n  array_walk_recursive() cursive() 函数 \r\n  array_walk() 对数组中的每个元素应用回调函数。如果成功则返回 TRUE，否则返回 FALSE。 \r\n  array_values() 返回一个包含给定数组中所有键值的数组，但不保留键名。 \r\n  array_unshift() 在数组开头插入一个或多个元素。 \r\n  array_unique() 移除数组中的重复的值，并返回结果数组。 \r\n  array_uintersect_assoc() 带索引检查计算数组的交集，用回调函数比较数据。 \r\n  array_uintersect() 计算数组的交集，用回调函数比较数据。 \r\n  array_udiff_uassoc() 返回 array1 数组中存在但其它数组中都不存在的部分。返回的数组中键名保持不变。 \r\n  array_udiff_assoc() 返回 array1 中存在但其它数组中都不存在的部分。 \r\n  array_udiff() 返回一个数组，该数组包括了所有在被比较数组中，但是不在任何其它参数数组中的值，键名保留不变。 \r\n  array_sum() 返回数组中所有值的总和。 \r\n  array_splice() 与 array_slice() 函数类似，选择数组中的一系列元素，但不返回，而是删除它们并用其它值代替。 \r\n  array_slice() 在数组中根据条件取出一段值，并返回。 \r\n  array_shift() 删除数组中的第一个元素，并返回被删除元素的值。 \r\n  array_search() 与in_array()一样，在数组中查找一个键值。如果找到了该值，匹配元素的键名会被返回。如果没找到，则返回 false。 \r\n  array_reverse() 将原数组中的元素顺序翻转，创建新的数组并返回。如果第二个参数指定为 true，则元素的键名保持不变，否则键名将丢失。 \r\n  array_reduce() 用回调函数迭代地将数组简化为单一的值。如果指定第三个参数，则该参数将被当成是数组中的第一个值来处理，或者如果数组为空的话就作为最终返回值。 \r\n  array_rand() 从数组中随机选出一个或多个元素，并返回。 \r\n  array_push() 向第一个参数的数组尾部添加一个或多个元素（入栈），然后返回新数组的长度。 \r\n  array_product() 计算并返回数组中所有值的乘积。 \r\n  array_pad() 向一个数组插入带有指定值的指定数量的元素。 \r\n  array_merge() 把两个或多个数组合并为一个数组。 \r\n  array_map() 返回用户自定义函数作用后的数组。回调函数接受的参数数目应该和传递给 array_map() 函数的数组数目一致。 \r\n  array_keys() 返回包含数组中所有键名的一个新数组。 \r\n  array_key_exists() 判断某个数组中是否存在指定的 key，如果该 key 存在，则返回 true，否则返回 false。 \r\n  array_intersect_ukey() 用回调函数比较键名来计算数组的交集。 \r\n  array_intersect_uassoc() 使用用户自定义的回调函数计算数组的交集，用回调函数比较索引。 \r\n  array_intersect_key() 使用键名比较计算数组的交集。 \r\n  array_intersect_assoc() 返回两个或多个数组的交集数组。 \r\n  array_intersect() 返回两个或多个数组的交集数组。 \r\n  array_flip() 返回一个反转后的数组，如果同一值出现了多次，则最后一个键名将作为它的值，所有其他的键名都将丢失。 \r\n  array_filter() 用回调函数过滤数组中的元素，如果自定义过滤函数返回 true，则被操作的数组的当前值就会被包含在返回的结果数组中， 并将结果组成一个新的数组。如果原数组是一个关联数组，键名保持不变。 \r\n  array_fill() 用给定的值填充数组，返回的数组有 number 个元素，值为 value。返回的数组使用数字索引，从 start 位置开始并递增。如果 number 为 0 或小于 0，就会出错。 \r\n  array_diff_ukey() 返回一个数组，该数组包括了所有出现在 array1 中但是未出现在任何其它参数数组中的键名的值。注意关联关系保留不变。与 array_diff() 不同的是，比较是根据键名而不是值来进行的。 \r\n  array_diff_uassoc() 使用用户自定义的回调函数 (callback) 做索引检查来计算两个或多个数组的差集。返回一个数组，该数组包括了在 array1 中但是不在任何其他参数数组中的值。 \r\n  array_diff_key() 返回一个数组，该数组包括了所有在被比较的数组中，但是不在任何其他参数数组中的键。 \r\n  array_diff_assoc() 返回两个数组的差集数组。该数组包括了所有在被比较的数组中，但是不在任何其他参数数组中的键和值。 \r\n  array_diff() 返回两个数组的差集数组。该数组包括了所有在被比较的数组中，但是不在任何其他参数数组中的键值。 \r\n  array_count_values() 用于统计数组中所有值出现的次数。 \r\n  array_combine() 通过合并两个数组来创建一个新数组，其中的一个数组是键名，另一个数组的值为键值。 \r\n  array_chunk() 把一个数组分割为新的数组块。 \r\n  array_change_key_case() 将数组的所有的 KEY 都转换为大写或小写。 \r\n  array() 创建数组，带有键和值。如果在规定数组时省略了键，则生成一个整数键，这个 key 从 0 开始，然后以 1 进行递增。 \r\n  \n', ''),
(40, 'rsync', 'rsync rsync -rogpav --delete /home /tmp 同步两边的目录\nrsync -rogpav -e ssh --delete /home ip_address:/tmp 通过SSH通道rsync\nrsync -az -e ssh --delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录\nrsync -az -e ssh --delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录\n', ''),
(41, 'yum', 'yum YUM 软件包升级器 - （Fedora, RedHat及类似系统）\nyum install package_name 下载并安装一个rpm包\nyum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系\nyum update package_name.rpm 更新当前系统中所有安装的rpm包\nyum update package_name 更新一个rpm包\nyum remove package_name 删除一个rpm包\nyum list 列出当前系统中安装的所有包\nyum search package_name 在rpm仓库中搜寻软件包\nyum clean packages 清理rpm缓存删除下载的包\nyum clean headers 删除所有头文件\nyum clean all 删除所有缓存的包和头文件\n', ''),
(30, 'dd', '\ndd bs=1M if=/dev/hda | gzip | ssh user@ip_addr ''dd of=hda.gz'' 通过ssh在远程主机上执行一次备份本地磁盘的操作\ndd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件\ndd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作\ndd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容\ndd if=/dev/hdc | md5sum 校验一个设备的md5sum编码，例如一张 CD\n', ''),
(31, 'sed', 'sed sed 使用说明书 \r\n  是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作，下面先了解一下sed的用法 \r\n  sed命令行格式为： \r\n           sed [-nefri] ‘command’ 输入文本        \r\n   \r\n  常用选项： \r\n          -n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 \r\n          -e∶直接在指令列模式上进行 sed 的动作编辑； \r\n          -f∶直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作； \r\n          -r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法) \r\n          -i∶直接修改读取的档案内容，而不是由萤幕输出。       \r\n   \r\n  常用命令： \r\n          a   ∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ \r\n          c   ∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ \r\n          d   ∶删除，因为是删除啊，所以 d 后面通常不接任何咚咚； \r\n           i   ∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； \r\n           p  ∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～ \r\n           s  ∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ \r\n   \r\n  举例：（假设我们有一文件名为ab） \r\n       删除某行 \r\n       [root@localhost ruby] # sed ''1d'' ab              #删除第一行 \r\n       [root@localhost ruby] # sed ''$d'' ab              #删除最后一行 \r\n       [root@localhost ruby] # sed ''1,2d'' ab           #删除第一行到第二行 \r\n       [root@localhost ruby] # sed ''2,$d'' ab           #删除第二行到最后一行 \r\n   \r\n  　　显示某行 \r\n  .    [root@localhost ruby] # sed -n ''1p'' ab           #显示第一行 \r\n       [root@localhost ruby] # sed -n ''$p'' ab           #显示最后一行 \r\n       [root@localhost ruby] # sed -n ''1,2p'' ab        #显示第一行到第二行 \r\n       [root@localhost ruby] # sed -n ''2,$p'' ab        #显示第二行到最后一行 \r\n   \r\n  　　使用模式进行查询 \r\n       [root@localhost ruby] # sed -n ''/ruby/p'' ab    #查询包括关键字ruby所在所有行 \r\n       [root@localhost ruby] # sed -n ''/\\$/p'' ab        #查询包括关键字$所在所有行，使用反斜线\\屏蔽特殊含义 \r\n   \r\n  　　增加一行或多行字符串 \r\n       [root@localhost ruby]# cat ab \r\n       Hello!  \r\n       ruby is me,welcome to my blog.  \r\n       end \r\n       [root@localhost ruby] # sed ''1a drink tea'' ab  #第一行后增加字符串"drink tea" \r\n       Hello!  \r\n       drink tea \r\n       ruby is me,welcome to my blog.  \r\n       end \r\n       [root@localhost ruby] # sed ''1,3a drink tea'' ab #第一行到第三行后增加字符串"drink tea" \r\n       Hello!  \r\n       drink tea \r\n       ruby is me,welcome to my blog.  \r\n       drink tea \r\n       end \r\n       drink tea \r\n       [root@localhost ruby] # sed ''1a drink tea\r\nor coffee'' ab   #第一行后增加多行，使用换行符\r\n \r\n       Hello!  \r\n       drink tea \r\n       or coffee \r\n       ruby is me,welcome to my blog.  \r\n       end \r\n   \r\n  　　代替一行或多行 \r\n       [root@localhost ruby] # sed ''1c Hi'' ab                #第一行代替为Hi \r\n       Hi \r\n       ruby is me,welcome to my blog.  \r\n       end \r\n       [root@localhost ruby] # sed ''1,2c Hi'' ab             #第一行到第二行代替为Hi \r\n       Hi \r\n       end \r\n   \r\n  　　替换一行中的某部分 \r\n  　　格式：sed ''s/要替换的字符串/新的字符串/g''   （要替换的字符串可以用正则表达式） \r\n       [root@localhost ruby] # sed -n ''/ruby/p'' ab | sed ''s/ruby/bird/g''    #替换ruby为bird \r\n  　  [root@localhost ruby] # sed -n ''/ruby/p'' ab | sed ''s/ruby\n   \r\n       插入 \r\n       [root@localhost ruby] # sed -i ''$a bye'' ab         #在文件ab中最后一行直接输入"bye" \r\n       [root@localhost ruby]# cat ab \r\n       Hello!  \r\n       ruby is me,welcome to my blog.  \r\n       end \r\n       bye\nsed ''s/stringa1/stringa2/g'' example.txt 将example.txt文件中的 "string1" 替换成 "string2"\nsed ''/^$/d'' example.txt 从example.txt文件中删除所有空白行\nsed ''/ *#/d; /^$/d'' example.txt 从example.txt文件中删除所有注释和空白行\nsed -e ''1d'' result.txt 从文件example.txt 中排除第一行\nsed -n ''/stringa1/p'' 查看只包含词汇 "string1"的行\nsed -e ''s/ *$//'' example.txt 删除每一行最后的空白字符\nsed -e ''s/stringa1//g'' example.txt 从文档中只删除词汇 "string1" 并保留剩余全部\nsed -n ''1,5p;5q'' example.txt 查看从第一行到第5行内容\nsed -n ''5p;5q'' example.txt 查看第5行\nsed -e ''s/00*/0/g'' example.txt 用单个零替换多个零\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(32, 'awk', 'awk awk 使用说明书\r\n \r\n  变量名 含义 \r\n  ARGC 命令行变元个数 \r\n  ARGV 命令行变元数组 \r\n  FILENAME当前输入文件名 \r\n  FNR 当前文件中的记录号 \r\n  fSum 输入域分隔符，默认为一个空格 \r\n  RS 输入记录分隔符 \r\n  NF 当前记录里域个数 \r\n  NR 到目前为止记录数 \r\n  OFS 输出域分隔符 \r\n  ORS 输出记录分隔符 \r\n   \r\n  1、awk ''/101/''               file 显示文件file中包含101的匹配行。 \r\n     awk ''/101/,/105/''         file \r\n     awk ''$1 == 5''             file \r\n     awk ''$1 == "CT"''          file 注意必须带双引号 \r\n     awk ''$1 * $2 >100 ''       file  \r\n     awk ''$2 >5 && $2<=15''     file \r\n   \r\n   \r\n  2、awk ''{print NR,NF,$1,$NF,}'' file 显示文件file的当前记录号、域数和每一行的第一个和最后一个域。 \r\n     awk ''/101/ {print $1,$2 + 10}'' file 显示文件file的匹配行的第一、二个域加10。 \r\n     awk ''/101/ {print $1$2}''  file \r\n     awk ''/101/ {print $1 $2}'' file 显示文件file的匹配行的第一、二个域，但显示时域中间没有分隔符。 \r\n   \r\n   \r\n  3、df | awk ''$4>1000000 ''         通过管道符获得输入，如：显示第4个域满足条件的行。 \r\n   \r\n   \r\n  4、awk -F "|" ''{print $1}''   file 按照新的分隔符“|”进行操作。 \r\n     awk  ''BEGIN { FS="[:   |]" } \r\n     {print $1,$2,$3}''         file 通过设置输入分隔符（FS="[:   |]"）修改输入分隔符。 \r\n   \r\n     Sep="|" \r\n     awk -F $Sep ''{print $1}''  file 按照环境变量Sep的值做为分隔符。    \r\n     awk -F ''[ :  |]'' ''{print $1}'' file 按照正则表达式的值做为分隔符，这里代表空格、:、TAB、|同时做为分隔符。 \r\n     awk -F ''[][]''    ''{print $1}'' file 按照正则表达式的值做为分隔符，这里代表[、] \r\n   \r\n   \r\n  5、awk -f awkfile        file 通过文件awkfile的内容依次进行控制。 \r\n     cat awkfile \r\n  /101/{print "\\047 Hello! \\047"} --遇到匹配行以后打印 '' Hello! ''.\\047代表单引号。 \r\n  {print $1,$2}                   --因为没有模式控制，打印每一行的前两个域。 \r\n   \r\n   \r\n  6、awk ''$1 ~ /101/ {print $1}'' file 显示文件中第一个域匹配101的行（记录）。 \r\n   \r\n   \r\n  7、awk   ''BEGIN { OFS="%"} \r\n     {print $1,$2}''           file 通过设置输出分隔符（OFS="%"）修改输出格式。 \r\n   \r\n   \r\n  8、awk   ''BEGIN { max=100 ;print "max=" max}             BEGIN 表示在处理任意行之前进行的操作。 \r\n     {max=($1 >max ?$1:max); print $1,"Now max is "max}'' file 取得文件第一个域的最大值。 \r\n     （表达式1?表达式2:表达式3 相当于： \r\n     if (表达式1) \r\n         表达式2 \r\n     else \r\n         表达式3 \r\n     awk ''{print ($1>4 ? "high "$1: "low "$1)}'' file \r\n   \r\n   \r\n  9、awk ''$1 * $2 >100 {print $1}'' file 显示文件中第一个域匹配101的行（记录）。 \r\n   \r\n   \r\n  10、awk ''{$1 == ''Chi'' {$3 = ''China''; print}'' file 找到匹配行后先将第3个域替换后再显示该行（记录）。 \r\n      awk ''{$7 %= 3; print $7}''  file 将第7域被3除，并将余数赋给第7域再打印。 \r\n   \r\n   \r\n  11、awk ''/tom/ {wage=$2+$3; printf wage}'' file 找到匹配行后为变量wage赋值并打印该变量。 \r\n   \r\n   \r\n  12、awk ''/tom/ {count++;}  \r\n           END {print "tom was found "count" times"}'' file END表示在所有输入行处理完后进行处理。 \r\n   \r\n   \r\n  13、awk ''gsub(/\\$/,"");gsub(/,/,""); cost+=$4; \r\n           END {print "The total is $" cost>"filename"}''    file gsub函数用空串替换$和,再将结果输出到filename中。 \r\n      1 2 3 $1,200.00 \r\n      1 2 3 $2,300.00 \r\n      1 2 3 $4,000.00 \r\n   \r\n      awk ''{gsub(/\\$/,"");gsub(/,/,""); \r\n      if ($4>1000&&$4<2000) c1+=$4; \r\n      else if ($4>2000&&$4<3000) c2+=$4; \r\n      else if ($4>3000&&$4<4000) c3+=$4; \r\n      else c4+=$4; } \r\n      END {printf  "c1=[%d];c2=[%d];c3=[%d];c4=[%d]\r\n",c1,c2,c3,c4}"'' file \r\n      通过if和else if完成条件语句 \r\n   \r\n      awk ''{gsub(/\\$/,"");gsub(/,/,""); \r\n      if ($4>3000&&$4<4000) exit; \r\n      else c4+=$4; } \r\n      END {printf  "c1=[%d];c2=[%d];c3=[%d];c4=[%d]\r\n",c1,c2,c3,c4}"'' file \r\n      通过exit在某条件时退出，但是仍执行END操作。 \r\n      awk ''{gsub(/\\$/,"");gsub(/,/,""); \r\n      if ($4>3000) next; \r\n      else c4+=$4; } \r\n      END {printf  "c4=[%d]\r\n",c4}"'' file \r\n      通过next在某条件时跳过该行，对下一行执行操作。 \r\n   \r\n   \r\n  14、awk ''{ print FILENAME,$0 }'' file1 file2 file3>fileall 把file1、file2、file3的文件内容全部写到fileall中，格式为 \r\n      打印文件并前置文件名。 \r\n   \r\n   \r\n  15、awk '' $1!=previous { close(previous); previous=$1 }    \r\n      {print substr($0,index($0," ") +1)>$1}'' fileall 把合并后的文件重新分拆为3个文件。并与原文件一致。 \r\n   \r\n   \r\n  16、awk ''BEGIN {"date"|getline d; print d}''         通过管道把date的执行结果送给getline，并赋给变量d，然后打印。 \r\n   \r\n   \r\n  17、awk ''BEGIN {system("echo \\"Input your name:\\\\c\\""); getline d;print "\r\nYour name is",d,"\\b!\r\n"}'' \r\n      通过getline命令交互输入name，并显示出来。 \r\n      awk ''BEGIN {FS=":"; while(getline< "/etc/passwd" >0) { if($1~"050[0-9]_") print $1}}'' \r\n      打印/etc/passwd文件中用户名包含050x_的用户名。 \r\n   \r\n  18、awk ''{ i=1;while(i<NF) {print NF,$i;i++}}'' file 通过while语句实现循环。 \r\n      awk ''{ for(i=1;i<NF;i++) {print NF,$i}}''   file 通过for语句实现循环。     \r\n      type file|awk -F "/" '' \r\n      { for(i=1;i<NF;i++) \r\n      { if(i==NF-1) { printf "%s",$i } \r\n      else { printf "%s/",$i } }}''               显示一个文件的全路径。 \r\n      用for和if显示日期 \r\n      awk  ''BEGIN { \r\n  for(j=1;j<=12;j++) \r\n  { flag=0; \r\n    printf "\r\n%d月份\r\n",j; \r\n          for(i=1;i<=31;i++) \r\n          { \r\n          if (j==2&&i>28) flag=1; \r\n          if ((j==4||j==6||j==9||j==11)&&i>30) flag=1; \r\n          if (flag==0) {printf "%02d%02d ",j,i} \r\n          } \r\n  } \r\n  }'' \r\n   \r\n   \r\n  19、在awk中调用系统变量必须用单引号，如果是双引号，则表示字符串 \r\n  Flag=abcd \r\n  awk ''{print ''$Flag''}''   结果为abcd \r\n  awk ''{print  "$Flag"}''   结果为$Flag\nawk ''/^(no|so)/'' test-----打印所有以模式no或so开头的行。\nawk ''/^[ns]/{print $1}'' test-----如果记录以n或s开头，就打印这个记录。\nawk ''$1 ~/[0-9][0-9]$/(print $1}'' test-----如果第一个域以两个数字结束就打印这个记录。\nawk ''$1 == 100 || $2 < 50'' test-----如果第一个或等于100或者第二个域小于50，则打印该行。\nawk ''$1 != 10'' test-----如果第一个域不等于10就打印该行。\nawk ''/test/{print $1 + 10}'' test-----如果记录包含正则表达式test，则第一个域加10并打印出来。\nawk ''{print ($1 > 5 ? "ok "$1: "error"$1)}'' test-----如果第一个域大于5则打印问号后面的表达式值，否则打印冒号后面的表达式值。\nawk ''/^root/,/^mysql/'' test----打印以正则表达式root开头的记录到以正则表达式mysql开头的记录范围内的所有记录。如果找到一个新的正则表达式root开头的记 录，则继续打印直到下一个以正则表达式mysql开头的记录为止，或到文件末尾。\nawk ''BEGIN{total=0}{total+=$4}END{print total}'' a.txt   -----对a.txt文件的第四个域进行求和！\nawk 函数说明 \r\n  一、算术函数: \r\n   \r\n  以下算术函数执行与 C 语言中名称相同的子例程相同的操作： \r\n  函数名  说明 \r\n  atan2( y, x )   返回 y/x 的反正切。 \r\n  cos( x )    返回 x 的余弦；x 是弧度。 \r\n  sin( x )    返回 x 的正弦；x 是弧度。 \r\n  exp( x )    返回 x 幂函数。 \r\n  log( x )    返回 x 的自然对数。 \r\n  sqrt( x )   返回 x 平方根。 \r\n  int( x )    返回 x 的截断至整数的值。 \r\n  rand( )     返回任意数字 n，其中 0 <= n < 1。 \r\n  srand( [Expr] )     将 rand 函数的种子值设置为 Expr 参数的值，或如果省略 Expr 参数则使用某天的时间。返回先前的种子值。 \r\n      举例说明： \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{OFMT="%.3f";fs=sin(1);fe=exp(10);fl=log(10);fi=int(3.1415);print fs,fe,fl,fi;}'' \r\n      0.841 22026.466 2.303 3 \r\n   \r\n   \r\n      OFMT 设置输出数据格式是保留3位小数 \r\n   \r\n      获得随机数： \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{srand();fr=int(100*rand());print fr;}'' \r\n      78 \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{srand();fr=int(100*rand());print fr;}'' \r\n      31 \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{srand();fr=int(100*rand());print fr;}'' \r\n   \r\n      41 \r\n   \r\n  二、字符串函数是： \r\n  函数    说明 \r\n  gsub( Ere, Repl, [ In ] )   除了正则表达式所有具体值被替代这点，它和 sub 函数完全一样地执行，。 \r\n  sub( Ere, Repl, [ In ] )    用 Repl 参数指定的字符串替换 In 参数指定的字符串中的由 Ere 参数指定的扩展正则表达式的第一个具体值。sub 函数返回替换的数量。出现在 Repl 参数指定的字符串中的 &（和符号）由 In 参数指定的与 Ere 参数的指定的扩展正则表达式匹配的字符串替换。如果未指定 In 参数，缺省值是整个记录（$0 记录变量）。 \r\n  index( String1, String2 )   在由 String1 参数指定的字符串（其中有出现 String2 指定的参数）中，返回位置，从 1 开始编号。如果 String2 参数不在 String1 参数中出现，则返回 0（零）。 \r\n  length [(String)]   返回 String 参数指定的字符串的长度（字符形式）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 \r\n  blength [(String)]  返回 String 参数指定的字符串的长度（以字节为单位）。如果未给出 String 参数，则返回整个记录的长度（$0 记录变量）。 \r\n  substr( String, M, [ N ] )  返回具有 N 参数指定的字符数量子串。子串从 String 参数指定的字符串取得，其字符以 M 参数指定的位置开始。M 参数指定为将 String 参数中的第一个字符作为编号 1。如果未指定 N 参数，则子串的长度将是 M 参数指定的位置到 String 参数的末尾 的长度。 \r\n  match( String, Ere )    在 String 参数指定的字符串（Ere 参数指定的扩展正则表达式出现在其中）中返回位置（字符形式），从 1 开始编号，或如果 Ere 参数不出现，则返回 0（零）。RSTART 特殊变量设置为返回值。RLENGTH 特殊变量设置为匹配的字符串的长度，或如果未找到任何匹配，则设置为 -1（负一）。 \r\n  split( String, A, [Ere] )   将 String 参数指定的参数分割为数组元素 A[1], A[2], . . ., A[n]，并返回 n 变量的值。此分隔可以通过 Ere 参数指定的扩展正则表达式进行，或用当前字段分隔符（FS 特殊变量）来进行（如果没有给出 Ere 参数）。除非上下文指明特定的元素还应具有一个数字值，否则 A 数组中的元素用字符串值来创建。 \r\n  tolower( String )   返回 String 参数指定的字符串，字符串中每个大写字符将更改为小写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 \r\n  toupper( String )   返回 String 参数指定的字符串，字符串中每个小写字符将更改为大写。大写和小写的映射由当前语言环境的 LC_CTYPE 范畴定义。 \r\n  sprintf(Format, Expr, Expr, . . . )     根据 Format 参数指定的 printf 子例程格式字符串来格式化 Expr 参数指定的表达式并返回最后生成的字符串。 \r\n  Ere都可以是正则表达式 \r\n   \r\n      gsub,sub使用 \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{info="this is a test2010test!";gsub(/[0-9]+/,"!",info);print info}''  \r\n      this is a test!test!  \r\n   \r\n       \r\n   \r\n      在 info中查找满足正则表达式，/[0-9]+/ 用””替换，并且替换后的值，赋值给info 未给info值，默认是$0 \r\n   \r\n       \r\n   \r\n      查找字符串（index使用） \r\n   \r\n      [wangsl@centos5 ~]$ awk ''BEGIN{info="this is a test2010test!";print index(info,"test")?"ok":"no found";}''   \r\n      ok \r\n   \r\n      未找到，返回0 \r\n   \r\n       \r\n   \r\n      正则表达式匹配查找(match使用） \r\n   \r\n      [wangsl@centos5 ~]$ awk ''BEGIN{info="this is a test2010test!";print match(info,/[0-9]+/)?"ok":"no found";}''          \r\n      ok \r\n   \r\n       \r\n   \r\n      截取字符串(substr使用） \r\n   \r\n      [wangsl@centos5 ~]$ awk ''BEGIN{info="this is a test2010test!";print substr(info,4,10);}''                        \r\n      s is a tes \r\n   \r\n      从第 4个 字符开始，截取10个长度字符串 \r\n   \r\n       \r\n   \r\n      字符串分割（split使用） \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{info="this is a test";split(info,tA," ");print length(tA);for(k in tA){print k,tA[k];}}'' \r\n      4 \r\n      4 test \r\n      1 this \r\n      2 is \r\n      3 a \r\n   \r\n       \r\n   \r\n      分割info,动态创建数组tA,这里比较有意思，awk for …in 循环，是一个无序的循环。 并不是从数组下标1…n ，因此使用时候需要注意。 \r\n   \r\n       \r\n   \r\n      格式化字符串输出（sprintf使用） \r\n   \r\n      格式化字符串格式： \r\n   \r\n      其中格式化字符串包括两部分内容: 一部分是正常字符, 这些字符将按原样输出; 另一部分是格式化规定字符, 以"%"开始, 后跟一个或几个规定字符,用来确定输出内容格式。 \r\n   \r\n       \r\n      格式符  说明 \r\n      %d  十进制有符号整数 \r\n      %u  十进制无符号整数 \r\n      %f  浮点数 \r\n      %s  字符串 \r\n      %c  单个字符 \r\n      %p  指针的值 \r\n      %e  指数形式的浮点数 \r\n      %x  %X 无符号以十六进制表示的整数 \r\n      %o  无符号以八进制表示的整数 \r\n      %g  自动选择合适的表示法 \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{n1=124.113;n2=-1.224;n3=1.2345; printf("%.2f,%.2u,%.2g,%X,%o\r\n",n1,n2,n3,n1,n1);}'' \r\n      124.11,18446744073709551615,1.2,7C,174 \r\n   \r\n       \r\n   \r\n  三、一般函数是： \r\n  函数    说明 \r\n  close( Expression )     用同一个带字符串值的 Expression 参数来关闭由 print 或 printf 语句打开的或调用 getline 函数打开的文件或管道。如果文件或管道成功关闭，则返回 0；其它情况下返回非零值。如果打算写一个文件，并稍后在同一个程序中读取文件，则 close 语句是必需的。 \r\n  system(Command )    执行 Command 参数指定的命令，并返回退出状态。等同于 system 子例程。 \r\n  Expression | getline [ Variable ]   从来自 Expression 参数指定的命令的输出中通过管道传送的流中读取一个输入记录，并将该记录的值指定给 Variable 参数指定的变量。如果当前未打开将 Expression 参数的值作为其命令名称的流，则创建流。创建的流等同于调用 popen 子例程，此时 Command 参数取 Expression 参数的值且 Mode 参数设置为一个是 r 的值。只要流保留打开且 Expression 参数求得同一个字符串，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。 \r\n  getline [ Variable ] < Expression   从 Expression 参数指定的文件读取输入的下一个记录，并将 Variable 参数指定的变量设置为该记录的值。只要流保留打开且 Expression 参数对同一个字符串求值，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。 \r\n  getline [ Variable ]    将 Variable 参数指定的变量设置为从当前输入文件读取的下一个输入记录。如果未指定 Variable 参数，则 $0 记录变量设置为该记录的值，还将设置 NF、NR 和 FNR 特殊变量。 \r\n   \r\n   \r\n   \r\n      打开外部文件（close用法） \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{while("cat /etc/passwd"|getline){print $0;};close("/etc/passwd");}'' \r\n      root:x:0:0:root:/root:/bin/bash \r\n      bin:x:1:1:bin:/bin:/sbin/nologin \r\n      daemon:x:2:2:daemon:/sbin:/sbin/nologin \r\n   \r\n       \r\n   \r\n      逐行读取外部文件(getline使用方法） \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{while(getline < "/etc/passwd"){print $0;};close("/etc/passwd");}'' \r\n      root:x:0:0:root:/root:/bin/bash \r\n      bin:x:1:1:bin:/bin:/sbin/nologin \r\n      daemon:x:2:2:daemon:/sbin:/sbin/nologin \r\n   \r\n       \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{print "Enter your name:";getline name;print name;}'' \r\n      Enter your name: \r\n      chengmo \r\n      chengmo \r\n   \r\n        \r\n   \r\n      调用外部应用程序(system使用方法） \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{b=system("ls -al");print b;}'' \r\n      total 42092 \r\n      drwxr-xr-x 14 chengmo chengmo     4096 09-30 17:47 .  \r\n      drwxr-xr-x 95 root   root       4096 10-08 14:01 ..  \r\n   \r\n       \r\n   \r\n      b返回值，是执行结果。 \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n   \r\n  四、时间函数 \r\n   \r\n   \r\n  函数名  说明 \r\n  mktime( YYYY MM DD HH MM SS[ DST])  生成时间格式 \r\n  strftime([format [, timestamp]])    格式化时间输出，将时间戳转为时间字符串 \r\n  具体格式，见下表.  \r\n  systime()   得到时间戳,返回从1970年1月1日开始到当前时间(不计闰年)的整秒数 \r\n   \r\n   \r\n   \r\n      创建指定时间(mktime使用） \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{tstamp=mktime("2001 01 01 12 12 12");print strftime("%c",tstamp);}'' \r\n      2001年01月01日 星期一 12时12分12秒 \r\n   \r\n       \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{tstamp1=mktime("2001 01 01 12 12 12");tstamp2=mktime("2001 02 01 0 0 0");print tstamp2-tstamp1;}'' \r\n      2634468 \r\n   \r\n      求2个时间段中间时间差,介绍了strftime使用方法 \r\n   \r\n       \r\n   \r\n      [chengmo@centos5 ~]$ awk ''BEGIN{tstamp1=mktime("2001 01 01 12 12 12");tstamp2=systime();print tstamp2-tstamp1;}'' \r\n      308201392 \r\n   \r\n       \r\n   \r\n      strftime日期和时间格式说明符 \r\n      格式化时间输出描述 \r\n      %a  星期几的缩写(Sun) \r\n      %A  星期几的完整写法(Sunday) \r\n      %b  月名的缩写(Oct) \r\n      %B  月名的完整写法(October) \r\n      %c  本地日期和时间 \r\n      %d  十进制日期 \r\n      %D  日期 08/20/99 \r\n      %e  日期，如果只有一位会补上一个空格 \r\n      %H  用十进制表示24小时格式的小时 \r\n      %I  用十进制表示12小时格式的小时 \r\n      %j  从1月1日起一年中的第几天 \r\n      %m  十进制表示的月份 \r\n      %M  十进制表示的分钟 \r\n      %p  12小时表示法(AM/PM) \r\n      %S  十进制表示的秒 \r\n      %U  十进制表示的一年中的第几个星期(星期天作为一个星期的开始) \r\n      %w  十进制表示的星期几(星期天是0) \r\n      %W  十进制表示的一年中的第几个星期(星期一作为一个星期的开始) \r\n      %x  重新设置本地日期(08/20/99) \r\n      %X  重新设置本地时间(12：00：00) \r\n      %y  两位数字表示的年(99) \r\n      %Y  当前月份 \r\n      %Z  时区(PDT) \r\n      %%  百分号(%)\nawk 中使用shell中的变量 \r\n   \r\n  一: "''$var''" \r\n   \r\n  这种写法大家无需改变用''括起awk程序的习惯,是老外常用的写法.如: \r\n   \r\n  var="test" \r\n  awk ''BEGIN{print "''$var''"}'' \r\n   \r\n  这种写法其实际是双括号变为单 括号的常量,传递给了awk.  \r\n   \r\n  如果var中含空格,为了shell不把空格作为分格符,便应该如下使用: \r\n   \r\n  var="this is a test" \r\n  awk ''BEGIN{print "''"$var"''"}'' \r\n  二: ''"$var"'' \r\n   \r\n  这种写法与上一种类似.如果变量含空格,则变为''""$var""''较为可靠.  \r\n  三: export变量,使用ENVIRON["var"]形式,获取环境变量的值 \r\n   \r\n  例如: \r\n  var="this is a test"; export var; \r\n   \r\n  awk ''BEGIN{print ENVIRON["var"]}'' \r\n  四:可以使用awk的-v选项 （如果变量个数不多，个人偏 向于这种写法） \r\n   \r\n  例如: \r\n  var="this is a test" \r\n  awk -v awk_var="$var" ''BEGIN {print awk_var}'' \r\n   \r\n  这样便把系统变量var传递给了awk变量awk_var.  \r\n   \r\n   \r\n   \r\n   awk向shell变量传递值 \r\n   \r\n  “由awk向shell传递变量”，其思想无非是用awk(sed/perl等也是一样)输出若干条shell命令，然后再用shell去执行这些命令。 \r\n   \r\n  eval $(awk ''BEGIN{print "var1=''str1'';var2=''str2''"}'') \r\n   \r\n  或者eval $(awk ''{printf("var1=%s; var2=%s; var3=%s;",$1,$2,$3)}'' abc.txt) \r\n   \r\n  之后可以在当前shell中使用var1,var2等变量了。 \r\n   \r\n  echo "var1=$var1 ----- var2=$var2"\n', ''),
(33, 'iptables', 'iptables iptables 使用说明书 \r\n \r\n  一：前言 \r\n   \r\n  防火墙，其实说白了讲，就是用于实现Linux下访问控制的功能的，它分为硬件的或者软件的防火墙两种。无论是在哪个网络中，防火墙工作的地方一定是在网络的边缘。而我们的任务就是需要去定义到底防火墙如何工作，这就是防火墙的策略，规则，以达到让它对出入网络的IP、数据进行检测。 \r\n   \r\n  目前市面上比较常见的有3、4层的防火墙，叫网络层的防火墙，还有7层的防火墙，其实是代理层的网关。 \r\n   \r\n  对于TCP/IP的七层模型来讲，我们知道第三层是网络层，三层的防火墙会在这层对源地址和目标地址进行检测。但是对于七层的防火墙，不管你源端口或者目标端口，源地址或者目标地址是什么，都将对你所有的东西进行检查。所以，对于设计原理来讲，七层防火墙更加安全，但是这却带来了效率更低。所以市面上通常的防火墙方案，都是两者结合的。而又由于我们都需要从防火墙所控制的这个口来访问，所以防火墙的工作效率就成了用户能够访问数据多少的一个最重要的控制，配置的不好甚至有可能成为流量的瓶颈。 \r\n   \r\n  二：iptables 的历史以及工作原理 \r\n   \r\n  1.iptables的发展: \r\n   \r\n  1iptables的前身叫ipfirewall （内核1.x时代）,这是一个作者从freeBSD上移植过来的，能够工作在内核当中的，对数据包进行检测的一款简易访问控制工具。但是ipfirewall工作功能极其有限(它需要将所有的规则都放进内核当中，这样规则才能够运行起来，而放进内核，这个做法一般是极其困难的)。当内核发展到2.x系列的时候，软件更名为ipchains，它可以定义多条规则，将他们串起来，共同发挥作用，而现在，它叫做iptables，可以将规则组成一个列表，实现绝对详细的访问控制功能。 \r\n   \r\n  1iptables他们都是工作在用户空间中，定义规则的工具，本身并不算是防火墙。它们定义的规则，可以让在内核空间当中的netfilter来读取，并且实现让防火墙工作。而放入内核的地方必须要是特定的位置，必须是tcp/ip的协议栈经过的地方。而这个tcp/ip协议栈必须经过的地方，可以实现读取规则的地方就叫做 netfilter.(网络过滤器) \r\n   \r\n      作者一共在内核空间中选择了5个位置， \r\n      1.内核空间中：从一个网络接口进来，到另一个网络接口去的 \r\n      2.数据包从内核流入用户空间的 \r\n      3.数据包从用户空间流出的 \r\n      4.进入/离开本机的外网接口 \r\n      5.进入/离开本机的内网接口 \r\n          \r\n  2.iptables的工作机制 \r\n   \r\n  2从上面的发展我们知道了作者选择了5个位置，来作为控制的地方，但是你有没有发现，其实前三个位置已经基本上能将路径彻底封锁了，但是为什么已经在进出的口设置了关卡之后还要在内部卡呢？ 由于数据包尚未进行路由决策，还不知道数据要走向哪里，所以在进出口是没办法实现数据过滤的。所以要在内核空间里设置转发的关卡，进入用户空间的关卡，从用户空间出去的关卡。那么，既然他们没什么用，那我们为什么还要放置他们呢？因为我们在做NAT和DNAT的时候，目标地址转换必须在路由之前转换。所以我们必须在外网而后内网的接口处进行设置关卡。        \r\n   \r\n  2 这五个位置也被称为五个钩子函数（hook functions）,也叫五个规则链。 \r\n  cp1.PREROUTING (路由前) \r\n  22.INPUT (数据包流入口) \r\n  cp13.FORWARD (转发管卡) \r\n  224.OUTPUT(数据包出口) \r\n  cp135.POSTROUTING（路由后） \r\n          这是NetFilter规定的五个规则链，任何一个数据包，只要经过本机，必将经过这五个链中的其中一个链。       \r\n   \r\n  3.防火墙的策略 \r\n   \r\n  3防火墙策略一般分为两种，一种叫“通”策略，一种叫“堵”策略，通策略，默认门是关着的，必须要定义谁能进。堵策略则是，大门是洞开的，但是你必须有身份认证，否则不能进。所以我们要定义，让进来的进来，让出去的出去，所以通，是要全通，而堵，则是要选择。当我们定义的策略的时候，要分别定义多条功能，其中：定义数据包中允许或者不允许的策略，filter过滤的功能，而定义地址转换的功能的则是nat选项。为了让这些功能交替工作，我们制定出了“表”这个定义，来定义、区分各种不同的工作功能和处理方式。 \r\n   \r\n  3我们现在用的比较多个功能有3个： \r\n  cp1351.filter 定义允许或者不允许的 \r\n  32.nat 定义地址转换的 \r\n                  3.mangle功能:修改报文原数据 \r\n   \r\n  32我们修改报文原数据就是来修改TTL的。能够实现将数据包的元数据拆开，在里面做标记/修改内容的。而防火墙标记，其实就是靠mangle来实现的。 \r\n   \r\n  小扩展: \r\n  对于filter来讲一般只能做在3个链上：INPUT ，FORWARD ，OUTPUT \r\n  对于nat来讲一般也只能做在3个链上：PREROUTING ，OUTPUT ，POSTROUTING \r\n  而mangle则是5个链都可以做：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING \r\n   \r\n  iptables/netfilter（这款软件）是工作在用户空间的，它可以让规则进行生效的，本身不是一种服务，而且规则是立即生效的。而我们iptables现在被做成了一个服务，可以进行启动，停止的。启动，则将规则直接生效，停止，则将规则撤销。 \r\n  iptablesiptables还支持自己定义链。但是自己定义的链，必须是跟某种特定的链关联起来的。在一个关卡设定，指定当有数据的时候专门去找某个特定的链来处理，当那个链处理完之后，再返回。接着在特定的链中继续检查。 \r\n   \r\n  注意：规则的次序非常关键，谁的规则越严格，应该放的越靠前，而检查规则的时候，是按照从上往下的方式进行检查的。 \r\n   \r\n  三．规则的写法: \r\n   \r\n   iptables定义规则的方式比较复杂: \r\n   格式：iptables [-t table] COMMAND chain CRETIRIA -j ACTION \r\n   -t table ：3个filter nat mangle \r\n   COMMAND：定义如何对规则进行管理 \r\n   chain：指定你接下来的规则到底是在哪个链上操作的，当定义策略的时候，是可以省略的 \r\n   CRETIRIA:指定匹配标准 \r\n   -j ACTION :指定如何进行处理 \r\n   \r\n  able 比如：不允许172.16.0.0/24的进行访问。 \r\n  able iptables -t filter -A INPUT -s 172.16.0.0/16 -p udp --dport 53 -j DROP \r\n  able 当然你如果想拒绝的更彻底： \r\n  able iptables -t filter -R INPUT 1 -s 172.16.0.0/16 -p udp --dport 53 -j REJECT \r\n   \r\n  able iptables -L -n -v2a#查看定义规则的详细信息 \r\n   \r\n  四：详解COMMAND: \r\n   \r\n  1.链管理命令（这都是立即生效的） \r\n  1-P :设置默认策略的（设定默认门是关着的还是开着的） \r\n  默认策略一般只有两种 \r\n  1iptables -P INPUT (DROP|ACCEPT)  默认是关的/默认是开的 \r\n  比如： \r\n  1iptablesiptables -P INPUT DROP 这就把默认规则给拒绝了。并且没有定义哪个动作，所以关于外界连接的所有规则包括Xshell连接之类的，远程连接都被拒绝了。 \r\n          -F: FLASH，清空规则链的(注意每个链的管理权限) \r\n  1iptablesiptables    iptables -t nat -F PREROUTING \r\n  1iptablesiptables    iptables -t nat -F 清空nat表的所有链 \r\n          -N:NEW 支持用户新建一个链 \r\n              iptables -N inbound_tcp_web 表示附在tcp表上用于检查web的。 \r\n          -X: 用于删除用户自定义的空链 \r\n              使用方法跟-N相同，但是在删除之前必须要将里面的链给清空昂了 \r\n          -E：用来Rename chain主要是用来给用户自定义的链重命名 \r\n              -E oldname newname \r\n           -Z：清空链，及链中默认规则的计数器的（有两个计数器，被匹配到多少个数据包，多少个字节） \r\n              iptables -Z :清空 \r\n   \r\n  2.规则管理命令 \r\n           -A：追加，在当前链的最后新增一个规则 \r\n           -I num : 插入，把当前规则插入为第几条。 \r\n              -I 3 :插入为第三条 \r\n           -R num：Replays替换/修改第几条规则 \r\n              格式：iptables -R 3 ………… \r\n           -D num：删除，明确指定删除第几条规则 \r\n          \r\n  3.查看管理命令 “-L” \r\n  3 附加子命令 \r\n  3 -n：以数字的方式显示ip，它会将ip直接显示出来，如果不加-n，则会将ip反向解析成主机名。 \r\n  3 -v：显示详细信息 \r\n  3 -vv \r\n  3 -vvv :越多越详细 \r\n  3 -x：在计数器上显示精确值，不做单位换算 \r\n  3 --line-numbers : 显示规则的行号 \r\n  3 -t nat：显示所有的关卡的信息 \r\n   \r\n  五：详解匹配标准 \r\n   \r\n  1.通用匹配：源地址目标地址的匹配 \r\n  1 -s：指定作为源地址匹配，这里不能指定主机名称，必须是IP \r\n  IP | IP/MASK | 0.0.0.0/0.0.0.0 \r\n  1而且地址可以取反，加一个“!”表示除了哪个IP之外 \r\n  1 -d：表示匹配目标地址 \r\n  1 -p：用于匹配协议的（这里的协议通常有3种，TCP/UDP/ICMP） \r\n\\TCP -i eth0：从这块网卡流入的数据 \r\n  1流入一般用在INPUT和PREROUTING上 \r\n  1 -o eth0：从这块网卡流出的数据 \r\n\\TCP流出一般在OUTPUT和POSTROUTING上 \r\n          \r\n  2.扩展匹配 \r\n  2.1隐含扩展：对协议的扩展 \r\n      -p tcp :TCP协议的扩展。一般有三种扩展 \r\n\\TCP--dport XX-XX：指定目标端口,不能指定多个非连续端口,只能指定单个端口，比如 \r\n\\TCP--dport 21  或者 --dport 21-23 (此时表示21,22,23) \r\n\\TCP--sport：指定源端口 \r\n\\TCP--tcp-fiags：TCP的标志位（SYN,ACK，FIN,PSH，RST,URG） \r\n\\TCP    对于它，一般要跟两个参数： \r\n  cp1.检查的标志位 \r\n\\TCP2.必须为1的标志位 \r\n  cp1--tcpflags syn,ack,fin,rst syn   =    --syn \r\n  cp1表示检查这4个位，这4个位中syn必须为1，其他的必须为0。所以这个意思就是用于检测三次握手的第一次包的。对于这种专门匹配第一包的SYN为1的包，还有一种简写方式，叫做--syn \r\n      -p udp：UDP协议的扩展 \r\n          --dport \r\n          --sport \r\n      -p icmp：icmp数据报文的扩展 \r\n          --icmp-type： \r\n  cp1echo-request(请求回显)，一般用8 来表示 \r\n  ype所以 --icmp-type 8 匹配请求回显数据包 \r\n  cp1echoecho-reply （响应的数据包）一般用0来表示 \r\n                    \r\n  2.2显式扩展（-m） \r\n       扩展各种模块 \r\n        -m multiport：表示启用多端口扩展 \r\n        之后我们就可以启用比如 --dports 21,23,80 \r\n                    \r\n          \r\n  六：详解-j ACTION \r\n   \r\n   常用的ACTION： \r\n   DROP：悄悄丢弃 \r\n  2一般我们多用DROP来隐藏我们的身份，以及隐藏我们的链表 \r\n  2 REJECT：明示拒绝 \r\n  2 ACCEPT：接受 \r\n  custom_chain：转向一个自定义的链 \r\n  custom_chain DNAT \r\n  custom_chain SNAT \r\n  custom_chain MASQUERADE：源地址伪装 \r\n  custom_chain REDIRECT：重定向：主要用于实现端口重定向 \r\n  custom_chain MARK：打防火墙标记的 \r\n  custom_chain RETURN：返回 \r\n  2在自定义链执行完毕后使用返回，来返回原规则链。 \r\n   \r\n  练习题1： \r\n       只要是来自于172.16.0.0/16网段的都允许访问我本机的172.16.100.1的SSHD服务 \r\n       分析：首先肯定是在允许表中定义的。因为不需要做NAT地址转换之类的，然后查看我们SSHD服务，在22号端口上，处理机制是接受，对于这个表，需要有一来一回两个规则，如果我们允许也好，拒绝也好，对于访问本机服务，我们最好是定义在INPUT链上，而OUTPUT再予以定义就好。(会话的初始端先定义)，所以加规则就是： \r\n       定义进来的： iptables -t filter -A INPUT -s 172.16.0.0/16 -d 172.16.100.1 -p tcp --dport 22 -j ACCEPT \r\n       定义出去的： iptables -t filter -A OUTPUT -s 172.16.100.1 -d 172.16.0.0/16 -p tcp --dport 22 -j ACCEPT \r\n       将默认策略改成DROP: \r\n  custom_chain  iptables -P INPUT DROP \r\n  2  iptables -P OUTPUT DROP \r\n    iptables -P FORWARD DROP \r\n          \r\n  七：状态检测： \r\n   \r\n  是一种显式扩展，用于检测会话之间的连接关系的，有了检测我们可以实现会话间功能的扩展 \r\n          什么是状态检测？对于整个TCP协议来讲，它是一个有连接的协议，三次握手中，第一次握手，我们就叫NEW连接，而从第二次握手以后的，ack都为1，这是正常的数据传输，和tcp的第二次第三次握手，叫做已建立的连接（ESTABLISHED）,还有一种状态，比较诡异的，比如：SYN=1 ACK=1 RST=1,对于这种我们无法识别的，我们都称之为INVALID无法识别的。还有第四种，FTP这种古老的拥有的特征，每个端口都是独立的，21号和20号端口都是一去一回，他们之间是有关系的，这种关系我们称之为RELATED。 \r\n  cp所以我们的状态一共有四种： \r\n          NEW \r\n          ESTABLISHED \r\n          RELATED \r\n          INVALID \r\n   \r\n  cp所以我们对于刚才的练习题，可以增加状态检测。比如进来的只允许状态为NEW和ESTABLISHED的进来，出去只允许ESTABLISHED的状态出去，这就可以将比较常见的反弹式木马有很好的控制机制。 \r\n          \r\n  对于练习题的扩展： \r\n  进来的拒绝出去的允许，进来的只允许ESTABLISHED进来，出去只允许ESTABLISHED出去。默认规则都使用拒绝 \r\n  cpiptables -L -n --line-number  ：查看之前的规则位于第几行 \r\n      改写INPUT \r\n          iptables -R INPUT 2 -s 172.16.0.0/16 -d 172.16.100.1 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT \r\n          iptables -R OUTPUT 1 -m state --state ESTABLISHED -j ACCEPT \r\n   \r\n      此时如果想再放行一个80端口如何放行呢？ \r\n          iptables -A INPUT -d 172.16.100.1 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT \r\n   \r\n          iptables -R INPUT 1 -d 172.16.100.1 -p udp --dport 53 -j ACCEPT \r\n   \r\n  练习题2： \r\n  假如我们允许自己ping别人，但是别人ping自己ping不通如何实现呢？ \r\n  分析：对于ping这个协议，进来的为8（ping），出去的为0(响应).我们为了达到目的，需要8出去,允许0进来 \r\n   \r\n  在出去的端口上：iptables -A OUTPUT -p icmp --icmp-type 8 -j ACCEPT \r\n  在进来的端口上：iptables -A INPUT -p icmp --icmp-type 0 -j ACCEPT \r\n   \r\n  小扩展：对于127.0.0.1比较特殊，我们需要明确定义它 \r\n  cpiptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT \r\n  ypeiptables -A OUTPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT \r\n   \r\n  八：SNAT和DNAT的实现 \r\n   \r\n  由于我们现在IP地址十分紧俏，已经分配完了，这就导致我们必须要进行地址转换，来节约我们仅剩的一点IP资源。那么通过iptables如何实现NAT的地址转换呢？ \r\n   \r\n  1.SNAT基于原地址的转换 \r\n  1基于原地址的转换一般用在我们的许多内网用户通过一个外网的口上网的时候，这时我们将我们内网的地址转换为一个外网的IP，我们就可以实现连接其他外网IP的功能。 \r\n  所以我们在iptables中就要定义到底如何转换： \r\n  定义的样式： \r\n  比如我们现在要将所有192.168.10.0网段的IP在经过的时候全都转换成172.16.100.1这个假设出来的外网地址： \r\n  iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SNAT --to-source 172.16.100.1 \r\n  o这样，只要是来自本地网络的试图通过网卡访问网络的，都会被统统转换成172.16.100.1这个IP.  \r\n  o那么，如果172.16.100.1不是固定的怎么办？ \r\n  o我们都知道当我们使用联通或者电信上网的时候，一般它都会在每次你开机的时候随机生成一个外网的IP，意思就是外网地址是动态变换的。这时我们就要将外网地址换成 MASQUERADE(动态伪装):它可以实现自动寻找到外网地址，而自动将其改为正确的外网地址。所以，我们就需要这样设置： \r\n           iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j MASQUERADE \r\n           这里要注意：地址伪装并不适用于所有的地方。 \r\n   \r\n  2.DNAT目标地址转换 \r\n  2对于目标地址转换，数据流向是从外向内的，外面的是客户端，里面的是服务器端通过目标地址转换，我们可以让外面的ip通过我们对外的外网ip来访问我们服务器不同的服务器，而我们的服务却放在内网服务器的不同的服务器上。 \r\n   \r\n      如何做目标地址转换呢？： \r\n  oiptables -t nat -A PREROUTING -d 192.168.10.18 -p tcp --dport 80 -j DNAT --todestination 172.16.100.2 \r\n          目标地址转换要做在到达网卡之前进行转换,所以要做在PREROUTING这个位置上 \r\n   \r\n  九：控制规则的存放以及开启 \r\n   \r\n  注意：你所定义的所有内容，当你重启的时候都会失效，要想我们能够生效，需要使用一个命令将它保存起来 \r\n  1.service iptables save 命令 \r\n  它会保存在/etc/sysconfig/iptables这个文件中 \r\n      2.iptables-save 命令 \r\n  1iptables-save > /etc/sysconfig/iptables \r\n   \r\n      3.iptables-restore 命令 \r\n  1开机的时候，它会自动加载/etc/sysconfig/iptabels \r\n  如果开机不能加载或者没有加载，而你想让一个自己写的配置文件（假设为iptables.2）手动生效的话： \r\n  1iptablesiptables-restore < /etc/sysconfig/iptables.2 \r\n  1则完成了将iptables中定义的规则手动生效 \r\n   \r\n   \r\n  十：总结 \r\n           Iptables是一个非常重要的工具，它是每一个防火墙上几乎必备的设置，也是我们在做大型网络的时候，为了很多原因而必须要设置的。学好Iptables,可以让我们对整个网络的结构有一个比较深刻的了解，同时，我们还能够将内核空间中数据的走向以及linux的安全给掌握的非常透彻。我们在学习的时候，尽量能结合着各种各样的项目，实验来完成，这样对你加深iptables的配置，以及各种技巧有非常大的帮助。\niptables -A INPUT -p tcp --dport 22 -j ACCEPT\niptables -A OUTPUT -p tcp --sport 22 -j ACCEPT \r\n  1、为了能采用远程SSH登陆,我们要开启22端口. (注:这个规则,如果你把OUTPUT 设置成DROP的就要写上这一部,好多人都是望了写这一部规则导致,始终无法SSH.在远程一下,是不是好了.）\niptables -A INPUT -p icmp -j ACCEPT    (INPUT设置成DROP的话)\niptables -A OUTPUT -p icmp -j ACCEPT (OUTPUT设置成DROP的话) \r\n  1、允许icmp包通过,也就是允许ping\niptables -A FORWARD -f -m limit --limit 100/s --limit-burst 100 -j ACCEPT \r\n  处理IP碎片数量,防止攻击,允许每秒100个\niptables -A FORWARD -p icmp -m limit --limit 1/s --limit-burst 10 -j ACCEPT \r\n  设置ICMP包过滤,允许每秒1个包,限制触发条件是10个包.\niptables -A INPUT     -m state --state INVALID -j DROP \r\n   drop非法连接\niptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADE \r\n  将源地址是 192.168.0.0/24 的数据包进行地址伪装\niptables -t nat -A PREROUTING -p tcp --dport 3307 -j DNAT --to 172.16.201.241:3306  （将172.16.201.244 3307的目标地址改为 172.16.201.241的3306 端口上 ）\niptables -t nat -A POSTROUTING -o eth3 -j MASQUERADE \r\n   以上两条实现IP和端口转发\niptables 小结 \r\n     Firewall： \r\n       rules、policy \r\n     防火墙分类： \r\n       工作在三层的网络防火墙、七层防火墙    \r\n      NetFilter： \r\n        hook functions 五个“钩子函数” \r\n         chains \r\n          PREROUTINT 路由前的 \r\n          INPUT  数据包包的流入接口 \r\n          FORWARD 转发 \r\n          OUTPUT 由本机出来的 \r\n          POSTROUTING 路由后的 \r\n        防火墙策略：“通”、“堵” ： 通就全通，堵只需单堵 \r\n        允许/不允许：filter \r\n        地址转换：nat \r\n        修改报文原数据：mangle \r\n        使用表来实现同一个链上的不同规则 \r\n        \r\n        三表五链 \r\n          filter ：INPUT,FORWARD,OUTPUT \r\n          nat    ：PREROUTING OUTPUT POSTROUTING \r\n          mngle  : PREROUTING INPUT FORWARD OUTPUT POSTROUTING \r\n   \r\n   \r\n        iptables定义规则 \r\n        iptables [-t table(默认filter)] COMMAND chain CRETIRIA(匹配规则) -j ACTION \r\n            COMMAND: \r\n               链管理命令： \r\n                  -P ：设置默认策略 \r\n                      # iptables -P INPUT {DROP|ACCEPT} \r\n                  -F : flush 清空规则链的 \r\n                      # iptables -t nat -F PREROUTING \r\n                  -N :new 新建一个链 \r\n                      # iptables -N inbound_tcp_web \r\n                  -X ：删除用户自定义的空链，删除之前清空里面的规则 \r\n                  -E : 给用户自定义的链重命名 \r\n                  -Z ：清空链默认规则及链中规的计数器的 \r\n               规则管理命令： \r\n                  -A ：在当前的链中最后追加 \r\n                  -I num：插入为第num条 \r\n                  -R num：修改规则,替换 \r\n                     # iptables -R -num +新规则 \r\n                  -D num:删除，指定删除第num条                \r\n               查看命令： \r\n                  -L ：list 查看 \r\n                     -n 以数字方式显示，不进行解析 \r\n                     -v 详细信息 \r\n                     -vv \r\n                     -vvv \r\n                     -x 计数器的精确值，不做单位换算 \r\n                     --line-numbers :显示行号   \r\n            匹配标准 \r\n              通用匹配： \r\n                  -s,--source,-src :做原地址匹配源码天空，不能使用主机名，使用ip \r\n                       eg: IP,NETWORK/NETMASK,0.0.0.0/0.0.0.0 \r\n                  -d :匹配目标地址 \r\n                  -p ：匹配协议的｛tcp|udp|icmp｝ \r\n                  -i eth0: inbount流入的 \r\n                  -o eth0：流出的接口 \r\n              扩展匹配： \r\n                隐含扩展： \r\n                  -p tcp \r\n                      --dport ：目标端口 \r\n                      --sport : 源端口 \r\n                      --tcp-flags:tcp的标志位  SYN.ACK.FIN.PSH.RST.URG.  \r\n                         --tcp-flags  检查的标志位 必须为1的标志位 \r\n                          eg:--tcp-flags syn,ack,fin,rst   syn  ==--syn\n                  -p udp \r\n                     --dport \r\n                     --sport \r\n                  -p icmp \r\n                     --icmp-type 8 \r\n                       echo-request ==8  ping出去的数据包 \r\n                       echo-reply ==0  ping的相应 \r\n                显式扩展         \r\n                   使用各种扩展模块 \r\n                     -p tcp -m multiport --drops 21,23,80 \r\n             ACTION \r\n                -j  ACTION  \r\n                    DROP   悄悄拒绝 \r\n                    REJECT 明确拒绝 \r\n                    ACCEPT 接受 \r\n                    custom_chain \r\n                    DNAT 目标nat \r\n                    SNAT 原nat \r\n                    MASQUERADE 地址伪装 \r\n                    REDIRECT重定向 \r\n                    MARK 标记 \r\n                    RETURN    \r\n   state状态 \r\n     NEW \r\n     ESTABLSHED \r\n     RELATED \r\n     INVALID                \r\n                    \r\n  service iptables save 保存 \r\n  默认保存在/etc/sysconfig/iptables \r\n   \r\n  iptable-save > /etc/sysconfig/iptables.2 保存到指定的文件中 \r\n   \r\n  iptables-restore < /etc/sysconfig/iptables.2 启动文件iptables.2里面定义的规则 \r\n   \r\n                     \r\n  iptables实现nat： \r\n   源地址转换 \r\n   iptables -t nat -A  POSTROUTING -s NETWORK/PREFIX  -j SNAT --to-source  Internet_IP              \r\n   如果地址不是固定的，使用MASQUERADE来伪装地址 \r\n    iptables -t nat -A  POSTROUTING -s 192.168.0.0/24 -j  MASQUERADE                  \r\n   目标 地址转换 \r\n     iptables -t nat -A PREROUTING -d INternet_fa  -p tcp --dport 80 -j DNAT --to-destination NEI_IP\n', ''),
(34, 'find', 'find find . -maxdepth 1 -name *.jpg -print -exec convert "{}" -resize 80x60 "thumbs/{}" \\; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick)\nfind / -name file1 从 ''/'' 开始进入根文件系统搜索文件和目录\nfind / -user user1 搜索属于用户 ''user1'' 的文件和目录\nfind /home/user1 -name \\*.bin 在目录 ''/ home/user1'' 中搜索带有''.bin'' 结尾的文件\nfind /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件\nfind /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件\nfind / -name \\*.rpm -exec chmod 755 ''{}'' \\; 搜索以 ''.rpm'' 结尾的文件并定义其权限\nfind / -xdev -name \\*.rpm 搜索以 ''.rpm'' 结尾的文件，忽略光驱、捷盘等可移动设备\nfind / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件\nfind /home/user1 -name ''*.txt'' | xargs cp -av --target-directory=/home/backup/ --parents 从一个目录查找并复制所有以 ''.txt'' 结尾的文件到另一个目录\nfind /var/log -name ''*.log'' | tar cv --files-from=- | bzip2 > log.tar.bz2 查找所有以 ''.log'' 结尾的文件并做成一个bzip包\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(35, 'brctl', 'brctl brctl 网桥使用说明\r\n \r\n    什么是网桥 \r\n   \r\n    网桥是一种在链路层实现中继，对帧进行转发的技术，根据MAC分区块，可隔离碰撞，将网络的多个网段在数据链路层连接起来的网络设备。 \r\n   \r\n    Linux 网桥配置命令：brctl \r\n   \r\n    在Linux中配置网络一般使用 brctl 命令，使用此命令首先要安装：bridge-utils软件包。 \r\n   \r\n    [inbi@debian~]#apt-get install bridge-utils \r\n   \r\n    [inbi@debian~]#modprobe bridge \r\n   \r\n    [inbi@debian~]#echo "1">/proc/sys/net/ipv4/ip_forward \r\n   \r\n    #安装bridge-utils软件包，并加载bridge模块和开启内核转发。 \r\n   \r\n    [inbi@debian~]#brctl \r\n   \r\n    #直接输入brctl命令将显示帮助信息！ \r\n   \r\n    Usage: brctl [commands] \r\n   \r\n    commands: \r\n            addbr bridge的名称  #添加bridge； \r\n   \r\n      delbr bridge的名称              #删除bridge； \r\n   \r\n      addif bridge的名称device的名称#添加接口到bridge； \r\n   \r\n      delif bridge的名称device的名称#从bridge中删除接口 \r\n   \r\n      setageing bridge的名称时间     #设置老化时间，即生存周期 \r\n   \r\n      setbridgeprio bridge的名称 优先级#设置bridge的优先级 \r\n   \r\n      setfd bridge的名称时间         #设置bridge转发延迟时间 \r\n   \r\n      sethello bridge的名称时间      #设置hello时间 \r\n   \r\n      setmaxage bridge的名称时间     #设置消息的最大生命周期 \r\n   \r\n      setpathcost bridge的名称 端口 权重#设置路径的权值 \r\n   \r\n      setportprio bridge的名称 端口 优先级#设置端口的优先级 \r\n   \r\n      show     #显示bridge列表 \r\n   \r\n      showmacs bridge的名称  #显示MAC地址 \r\n   \r\n      showstp  bridge的名称           #显示bridge的stp信息 \r\n   \r\n      stp bridge的名称{on|off}       #开/关stp \r\n   \r\n     \r\n   \r\n  一、  增加网桥 \r\n   \r\n   \r\n    [inbi@debian~]#brctl addbr br0 \r\n   \r\n    #增加一个网桥 \r\n   \r\n    [inbi@debian~]#ifconfig eth0 0.0.0.0 promisc \r\n   \r\n    [inbi@debian~]#ifconfig eth1 0.0.0.0 promisc \r\n   \r\n    [inbi@debian~]#brctl addif br0 eth0 eth1 \r\n   \r\n    #将两块已有的网卡添加到网桥，此时这两个网卡工作于混杂模式，所以不需要IP了，因为网桥是工作在链路层的。 \r\n   \r\n    [inbi@debian~]#brctl show \r\n   \r\n    #查看已有网桥 \r\n   \r\n     \r\n   \r\n    你也可以为 br0 设置一个IP，已访问这台机器。 \r\n   \r\n    [inbi@debian~]#ifconfig br0 10.10.1.1 netmask 255.255.0.0 up \r\n   \r\n  二、  删除网桥 \r\n   \r\n    [inbi@debian~]#brctl delif br0 eth0 eth1 \r\n   \r\n    #增加网桥中的接口 \r\n   \r\n    [inbi@debian~]#brctl delbr br0 \r\n   \r\n    #删除网桥 \r\n   \r\n  三、  关闭网桥 \r\n   \r\n     \r\n   \r\n    [inbi@debian~]#brctl stp br0 off \r\n   \r\n    #关闭生成树协议，减少数据包污染，因为我这里只有一个路由器哦！ \r\n   \r\n  四、  配置桥开机激活 \r\n   \r\n     \r\n   \r\n    [inbi@debian~]#echo "modprobe bridge">>/etc/rc.local \r\n   \r\n    #开机加载 bridge 模块，或者echo "bridge">>/etc/modules \r\n   \r\n    [inbi@debian~]#cp /etc/network/interfaces /etc/network/interfaces.default \r\n   \r\n    #备份下，方便以后使用啊！ \r\n   \r\n    [inbi@debian~]#vim /etc/network/interfaces \r\n   \r\n    auto lo eth0 eth1 br0 \r\n   \r\n    iface lo inet loopback \r\n   \r\n    iface br0 inet static \r\n   \r\n        address 10.10.10.1 \r\n   \r\n        netmask 255.255.0.0 \r\n   \r\n        gateway 10.10.10.254 \r\n   \r\n        pre-up ip link set eth0 promisc on \r\n   \r\n        pre-up ip link set eth1 promisc on \r\n   \r\n        pre-up echo "1">/proc/sys/net/ipv4/ip_forward \r\n   \r\n        bridge_ports eth0 eth1 \r\n   \r\n    #配置eth0 eth1 br0开机启动，eth0，eth1未设置IP信息，在启动br0网卡时，开启了eth0，eth1的混杂模式，并桥接了它们。\n', ''),
(36, 'fuser', 'fuser fuser -km /mnt/hda2 当设备繁忙时强制卸载\n', ''),
(37, 'dpkg', 'dpkg dpkg-query -W -f=''${Installed-Size;10}t${Package}n'' | sort -k1,1n 以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统)\ndpkg -i package.deb 安装/更新一个 deb 包\ndpkg -r package_name 从系统删除一个 deb 包\ndpkg -l 显示系统中所有已经安装的 deb 包\ndpkg -l | grep httpd 显示所有名称中包含 "httpd" 字样的deb包\ndpkg -s package_name 获得已经安装在系统中一个特殊包的信息\ndpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表\ndpkg --contents package.deb 显示尚未安装的一个包所提供的文件列表\ndpkg -S /bin/ping 确认所给的文件由哪个deb包提供\n', ''),
(38, 'git', 'git git 常用命令 \r\n  Git查看、添加、提交、删除、找回，重置修改文件 \r\n   \r\n    git help <command> # 显示command的help \r\n   \r\n    git show # 显示某次提交的内容 git show $id \r\n   \r\n    git co -- <file> # 抛弃工作区修改 \r\n   \r\n    git co . # 抛弃工作区修改 \r\n   \r\n    git add <file> # 将工作文件修改提交到本地暂存区 \r\n   \r\n    git add . # 将所有修改过的工作文件提交暂存区 \r\n   \r\n    git rm <file> # 从版本库中删除文件 \r\n   \r\n    git rm <file> --cached # 从版本库中删除文件，但不删除文件 \r\n   \r\n    git reset <file> # 从暂存区恢复到工作文件 \r\n   \r\n    git reset -- . # 从暂存区恢复到工作文件 \r\n   \r\n    git reset --hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改 \r\n   \r\n    git ci <file> git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做　git ci -am "some comments" \r\n   \r\n    git ci --amend # 修改最后一次提交记录 \r\n   \r\n    git revert <$id> # 恢复某次提交的状态，恢复动作本身也创建次提交对象 \r\n   \r\n    git revert HEAD # 恢复最后一次提交的状态 \r\n   \r\n  Git 查看文件diff \r\n   \r\n    git diff <file> # 比较当前文件和暂存区文件差异 git diff \r\n   \r\n    git diff <$id1> <$id2> # 比较两次提交之间的差异 \r\n   \r\n    git diff <branch1>..<branch2> # 在两个分支之间比较 \r\n   \r\n    git diff --staged # 比较暂存区和版本库差异 \r\n   \r\n    git diff --cached # 比较暂存区和版本库差异 \r\n   \r\n    git diff --stat # 仅仅比较统计信息 \r\n   \r\n  Git 查看提交记录 \r\n   \r\n    git log git log <file> # 查看该文件每次提交记录 \r\n   \r\n    git log -p <file> # 查看每次详细修改内容的diff \r\n   \r\n    git log -p -2 # 查看最近两次详细修改内容的diff \r\n   \r\n    git log --stat #查看提交统计信息 \r\n   \r\n    tig Mac上可以使用tig代替diff和log，brew install tig \r\n   \r\n  Git 本地分支管理  查看、切换、创建和删除分支 \r\n   \r\n    git br -r # 查看远程分支 \r\n   \r\n    git br <new_branch> # 创建新的分支 \r\n   \r\n    git br -v # 查看各个分支最后提交信息 \r\n   \r\n    git br --merged # 查看已经被合并到当前分支的分支 \r\n   \r\n    git br --no-merged # 查看尚未被合并到当前分支的分支 \r\n   \r\n    git co <branch> # 切换到某个分支 \r\n   \r\n    git co -b <new_branch> # 创建新的分支，并且切换过去 \r\n   \r\n    git co -b <new_branch> <branch> # 基于branch创建新的new_branch \r\n   \r\n    git co $id # 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除 \r\n   \r\n    git co $id -b <new_branch> # 把某次历史提交记录checkout出来，创建成一个分支 \r\n   \r\n    git br -d <branch> # 删除某个分支 \r\n   \r\n    git br -D <branch> # 强制删除某个分支 (未被合并的分支被删除的时候需要强制) \r\n   \r\n  Git 分支合并和rebase \r\n   \r\n    git merge <branch> # 将branch分支合并到当前分支 \r\n   \r\n    git merge origin/master --no-ff # 不要Fast-Foward合并，这样可以生成merge提交 \r\n   \r\n    git rebase master <branch> # 将master rebase到branch，相当于： git co <branch> && git rebase master && git co master && git merge <branch> \r\n   \r\n     Git补丁管理(方便在多台机器上开发同步时用) \r\n   \r\n    git diff > ../sync.patch # 生成补丁 \r\n   \r\n    git apply ../sync.patch # 打补丁 \r\n   \r\n    git apply --check ../sync.patch #测试补丁能否成功 \r\n   \r\n  Git 暂存管理 \r\n   \r\n    git stash # 暂存 \r\n   \r\n    git stash list # 列所有stash \r\n   \r\n    git stash apply # 恢复暂存的内容 \r\n   \r\n    git stash drop # 删除暂存区 \r\n   Git远程分支管理 \r\n   \r\n    git pull # 抓取远程仓库所有分支更新并合并到本地 \r\n   \r\n    git pull --no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并 \r\n   \r\n    git fetch origin # 抓取远程仓库更新 \r\n   \r\n    git merge origin/master # 将远程主分支合并到本地当前分支 \r\n   \r\n    git co --track origin/branch # 跟踪某个远程分支创建相应的本地分支 \r\n   \r\n    git co -b <local_branch> origin/<remote_branch> # 基于远程分支创建本地分支，功能同上 \r\n   \r\n    git push # push所有分支 \r\n   \r\n    git push origin master # 将本地主分支推到远程主分支 \r\n   \r\n    git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库) \r\n   \r\n    git push origin <local_branch> # 创建远程分支， origin是远程仓库名 \r\n   \r\n    git push origin <local_branch>:<remote_branch> # 创建远程分支 \r\n   \r\n    git push origin :<remote_branch> #先删除本地分支(git br -d <branch>)，然后再push删除远程分支 \r\n   \r\n  Git远程仓库管理 GitHub \r\n   \r\n    git remote -v # 查看远程服务器地址和仓库名称 \r\n   \r\n    git remote show origin # 查看远程服务器仓库状态 \r\n   \r\n    git remote add origin git@ github:robbin/robbin_site.git # 添加远程仓库地址 \r\n   \r\n    git remote set-url origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址(用于修改远程仓库地址) git remote rm <repository> # 删除远程仓库 \r\n   \r\n  Git 创建远程仓库 \r\n   \r\n    git clone --bare robbin_site robbin_site.git # 用带版本的项目创建纯版本仓库 \r\n   \r\n    scp -r my_project.git git@ git.csdn.net:~ # 将纯仓库上传到服务器上 \r\n   \r\n    mkdir robbin_site.git && cd robbin_site.git && git --bare init # 在服务器创建纯仓库 \r\n   \r\n    git remote add origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址 \r\n   \r\n    git push -u origin master # 客户端首次提交 \r\n   \r\n    git push -u origin develop # 首次将本地develop分支提交到远程develop分支，并且track \r\n   \r\n    git remote set-head origin master # 设置远程仓库的HEAD指向master分支 \r\n   \r\n    也可以命令设置跟踪远程库和本地库 \r\n   \r\n    git branch --set-upstream master origin/master \r\n   \r\n    git branch --set-upstream develop origin/develop\n', ''),
(42, 'zip', 'zip zip file1.zip file1 创建一个zip格式的压缩包\nzip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包\n', ''),
(44, 'top', 'top top -H -p pid 查看某进行的线程情况\ntop -n 1 -b 显示所有进程信息后退出\ntop -d 3 每三秒更新一次\ntop -p pid 对某个进程进行监测\ntop -b -n 1 > /tmp/top.txt 这样一来，嘿嘿！就可以将 top 的信息存到 /tmp/top.txt 档案中了。 \r\n  (1) 在top中可以输入 ''?'' 得到帮助\n', ''),
(45, 'mysql', 'mysql mysqldump 导入导出语句诠释\r\n \r\n  表结构等已经在目标数据库中存在，不想拷贝数据库过去，MySQL的存储过程导出和导入，Mysqldump工具可以实现，具体用法为： \r\n  D:\\> mysqldump -uroot -p -hlocalhost -P3306 -n -d -t -R DBName > procedure_name.sql \r\n  参数说明： \r\n  -n: --no-create-db \r\n  -d: --no-data \r\n  -t: --no-create-info \r\n  -R: --routines Dump stored routines (functions and procedures) \r\n  只导出存储过程和函数。 \r\n   \r\n  导入存储过程 \r\n   \r\n  命令导入数据库中的存储过程 \r\n  D:\\>mysql -uroot -p123 dbname < procedurefile.sql \r\n   \r\n   \r\n  mysqldump备份： \r\n  mysqldump -u用户名 -p密码 -h主机 数据库 a -w "sql条件" --lock-all-tables > 路径 \r\n  案例： \r\n  mysqldump -uroot -p1234 -hlocalhost db1 a -w "id in (select id from b)" --lock-all-tables > c:\\aa.txt \r\n  mysqldump -c -t z3000_ext VT_UnAnswerDetail -w '' beginTime >= "2010-06-01 00:00:00"'' > VT_UnAnswerDetail.sql \r\n  mysqldump还原： \r\n  mysqldump -u用户名 -p密码 -h主机 数据库 < 路径 \r\n  案例： \r\n  mysql -uroot -p1234 db1 < c:\\aa.txt \r\n  mysqldump按条件导出： \r\n  mysqldump -u用户名 -p密码 -h主机 数据库  a --where "条件语句" --no-建表> 路径 \r\n  mysqldump -uroot -p1234 dbname a --where "tag=''88''" --no-create-info> c:\\a.sql \r\n  mysqldump按导入： \r\n  mysqldump -u用户名 -p密码 -h主机 数据库 < 路径 \r\n  案例： \r\n  mysql -uroot -p1234 db1 < c:\\a.txt \r\n   \r\n  mysqldump导出表： \r\n  mysqldump -u用户名 -p密码 -h主机 数据库 表 \r\n  案例： \r\n  mysqldump -uroot -p sqlhk9 a --no-data \r\n  讲一下 mysqldump 的一些主要参数 \r\n   \r\n  --compatible=name \r\n  它告诉 mysqldump，导出的数据将和哪种数据库或哪个旧版本的 MySQL 服务器相兼容。值可以为 ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options 等，要使用几个值，用逗号将它们隔开。当然了，它并不保证能完全兼容，而是尽量兼容。 \r\n  --complete-insert，-c \r\n  导出的数据采用包含字段名的完整 INSERT 方式，也就是把所有的值都写在一行。这么做能提高插入效率，但是可能会受到 max_allowed_packet 参数的影响而导致插入失败。因此，需要谨慎使用该参数，至少我不推荐。 \r\n  --default-character-set=charset \r\n  指定导出数据时采用何种字符集，如果数据表不是采用默认的 latin1 字符集的话，那么导出时必须指定该选项，否则再次导入数据后将产生乱码问题。 \r\n  --disable-keys \r\n  告诉 mysqldump 在 INSERT 语句的开头和结尾增加 ; 和 ; 语句，这能大大提高插入语句的速度，因为它是在插入完所有数据后才重建索引的。该选项只适合 MyISAM 表。 \r\n  --extended-insert = true|false \r\n  默认情况下，mysqldump 开启 --complete-insert 模式，因此不想用它的的话，就使用本选项，设定它的值为 false 即可。 \r\n  --hex-blob \r\n  使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用本选项。影响到的字段类型有 BINARY、VARBINARY、BLOB。 \r\n  --lock-all-tables，-x \r\n  在开始导出之前，提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭 --single-transaction 和 --lock-tables 选项。 \r\n  --lock-tables \r\n  它和 --lock-all-tables 类似，不过是锁定当前导出的数据表，而不是一下子锁定全部库下的表。本选项只适用于 MyISAM 表，如果是 Innodb 表可以用 --single-transaction 选项。 \r\n  --no-create-info，-t \r\n  只导出数据，而不添加 CREATE TABLE 语句。 \r\n  --no-data，-d \r\n  不导出任何数据，只导出数据库表结构。 \r\n  --opt \r\n  这只是一个快捷选项，等同于同时添加 --add-drop-tables --add-locking --create-option --disable-keys --extended-insert --lock-tables --quick --set-charset 选项。本选项能让 mysqldump 很快的导出数据，并且导出的数据能很快导回。该选项默认开启，但可以用 --skip-opt 禁用。注意，如果运行 mysqldump 没有指定 --quick 或 --opt 选项，则会将整个结果集放在内存中。如果导出大数据库的话可能会出现问题。 \r\n  --quick，-q \r\n  该选项在导出大表时很有用，它强制 mysqldump 从服务器查询取得记录直接输出而不是取得所有记录后将它们缓存到内存中。 \r\n  --routines，-R \r\n  导出存储过程以及自定义函数。 \r\n  --single-transaction \r\n  该选项在导出数据之前提交一个 BEGIN SQL语句，BEGIN 不会阻塞任何应用程序且能保证导出时数据库的一致性状态。它只适用于事务表，例如 InnoDB 和 BDB。 \r\n  本选项和 --lock-tables 选项是互斥的，因为 LOCK TABLES 会使任何挂起的事务隐含提交。 \r\n  要想导出大表的话，应结合使用 --quick 选项。 \r\n  --triggers \r\n  同时导出触发器。该选项默认启用，用 --skip-triggers 禁用它。 \r\n  其他参数详情请参考手册，我通常使用以下 SQL 来备份 MyISAM 表： \r\n  /usr/local/mysql/bin/mysqldump -uyejr -pyejr " \r\n  --default-character-set=utf8 --opt --extended-insert=false " \r\n  --triggers -R --hex-blob -x db_name > db_name.sql \r\n  使用以下 SQL 来备份 Innodb 表： \r\n  /usr/local/mysql/bin/mysqldump -uyejr -pyejr " \r\n  --default-character-set=utf8 --opt --extended-insert=false " \r\n  --triggers -R --hex-blob --single-transaction db_name > db_name.sql \r\n  另外，如果想要实现在线备份，还可以使用 --master-data 参数来实现，如下： \r\n  /usr/local/mysql/bin/mysqldump -uyejr -pyejr " \r\n  --default-character-set=utf8 --opt --master-data=1 " \r\n  --single-transaction --flush-logs db_name > db_name.sql \r\n  它只是在一开始的瞬间请求锁表，然后就刷新binlog了，而后在导出的文件中加入CHANGE MASTER 语句来指定当前备份的binlog位置，如果要把这个文件恢复到slave里去，就可以采用这种方法来做。 \r\n  1.2 还原 \r\n  用 mysqldump 备份出来的文件是一个可以直接倒入的 SQL 脚本，有两种方法可以将数据导入。 \r\n  直接用 mysql 客户端 \r\n  例如： \r\n  /usr/local/mysql/bin/mysql -uyejr -pyejr db_name < db_name.sql \r\n  用 SOURCE 语法 （实验不成功！！！） \r\n  其实这不是标准的 SQL 语法，而是 mysql 客户端提供的功能，例如： \r\n  SOURCE /tmp/db_name.sql; \r\n  这里需要指定文件的绝对路径，并且必须是 mysqld 运行用户(例如 nobody)有权限读取的文件。\nmysql 授权\r\n \r\n  GRANT ALL PRIVILEGES ON test.* TO ''mysqluser''@''%'' IDENTIFIED BY ''mysqluser''; \r\n  FLUSH PRIVILEGES;\r\n\r\n \r\n  mysql> grant 权限1,权限2,…权限n on 数据库名称.表名称 to 用户名@用户地址 identified by ‘连接口令’; \r\n   \r\n  权限1,权限2,…权限n代表select,insert,update,delete,create,drop,index,alter,grant,references,reload,shutdown,process,file等14个权限。 \r\n  当权限1,权限2,…权限n被all privileges或者all代替，表示赋予用户全部权限。 \r\n  当数据库名称.表名称被*.*代替，表示赋予用户操作服务器上所有数据库所有表的权限。 \r\n  用户地址可以是localhost，也可以是ip地址、机器名字、域名。也可以用’%''表示从任何地址连接。 \r\n  ‘连接口令’不能为空，否则创建失败。 \r\n   \r\n  mysql>grant select,insert,update,delete,create,drop on vtdc.employee to joe@10.163.225.87 identified by ‘123′; \r\n  给来自10.163.225.87的用户joe分配可对数据库vtdc的employee表进行select,insert,update,delete,create,drop等操作的权限，并设定口令为123。\nmysql 简单操作语句\r\n\r\n \r\n   \r\n  产生测试数据 \r\n  INSERT INTO test.SCHEDULE_TEST \r\n  ( \r\n  DEAL_COUNT, \r\n  STS, \r\n  OWN_SIGN \r\n  ) \r\n  SELECT \r\n  DEAL_COUNT, \r\n  STS, \r\n  OWN_SIGN \r\n  FROM \r\n  test.SCHEDULE_TEST \r\n  test\r\n  备分表 \r\n  CREATE TABLE bak SELECT * FROM SCHEDULE_TEST \r\n   \r\n   \r\n  复制表结构 \r\n  CREATE TABLE bak SELECT * FROM SCHEDULE_TEST WHERE 1=0 \r\n   \r\n   \r\n  删除表 \r\n  DROP TABLE bak; \r\n   \r\n  清空表 \r\n  TRUNCATE TABLE bak; \r\n   \r\n  mysql关联多表进行update更新操作 \r\n  UPDATE Track \r\n  INNER JOIN MV \r\n  ON Track.trkid=MV.mvid \r\n  SET Track.is_show=MV.is_show \r\n  WHERE trkid<6 \r\n   \r\n  等同于 \r\n   \r\n  UPDATE Track,MV \r\n  SET Track.is_show=MV.is_show \r\n  WHERE Track.trkid=MV.mvid and trkid<6 \r\n   \r\n  \n', ''),
(46, 'postgresql', 'postgresql postgresql 使用说明 \r\n  1.  \r\n  PostgresSQL 支持标准的 SQL 类型 int，smallint， real，double precision， char(N)， varchar(N)，date， time，timestamp 和 interval \r\n  2.  \r\n  \\c [数据库名]   多个数据库之间的切换 \r\n   \r\n  \\a              在非对齐和对齐的输出模式之间切换 \r\n  \\C [字串]       设置表标题, 如果参数空则取消标题 \r\n  \\cd [目录名]    改变当前的工作目录 \r\n  \\copy ...       执行 SQL COPY, 数据流指向客户端主机 \r\n  \\copyright      显示 PostgreSQL 用法和发布信息 \r\n  \\d [名字]       描述表, 索引, 序列, 或者视图 \r\n                   列出表/索引/序列/视图/系统表 \r\n  \\d{t|i|s|v|S} [模式]     (加 "+" 获取更多信息) \r\n                   列出表/索引/序列/视图/系统表 \r\n  \\da [模式]      列出聚集函数 \r\n  \\dd [模式]      显示目标的注释 \r\n  \\dD [模式]      列出域 \r\n  \\df [模式]      列出函数 (加 "+" 获取更多的信息) \r\n  \\do [名字]      列出操作符 \r\n  \\dl             列出大对象, 和 \\lo_list 一样 \r\n  \\dp [模式]      列出表访问权限 \r\n  \\dT [模式]      列出数据类型 (加 "+" 获取更多的信息) \r\n  \\du [模式]      列出用户 \r\n  \\e [文件名]     用一个外部编辑器编辑当前查询缓冲区或者文件 \r\n  \\echo [字串]    向标准输出写出文本 \r\n  \\encoding [哪种编码]       设置客户端编码(EUC_JP,GBK) \r\n  \\f [字串]       设置域分隔符 \r\n  \\g 文件名       向服务器发送 SQL 命令 (并且把结果写到文件或者 |管道) \r\n  \\h [名字]       SQL 命令的语法帮助, 用 * 可以看所有命令的帮助 \r\n  \\H              在 HTML 输出模式之间切换 (当前是 关闭) \r\n  \\i 文件名       执行来自文件的命令 \r\n  \\l              列出所有数据库 \r\n  \\lo_export, \\lo_import, \\lo_list, \\lo_unlink \r\n                   大对象操作 \r\n  \\o 文件名       向文件或者 |管道 发送所有查询结果 \r\n  \\p              显示当前查询缓冲区的内容 \r\n  \\pset 名字 [值]      设置表的输出选项 (NAME := {foramt|border|expaned| \r\n                   (名字 := {foramt|border|expanded|fieldsep|null|recordsep| \r\n                   tuples_only|title|tableattr|pager}) \r\n  \\q              退出 psql \r\n  \\r              重置 (清理) 查询缓冲区 \r\n  \\s [文件名]     打印历史或者将其保存到文件 \r\n  \\set [名字 [值]]      设置内部变量, 如果没有参数就列出所有 \r\n                  只显示行 (当前是 关闭) \r\n  \\T [字串]       设置 HTML <表>标记属性, 如果没有参数就取消设置 \r\n    iming         查询计时开关切换 (目前是 关闭) \r\n  \\unset 名字     取消(删除)内部变量 \r\n  \\w [文件名]     将当前查询缓冲区写出到文件 \r\n  \\x              在扩展输出之间切换 (目前是 关闭) \r\n  \\z [模式]       列出表访问权限 (和 \\dp 一样) \r\n  \\! [命令]       在 shell 里执行命令或者开始一个交互的 shell \r\n   \r\n  \\echo [string]  输出字符串 \r\n   \r\n  \\qecho [字串]     向查询输出流写出文本 (见 \\o) \r\n   \r\n  3. 将数据库 导出到 文件标识符 \r\n   \r\n   \r\n   \r\n  命令： \r\n   \r\n  \\copy 表名 to 文件名|标准输出 [delimiter  as  ‘分隔符’]  [null  as ‘null表示的字符串’ ] [csv  quote  as ‘引号的类型’] \r\n   \r\n   \r\n   \r\n  解释： \r\n   \r\n  可以将表中的数据输出到 文件或标准输出。 \r\n   \r\n   \r\n  delimiter as ‘分隔符’   ：说明输出设备的文本中表的每个字段用什么字符分割，默认是tab； \r\n   \r\n  null  as ‘null表示的字符串’：说明输出设备的文本中表的NULL值的表示方法，默认为“\\N”； \r\n   \r\n  csv quote as ‘引号类型’ ：说明导出的csv文件中的引号类型是什么， \r\n   \r\n  对于Postgres7.4以前的版本，不支持csv的导入与导出，这时不要使用这个可选项。 \r\n   \r\n  例子： \r\n   \r\n  aa=#\\copy  testtable to data.csv  delimiter as ‘,’ csv quote as ‘”‘ \r\n   \r\n  这条命令将testtable表中的内容作为SQL语句，导出data.csv文件中。 \r\n   \r\n  delimiter as ‘,’   ：说明data.txt文本中表的每个字段用“逗号”分割； \r\n   \r\n  csv quote as ‘”‘ ：说明csv中的引号类型是“双引号”。 \r\n   \r\n  像前面说的：这个例子不适用在Postgres7.4以前的版本。 \r\n   \r\n   \r\n   \r\n  注意文件保存路径默认在： \r\n   \r\n  C:\\Documents and Settings\\zhuyaopeng\\目录下  而且只保存数据，不保存表结构 \r\n   \r\n   \r\n   \r\n  4. 从 文件标识符 导入数据到数据库 \r\n   \r\n   \r\n   \r\n  命令： \r\n   \r\n  \\copy 表名 form 文件名|标准输入 [delimiter  as  ‘分隔符’]  [null  as ‘null表示的字符串’ ]   [csv  quote  as ‘引号的类型’] \r\n  例子： \r\n  aa=#\\copy  testtable from data.csv  delimiter as ‘,’ csv quote as ‘”‘ \r\n   \r\n  这条命令将data.csv文件中的文本，作为sql语句导入到testtable表， \r\n   \r\n  delimiter as ‘,’   ：说明data.txt文本中表的每个字段用“逗号”分割； \r\n   \r\n  csv quote as ‘”‘ ：说明csv中的引号类型是“双引号”。 \r\n   \r\n   \r\n   \r\n  5.如何只选择一个查询结果的头几行？或是随机的一行？ \r\n   \r\n   \r\n   \r\n  如果你只是要提取几行数据，并且你在执行查询中知道确切的行数，你可以使用LIMIT功能。 如果有一个索引与 ORDER BY中的条件匹配，PostgreSQL 可能就只处理要求的头几条记录， （否则将对整个查询进行处理直到生成需要的行）。如果在执行查询功能时不知道确切的记录数， 可使用游标(cursor)和FETCH功能。 \r\n   \r\n  可使用以下方法提取一行随机记录的： \r\n   \r\n    SELECT  cols \r\n    FROM tab \r\n    ORDER BY random() \r\n    LIMIT 1 ;\n', ''),
(47, 'ls', 'ls lspci -tv 罗列 PCI 设备\nlsusb -tv 显示 USB 设备\nls 查看目录中的文件\nls -F 查看目录中的文件\nls -l 显示文件和目录的详细资料\nls -a 显示隐藏文件\nls *[0-9]* 显示包含数字的文件名和目录名\nlstree 显示文件和目录由根目录开始的树形结构(2)\nls -lSr |more 以尺寸大小排列文件和目录\nls -lh 显示权限\nls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示\nlsattr 显示特殊的属性\n', ''),
(48, 'ln', 'ln ln -s file1 lnk1 创建一个指向文件或目录的软链接\nln file1 lnk1 创建一个指向文件或目录的物理链接\n', ''),
(49, 'linux', 'linux linuxcmd linux命令速查手册 \r\n  一. 启动,关机,登入,登出相关命令 \r\n    login 登录 \r\n    logout 登出 \r\n    exit 登出 \r\n    shutdown 停止系统 \r\n    halt 停止系统 \r\n    reboot 重启动 \r\n    poweroff 切断电源 \r\n    sync 把内存里的内容写入磁盘 \r\n    lilo 安装lilo启动管理程序 \r\n    grub 安装lilo启动管理程序 \r\n   \r\n   \r\n  二. Shell相关命令 \r\n    chsh 切换Shell \r\n    history 显示命令履历 \r\n    alias 设置命令别名 \r\n    unalias 取消命令别名 \r\n    which 显示命令所在位置 \r\n    type 查询命令种类 \r\n    echo 显示字符串或者变量内容 \r\n    set 设置/显示Shell变量 \r\n    printenv 显示环境变量 \r\n    export 设置环境变量 \r\n    env 设置临时环境变量 \r\n    unset 释放环境变量 \r\n    setenv 设置环境变量 \r\n    unsetenv 释放环境变量 \r\n    source 执行文件当中的命令 \r\n    man 查询命令手册 \r\n    info 查询超文本命令手册 \r\n    whatis 显示命令简介 \r\n    apropos 通过关键字查询手册 \r\n   \r\n   \r\n  三. 用户管理相关命令 \r\n    su 切换到其他用户 \r\n    useradd 追加用户 \r\n    adduser 追加用户 \r\n    userdel 删除用户 \r\n    usermod 修改用户设置 \r\n    chfn 修改用户私人信息 \r\n    groupadd 追加组 \r\n    groupdel 删除组 \r\n    groupmod 修改组设置 \r\n    passwd 更改密码 \r\n    whoami 显示用户名 \r\n    logname 显示登录用户帐号 \r\n    users 显示所有登录用户信息 \r\n    who 查询登录用户信息 \r\n    w 查询登录用户信息 \r\n    id 显示指定用户的ID信息 \r\n    groups 显示指定用户的所属组 \r\n    finger 显示指定用户的个人信息 \r\n    mesg 开关与他人收发消息 \r\n    write 给其他用户发消息 \r\n    wall 给所有用户发消息 \r\n    talk 和其他用户聊天 \r\n   \r\n   \r\n  四. 系统消息相关命令 \r\n    date 显示/设置当前时间 \r\n    uptime 显示系统运行时间 \r\n    arch 显示机器的核心构架（如i386） \r\n    uname 显示操作系统信息 \r\n    tty 显示终端名 \r\n    last 显示登录/登出在履历 \r\n    lastb 显示非法登录信息 \r\n    dumpkeys 显示当前键盘配置 \r\n    loadkeys 变更键盘配置 \r\n    df 查询磁盘使用信息 \r\n    du 查询磁盘使用信息 \r\n    dmesg 显示系统启动消息 \r\n    script 保存输入输出到文件 \r\n   \r\n   \r\n  五. 文件操作相关命令 \r\n    ls 显示文件列表 \r\n    tree 显示目录树 \r\n    pwd 显示当前路径 \r\n    cd 更改当前路径 \r\n    pushd 追加路径到目录堆栈 \r\n    popd 从目录堆栈删除路径 \r\n    dirs 显示目录堆栈的内容 \r\n    mkdir 创建路径 \r\n    rmdir 删除路径 \r\n    cp 复制文件/目录 \r\n    rm 删除文件/目录 \r\n    mv 移动文件/目录，修改文件名 \r\n    chown 更改文件/目录的所有者 \r\n    chgrp 修改文件/目录的所有组 \r\n    chmod 修改文件/目录的权限 \r\n    touch 更改文件时间 \r\n    ln 建立文件/目录链接 \r\n    find 查找文件 \r\n    whereis 显示文件存在的路径名 \r\n    file 查询文件种类 \r\n    size 查询文件大小 \r\n   \r\n   \r\n  六. 文件编辑相关命令 \r\n    cat 显示文件内容 \r\n    tee 输出到文件和屏幕 \r\n    more 分屏显示文件内容 \r\n    less 分屏显示文件内容 \r\n    head 显示文件头部内容 \r\n    tail 显示文件尾部内容 \r\n    fold 折叠显示长行 \r\n    sort 排列文件的行 \r\n    cmp 比较文件内容 \r\n    diff 显示文件差异 \r\n    nkf 更改日语文件编码 \r\n    dd 变更文件之后复制 \r\n    wc 统计文本单词数，文件大小等 \r\n    split 分割文件 \r\n    paste 以行连接文件 \r\n    join 以字段连接文件 \r\n    grep 查询文字 \r\n    uniq 过滤重复部分显示文件内容 \r\n    tr 替换文字 \r\n    sed 替换文字 \r\n   \r\n   \r\n  七. 压缩/解压缩相关命令 \r\n    ar 压缩/解压缩文件 \r\n    tar 压缩/解压缩文件 \r\n    compress 压缩/解压缩文件 \r\n    uncompress 解压缩 \r\n    gzip 压缩/解压缩文件 \r\n    gunzip 解压缩 \r\n    zcat 显示压缩文件的内容 \r\n    lha 压缩/解压缩文件 \r\n    uuencode 把二进制文件编码为文本文件 \r\n    uudecode 把经过编码的文本文件还原为二进制文件 \r\n   \r\n   \r\n  八. MS-DOS工具集[mtools]命令 \r\n    mdir 显示文件列表 \r\n    mcd 改变当前目录 \r\n    mmd 新建目录 \r\n    mrd 删除目录 \r\n    mdeltree 删除目录树 \r\n    mcopy 复制文件 \r\n    mdel 删除文件 \r\n    mmove 移动文件 \r\n    mren 更改文件或目录名 \r\n    mattrib 修改文件属性 \r\n    mtype 显示文件内容 \r\n    mdu 查询文件或目录大小 \r\n    minfo 显示磁盘信息 \r\n    mformat 以MS-DOS方式格式化磁盘 \r\n    mlabel 设置磁盘标签 \r\n   \r\n   \r\n  九. 控制外部设备相关命令 \r\n    mount mount上设备 \r\n    umount 解除已经mount上的设备 \r\n    eject 弹出（CD/DVD等） \r\n    fdformat 格式化软盘 \r\n    fdisk 配置/显示硬盘分区 \r\n    mkfs 格式化磁盘分区 \r\n    fsck 检查/修复磁盘错误 \r\n    lpr 打印到打印机 \r\n    lprm 中断打印任务 \r\n    lpq 显示打印任务的状态 \r\n    lpc 管理/控制打印任务 \r\n    ifconfig 显示/设定NIC配置 \r\n   \r\n   \r\n  十. 进程及任务管理相关命令 \r\n    ps 显示正在运行的进程 \r\n    jobs 显示后台运行任务 \r\n    fg 把任务切换到前台 \r\n    bg 把任务切换到后台 \r\n    kill 中止进程或任务 \r\n    killall 中止进程或任务 \r\n    wait 等待进程或任务的结束 \r\n    at 设置定时执行任务 \r\n    atq 显示尚未执行的任务 \r\n    atrm 删除定时执行任务 \r\n    batch 在系统负荷减轻的时候执行任务 \r\n    nice 改变优先度并执行任务 \r\n    nohup 在后台执行任务，Logout之后也不退出 \r\n    sleep 休眠一定的时间 \r\n   \r\n   \r\n  十一. 网络管理相关命令 \r\n    ip ip设置,路由,网关等 \r\n    ifconfig 查看ip信息 \r\n    dig 查看路由信息 \r\n    netstat 显示当前网络连接状况 \r\n    route 显示/设置路由 \r\n    host 显示网络主机情况 \r\n    hostname 显示/设置当前主机的名字 \r\n    ping 确认和远程机器的连接情况 \r\n    traceroute 显示路由信息 \r\n    rwho 查询网上机器的登陆用户 \r\n    ruptime 查询网上机器的系统运行时间 \r\n    rlogin 登陆到远程机器 \r\n    telnet 用telnet登陆到远程机器 \r\n    rsh 给远程机器发送命令 \r\n    rcp 在远程机器之间复制文件 \r\n    mail 收取邮件 \r\n    sendmail 发送邮件 \r\n    mailq 确认邮件队列 \r\n    ftp 用ftp传输文件 \r\n   \r\n   \r\n  十一. 其他命令 \r\n    cal 显示日历 \r\n    clear 清屏 \r\n    gcc 编译C语言代码 \r\n    as 汇编 \r\n    bc 计算 \r\n    rpm Redhat的包管理 \r\n    dpkg Debian的包管理 \r\n    installpkg Slackware的包安装（删除命令则是removepkg） \r\n    XF86Setup,turboxfg,Xconfigurator 配置 X 服务器 \r\n    startx 启动 X-Window 系统 \r\n    附：组合命令 \r\n    重定向，如 \r\n    $ ls -l /bin  ls-output \r\n    $ more ls-output \r\n    管道命令，如 \r\n    $ cat file1 file2 | sort | uniq \r\n    经常被用于管道的命令 \r\n    awk, fold, grep, head, nnkf, pr, sed, sort, tail, tee, tr, uniq, wc\n', ''),
(50, 'openvswitch', 'openvswitch openvswitch 使用说明\r\n \r\n  一、  网桥管理 \r\n    添加名为br0的网桥 \r\n    ovs-vsctl add-br br0 \r\n    删除名为br0的网桥 \r\n    ovs-vsctl del-br br0 \r\n    列出所有网桥 \r\n    ovs-vsctl list-br \r\n    判断网桥br0是否存在 \r\n    ovs-vsctl br-exists br0 \r\n    列出挂接到网桥br0上的所有网络接口 \r\n    ovs-vsctl list-ports br0 \r\n    将网络接口eth0挂接到网桥br0上 \r\n    ovs-vsctl add-port br0 eth0 \r\n    删除网桥br0上挂接的eth0网络接口 \r\n    ovs-vsctl del-port br0 eth0 \r\n    列出已挂接eth0网络接口的网桥 \r\n    ovs-vsctl port-to-br eth0 \r\n   \r\n  二、  网桥管理（ovsdb数据库操作） \r\n    ovsdb是一个非常轻量级的数据库，与其说它是一个数据库，不如说它是一个提供增删查改等功能的临时配置缓存，之所以这么说，是因为ovsdb数据库的根本就未使用多少数据库技术，如SQL语言查询、存储过程等等。ovsdb 数据库通过模式文件“openvswitch-1.1.0pre2/vswitchd/vswitch.ovsschema”，如要定制ovsdb数据库，可通过更改 vswitch.ovsschema 文件实现，不过以下姑且仍以数据库称之。 \r\n   \r\n    数据库操作的一般格式为： \r\n    ovs-vsctl list/set/get/add/remove/clear/destroy table record column [value] \r\n    默认情况下ovsdb中有以下数据表： \r\n    bridge, controller,interface,mirror,netflow,open_vswitch,port,qos,queue,ssl,sflow \r\n    即table可为上面的任一个。record为数据表中name字段的值，column为数据表任一个字段的字段名，value字段值。 \r\n    基本操作： \r\n    查看bridge数据表中的所有记录 \r\n   \r\n    获得bridge数据表_uuid字段的值 \r\n   \r\n    设置bridge数据表datapath_type字段的值 \r\n   \r\n    清除bridge数据表flood_vlans字段的值 \r\n    ovs-vsctl remove bridge xenbr0 flood_vlans 23 \r\n    或者 \r\n    ovs-vsctl clear bridge xenbr0 flood_vlans \r\n    删除uuid为69ee0c09-9e52-4236-8af6-037a98ca704d的qos记录 \r\n    ovs-vsctl destroy qos 69ee0c09-9e52-4236-8af6-037a98ca704d \r\n  三、  应用场景设置： \r\n    \r\n    1)QoS设置 \r\n   \r\n    针对网络接口的设置：设置网络接口vif0.0的带宽为1000±100kbps \r\n    ovs-vsctl set interface vif0.0 ingress_policing_rate=1000 \r\n    ovs-vsctl set interface vif0.0 ingress_policing_burst=100 \r\n    (ingress_policing_rate:最大发送速率（单位均为kbps） \r\n    ingress_policing_burst:超过ingress_policing_rate的最大浮动值) \r\n    针对交换机端口的设置：创建在vif0.0端口上的linux-htb QoS，linux-htb QoS可以针对具有指定特征的数据包流设置最大最小带宽，且在最大带宽范围内，某一特征的数据包流可以借用其他特征数据包流未用完的带宽。 \r\n    ovs-vsctl -- set port vif0.0 qos=@newqos \r\n    -- --id=@newqos create qos type=linux-htb other-config: \r\n    max-rate=100000000 queues=0=@q0,1=@q1 \r\n    -- --id=@q0 create queue other-config:min-rate=100000000 other-config:max-rate=100000000 \r\n    -- --id=@q1 create queue other-config:min-rate=500000000 \r\n    将带宽限制加于某特征数据包流上 \r\n    (假设vif0.0的接在交换机1号端口上，ovs-ofctl命令的使用见2.2.3) \r\n    ovs-ofctl add-flow xenbr0 "in_port=2,idle_timeout=0,actions=enqueue:1:0" \r\n    \r\n    2)端口映射 \r\n   \r\n    将发往eth0端口和从eth1端口发出的数据包全部定向到eth2端口 \r\n    （假设eth0、eth1、eth2端口的uuid分别为： \r\n    69ee0c09-9e52-4236-8af6-037a98ca704d \r\n    69ee0c09-9e52-4236-8af6-037a98ca704e \r\n    69ee0c09-9e52-4236-8af6-037a98ca704f \r\n    端口的uuid可以通过ovs-vsctl list port命令查看） \r\n    ovs-vsctl -- set bridge xenbr0 mirrors=@m \r\n    -- --id=@m create mirror name=mymirror \r\n    select-dst-port=69ee0c09-9e52-4236-8af6-037a98ca704d \r\n    select-src-port=69ee0c09-9e52-4236-8af6-037a98ca704e \r\n    output-port=69ee0c09-9e52-4236-8af6-037a98ca704f \r\n    \r\n    3)流规则管理 流规则组成 \r\n   \r\n    每条流规则由一系列字段组成，分为基本字段、条件字段和动作字段三部分： \r\n    基本字段包括生效时间duration_sec、所属表项table_id、优先级priority、处理的数据包数n_packets，空闲超时时间idle_timeout等，空闲超时时间idle_timeout以秒为单位，超过设置的空闲超时时间后该流规则将被自动删除，空闲超时时间设置为0表示该流规则永不过期，idle_timeout将不包含于ovs-ofctl dump-flows brname的输出中。 \r\n   \r\n    条件字段包括输入端口号in_port、源目的mac地址dl_src/dl_dst、源目的ip地址nw_src/nw_dst、数据包类型dl_type、网络层协议类型nw_proto等，可以为这些字段的任意组合，但在网络分层结构中底层的字段未给出确定值时上层的字段不允许给确定值，即一条流规则中允许底层协议字段指定为确定值，高层协议字段指定为通配符(不指定即为匹配任何值)，而不允许高层协议字段指定为确定值，而底层协议字段却为通配符(不指定即为匹配任何值)，否则，ovs-vswitchd 中的流规则将全部丢失，网络无法连接。 \r\n   \r\n    动作字段包括正常转发normal、定向到某交换机端口output：port、丢弃drop、更改源目的mac地址mod_dl_src/mod_dl_dst等，一条流规则可有多个动作，动作执行按指定的先后顺序依次完成。 \r\n    基本操作 \r\n    查看虚拟交换机xenbr0的信息 \r\n   \r\n    显示的xenbr0信息中网络接口名称前的数字为该网络接口挂接到Open vSwitch上的端口号，如1(vif0.0): 中的1为网络接口vif0.0对应的端口号，在添加包含in_port字段的流规则时可通过该命令查看网络接口对应的端口号。 \r\n    查看xenbr0上各交换机端口的状态 \r\n   \r\n    输出的结果中包含了各网络接口上收到的数据包数，字节数，丢包数，错误数据包数等信息 \r\n    查看xenbr0上的所有流规则 \r\n   \r\n    输出结果中共有两条流规则，第一条为默认的流规则，即对所有数据包进行正常转发，为普通二层交换机完成的功能，优先级为0，最低，永不超时。 \r\n    第二条为手动添加的流规则，基本字段中不包含idle_timeout字段，表示永不超时，优先级为32768，Open vSwitch将先根据该条流规则处理收到的数据包，如从数据包中提取出的特征与条件字段不符，则该用第一条流规则处理收到的所有数据包。 \r\n    添加一条流规则：丢弃从2号端口发来的所有数据包 \r\n   \r\n    删除一条流规则：删除条件字段中包含in_port=2的所有流规则 \r\n   \r\n   \r\n    流规则中可包含通配符和简写形式，任何字段都可等于*或ANY，如： \r\n    丢弃所有收到的数据包 \r\n    ovs-ofctl add-flow xenbr0 dl_type=*,nw_src=ANY,actions=drop \r\n    简写形式为将字段组简写为协议名，目前支持的简写有ip，arp，icmp，tcp，udp，与流规则条件字段的对应关系如下: \r\n    dl_type=0x0800 <=>ip \r\n    dl_type=0x0806 <=>arp \r\n    dl_type=0x0800，nw_proto=1 <=> icmp \r\n    dl_type=0x0800，nw_proto=6 <=> tcp \r\n    dl_type=0x0800，nw_proto=17 <=> udp \r\n   \r\n   \r\n    （1.1.0 即以后版本支持） \r\n    dl_type=0x86dd. <=> ipv6 \r\n    dl_type=0x86dd,nw_proto=6. <=> tcp6 \r\n    dl_type=0x86dd,nw_proto=17. <=> udp6 \r\n    dl_type=0x86dd,nw_proto=58. <=> icmp6 \r\n   \r\n    \r\n    4)应用场景设置 网站屏蔽 \r\n   \r\n    屏蔽由Open vSwitch管理的任何主机对主机119.75.213.50的访问，但只屏蔽ip数据包(由dl_type=0x0800指定)，即所有主机将无法访问该主机上所有基于IP协议的服务，如万维网服务、FTP访问等 \r\n    ovs-ofctl add-flow xenbr0 idle_timeout=0,dl_type=0x0800,nw_src=119.75.213.50,actions=drop \r\n    数据包重定向 \r\n    将交换机中所有的icmp协议包（有dl_type=0x0800,nw_proto=1指定）全部转发到4号端口，包括4号端口自己发出的icmp包，该流规则将导致由Open vSwitch管理的主机间以及与外部网络间都将访问ping通，但可以使用万维网、FTP等服务。 \r\n    ovs-ofctl add-flow xenbr0 idle_timeout=0,dl_type=0x0800,nw_proto=1,actions=output:4 \r\n    去除VLAN tag \r\n    去除从3号端口发来的所有VLAN数据包中的tag，然后转发 \r\n    ovs-ofctl add-flow xenbr0 idle_timeout=0,in_port=3,actions=strip_vlan,normal \r\n    更改数据包源IP地址后转发 \r\n    将从3号端口收到的所有IP包的源IP字段更改为211.68.52.32 \r\n    ovs-ofctl add-flow xenbr0 idle_timeout=0,in_port=3,actions=mod_nw_src:211.68.52.32,normal \r\n    内核模块中flow操作 \r\n    查看内核模块flow \r\n    ovs-dpctl dump-flows xenbr0 \r\n   \r\n    \r\n    5)后台模块控制，如日志系统、后台模块退出 \r\n   \r\n    查看后台模块支持的appctl命令 \r\n    查看ovsdb-server支持的appctl命令，ovs-appctl必须在后台模块运行后才能针对后台模块使用，默认情况下，所有运行的后台模块都会在/usr/local/var/run/openvswitch/目录下创建一个与ovs-appctl通信的socket文件 \r\n   \r\n    更改Open vSwitch各后台的模块的日志级别 \r\n    更改ovs-vswitchd模块的日志级别info，“ANY:ANY:info”中的前一个“ANY”代表ovs-vswitchd中的任何模块组件，“ovs-appctl --target=/usr/local/var/run/openvswitch/ \r\n    ovs-vswitchd.29384.ctl vlog/list”命令输出的第一列将为ovs-vswitchd包含的所有模块组件。“ANY:ANY:info”中的后一个“ANY”代表日志的任何方式的输出，日志的输出方式有三种，分别为：console，syslog，file，分别代表将日志输出到控制台、写入到系统日志系统和写入到ovs-vswitchd启动时由—log-file参数指定的文件。“ANY:ANY:info”中的“info”表示日志级别，共有emer、err、warn、info、dbg五个日志级别，dbg为最低级别，指定为dbg时，所有的日志信息都将输出，但此时可能导致日志系统迅速膨胀，而占用越来越多的硬盘存储空间。 \r\n    ovs-appctl --target=/usr/local/var/run/openvswitch/ovs-vswitchd.29384.ctl vlog/set \r\n    ANY:ANY:info \r\n    退出后台模块 \r\n    让ovs-vswitchd停止运行 \r\n    ovs-appctl --target=/usr/local/var/run/openvswitch/ovs-vswitchd.29384.ctl exit\n', ''),
(51, 'rpm', 'rpm rpm -q -a --qf ''%10{SIZE}t%{NAME}n'' | sort -k1,1n 以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统)\nRPM 包 - （Fedora, Redhat及类似系统）\nrpm -ivh package.rpm 安装一个rpm包\nrpm -ivh --nodeeps package.rpm 安装一个rpm包而忽略依赖关系警告\nrpm -U package.rpm 更新一个rpm包但不改变其配置文件\nrpm -F package.rpm 更新一个确定已经安装的rpm包\nrpm -e package_name.rpm 删除一个rpm包\nrpm -qa 显示系统中所有已经安装的rpm包\nrpm -qa | grep httpd 显示所有名称中包含 "httpd" 字样的rpm包\nrpm -qi package_name 获取一个已安装包的特殊信息\nrpm -qg "System Environment/Daemons" 显示一个组件的rpm包\nrpm -ql package_name 显示一个已经安装的rpm包提供的文件列表\nrpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表\nrpm -q package_name --whatrequires 显示与一个rpm包存在依赖关系的列表\nrpm -q package_name --whatprovides 显示一个rpm包所占的体积\nrpm -q package_name --scripts 显示在安装/删除期间所执行的脚本l\nrpm -q package_name --changelog 显示一个rpm包的修改历史\nrpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供\nrpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表\nrpm --import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书\nrpm --checksig package.rpm 确认一个rpm包的完整性\nrpm -qa gpg-pubkey 确认已安装的所有rpm包的完整性\nrpm -V package_name 检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间\nrpm -Va 检查系统中所有已安装的rpm包- 小心使用\nrpm -Vp package.rpm 确认一个rpm包还未安装\nrpm2cpio package.rpm | cpio --extract --make-directories *bin* 从一个rpm包运行可执行文件\nrpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm 从一个rpm源码安装一个构建好的包\nrpmbuild --rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包\n', ''),
(52, 'for', 'for for 循环语句 \r\n  EX1 for循环遍历数组: \r\n   \r\n  #!/bin/sh \r\n  WORD="a b c d e f g h i j l m n o p q r s t u v w x y z" \n  for i in $WORD ; do   // 遍历WORD变量里面的数据 \r\n  echo $i                     // 输出WORD数据集中的没有元素 \r\n  done                         // 循环结束 \r\n  程序依次读入WORD中的元素赋给变量i,然后输出i的值,有没有发现,shell的语法中,变量没有数据类型?是的,就是这样.  \r\n   \r\n  EX2 for循环遍历文件: \r\n   \r\n  #!/bin/sh \r\n  FILES=`ls /txt/*.txt` \r\n  for txt in $FILES ; do  \r\n  mv $txt /newDir/$txt \r\n  done \r\n  以上代码是将/txt/*.txt转移到新目录下，数据集来源于ls指令的结果，通过重定向输入到变量FILES中。 \r\n   \r\n   \r\n  EX3 while循环: \r\n   \r\n  #!/bin/sh \r\n  while : ; do \r\n  echo "do something forever here" \r\n  sleep 5 \r\n  done \r\n  无限循环打印"do something forever here" ，间隔5秒\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(53, 'qemu', 'qemu qemu 简要说明\r\n \r\n    qemu是一款很好的虚拟机，下面废话不说，直接说安装过程。 \r\n   \r\n  （1）安装qemu    \r\n   \r\n    仿真ARM需要使用qemu-system-arm，安装模拟器    \r\n   \r\n    sudo apt-get install  qemu-kvm qemu-kvm-extras \r\n   \r\n  （2）下载内核镜像。以下名称叫ubuntu.iso \r\n   \r\n  （3）创建一个虚拟磁盘 \r\n   \r\n    sudo qemu-img create -f qcow2 /opt/vm/ubuntu1010.img 10G \r\n   \r\n  （4）安装虚拟机操作系统 \r\n   \r\n    sudo qemu-system-x86_64 -hda /opt/vm/ubuntu1010.img -cdrom /opt/iso/ubuntu.iso -boot d -m 1024 -no-acpi \r\n   \r\n    -hda 指定了硬盘是哪个虚拟磁盘，这里用刚刚创建的ubuntu1010.img \r\n   \r\n    -cdrom指定cdrom是哪个，可以用iso文件，烨可以用机器光驱，我们选择用iso文件。 \r\n   \r\n    -boot指定启动的时候从磁盘，硬盘，光驱还是网络上启动，我们安装的时候选择从光驱启动，所以用d \r\n   \r\n    -m虚拟机使用的内存大小，单位是MB，默认是128mb，这个用1024 \r\n   \r\n    -no-acpi由于qemu支持不大好导致系统很慢，所以暂时禁止掉。 \r\n   \r\n    进入之后安装向导安装即可。 \r\n   \r\n  （ 5）启动虚拟机 \r\n   \r\n    sudo qemu-system-x86_64 /opt/vm/ubuntu1010.img -m 1024\n', ''),
(54, 'jquery', 'jquery jquery 选择器\r\njQuery 的选择器可谓之强大无比，这里简单地总结一下常用的元素查找方法 \r\n   \r\n  常用选择器 \r\n   \r\n    $("#myELement")    选择id值等于myElement的元素，id值不能重复在文档中只能有一个id值是myElement所以得到的是唯一的元素 \r\n    $("div")           选择所有的div标签元素，返回div元素数组 \r\n    $(".myClass")      选择使用myClass类的css的所有元素 \r\n    $("*")             选择文档中的所有的元素，可以运用多种的选择方式进行联合选择：例如$("#myELement,div,.myclass") \r\n   \r\n  层叠选择器： \r\n   \r\n    $("form input")         选择所有的form元素中的input元素 \r\n    $("#main > *")          选择id值为main的所有的子元素 \r\n    $("label + input")     选择所有的label元素的下一个input元素节点，经测试选择器返回的是label标签后面直接跟一个input标签的所有input标签元素 \r\n    $("#prev ~ div")       同胞选择器，该选择器返回的为id为prev的标签元素的所有的属于同一个父元素的div标签 \r\n   \r\n  基本过滤选择器： \r\n   \r\n    $("tr:first")               选择所有tr元素的第一个 \r\n    $("tr:last")                选择所有tr元素的最后一个 \r\n    $("input:not(:checked) + span")   \r\n   \r\n  过滤掉：checked的选择器的所有的input元素 \r\n   \r\n    $("tr:even")               选择所有的tr元素的第0，2，4... ...个元素（注意：因为所选择的多个元素时为数组，所以序号是从0开始） \r\n     \r\n    $("tr:odd")                选择所有的tr元素的第1，3，5... ...个元素 \r\n    $("td:eq(2)")             选择所有的td元素中序号为2的那个td元素 \r\n    $("td:gt(4)")             选择td元素中序号大于4的所有td元素 \r\n    $("td:ll(4)")              选择td元素中序号小于4的所有的td元素 \r\n    $(":header") \r\n    $("div:animated") \r\n   \r\n  内容过滤选择器： \r\n   \r\n    $("div:contains(''John'')") 选择所有div中含有John文本的元素 \r\n    $("td:empty")           选择所有的为空（也不包括文本节点）的td元素的数组 \r\n    $("div:has(p)")        选择所有含有p标签的div元素 \r\n    $("td:parent")          选择所有的以td为父节点的元素数组 \r\n   \r\n  可视化过滤选择器： \r\n   \r\n    $("div:hidden")        选择所有的被hidden的div元素 \r\n    $("div:visible")        选择所有的可视化的div元素 \r\n   \r\n  属性过滤选择器： \r\n   \r\n    $("div[id]")              选择所有含有id属性的div元素 \r\n    $("input[name=''newsletter'']")    选择所有的name属性等于''newsletter''的input元素 \r\n     \r\n    $("input[name!=''newsletter'']") 选择所有的name属性不等于''newsletter''的input元素 \r\n     \r\n    $("input[name^=''news'']")         选择所有的name属性以''news''开头的input元素 \r\n    $("input[name$=''news'']")         选择所有的name属性以''news''结尾的input元素 \r\n    $("input[name*=''man'']")          选择所有的name属性包含''news''的input元素 \r\n     \r\n    $("input[id][name$=''man'']")    可以使用多个属性进行联合选择，该选择器是得到所有的含有id属性并且那么属性以man结尾的元素 \r\n   \r\n  子元素过滤选择器： \r\n   \r\n    $("ul li:nth-child(2)"),$("ul li:nth-child(odd)"),$("ul li:nth-child(3n + 1)") \r\n     \r\n    $("div span:first-child")          返回所有的div元素的第一个子节点的数组 \r\n    $("div span:last-child")           返回所有的div元素的最后一个节点的数组 \r\n    $("div button:only-child")       返回所有的div中只有唯一一个子节点的所有子节点的数组 \r\n   \r\n  表单元素选择器： \r\n   \r\n    $(":input")                  选择所有的表单输入元素，包括input, textarea, select 和 button \r\n     \r\n    $(":text")                     选择所有的text input元素 \r\n    $(":password")           选择所有的password input元素 \r\n    $(":radio")                   选择所有的radio input元素 \r\n    $(":checkbox")            选择所有的checkbox input元素 \r\n    $(":submit")               选择所有的submit input元素 \r\n    $(":image")                 选择所有的image input元素 \r\n    $(":reset")                   选择所有的reset input元素 \r\n    $(":button")                选择所有的button input元素 \r\n    $(":file")                     选择所有的file input元素 \r\n    $(":hidden")               选择所有类型为hidden的input元素或表单的隐藏域 \r\n   \r\n  表单元素过滤选择器： \r\n   \r\n    $(":enabled")             选择所有的可操作的表单元素 \r\n    $(":disabled")            选择所有的不可操作的表单元素 \r\n    $(":checked")            选择所有的被checked的表单元素 \r\n    $("select option:selected") 选择所有的select 的子元素中被selected的元素 \r\n   \r\n    \r\n   \r\n  选取一个 name 为”S_03_22″的input text框的上一个td的text值 \r\n  $(”input[@ name =S_03_22]“).parent().prev().text() \r\n   \r\n  名字以”S_”开始，并且不是以”_R”结尾的 \r\n  $(”input[@ name ^=''S_'']“).not(”[@ name $=''_R'']“) \r\n   \r\n  一个名为 radio_01的radio所选的值 \r\n  $(”input[@ name =radio_01][@checked]“).val(); \r\n   \r\n    \r\n   \r\n    \r\n   \r\n  $("A B") 查找A元素下面的所有子节点，包括非直接子节点 \r\n  $("A>B") 查找A元素下面的直接子节点 \r\n  $("A+B") 查找A元素后面的兄弟节点，包括非直接子节点 \r\n  $("A~B") 查找A元素后面的兄弟节点，不包括非直接子节点 \r\n   \r\n  1. $("A B") 查找A元素下面的所有子节点，包括非直接子节点 \r\n   \r\n  例子：找到表单中所有的 input 元素 \r\n   \r\n  HTML 代码: \r\n   \r\n  <form> \r\n  <label>Name:</label> \r\n  <input name="name" /> \r\n  <fieldset> \r\n        <label>Newsletter:</label> \r\n        <input name="newsletter" /> \r\n  </fieldset> \r\n  </form> \r\n  <input name="none" /> \r\n  jQuery 代码: \r\n   \r\n  $("form input") \r\n  结果: \r\n   \r\n  [ <input name="name" />, <input name="newsletter" /> ] \r\n   \r\n  2. $("A>B") 查找A元素下面的直接子节点 \r\n  例子：匹配表单中所有的子级input元素。 \r\n   \r\n  HTML 代码: \r\n   \r\n  <form> \r\n  <label>Name:</label> \r\n  <input name="name" /> \r\n  <fieldset> \r\n        <label>Newsletter:</label> \r\n        <input name="newsletter" /> \r\n  </fieldset> \r\n  </form> \r\n  <input name="none" /> \r\n  jQuery 代码: \r\n   \r\n  $("form > input") \r\n  结果: \r\n   \r\n  [ <input name="name" /> ] \r\n   \r\n  3. $("A+B") 查找A元素后面的兄弟节点，包括非直接子节点 \r\n  例子：匹配所有跟在 label 后面的 input 元素 \r\n   \r\n  HTML 代码: \r\n   \r\n  <form> \r\n  <label>Name:</label> \r\n  <input name="name" /> \r\n  <fieldset> \r\n        <label>Newsletter:</label> \r\n        <input name="newsletter" /> \r\n  </fieldset> \r\n  </form> \r\n  <input name="none" /> \r\n  jQuery 代码: \r\n   \r\n  $("label + input") \r\n  结果: \r\n   \r\n  [ <input name="name" />, <input name="newsletter" /> ] \r\n   \r\n   \r\n  4. $("A~B") 查找A元素后面的兄弟节点，不包括非直接子节点 \r\n  例子：找到所有与表单同辈的 input 元素 \r\n   \r\n  HTML 代码: \r\n   \r\n  <form> \r\n  <label>Name:</label> \r\n  <input name="name" /> \r\n  <fieldset> \r\n        <label>Newsletter:</label> \r\n        <input name="newsletter" /> \r\n  </fieldset> \r\n  </form> \r\n  <input name="none" /> \r\n  jQuery 代码: \r\n   \r\n  $("form ~ input") \r\n  结果: \r\n   \r\n  [ <input name="none" /> ]\n', ''),
(55, 'shell', 'shell shell \r\n  一、基本语法 \r\n   \r\n  1.1、shell文件开头 \r\n   \r\n    shell文件必须以下面的行开始（必须方在文件的第一行）： \r\n    #!/bin/sh \r\n    符号#!用来告诉系统它后面的参数是用来执行该文件的程序。在这个例子中我们使用/bin/sh来执行程序。 \r\n    当编辑好脚本时，如果要执行该脚本，还必须使其可执行。 \r\n    要使脚本可执行： \r\n    运行chmod +x filename 这样才能用./filename 来运行 \r\n   \r\n  1.2 注释 \r\n   \r\n    在进行shell编程时，以#开头的句子表示注释，直到这一行的结束。我们真诚地建议您在程序中使用注释。 \r\n    如果您使用了注释，那么即使相当长的时间内没有使用该脚本，您也能在很短的时间内明白该脚本的作用 \r\n    及工作原理。 \r\n   \r\n  1.3 变量 \r\n   \r\n    在shell编程中，所有的变量都由字符串组成，并且您不需要对变量进行声明，直接赋值就可以，应用变量的话，用$+变量名的形式。 \r\n    要赋值给一个变量，您可以这样写： \r\n    a="hello world" \r\n    现在打印变量a的内容： \r\n    echo "A is:" \r\n    echo $a \r\n    有时候变量名很容易与其他文字混淆，比如： \r\n    num=2 \r\n    echo "this is the $numnd" \r\n    这并不会打印出"this is the 2nd"，而仅仅打印"this is the "，因为shell会去搜索变量numnd的值， \r\n    但是这个变量时没有值的。可以使用花括号来告诉shell我们要打印的是num变量： \r\n    num=2 \r\n    echo "this is the ${num}nd" \r\n    这将打印： this is the 2nd \r\n   \r\n  1.4 环境变量 \r\n   \r\n    由export关键字处理过的变量叫做环境变量。我们不对环境变量进行讨论，因为通常情况下仅仅在登录 \r\n    脚本中使用环境变量。 \r\n   \r\n  二、概念: 管道, 重定向和 backtick \r\n   \r\n   \r\n    这些不是系统命令，但是他们真的很重要。 \r\n    管道 (|)： 将一个命令的输出作为另外一个命令的输入。 \r\n    grep "hello" file.txt | wc -l \r\n    在file.txt中搜索包含有”hello”的行并计算其行数。 \r\n    在这里grep命令的输出作为wc命令的输入。当然您可以使用多个命令。 \r\n    重定向：将命令的结果输出到文件，而不是标准输出（屏幕）。 \r\n    > 写入文件并覆盖旧文件 \r\n    >> 加到文件的尾部，保留旧文件内容。 \r\n    反短斜线 \r\n    使用反短斜线("`")可以将一个命令的输出作为另外一个命令的一个命令行参数。 \r\n    命令： \r\n    find . -mtime -1 -type f -print \r\n    用来查找过去24小时（-mtime –2则表示过去48小时）内修改过的文件。如果您 \r\n    想将所有查找到的文件打一个包，则可以使用以下脚本： \r\n    #!/bin/sh \r\n    # The ticks are backticks (`) not normal quotes (''): \r\n    tar -zcvf lastmod.tar.gz `find . -mtime -1 -type f -print` \r\n   \r\n  三、 流程控制语句 \r\n   \r\n  3.1、if \r\n   \r\n    "if" 表达式 如果条件为真则执行then后面的部分： \r\n    if ....; then \r\n    ....  \r\n    elif ....; then \r\n    ....  \r\n    else \r\n    ....  \r\n    fi \r\n   \r\n    大多数情况下，可以使用测试命令来对条件进行测试。比如可以比较字符串、判断文件 \r\n    是否存在及是否可读等等… \r\n    通常用" [ ] "来表示条件测试。注意这里的空格很重要。要确保方括号的空格。 \r\n    [ -f "somefile" ] ：判断是否是一个文件 \r\n    [ -x "/bin/ls" ] ：判断/bin/ls是否存在并有可执行权限 \r\n    [ -n "$var" ] ：判断$var变量是否有值 \r\n    [ "$a" = "$b" ] ：判断$a和$b是否相等 ,注意“=”和变量之间要有空格。 \r\n    执行man test可以查看所有测试表达式可以比较和判断的类型。 \r\n    直接执行以下脚本： \r\n    #!/bin/sh \r\n    if [ "$SHELL" = "/bin/bash" ]; then \r\n    echo "your login shell is the bash (bourne again shell)" \r\n    else \r\n    echo "your login shell is not bash but $SHELL" \r\n    fi \r\n    变量$SHELL包含了登录shell的名称，我们和/bin/bash进行了比较。 \r\n   \r\n  3.2、快捷操作符&&和|| \r\n   \r\n    熟悉C语言的朋友可能会很喜欢下面的表达式： \r\n    [ -f "/etc/shadow" ] && echo "This computer uses shadow passwors" \r\n    这里 && 就是一个快捷操作符，如果左边的表达式为真则执行右边的语句。 \r\n    您也可以认为是逻辑运算中的与操作。上例中表示如果/etc/shadow文件存在 \r\n    则打印” This computer uses shadow passwors”。同样或操作(||)在shell编程中也是 \r\n    可用的。这里有个例子： \r\n    #!/bin/sh \r\n    mailfolder=/var/spool/mail/james \r\n    [ -r "$mailfolder" ]||{ echo "Can not read $mailfolder" ; exit 1; } \r\n    echo "$mailfolder has mail from:" \r\n    grep "^From " $mailfolder \r\n    该脚本首先判断mailfolder是否可读。如果可读则打印该文件中的"From" 一行。如果不可读 \r\n    则或操作生效，打印错误信息后脚本退出。这里有个问题，那就是我们必须有两个命令： \r\n    -打印错误信息 \r\n    -退出程序 \r\n    我们使用花括号以匿名函数的形式将两个命令放到一起作为一个命令使用。一般函数将在下文提及。 \r\n    不用与和或操作符，我们也可以用if表达式作任何事情，但是使用与或操作符会更便利很多。 \r\n   \r\n  3.3、case \r\n   \r\n    case :表达式可以用来匹配一个给定的字符串，而不是数字。 \r\n    case ... in \r\n    ...) do something here ;; \r\n    esac \r\n    以下是一个使用case的实例： \r\n    dirs=`ls $sourceRoot/android | tr ''\r\n'' '' ''` \r\n    for i in $dirs \r\n    do \r\n    sourceFold=$sourceRoot/android/${i} \r\n    case ${i} in \r\n    out) \r\n    echo "skip ${i}";; \r\n    kernel|frameworks|vendor|build) \r\n    cp -rfu $sourceFold $workRoot/android \r\n    echo "copy ${i}";; \r\n    *) \r\n    ln -sf $sourceFold $workRoot/android \r\n    echo "linking ${i}";; \r\n    esac \r\n    done \r\n    再让我们看一个例子。 file命令可以辨别出一个给定文件的文件类型，比如： \r\n    file lf.gz \r\n    这将返回： \r\n    lf.gz: gzip compressed data, deflated, original filename, \r\n    last modified: Mon Aug 27 23:09:18 2001, os: Unix \r\n    下面有个一个叫做smartzip的脚本，该脚本可以自动解压bzip2, gzip 和zip 类型的压缩文件： \r\n    #!/bin/sh \r\n    ftype=`file "$1"` \r\n    case "$ftype" in \r\n    "$1: Zip archive"*) \r\n    unzip "$1" ;; \r\n    "$1: gzip compressed"*) \r\n    gunzip "$1" ;; \r\n    "$1: bzip2 compressed"*) \r\n    bunzip2 "$1" ;; \r\n    *) echo "File $1 can not be uncompressed with smartzip";; \r\n    esac \r\n    您可能注意到我们在这里使用了一个特殊的变量$1。该变量包含了传递给该程序的第一个参数值。 \r\n    也就是说，当我们运行： \r\n    smartzip articles.zip \r\n    $1 就是字符串 articles.zip \r\n   \r\n  3.4、 selsect \r\n   \r\n    select 表达式是一种bash的扩展应用，尤其擅长于交互式使用。用户可以从一组不同的值中进行选择。 \r\n    select var in ... ; do \r\n    break \r\n    done \r\n    .... now $var can be used ....  \r\n    下面是一个例子： \r\n    #!/bin/sh \r\n    echo "What is your favourite OS?" \r\n    select var in "Linux" "Gnu Hurd" "Free BSD" "Other"; do \r\n    break \r\n    done \r\n    echo "You have selected $var" \r\n    下面是该脚本运行的结果： \r\n    What is your favourite OS?  \r\n    1) Linux \r\n    2) Gnu Hurd \r\n    3) Free BSD \r\n    4) Other \r\n    #? 1 \r\n    You have selected Linux \r\n    注意：select是扩展应用。 \r\n   \r\n  3.4、while \r\n   \r\n    while表达式： \r\n    while ...; do \r\n    ....  \r\n    done \r\n    当while中的表达式为真时，将一直循环。 \r\n    可以用关键字"break" 用来跳出循环；也可以用关键字”continue”用来不执行余下的部分而直接跳到下一个循环。 \r\n    实例3-4-1 \r\n    #!/bin/sh \r\n    num=10 \r\n    while [ ! "$num" = "0" ]; do \r\n    #num=num-1 \r\n    num=`expr "$num" "-" "1"` \r\n    echo $num \r\n    done \r\n    3.5、for \r\n    for-loop表达式查看一个字符串列表 (字符串用空格分隔) 然后将其赋给一个变量： \r\n    for var in ....; do \r\n    ....  \r\n    done \r\n    在下面的例子中，将分别打印ABC到屏幕上： \r\n    #!/bin/sh \r\n    for var in A B C ; do \r\n    echo "var is $var" \r\n    done \r\n    下面是一个更为有用的脚本showrpm，其功能是打印一些RPM包的统计信息： \r\n    #!/bin/sh \r\n    # list a content summary of a number of RPM packages \r\n    # USAGE: showrpm rpmfile1 rpmfile2 ...  \r\n    # EXAMPLE: showrpm /cdrom/RedHat/RPMS/*.rpm \r\n    for rpmpackage in $*; do \r\n    if [ -r "$rpmpackage" ];then \r\n    echo "=============== $rpmpackage ==============" \r\n    rpm -qi -p $rpmpackage \r\n    else \r\n    echo "ERROR: cannot read file $rpmpackage" \r\n    fi \r\n    done \r\n    这里出现了第二个特殊的变量$*，该变量包含了所有输入的命令行参数值。 \r\n    如果您运行showrpm openssh.rpm w3m.rpm webgrep.rpm \r\n    此时 $* 包含了 3 个字符串，即openssh.rpm, w3m.rpm and webgrep.rpm.  \r\n   \r\n  四、引号 \r\n   \r\n    在向程序传递任何参数之前，程序会扩展通配符和变量。这里所谓扩展的意思是程序会把通配符 \r\n    （比如*）替换成合适的文件名，它变量替换成变量值。为了防 止程序作这种替换，您可以使用 \r\n    引号：让我们来看一个例子，假设在当前目录下有一些文件，两个jpg文件， mail.jpg 和tux.jpg。 \r\n    echo *.jpg \r\n    这将打印出"mail.jpg tux.jpg"的结果。 \r\n    引号 (单引号和双引号) 将防止这种通配符扩展： \r\n    #!/bin/sh \r\n    echo "*.jpg" \r\n    echo ''*.jpg'' \r\n    这将打印"*.jpg" 两次。 \r\n    单引号更严格一些。它可以防止任何变量扩展。双引号可以防止通配符扩展但允许变量扩展。 \r\n    #!/bin/sh \r\n    echo $SHELL \r\n    echo "$SHELL" \r\n    echo ''$SHELL'' \r\n    运行结果为： \r\n    /bin/bash \r\n    /bin/bash \r\n    $SHELL \r\n    最后，还有一种防止这种扩展的方法，那就是使用转义字符——反斜杆： \r\n    echo \\*.jpg \r\n    echo \\$SHELL \r\n    这将输出： \r\n    *.jpg \r\n    $SHELL \r\n   \r\n  五、函数 \r\n   \r\n    如果您写了一些稍微复杂一些的程序，您就会发现在程序中可能在几个地方使用了相同的代码， \r\n    并且您也会发现，如果我们使用了函数，会方便很多。一个函数是这个样子的： \r\n    functionname() \r\n    { \r\n    # inside the body $1 is the first argument given to the function \r\n    # $2 the second ...  \r\n    body \r\n    } \r\n    您需要在每个程序的开始对函数进行声明。 \r\n    下面是一个叫做xtitlebar的脚本，使用这个脚本您可以改变终端窗口的名称。 \r\n    这里使用了一个叫做help的函数。正如您可以看到的那样，这个定义的函数被使用了两次。 \r\n    #!/bin/sh \r\n    # vim: set sw=4 ts=4 et: \r\n    help() \r\n    { \r\n    cat << HELP \r\n    xtitlebar -- change the name of an xterm, gnome-terminal or kde konsole \r\n    USAGE: xtitlebar [-h] "string_for_titelbar" \r\n    OPTIONS: -h help text \r\n    EXAMPLE: xtitlebar "cvs" \r\n    HELP \r\n    exit 0 \r\n    } \r\n    # in case of error or if -h is given we call the function help: \r\n    [ -z "$1" ] && help \r\n    [ "$1" = "-h" ] && help \r\n    # send the escape sequence to change the xterm titelbar: \r\n    echo $1 \r\n    echo -e "33]0;"$1"07" \r\n    # \r\n    在脚本中提供帮助是一种很好的编程习惯，这样方便其他用户（和您）使用和理解脚本。命令行参数我们已经见过$* 和 $1, $2 ... $9 等特殊变量，这些特殊变量包含了用户从命令行输入的参数。迄今为止，我们仅仅了解了一些简单的命令行语法（比如一些强制性的参数和查看帮助的-h选项）。 但是在编写更复杂的程序时，您可能会发现您需要更多的自定义的选项。通常的惯例是在所有可选的参数之前加一个减号，后面再加上参数值 (比如文件名)。 有好多方法可以实现对输入参数的分析，但是下面的使用case表达式的例子无疑是一个不错的方法。 \r\n    文件test.sh \r\n    #!/bin/sh \r\n    help() \r\n    { \r\n    cat << HELP \r\n    This is a generic command line parser demo.  \r\n    USAGE EXAMPLE: cmdparser -l hello -f somefile1 somefile2 \r\n    HELP \r\n    exit 0 \r\n    } \r\n    while [ -n "$1" ]; do \r\n    case $1 in \r\n    -h) help;shift 1;; # function help is called \r\n    -f) opt_f=1;shift 1;; # variable opt_f is set \r\n    -l) opt_l=$2;shift 2;; # -l takes an argument -> shift by 2 \r\n    -*) echo "error: no such option $1. -h for help";exit 1;; \r\n    *) break;; \r\n    esac \r\n    done \r\n    echo "opt_f is $opt_f" \r\n    echo "opt_l is $opt_l" \r\n    echo "first arg is $1" \r\n    echo "2nd arg is $2" \r\n    您可以这样运行该脚本： \r\n    sh test.sh -l hello -f a b \r\n    返回的结果是： \r\n    opt_f is 1 \r\n    opt_l is hello \r\n    first arg is a \r\n    2nd arg is b \r\n    这个脚本是如何工作的呢？脚本首先在所有输入命令行参数中进行循环，将输入参数 \r\n    与case表达式进行比较，如果匹配则设置一个变量并且移除该参数。根据unix系统的惯例， \r\n    首先输入的应该是包含减号的参数.  \r\n   \r\n   \r\n  六、 Here documents \r\n   \r\n    当要将几行文字传递给一个命令时，here documents（译者注：目前还没有见到过对该词适合的翻译） \r\n    一种不错的方法。对每个脚本写一段帮助性的文字是很有用的，此时如果我们使用here documents技术 \r\n     就不必用echo函数一行行输出。 一个 Here document 以 << 开头，后面接上一个字符串(任意的)，假设是“robin” \r\n    在你文本结束后，再用这个字符串(“robin”)追加一行，以表示文本结束。这个字符串我暂称之为边界区分字符串。下面是一个例子， \r\n    #!/bin/sh \r\n    cat << HELP \r\n    ren -- renames a number of files using sed regular expressions \r\n    USAGE: ren ''regexp'' ''replacement'' files...  \r\n    EXAMPLE: rename all *.HTM files in *.html: \r\n    ren ''HTM$'' ''html'' *.HTM \r\n    HELP \r\n    上面我们是选用HELP作为边界区分字符串的。其实我们也可以使用任意的字符串，比如robin，那么上例将变成如下： \r\n    #!/bin/sh \r\n    cat << robin \r\n    ren -- renames a number of files using sed regular expressions \r\n    USAGE: ren ''regexp'' ''replacement'' files...  \r\n    EXAMPLE: rename all *.HTM files in *.html: \r\n    ren ''HTM$'' ''html'' *.HTM \r\n    robin \r\n   \r\n  七、调试 \r\n   \r\n    最简单的调试命令当然是使用echo命令。您可以使用echo在任何怀疑出错的地方打印任何变量值。这也是绝大多数的shell程序员要花费80%的时间来调试程序的原因。Shell程序的好处在于不需要重新编译，插入一个echo命令也不需要多少时间。 \r\n    shell也有一个真实的调试模式。如果在脚本中有错误，您可以这样来进行调试： \r\n    sh -x test.sh \r\n    这将执行该脚本并显示所有变量的值。 \r\n    shell还有一个不需要执行脚本只是检查语法的模式。可以这样使用： \r\n    sh -n test,sh \r\n    这将返回所有语法错误 \r\n    八、 Shell基本命令 \r\n    在shell脚本中可以使用任意的unix/linux命令，但是还是由一些相对更常用的命令。这些命令通常是用来 \r\n    进行文件和文字操作的。 \r\n    关于linux命令的详细内容请参考《Linux命令简介》 \r\n    常用命令语法及功能 \r\n    echo "some text": 将文字内容打印在屏幕上 \r\n    ls: 文件列表 \r\n    wc –l filewc或-w filewc或-c file: 计算文件行数；计算文件中的单词数；计算文件中的字符数 \r\n    cp sourcefile destfile: 文件拷贝 \r\n    mv oldname newname : 重命名文件或移动文件 \r\n    rm file: 删除文件 \r\n    grep ''pattern'' file: 在文件内搜索字符串比如：grep ''searchstring'' file.txt \r\n    cut -b colnum file: 指定欲显示的文件内容范围，并将它们输出到标准输出设备比如：输出 \r\n    每行第5个到第9个字符cut -b5-9 file.txt \r\n    cat file.txt: 输出文件内容到标准输出设备（屏幕）上 \r\n    file somefile: 得到文件类型 \r\n    read var: 提示用户输入，并将输入赋值给变量 \r\n    sort file.txt: 对file.txt文件中的行进行排序 \r\n    uniq: 删除文本文件中出现的行列比如： sort file.txt | uniq \r\n    expr: 进行数学运算Example: add 2 and 3expr 2 "+" 3 \r\n    find: 搜索文件比如：根据文件名搜索find . -name filename -print \r\n    tee: 将数据输出到标准输出设备(屏幕) 和文件比如：somecommand | tee outfile \r\n    basename file: 返回不包含路径的文件名比如： basename /bin/tux将返回 tux \r\n    dirname file: 返回文件所在路径比如：dirname /bin/tux将返回 /bin \r\n    head file: 打印文本文件开头几行 \r\n    tail file : 打印文本文件末尾几行 \r\n    sed: Sed是一个基本的查找替换程序。可以从标准输入（比如命令管道）读入文本，并将 \r\n    结果输出到标准输出（屏幕）。该命令采用正则表达式（见参考）进行搜索。 \r\n    不要和shell中的通配符相混淆。比如：将linuxfocus 替换为 \r\n    LinuxFocus ：cat text.file | sed ''s/linuxfocus/LinuxFocus/'' > newtext.file \r\n    awk: awk 用来从文本文件中提取字段。缺省地，字段分割符是空格，可以使用-F指定其他分割符。 \r\n    cat file.txt | awk -F, ''{print $1 "," $3 }''这里我们使用，作为字段分割符，同时打印 \r\n    第一个和第三个字段。如果该文件内容如下： Adam Bor, 34, IndiaKerry Miller, 22, USA \r\n    命令输出结果为：Adam Bor, IndiaKerry Miller\n', ''),
(56, 'java', 'java java java性能调优 \r\n\r\n \r\n######################################################### \r\n##  注意：在java程序调试过程中如果想知道工具有那些选项 ## \r\n##   可以使用 -options 显示，例如： jstat -options     ## \r\n#########################################################\r\n\r\n \r\n  jps -- Java Virtual Machine Process Status Tool \r\n  可以列出本机所有java进程的pid \r\n  jps [ options ] [ hostid ] \r\n  -q 仅输出VM标识符，不包括class name,jar name,arguments in main method \r\n  -m 输出main method的参数 \r\n  -l 输出完全的包名，应用主类名，jar的完全路径名 \r\n  -v 输出jvm参数 \r\n  -V 输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件 \r\n  -Joption 传递参数到vm,例如:-J-Xms48m \r\n   \r\n  hostid: \r\n  [protocol:][[\n   \r\n  输出格式: \r\n  lvmid [ [ classname | JARfilename | "Unknown"] [ arg* ] [ jvmarg* ] ] \r\n   \r\n  样例: \r\n  jps -v \r\n  jps -lv \r\n   \r\n  ==================================================== \r\n  jstack -- Stack Trace \r\n  此命令打印java线程的堆栈跟踪，可以得知哪些线程被阻塞或正等待，以便于查找原因 \r\n  jstack [ option ] pid \r\n  -m 打印混合模式(java,c/c++ stack trace) \r\n   \r\n  样例： \r\n  jstack pid \r\n   \r\n  ==================================================== \r\n  jmap -- Memory Map \r\n  此命令打印java的共享对象内存map和堆内存的细节 \r\n  jmap [ option ] pid \r\n  -- 打印共享对象mapping \r\n  -dump:[live,]format=b,file= -- dump堆中的对象到文件 \r\n  -finalizerinfo  打印等待回收对象的信息 \r\n  -heap  打印堆总结 \r\n  -histo[:live]  打印堆的对象统计，包括对象数、内存大小等等 \r\n  -permstat  打印java堆perm区的classloader统计 \r\n  -F  强制，在jmap -dump或jmap -histo中使用，如果pid没有相应的回复 \r\n  -J  提供jvm选项，如：-J-Xms256m \r\n   \r\n  样例： \r\n   \r\n  jmap -heap pid \r\n  jmap -dump:live,file=   dump堆中的live对象到文件 \r\n  jmap -dump:file=   dump堆中的所有对象 \r\n  jmap -dump:live,format=b,file=   以二进制格式dump \r\n   \r\n  ======================================== \r\n  jhat -- Java Heap Analysis Tool \r\n  -port  jhat的http server端口号 \r\n  -J  提供jvm选项 \r\n   \r\n  jmap -dump:live,file= -- dump堆中live对象到文件,可以利用jhat去查看dump文件 \r\n  jhat 并且访问网址http://localhost:7000/ \r\n  如果报内存不够，则用jhat -J-Xmx256m 即可 \r\n   \r\n  ======================================== \r\n  jconsole \r\n  使用JTop插件 \r\n  <JDK6>/bin/jconsole -pluginpath <JDK6>/demo/management/JTop/JTop.jar \r\n   \r\n   \r\n   \r\n  jstat \r\n  工具特别强大，有众多的可选项，详细查看堆内各个部分的使用量，以及加载类的数量。使用时，需加上查看进程的进程id，和所选参数。以下详细介绍各个参数的意义。 \r\n  jstat -class pid:显示加载class的数量，及所占空间等信息。 \r\n  jstat -compiler pid:显示VM实时编译的数量等信息。 \r\n  jstat -gc pid:可以显示gc的信息，查看gc的次数，及时间。其中最后五项，分别是young gc的次数，young gc的时间，full gc的次数，full gc的时间，gc的总时间。 \r\n  jstat -gccapacity:可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小，如：PGCMN显示的是最小perm的内存使用量，PGCMX显示的是perm的内存最大使用量，PGC是当前新生成的perm内存占用量，PC是但前perm内存占用量。其他的可以根据这个类推， OC是old内纯的占用量。 \r\n  jstat -gcnew pid:new对象的信息。 \r\n  jstat -gcnewcapacity pid:new对象的信息及其占用量。 \r\n  jstat -gcold pid:old对象的信息。 \r\n  jstat -gcoldcapacity pid:old对象的信息及其占用量。 \r\n  jstat -gcpermcapacity pid: perm对象的信息及其占用量。 \r\n  jstat -util pid:统计gc信息统计。 \r\n  jstat -printcompilation pid:当前VM执行的信息。 \r\n  除了以上一个参数外，还可以同时加上 两个数字，如：jstat -printcompilation 3024 250 6是每250毫秒打印一次，一共打印6次，还可以加上-h3每三行显示一下标题。 \r\n  jmap是一个可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本。使用方法 jmap -histo pid。如果连用SHELL jmap -histo pid>a.log可以将其保存到文本中去，在一段时间后，使用文本对比工具，可以对比出GC回收了哪些对象。jmap -dump:format=b,file=String 3024可以将3024进程的内存heap输出出来到String文件里。 \r\n  jinfo:的用处比较简单，就是能输出并修改运行时的java进程的运行参数。用法是jinfo -opt  pid 如：查看2788的MaxPerm大小可以用  jinfo -flag MaxPermSize 2788。 \r\n  jps:查看当前运行的jvm进程号 \r\n  jstack：打印当前某个jvm的详细的线程堆栈信息 \r\n######################################################### \r\n##  注意：在java程序调试过程中如果想知道工具有那些选项 ## \r\n##   可以使用 -options 显示，例如： jstat -options     ## \r\n#########################################################\r\n\r\n\n', ''),
(57, 'wget', 'wget wget 使用文档\r\n \r\n  1、使用wget下载单个文件 \r\n   \r\n    下的例子是从网络下载一个文件并保存在当前目录 \r\n   \r\n    get http:\n   \r\n    下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。 \r\n   \r\n  2、使用wget -O下载并以不同的文件名保存 \r\n   \r\n    get默认会以最后一个符合”/”的后面的字符来命令，对于动态链接的下载通常文件名会不正确。 \r\n    误：下面的例子会下载一个文件并以名称download.php?id=1080保存 \r\n   \r\n    get http://www.centos.bz/download?id=1 \r\n    使下载的文件是zip格式，它仍然以download.php?id=1080命令。 \r\n    确：为了解决这个问题，我们可以使用参数-O来指定一个文件名： \r\n   \r\n    get -O wordpress.zip http://www.centos.bz/download.php?id=1080 \r\n   \r\n  3、使用wget –limit -rate限速下载 \r\n    你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。 \r\n   \r\n    get –limit-rate=300k http:\n   \r\n  4、使用wget -c断点续传 \r\n    用wget -c重新启动下载中断的文件: \r\n   \r\n    get -c http:\n    于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。 \r\n   \r\n  5、使用wget -b后台下载 \r\n    于下载非常大的文件的时候，我们可以使用参数-b进行后台下载。 \r\n   \r\n    get -b http:\n    ontinuing in background, pid 1840.  \r\n    utput will be written to `wget-log’.  \r\n    可以使用以下命令来察看下载进度 \r\n   \r\n    ail -f wget-log \r\n   \r\n  6、伪装代理名称下载 \r\n    些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过–user-agent参数伪装。 \r\n   \r\n    get –user-agent=”Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16″ 下载链接 \r\n   \r\n  7、使用wget –spider测试下载链接 \r\n    你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加–spider参数进行检查。 \r\n   \r\n    get –spider URL \r\n    果下载链接正确，将会显示 \r\n   \r\n    get –spider URL \r\n    pider mode enabled. Check if remote file exists.  \r\n    TTP request sent, awaiting response… 200 OK \r\n    ength: unspecified [text/html] \r\n    emote file exists and could contain further links, \r\n    ut recursion is disabled — not retrieving.  \r\n    保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误 \r\n   \r\n    get –spider url \r\n    pider mode enabled. Check if remote file exists.  \r\n    TTP request sent, awaiting response… 404 Not Found \r\n    emote file does not exist — broken link!!!  \r\n    可以在以下几种情况下使用spider参数： \r\n   \r\n    时下载之前进行检查 \r\n    隔检测网站是否可用 \r\n    查网站页面的死链接 \r\n   \r\n  8、使用wget –tries增加重试次数 \r\n    果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用–tries增加重试次数。 \r\n   \r\n    get –tries=40 URL \r\n   \r\n  9、使用wget -i下载多个文件 \r\n    先，保存一份下载链接文件 \r\n   \r\n    at > filelist.txt \r\n    rl1 \r\n    rl2 \r\n    rl3 \r\n    rl4 \r\n    着使用这个文件和参数-i下载 \r\n   \r\n    get -i filelist.txt \r\n   \r\n  10、使用wget –mirror镜像网站 \r\n    面的例子是下载整个网站到本地。 \r\n   \r\n    get –mirror -p –convert-links -P ./LOCAL URL \r\n    miror:开户镜像下载 \r\n    p:下载所有为了html页面显示正常的文件 \r\n    convert-links:下载后，转换成本地的链接 \r\n    P ./LOCAL：保存所有文件和目录到本地指定目录 \r\n   \r\n  11、使用wget –reject过滤指定格式下载 \r\n    想下载一个网站，但你不希望下载图片，你可以使用以下命令。 \r\n   \r\n    get –reject=gif url \r\n   \r\n  12、使用wget -o把下载信息存入日志文件 \r\n    不希望下载信息直接显示在终端而是在一个日志文件，可以使用以下命令： \r\n   \r\n    get -o download.log URL \r\n   \r\n  13、使用wget -Q限制总下载文件大小 \r\n    你想要下载的文件超过5M而退出下载，你可以使用以下命令: \r\n   \r\n    get -Q5m -i filelist.txt \r\n    意：这个参数对单个文件下载不起作用，只能递归下载时才有效。 \r\n   \r\n  14、使用wget -r -A下载指定格式文件 \r\n    以在以下情况使用该功能 \r\n   \r\n    载一个网站的所有图片 \r\n    载一个网站的所有视频 \r\n    载一个网站的所有PDF文件 \r\n    get -r -A.pdf url \r\n   \r\n  15、使用wget FTP下载 \r\n    可以使用wget来完成ftp链接的下载。 \r\n    用wget匿名ftp下载 \r\n   \r\n    get ftp-url \r\n   \r\n    用wget用户名和密码认证的ftp下载 \r\n   \r\n    get –ftp-user=USERNAME –ftp-password=PASSWORD url \r\n   \r\n    get是在Linux下开发的开放源代码的软件，作者是Hrvoje Niksic，后来被移植到包括Windows在内的各个平台上。它有以下功能和特点： \r\n   \r\n    1）支持断点下传功能；这一点，也是网络蚂蚁和FlashGet当年最大的卖点，现在，Wget也可以使用此功能，那些网络不是太好的用户可以放心了； \r\n    2）同时支持FTP和HTTP下载方式；尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件； \r\n    3）支持代理服务器；对安全强度很高的系统而言，一般不会将自己的系统直接暴露在互联网上，所以，支持代理是下载软件必须有的功能； \r\n    4）设置方便简单；可能，习惯图形界面的用户已经不是太习惯命令行了，但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标； \r\n    5）程序小，完全免费；程序小可以考虑不计，因为现在的硬盘实在太大了；完全免费就不得不考虑了，即使网络上有很多所谓的免费软件，但是，这些软件的广告却不是我们喜欢的； \r\n   \r\n    get虽然功能强大，但是使用起来还是比较简单的，基本的语法是：wget [参数列表] URL。下面就结合具体的例子来说明一下wget的用法。 \r\n   \r\n  1、下载整个http或者ftp站点。 \r\n    get http://place.your.url/here \r\n    个命令可以将http://place.your.url/here 首页下载下来。使用-x会强制建立服务器上一模一样的目录，如果使用-nd参数，那么服务器上下载的所有内容都会加到本地当前目录。 \r\n   \r\n    get -r http://place.your.url/here \r\n     个命令会按照递归的方法，下载服务器上所有的目录和文件，实质就是下载整个网站。这个命令一定要小心使用，因为在下载的时候，被下载网站指向的所有地址同 样会被下载，因此，如果这个网站引用了其他网站，那么被引用的网站也会被下载下来！基于这个原因，这个参数不常用。可以用-l number参数来指定下载的层次。例如只下载两层，那么使用-l 2。 \r\n   \r\n    是您想制作镜像站点，那么可以使用－m参数，例如：wget -m http://place.your.url/here \r\n    时wget会自动判断合适的参数来制作镜像站点。此时，wget会登录到服务器上，读入robots.txt并按robots.txt的规定来执行。 \r\n   \r\n  2、断点续传。 \r\n    文件特别大或者网络特别慢的时候，往往一个文件还没有下载完，连接就已经被切断，此时就需要断点续传。wget的断点续传是自动的，只需要使用-c参数，例如： \r\n    get -c http://the.url.of/incomplete/file \r\n    用断点续传要求服务器支持断点续传。-t参数表示重试次数，例如需要重试100次，那么就写-t 100，如果设成-t 0，那么表示无穷次重试，直到连接成功。-T参数表示超时等待时间，例如-T 120，表示等待120秒连接不上就算超时。 \r\n   \r\n  3、批量下载。 \r\n    果有多个文件需要下载，那么可以生成一个文件，把每个文件的URL写一行，例如生成文件download.txt，然后用命令：wget -i download.txt \r\n    样就会把download.txt里面列出的每个URL都下载下来。（如果列的是文件就下载文件，如果列的是网站，那么下载首页） \r\n   \r\n  4、选择性的下载。 \r\n    以指定让wget只下载一类文件，或者不下载什么文件。例如： \r\n    get -m –reject=gif http://target.web.site/subdirectory \r\n    示下载http://target.web.site/subdirectory，但是忽略gif文件。–accept=LIST 可以接受的文件类型，–reject=LIST拒绝接受的文件类型。 \r\n   \r\n  5、密码和认证。 \r\n    get只能处理利用用户名/密码方式限制访问的网站，可以利用两个参数： \r\n    http-user=USER设置HTTP用户 \r\n    http-passwd=PASS设置HTTP密码 \r\n    于需要证书做认证的网站，就只能利用其他下载工具了，例如curl。 \r\n   \r\n  6、利用代理服务器进行下载。 \r\n    果用户的网络需要经过代理服务器，那么可以让wget通过代理服务器进行文件的下载。此时需要在当前用户的目录下创建一个.wgetrc文件。文件中可以设置代理服务器： \r\n    ttp-proxy = 111.111.111.111:8080 \r\n    tp-proxy = 111.111.111.111:8080 \r\n    别表示http的代理服务器和ftp的代理服务器。如果代理服务器需要密码则使用： \r\n    proxy-user=USER设置代理用户 \r\n    proxy-passwd=PASS设置代理密码 \r\n    两个参数。 \r\n    用参数–proxy=on/off 使用或者关闭代理。 \r\n    get还有很多有用的功能，需要用户去挖掘。 \r\n   \r\n    录： \r\n   \r\n    令格式： \r\n    get [参数列表] [目标软件、网页的网址] \r\n   \r\n    V,–version 显示软件版本号然后退出； \r\n    h,–help显示软件帮助信息； \r\n    e,–execute=COMMAND 执行一个 “.wgetrc”命令 \r\n   \r\n    o,–output-file=FILE 将软件输出信息保存到文件； \r\n    a,–append-output=FILE将软件输出信息追加到文件； \r\n    d,–debug显示输出信息； \r\n    q,–quiet 不显示输出信息； \r\n    i,–input-file=FILE 从文件中取得URL； \r\n   \r\n    t,–tries=NUMBER 是否下载次数（0表示无穷次） \r\n    O –output-document=FILE下载文件保存为别的文件名 \r\n    nc, –no-clobber 不要覆盖已经存在的文件 \r\n    N,–timestamping只下载比本地新的文件 \r\n    T,–timeout=SECONDS 设置超时时间 \r\n    Y,–proxy=on/off 关闭代理 \r\n   \r\n    nd,–no-directories 不建立目录 \r\n    x,–force-directories 强制建立目录 \r\n   \r\n    http-user=USER设置HTTP用户 \r\n    http-passwd=PASS设置HTTP密码 \r\n    proxy-user=USER设置代理用户 \r\n    proxy-passwd=PASS设置代理密码 \r\n   \r\n    r,–recursive 下载整个网站、目录（小心使用） \r\n    l,–level=NUMBER 下载层次 \r\n   \r\n    A,–accept=LIST 可以接受的文件类型 \r\n    R,–reject=LIST拒绝接受的文件类型 \r\n    D,–domains=LIST可以接受的域名 \r\n    exclude-domains=LIST拒绝的域名 \r\n    L,–relative 下载关联链接 \r\n    follow-ftp 只下载FTP链接 \r\n    H,–span-hosts 可以下载外面的主机 \r\n    I,–include-directories=LIST允许的目录 \r\n    X,–exclude-directories=LIST 拒绝的目录 \r\n   \r\n    文文档名在平常的情况下会被编码， 但是在 –cut-dirs 时又是正常的， \r\n    get -r -np -nH –cut-dirs=3 ftp://host/test/ \r\n    试.txt \r\n    get -r -np -nH -nd ftp://host/test/ \r\n    B4%FA%B8%D5.txt \r\n    get “ftp://host/test/*” \r\n    B4%FA%B8%D5.txt \r\n   \r\n     於不知名的原因，可能是为了避开特殊档名， wget 会自动将抓取档名的部分用 encode_string 处理过， 所以该 patch 就把被 encode_string 处理成 “%3A” 这种东西， 用 decode_string 还原成 “:”，并套用在目录与档案名称的部分，decode_string 是 wget 内建的函式。 \r\n   \r\n    get -t0 -c -nH -x -np -b -m -P /home/sunny/NOD32view/ http://downloads1.kaspersky-labs.com/bases/ -o wget.log\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(58, 'curl', 'curl curl 使用文档 \r\n   对于windows用户如果用Cygwin模拟unix环境的话，里面没有带curl命令，要自己装，所以建议用Gow来模拟，它已经自带了curl工具，安装后直接在cmd环境中用curl命令就可，因为路径已经自动给你配置好了。 \r\n      linux curl是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称url为下载工具。 \r\n  一，curl命令参数，有好多我没有用过，也不知道翻译的对不对，如果有误的地方，还请指正。 \r\n  　　-a/--append 上传文件时，附加到目标文件 \r\n  　　-A/--user-agent <string>  设置用户代理发送给服务器 \r\n  　　- anyauth   可以使用“任何”身份验证方法 \r\n  　　-b/--cookie <name=string/file> cookie字符串或文件读取位置 \r\n  　　- basic 使用HTTP基本验证 \r\n  　　-B/--use-ascii 使用ASCII /文本传输 \r\n  　　-c/--cookie-jar <file> 操作结束后把cookie写入到这个文件中 \r\n  　　-C/--continue-at <offset>  断点续转 \r\n  　　-d/--data <data>   HTTP POST方式传送数据 \r\n  　　--data-ascii <data>  以ascii的方式post数据 \r\n  　　--data-binary <data> 以二进制的方式post数据 \r\n  　　--negotiate     使用HTTP身份验证 \r\n  　　--digest        使用数字身份验证 \r\n  　　--disable-eprt  禁止使用EPRT或LPRT \r\n  　　--disable-epsv  禁止使用EPSV \r\n  　　-D/--dump-header <file> 把header信息写入到该文件中 \r\n  　　--egd-file <file> 为随机数据(SSL)设置EGD socket路径 \r\n  　　--tcp-nodelay   使用TCP_NODELAY选项 \r\n  　　-e/--referer 来源网址 \r\n  　　-E/--cert <cert[:passwd]> 客户端证书文件和密码 (SSL) \r\n  　　--cert-type <type> 证书文件类型 (DER/PEM/ENG) (SSL) \r\n  　　--key <key>     私钥文件名 (SSL) \r\n  　　--key-type <type> 私钥文件类型 (DER/PEM/ENG) (SSL) \r\n  　　--pass  <pass>  私钥密码 (SSL) \r\n  　　--engine <eng>  加密引擎使用 (SSL). "--engine list" for list \r\n  　　--cacert <file> CA证书 (SSL) \r\n  　　--capath <directory> CA目录 (made using c_rehash) to verify peer against (SSL) \r\n  　　--ciphers <list>  SSL密码 \r\n  　　--compressed    要求返回是压缩的形势 (using deflate or gzip) \r\n  　　--connect-timeout <seconds> 设置最大请求时间 \r\n  　　--create-dirs   建立本地目录的目录层次结构 \r\n  　　--crlf          上传是把LF转变成CRLF \r\n  　　-f/--fail          连接失败时不显示http错误 \r\n  　　--ftp-create-dirs 如果远程目录不存在，创建远程目录 \r\n  　　--ftp-method [multicwd/nocwd/singlecwd] 控制CWD的使用 \r\n  　　--ftp-pasv      使用 PASV/EPSV 代替端口 \r\n  　　--ftp-skip-pasv-ip 使用PASV的时候,忽略该IP地址 \r\n  　　--ftp-ssl       尝试用 SSL/TLS 来进行ftp数据传输 \r\n  　　--ftp-ssl-reqd  要求用 SSL/TLS 来进行ftp数据传输 \r\n  　　-F/--form <name=content> 模拟http表单提交数据 \r\n  　　-form-string <name=string> 模拟http表单提交数据 \r\n  　　-g/--globoff 禁用网址序列和范围使用{}和[] \r\n  　　-G/--get 以get的方式来发送数据 \r\n  　　-h/--help 帮助 \r\n  　　-H/--header <line>自定义头信息传递给服务器 \r\n  　　--ignore-content-length  忽略的HTTP头信息的长度 \r\n  　　-i/--include 输出时包括protocol头信息 \r\n  　　-I/--head  只显示文档信息 \r\n  　　从文件中读取-j/--junk-session-cookies忽略会话Cookie \r\n  　　- 界面<interface>指定网络接口/地址使用 \r\n  　　- krb4 <级别>启用与指定的安全级别krb4 \r\n  　　-j/--junk-session-cookies 读取文件进忽略session cookie \r\n  　　--interface <interface> 使用指定网络接口/地址 \r\n  　　--krb4 <level>  使用指定安全级别的krb4 \r\n  　　-k/--insecure 允许不使用证书到SSL站点 \r\n  　　-K/--config  指定的配置文件读取 \r\n  　　-l/--list-only 列出ftp目录下的文件名称 \r\n  　　--limit-rate <rate> 设置传输速度 \r\n  　　--local-port<NUM> 强制使用本地端口号 \r\n  　　-m/--max-time <seconds> 设置最大传输时间 \r\n  　　--max-redirs <num> 设置最大读取的目录数 \r\n  　　--max-filesize <bytes> 设置最大下载的文件总量 \r\n  　　-M/--manual  显示全手动 \r\n  　　-n/--netrc 从netrc文件中读取用户名和密码 \r\n  　　--netrc-optional 使用 .netrc 或者 URL来覆盖-n \r\n  　　--ntlm          使用 HTTP NTLM 身份验证 \r\n  　　-N/--no-buffer 禁用缓冲输出 \r\n  　　-o/--output 把输出写到该文件中 \r\n  　　-O/--remote-name 把输出写到该文件中，保留远程文件的文件名 \r\n  　　-p/--proxytunnel   使用HTTP代理 \r\n  　　--proxy-anyauth 选择任一代理身份验证方法 \r\n  　　--proxy-basic   在代理上使用基本身份验证 \r\n  　　--proxy-digest  在代理上使用数字身份验证 \r\n  　　--proxy-ntlm    在代理上使用ntlm身份验证 \r\n  　　-P/--ftp-port <address> 使用端口地址，而不是使用PASV \r\n  　　-Q/--quote <cmd>文件传输前，发送命令到服务器 \r\n  　　-r/--range <range>检索来自HTTP/1.1或FTP服务器字节范围 \r\n  　　--range-file 读取（SSL）的随机文件 \r\n  　　-R/--remote-time   在本地生成文件时，保留远程文件时间 \r\n  　　--retry <num>   传输出现问题时，重试的次数 \r\n  　　--retry-delay <seconds>  传输出现问题时，设置重试间隔时间 \r\n  　　--retry-max-time <seconds> 传输出现问题时，设置最大重试时间 \r\n  　　-s/--silent静音模式。不输出任何东西 \r\n  　　-S/--show-error   显示错误 \r\n  　　--socks4 <host[:port]> 用socks4代理给定主机和端口 \r\n  　　--socks5 <host[:port]> 用socks5代理给定主机和端口 \r\n  　　--stderr <file> \r\n      -t/--telnet-option <OPT=val> Telnet选项设置 \r\n  　　--trace <file>  对指定文件进行debug \r\n  　　--trace-ascii <file> Like --跟踪但没有hex输出 \r\n  　　--trace-time    跟踪/详细输出时，添加时间戳 \r\n  　　-T/--upload-file <file> 上传文件 \r\n  　　--url <URL>     Spet URL to work with \r\n  　　-u/--user <user[:password]>设置服务器的用户和密码 \r\n  　　-U/--proxy-user <user[:password]>设置代理用户名和密码 \r\n  　　-v/--verbose \r\n  　　-V/--version 显示版本信息 \r\n  　　-w/--write-out [format]什么输出完成后 \r\n  　　-x/--proxy <host[:port]>在给定的端口上使用HTTP代理 \r\n  　　-X/--request <command>指定什么命令 \r\n  　　-y/--speed-time 放弃限速所要的时间。默认为30 \r\n  　　-Y/--speed-limit 停止传输速度的限制，速度时间''秒 \r\n  　　-z/--time-cond  传送时间设置 \r\n  　　-0/--http1.0  使用HTTP 1.0 \r\n  　　-1/--tlsv1  使用TLSv1（SSL） \r\n  　　-2/--sslv2 使用SSLv2的（SSL） \r\n  　　-3/--sslv3         使用的SSLv3（SSL） \r\n  　　--3p-quote      like -Q for the source URL for 3rd party transfer \r\n  　　--3p-url        使用url，进行第三方传送 \r\n  　　--3p-user       使用用户名和密码，进行第三方传送 \r\n  　　-4/--ipv4   使用IP4 \r\n  　　-6/--ipv6   使用IP6 \r\n  　　-#/--progress-bar 用进度条显示当前的传送状态 \r\n  　　-a/--append 上传文件时，附加到目标文件 \r\n  　　-A/--user-agent <string>  设置用户代理发送给服务器 \r\n  　　- anyauth   可以使用“任何”身份验证方法 \r\n  　　-b/--cookie <name=string/file> cookie字符串或文件读取位置 \r\n  　　- basic 使用HTTP基本验证 \r\n  　　-B/--use-ascii 使用ASCII /文本传输 \r\n  　　-c/--cookie-jar <file> 操作结束后把cookie写入到这个文件中 \r\n  　　-C/--continue-at <offset>  断点续转 \r\n  　　-d/--data <data>   HTTP POST方式传送数据 \r\n  　　--data-ascii <data>  以ascii的方式post数据 \r\n  　　--data-binary <data> 以二进制的方式post数据 \r\n  　　--negotiate     使用HTTP身份验证 \r\n  　　--digest        使用数字身份验证 \r\n  　　--disable-eprt  禁止使用EPRT或LPRT \r\n  　　--disable-epsv  禁止使用EPSV \r\n  　　-D/--dump-header <file> 把header信息写入到该文件中 \r\n  　　--egd-file <file> 为随机数据(SSL)设置EGD socket路径 \r\n  　　--tcp-nodelay   使用TCP_NODELAY选项 \r\n  　　-e/--referer 来源网址 \r\n  　　-E/--cert <cert[:passwd]> 客户端证书文件和密码 (SSL) \r\n  　　--cert-type <type> 证书文件类型 (DER/PEM/ENG) (SSL) \r\n  　　--key <key>     私钥文件名 (SSL) \r\n  　　--key-type <type> 私钥文件类型 (DER/PEM/ENG) (SSL) \r\n  　　--pass  <pass>  私钥密码 (SSL) \r\n  　　--engine <eng>  加密引擎使用 (SSL). "--engine list" for list \r\n  　　--cacert <file> CA证书 (SSL) \r\n  　　--capath <directory> CA目录 (made using c_rehash) to verify peer against (SSL) \r\n  　　--ciphers <list>  SSL密码 \r\n  　　--compressed    要求返回是压缩的形势 (using deflate or gzip) \r\n  　　--connect-timeout <seconds> 设置最大请求时间 \r\n  　　--create-dirs   建立本地目录的目录层次结构 \r\n  　　--crlf          上传是把LF转变成CRLF \r\n  　　-f/--fail          连接失败时不显示http错误 \r\n  　　--ftp-create-dirs 如果远程目录不存在，创建远程目录 \r\n  　　--ftp-method [multicwd/nocwd/singlecwd] 控制CWD的使用 \r\n  　　--ftp-pasv      使用 PASV/EPSV 代替端口 \r\n  　　--ftp-skip-pasv-ip 使用PASV的时候,忽略该IP地址 \r\n  　　--ftp-ssl       尝试用 SSL/TLS 来进行ftp数据传输 \r\n  　　--ftp-ssl-reqd  要求用 SSL/TLS 来进行ftp数据传输 \r\n  　　-F/--form <name=content> 模拟http表单提交数据 \r\n  　　-form-string <name=string> 模拟http表单提交数据 \r\n  　　-g/--globoff 禁用网址序列和范围使用{}和[] \r\n  　　-G/--get 以get的方式来发送数据 \r\n  　　-h/--help 帮助 \r\n  　　-H/--header <line>自定义头信息传递给服务器 \r\n  　　--ignore-content-length  忽略的HTTP头信息的长度 \r\n  　　-i/--include 输出时包括protocol头信息 \r\n  　　-I/--head  只显示文档信息 \r\n  　　从文件中读取-j/--junk-session-cookies忽略会话Cookie \r\n  　　- 界面<interface>指定网络接口/地址使用 \r\n  　　- krb4 <级别>启用与指定的安全级别krb4 \r\n  　　-j/--junk-session-cookies 读取文件进忽略session cookie \r\n  　　--interface <interface> 使用指定网络接口/地址 \r\n  　　--krb4 <level>  使用指定安全级别的krb4 \r\n  　　-k/--insecure 允许不使用证书到SSL站点 \r\n  　　-K/--config  指定的配置文件读取 \r\n  　　-l/--list-only 列出ftp目录下的文件名称 \r\n  　　--limit-rate <rate> 设置传输速度 \r\n  　　--local-port<NUM> 强制使用本地端口号 \r\n  　　-m/--max-time <seconds> 设置最大传输时间 \r\n  　　--max-redirs <num> 设置最大读取的目录数 \r\n  　　--max-filesize <bytes> 设置最大下载的文件总量 \r\n      -M/--manual  显示全手动 \r\n  　　-n/--netrc 从netrc文件中读取用户名和密码 \r\n  　　--netrc-optional 使用 .netrc 或者 URL来覆盖-n \r\n  　　--ntlm          使用 HTTP NTLM 身份验证 \r\n  　　-N/--no-buffer 禁用缓冲输出 \r\n  　　-o/--output 把输出写到该文件中 \r\n  　　-O/--remote-name 把输出写到该文件中，保留远程文件的文件名 \r\n  　　-p/--proxytunnel   使用HTTP代理 \r\n  　　--proxy-anyauth 选择任一代理身份验证方法 \r\n  　　--proxy-basic   在代理上使用基本身份验证 \r\n  　　--proxy-digest  在代理上使用数字身份验证 \r\n  　　--proxy-ntlm    在代理上使用ntlm身份验证 \r\n  　　-P/--ftp-port <address> 使用端口地址，而不是使用PASV \r\n  　　-Q/--quote <cmd>文件传输前，发送命令到服务器 \r\n  　　-r/--range <range>检索来自HTTP/1.1或FTP服务器字节范围 \r\n  　　--range-file 读取（SSL）的随机文件 \r\n  　　-R/--remote-time   在本地生成文件时，保留远程文件时间 \r\n  　　--retry <num>   传输出现问题时，重试的次数 \r\n  　　--retry-delay <seconds>  传输出现问题时，设置重试间隔时间 \r\n  　　--retry-max-time <seconds> 传输出现问题时，设置最大重试时间 \r\n  　　-s/--silent静音模式。不输出任何东西 \r\n  　　-S/--show-error   显示错误 \r\n  　　--socks4 <host[:port]> 用socks4代理给定主机和端口 \r\n  　　--socks5 <host[:port]> 用socks5代理给定主机和端口 \r\n  　　--stderr <file> \r\n  　　-t/--telnet-option <OPT=val> Telnet选项设置 \r\n  　　--trace <file>  对指定文件进行debug \r\n  　　--trace-ascii <file> Like --跟踪但没有hex输出 \r\n  　　--trace-time    跟踪/详细输出时，添加时间戳 \r\n  　　-T/--upload-file <file> 上传文件 \r\n  　　--url <URL>     Spet URL to work with \r\n  　　-u/--user <user[:password]>设置服务器的用户和密码 \r\n  　　-U/--proxy-user <user[:password]>设置代理用户名和密码 \r\n  　　-v/--verbose \r\n  　　-V/--version 显示版本信息 \r\n  　　-w/--write-out [format]什么输出完成后 \r\n  　　-x/--proxy <host[:port]>在给定的端口上使用HTTP代理 \r\n  　　-X/--request <command>指定什么命令 \r\n  　　-y/--speed-time 放弃限速所要的时间。默认为30 \r\n  　　-Y/--speed-limit 停止传输速度的限制，速度时间''秒 \r\n  　　-z/--time-cond  传送时间设置 \r\n  　　-0/--http1.0  使用HTTP 1.0 \r\n  　　-1/--tlsv1  使用TLSv1（SSL） \r\n  　　-2/--sslv2 使用SSLv2的（SSL） \r\n  　　-3/--sslv3         使用的SSLv3（SSL） \r\n  　　--3p-quote      like -Q for the source URL for 3rd party transfer \r\n  　　--3p-url        使用url，进行第三方传送 \r\n  　　--3p-user       使用用户名和密码，进行第三方传送 \r\n  　　-4/--ipv4   使用IP4 \r\n  　　-6/--ipv6   使用IP6 \r\n  　　-#/--progress-bar 用进度条显示当前的传送状态 \r\n  二，常用curl实例 \r\n  　　 \r\n      1，抓取页面内容到一个文件中 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -o home.html  http:\n  　　[root@krlcgcms01 mytest]# curl -o home.html  http:\n  　　 \r\n      2，用-O（大写的），后面的url要具体到某个文件，不然抓不下来。我们还可以用正则来抓取东西 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -O \r\n  　　[root@krlcgcms01 mytest]# curl -O \r\n  　　 \r\n      3，模拟表单信息，模拟登录，保存cookie信息 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -c ./cookie_c.txt -F log=aaaa -F pwd=****** http://blog.51yip.com/wp-login.php \r\n  　　[root@krlcgcms01 mytest]# curl -c ./cookie_c.txt -F log=aaaa -F pwd=****** http://blog.51yip.com/wp-login.php \r\n  　　 \r\n      4，模拟表单信息，模拟登录，保存头信息 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -D ./cookie_D.txt -F log=aaaa -F pwd=****** http://blog.51yip.com/wp-login.php \r\n  　　[root@krlcgcms01 mytest]# curl -D ./cookie_D.txt -F log=aaaa -F pwd=****** http://blog.51yip.com/wp-login.php \r\n  　　-c(小写)产生的cookie和-D里面的cookie是不一样的。 \r\n  　　 \r\n      5，使用cookie文件 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -b ./cookie_c.txt  http://blog.51yip.com/wp-admin \r\n  　　[root@krlcgcms01 mytest]# curl -b ./cookie_c.txt  http://blog.51yip.com/wp-admin \r\n  　　 \r\n      6，断点续传，-C(大写的) \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -C -O \r\n  　　 \r\n      7，传送数据,最好用登录页面测试，因为你传值过去后，curl回抓数据，你可以看到你传值有没有成功 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -d log=aaaa  http://blog.51yip.com/wp-login.php \r\n  　　[root@krlcgcms01 mytest]# curl -d log=aaaa  http://blog.51yip.com/wp-login.php \r\n  　　 \r\n      8，显示抓取错误，下面这个例子，很清楚的表明了。 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -f http://blog.51yip.com/asdf \r\n  　　curl: (22) The requested URL returned error: 404 \r\n  　　[root@krlcgcms01 mytest]# curl http://blog.51yip.com/asdf \r\n  　　<HTML><HEAD><TITLE>404,not found</TITLE> \r\n  　　。。。。。。。。。。。。 \r\n  　　[root@krlcgcms01 mytest]# curl -f http://blog.51yip.com/asdf \r\n  　　curl: (22) The requested URL returned error: 404 \r\n  　　[root@krlcgcms01 mytest]# curl http://blog.51yip.com/asdf \r\n  　　<HTML><HEAD><TITLE>404,not found</TITLE> \r\n  　　。。。。。。。。。。。。 \r\n  　　 \r\n      9，伪造来源地址，有的网站会判断，请求来源地址。 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -e http://localhost http://blog.51yip.com/wp-login.php \r\n  　　[root@krlcgcms01 mytest]# curl -e http://localhost http://blog.51yip.com/wp-login.php \r\n  　　10，当我们经常用curl去搞人家东西的时候，人家会把你的IP给屏蔽掉的,这个时候,我们可以用代理 \r\n  　　[root@krlcgcms01 mytest]# curl -x 24.10.28.84:32779 -o home.html http:\n  　　[root@krlcgcms01 mytest]# curl -x 24.10.28.84:32779 -o home.html http:\n      \r\n      11，比较大的东西，我们可以分段下载 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -r 0-100 -o img.part1 http://blog.51yip.com/wp- \r\n  　　content/uploads/2010/09/compare_varnish.jpg \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　100   101  100   101    0     0    105      0 --:--:-- --:--:-- --:--:--     0 \r\n  　　[root@krlcgcms01 mytest]# curl -r 100-200 -o img.part2 http://blog.51yip.com/wp- \r\n  　　content/uploads/2010/09/compare_varnish.jpg \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　100   101  100   101    0     0     57      0  0:00:01  0:00:01 --:--:--     0 \r\n  　　[root@krlcgcms01 mytest]# curl -r 200- -o img.part3 http://blog.51yip.com/wp- \r\n  　　content/uploads/2010/09/compare_varnish.jpg \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　100  104k  100  104k    0     0  52793      0  0:00:02  0:00:02 --:--:-- 88961 \r\n  　　[root@krlcgcms01 mytest]# ls |grep part | xargs du -sh \r\n  　　4.0K    one.part1 \r\n  　　112K    three.part3 \r\n  　　4.0K    two.part2 \r\n  　　[root@krlcgcms01 mytest]# curl -r 0-100 -o img.part1 http://blog.51yip.com/wp- \r\n  　　content/uploads/2010/09/compare_varnish.jpg \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　100   101  100   101    0     0    105      0 --:--:-- --:--:-- --:--:--     0 \r\n  　　[root@krlcgcms01 mytest]# curl -r 100-200 -o img.part2 http://blog.51yip.com/wp- \r\n  　　content/uploads/2010/09/compare_varnish.jpg \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　100   101  100   101    0     0     57      0  0:00:01  0:00:01 --:--:--     0 \r\n  　　[root@krlcgcms01 mytest]# curl -r 200- -o img.part3 http://blog.51yip.com/wp- \r\n  　　content/uploads/2010/09/compare_varnish.jpg \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　100  104k  100  104k    0     0  52793      0  0:00:02  0:00:02 --:--:-- 88961 \r\n  　　[root@krlcgcms01 mytest]# ls |grep part | xargs du -sh \r\n  　　4.0K    one.part1 \r\n  　　112K    three.part3 \r\n  　　4.0K    two.part2 \r\n  　　用的时候，把他们cat一下就OK了,cat img.part* >img.jpg \r\n  　　 \r\n      12，不会显示下载进度信息 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -s -o aaa.jpg \r\n  　　 \r\n      13，显示下载进度条 \r\n   \r\n  　　[root@krlcgcms01 mytest]# curl -# -O \r\n  　　######################################################################## 100.0% \r\n  　　14,通过ftp下载文件 \r\n  　　[zhangy@BlackGhost ~]$ curl -u 用户名:密码 -O http://blog.51yip.com/demo/curtain/bbstudy_files/style.css \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　101  1934  101  1934    0     0   3184      0 --:--:-- --:--:-- --:--:--  7136 \r\n  　　[zhangy@BlackGhost ~]$ curl -u 用户名:密码 -O http://blog.51yip.com/demo/curtain/bbstudy_files/style.css \r\n  　　% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current \r\n  　　Dload  Upload   Total   Spent    Left  Speed \r\n  　　101  1934  101  1934    0     0   3184      0 --:--:-- --:--:-- --:--:--  7136 \r\n  　　或者用下面的方式 \r\n  　　[zhangy@BlackGhost ~]$ curl -O ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files/style.css \r\n  　　[zhangy@BlackGhost ~]$ curl -O ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files/style.css \r\n  　　 \r\n      15，通过ftp上传 \r\n   \r\n  　　[zhangy@BlackGhost ~]$ curl -T test.sql ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files/ \r\n  　　[zhangy@BlackGhost ~]$ curl -T test.sql ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files/\n', ''),
(59, 'netstat', 'netstat netstat 使用说明书\r\n \r\n  简介 \r\n   \r\n  Netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。 \r\n  输出信息含义 \r\n   \r\n  执行netstat后，其输出结果为 \r\n   \r\n   \r\n  Active Internet connections (w/o servers) \r\n  Proto Recv-Q Send-Q Local Address Foreign Address State \r\n  tcp 0 2 210.34.6.89:telnet 210.34.6.96:2873 ESTABLISHED \r\n  tcp 296 0 210.34.6.89:1165 210.34.6.84:netbios-ssn ESTABLISHED \r\n  tcp 0 0 localhost.localdom:9001 localhost.localdom:1162 ESTABLISHED \r\n  tcp 0 0 localhost.localdom:1162 localhost.localdom:9001 ESTABLISHED \r\n  tcp 0 80 210.34.6.89:1161 210.34.6.10:netbios-ssn CLOSE \r\n   \r\n  Active UNIX domain sockets (w/o servers) \r\n  Proto RefCnt Flags Type State I-Node Path \r\n  unix 1 [ ] STREAM CONNECTED 16178 @000000dd \r\n  unix 1 [ ] STREAM CONNECTED 16176 @000000dc \r\n  unix 9 [ ] DGRAM 5292 /dev/log \r\n  unix 1 [ ] STREAM CONNECTED 16182 @000000df \r\n   \r\n   \r\n   \r\n   \r\n  从整体上看，netstat的输出结果可以分为两个部分： \r\n   \r\n  一个是Active Internet connections，称为有源TCP连接，其中"Recv-Q"和"Send-Q"指%0A的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。 \r\n   \r\n  另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。 \r\n  Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。 \r\n  常见参数 \r\n   \r\n  -a (all)显示所有选项，默认不显示LISTEN相关 \r\n  -t (tcp)仅显示tcp相关选项 \r\n  -u (udp)仅显示udp相关选项 \r\n  -n 拒绝显示别名，能显示数字的全部转化成数字。 \r\n  -l 仅列出有在 Listen (监听) 的服務状态 \r\n   \r\n  -p 显示建立相关链接的程序名 \r\n  -r 显示路由信息，路由表 \r\n  -e 显示扩展信息，例如uid等 \r\n  -s 按各个协议进行统计 \r\n  -c 每隔一个固定时间，执行该netstat命令。 \r\n   \r\n  提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到 \r\n   \r\n   \r\n  实用命令实例 \r\n   \r\n  1. 列出所有端口 (包括监听和未监听的) \r\n   \r\n    列出所有端口 netstat -a \r\n   \r\n   \r\n  # netstat -a | more \r\n   Active Internet connections (servers and established) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State \r\n   tcp        0      0 localhost:30037         *:*                     LISTEN \r\n   udp        0      0 *:bootpc                *:* \r\n   \r\n  Active UNIX domain sockets (servers and established) \r\n   Proto RefCnt Flags       Type       State         I-Node   Path \r\n   unix  2      [ ACC ]     STREAM     LISTENING     6135     /tmp/.X11-unix/X0 \r\n   unix  2      [ ACC ]     STREAM     LISTENING     5140     /var/run/acpid.socket \r\n   \r\n   \r\n   \r\n    列出所有 tcp 端口 netstat -at \r\n   \r\n   \r\n  # netstat -at \r\n   Active Internet connections (servers and established) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State \r\n   tcp        0      0 localhost:30037         *:*                     LISTEN \r\n   tcp        0      0 localhost:ipp           *:*                     LISTEN \r\n   tcp        0      0 *:smtp                  *:*                     LISTEN \r\n   tcp6       0      0 localhost:ipp           [::]:*                  LISTEN \r\n   \r\n   \r\n   \r\n    列出所有 udp 端口 netstat -au \r\n   \r\n  # netstat -au \r\n   Active Internet connections (servers and established) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State \r\n   udp        0      0 *:bootpc                *:* \r\n   udp        0      0 *:49119                 *:* \r\n   udp        0      0 *:mdns                  *:* \r\n   \r\n   \r\n  2. 列出所有处于监听状态的 Sockets \r\n   \r\n    只显示监听端口 netstat -l \r\n   \r\n  # netstat -l \r\n   Active Internet connections (only servers) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State \r\n   tcp        0      0 localhost:ipp           *:*                     LISTEN \r\n   tcp6       0      0 localhost:ipp           [::]:*                  LISTEN \r\n   udp        0      0 *:49119                 *:* \r\n   \r\n    只列出所有监听 tcp 端口 netstat -lt \r\n   \r\n  # netstat -lt \r\n   Active Internet connections (only servers) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State \r\n   tcp        0      0 localhost:30037         *:*                     LISTEN \r\n   tcp        0      0 *:smtp                  *:*                     LISTEN \r\n   tcp6       0      0 localhost:ipp           [::]:*                  LISTEN \r\n   \r\n    只列出所有监听 udp 端口 netstat -lu \r\n   \r\n  # netstat -lu \r\n   Active Internet connections (only servers) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State \r\n   udp        0      0 *:49119                 *:* \r\n   udp        0      0 *:mdns                  *:* \r\n   \r\n    只列出所有监听 UNIX 端口 netstat -lx \r\n   \r\n   \r\n  # netstat -lx \r\n   Active UNIX domain sockets (only servers) \r\n   Proto RefCnt Flags       Type       State         I-Node   Path \r\n   unix  2      [ ACC ]     STREAM     LISTENING     6294     private/maildrop \r\n   unix  2      [ ACC ]     STREAM     LISTENING     6203     public/cleanup \r\n   unix  2      [ ACC ]     STREAM     LISTENING     6302     private/ifmail \r\n   unix  2      [ ACC ]     STREAM     LISTENING     6306     private/bsmtp \r\n   \r\n   \r\n   \r\n   \r\n   \r\n  3. 显示每个协议的统计信息 \r\n   \r\n    显示所有端口的统计信息 netstat -s \r\n   \r\n   \r\n  # netstat -s \r\n   Ip: \r\n   11150 total packets received \r\n   1 with invalid addresses \r\n   0 forwarded \r\n   0 incoming packets discarded \r\n   11149 incoming packets delivered \r\n   11635 requests sent out \r\n   Icmp: \r\n   0 ICMP messages received \r\n   0 input ICMP message failed.  \r\n   Tcp: \r\n   582 active connections openings \r\n   2 failed connection attempts \r\n   25 connection resets received \r\n   Udp: \r\n   1183 packets received \r\n   4 packets to unknown port received.  \r\n   .....  \r\n   \r\n   \r\n   \r\n    显示 TCP 或 UDP 端口的统计信息 netstat -st 或 -su \r\n   \r\n  # netstat -st \r\n  # netstat -su \r\n   \r\n   \r\n  4. 在 netstat 输出中显示 PID 和进程名称 netstat -p \r\n   \r\n  netstat -p 可以与其它开关一起使用，就可以添加 “PID/进程名称” 到 netstat 输出中，这样 debugging 的时候可以很方便的发现特定端口运行的程序。 \r\n   \r\n  # netstat -pt \r\n   Active Internet connections (w/o servers) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name \r\n   tcp        1      0 ramesh-laptop.loc:47212 192.168.185.75:www        CLOSE_WAIT  2109/firefox \r\n   tcp        0      0 ramesh-laptop.loc:52750 lax:www ESTABLISHED 2109/firefox \r\n   \r\n  5. 在 netstat 输出中不显示主机，端口和用户名 (host, port or user) \r\n   \r\n  当你不想让主机，端口和用户名显示，使用 netstat -n。将会使用数字代替那些名称。 \r\n   \r\n  同样可以加速输出，因为不用进行比对查询。 \r\n   \r\n  # netstat -an \r\n   \r\n  如果只是不想让这三个名称中的一个被显示，使用以下命令 \r\n   \r\n  # netsat -a --numeric-ports \r\n  # netsat -a --numeric-hosts \r\n  # netsat -a --numeric-users \r\n   \r\n   \r\n  6. 持续输出 netstat 信息 \r\n   \r\n  netstat 将每隔一秒输出网络信息。 \r\n   \r\n   \r\n  # netstat -c \r\n   Active Internet connections (w/o servers) \r\n   Proto Recv-Q Send-Q Local Address           Foreign Address         State \r\n   tcp        0      0 ramesh-laptop.loc:36130 101-101-181-225.ama:www ESTABLISHED \r\n   tcp        1      1 ramesh-laptop.loc:52564 101.11.169.230:www      CLOSING \r\n   tcp        0      0 ramesh-laptop.loc:43758 server-101-101-43-2:www ESTABLISHED \r\n   tcp        1      1 ramesh-laptop.loc:42367 101.101.34.101:www      CLOSING \r\n   ^C \r\n   \r\n   \r\n   \r\n  7. 显示系统不支持的地址族 (Address Families) \r\n   \r\n  netstat --verbose \r\n   \r\n  在输出的末尾，会有如下的信息 \r\n   \r\n  netstat: no support for `AF IPX'' on this system.  \r\n  netstat: no support for `AF AX25'' on this system.  \r\n  netstat: no support for `AF X25'' on this system.  \r\n  netstat: no support for `AF NETROM'' on this system.  \r\n   \r\n   \r\n  8. 显示核心路由信息 netstat -r \r\n   \r\n  # netstat -r \r\n   Kernel IP routing table \r\n   Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface \r\n   192.168.1.0     *               255.255.255.0   U         0 0          0 eth2 \r\n   link-local      *               255.255.0.0     U         0 0          0 eth2 \r\n   default         192.168.1.1     0.0.0.0         UG        0 0          0 eth2 \r\n   \r\n  注意： 使用 netstat -rn 显示数字格式，不查询主机名称。 \r\n   \r\n  9. 找出程序运行的端口 \r\n   \r\n  并不是所有的进程都能找到，没有权限的会不显示，使用 root 权限查看所有的信息。 \r\n   \r\n  # netstat -ap | grep ssh \r\n   tcp        1      0 dev-db:ssh           101.174.100.22:39213        CLOSE_WAIT  - \r\n   tcp        1      0 dev-db:ssh           101.174.100.22:57643        CLOSE_WAIT  - \r\n   \r\n    找出运行在指定端口的进程 \r\n   \r\n  # netstat -an | grep '':80'' \r\n   \r\n   \r\n  10. 显示网络接口列表 \r\n   \r\n  # netstat -i \r\n   Kernel Interface table \r\n   Iface   MTU Met   RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg \r\n   eth0       1500 0         0      0      0 0             0      0      0      0 BMU \r\n   eth2       1500 0     26196      0      0 0         26883      6      0      0 BMRU \r\n   lo        16436 0         4      0      0 0             4      0      0      0 LRU \r\n   \r\n  显示详细信息，像是 ifconfig 使用 netstat -ie: \r\n   \r\n   \r\n  # netstat -ie \r\n   Kernel Interface table \r\n   eth0      Link encap:Ethernet  HWaddr 00:10:40:11:11:11 \r\n   UP BROADCAST MULTICAST  MTU:1500  Metric:1 \r\n   RX packets:0 errors:0 dropped:0 overruns:0 frame:0 \r\n   TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 \r\n   collisions:0 txqueuelen:1000 \r\n   RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B) \r\n   Memory:f6ae0000-f6b00000 \r\n   \r\n   \r\n   \r\n   \r\n  11. IP和TCP分析 \r\n   \r\n    查看连接某服务端口最多的的IP地址 \r\n   \r\n   \r\n  wss8848@ubuntu:~$ netstat -nat | grep "192.168.1.15:22" |awk ''{print $5}''|awk -F: ''{print $1}''|sort|uniq -c|sort -nr|head -20 \r\n  18 221.136.168.36 \r\n  3 154.74.45.242 \r\n  2 78.173.31.236 \r\n  2 62.183.207.98 \r\n  2 192.168.1.14 \r\n  2 182.48.111.215 \r\n  2 124.193.219.34 \r\n  2 119.145.41.2 \r\n  2 114.255.41.30 \r\n  1 75.102.11.99 \r\n   \r\n   \r\n   \r\n    TCP各种状态列表 \r\n   \r\n   \r\n  wss8848@ubuntu:~$ netstat -nat |awk ''{print $6}'' \r\n  established) \r\n  Foreign \r\n  LISTEN \r\n  TIME_WAIT \r\n  ESTABLISHED \r\n  TIME_WAIT \r\n  SYN_SENT \r\n   \r\n   \r\n   \r\n    先把状态全都取出来,然后使用uniq -c统计，之后再进行排序。 \r\n   \r\n   \r\n   \r\n  wss8848@ubuntu:~$ netstat -nat |awk ''{print $6}''|sort|uniq -c \r\n  143 ESTABLISHED \r\n  1 FIN_WAIT1 \r\n  1 Foreign \r\n  1 LAST_ACK \r\n  36 LISTEN \r\n  6 SYN_SENT \r\n  113 TIME_WAIT \r\n  1 established) \r\n   \r\n   \r\n   \r\n    最后的命令如下: \r\n   \r\n  netstat -nat |awk ''{print $6}''|sort|uniq -c|sort -rn \r\n   \r\n  分析access.log获得访问前10位的ip地址 \r\n   \r\n  awk ''{print $1}'' access.log |sort|uniq -c|sort -nr|head -10 \r\n  \nnetstat -tup show all active network connections and their PID\nnetstat -tupl show all network services listening on the system and their PID\nnetstat -n | awk ''/^tcp/ {++state[$NF]} END {for(key in state) print key,"  ",state[key]}'' 统计网络状态\n', ''),
(60, 'tar', 'tar tar -cvf archive.tar file1 创建一个非压缩的 tarball\ntar -cvf archive.tar file1 file2 dir1 创建一个包含了 ''file1'', ''file2'' 以及 ''dir1''的档案文件\ntar -tf archive.tar 显示一个包中的内容\ntar -xvf archive.tar 释放一个包\ntar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下\ntar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包\ntar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包\ntar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包\ntar -xvfz archive.tar.gz 解压一个gzip格式的压缩包\ntar -Puf backup.tar /home/user 执行一次对 ''/home/user'' 目录的交互式备份操作\ntar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接\n', ''),
(61, 'time', 'time time 时间设定\r\n \r\n  　　查看/修改Linux时区和时间 \r\n  一、时区 \r\n  　　1. 查看当前时区 \r\n  　　date -R \r\n  　　2. 修改设置时区 \r\n  　　方法(1) \r\n  　　tzselect \r\n  　　方法(2) 仅限于RedHat Linux 和 CentOS \r\n  　　timeconfig \r\n  　　方法(3) 适用于Debian \r\n  　　dpkg-reconfigure tzdata \r\n  　　3. 复制相应的时区文件，替换系统时区文件；或者创建链接文件 \r\n  　　cp /usr/share/zoneinfo/$主时区/$次时区 /etc/localtime \r\n  　　在中国可以使用： \r\n  　　cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \r\n  二、时间 \r\n  　　1、查看时间和日期 \r\n  　　date \r\n  　　2、设置时间和日期 \r\n  　　将系统日期设定成1996年6月10日的命令 \r\n  　　date -s 06/22/96 \r\n  　　将系统时间设定成下午1点52分0秒的命令 \r\n  　　date -s 13:52:00 \r\n  　　3. 将当前时间和日期写入BIOS，避免重启后失效 \r\n  　　hwclock -w \r\n  三、定时同步时间 \r\n  　　* * * * * /usr/sbin/ntpdate 210.72.145.44 > /dev/null 2>&1 \r\n   \r\n   \r\n   \r\n  　在Linux中，用于时钟查看和设置的命令主要有date、hwclock和clock。其中，clock和hwclock用法相近，只用一个就行，只不过clock命令除了支持x86硬件体系外，还支持Alpha硬件体系。 \r\n   \r\n  　　查看Linux系统时间： \r\n  date \r\n  　　修改Linux系统时间： \r\n  date -s (后面跟时间) \r\n   \r\n  　　查看Linux硬件时间： \r\n  hwclock \r\n  或 \r\n  clock \r\n  或 \r\n  hwclock –show \r\n  或 \r\n  clock –show \r\n   \r\n  　　修改Linux硬件时间： \r\n  hwclock –set –date \r\n  或 \r\n  clock –set –date \r\n   \r\n  　　让系统时间与硬件时钟同步，用： \r\n  hwclock –hctosys \r\n  或 \r\n  clock –hctosys \r\n   \r\n  　　相反地，让硬件时钟与系统时间同步： \r\n  hwclock –systohc \r\n  或 \r\n  clock –systohc \r\n   \r\n  　　让系统时间每隔十分钟去同步一下硬件时间。 \r\n   \r\n  [hqw@localhost root]$ vi /etc/crontab \r\n  SHELL=/bin/bash \r\n  PATH=/sbin:/bin:/usr/sbin:/usr/bin  \r\n  MAILTO=root \r\n  HOME=/ \r\n  # run-parts  01 * * * * root run-parts /etc/cron.hourly \r\n  02 4 * * * root run-parts /etc/cron.daily \r\n  22 4 * * 0 root run-parts /etc/cron.weekly \r\n  42 4 1 * * root run-parts /etc/cron.monthly \r\n  */10 * * * * root hwclock --hctosys \r\n  #我加入了这么一行，表示每隔10分钟执行一次hwclock --hctosys。\n', ''),
(62, 'date', 'date date 显示系统日期\ndate 041217002007.00 设置日期和时间 - 月日时分年.秒\n', ''),
(63, 'crontab', 'crontab crontab 修改默认编辑器 \r\n  crontab默认编辑器为nano.  \r\n  修改crontab默认编辑器为vi或者其他的编辑器。 \r\n  法一： \r\n      export EDITOR="/usr/bin/vim" ; crontab -e \r\n  法二： \r\n      执行命令：select-editor \r\n  然后选择编辑器.\r\n\r\n\r\n \r\n   crontab 使用说明\r\n\r\n\r\n \r\n  第1列分钟1～59 \r\n  第2列小时1～23（0表示子夜） \r\n  第3列日1～31 \r\n  第4列月1～12 \r\n  第5列星期0～6（0表示星期天） \r\n  第6列要运行的命令 \r\n   \r\n  下面是crontab的格式： \r\n  分 时 日 月 星期 要运行的命令 \r\n   \r\n  这里有crontab文件条目的一些例子： \r\n   \r\n  30 21 * * * /usr/local/apache/bin/apachectl restart \r\n  上面的例子表示每晚的21:30重启apache。 \r\n   \r\n  45 4 1,10,22 * * /usr/local/apache/bin/apachectl restart \r\n  上面的例子表示每月1、10、22日的4 : 45重启apache。 \r\n   \r\n  10 1 * * 6,0 /usr/local/apache/bin/apachectl restart \r\n  上面的例子表示每周六、周日的1 : 10重启apache。 \r\n   \r\n  0,30 18-23 * * * /usr/local/apache/bin/apachectl restart \r\n  上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache。 \r\n   \r\n  0 23 * * 6 /usr/local/apache/bin/apachectl restart \r\n  上面的例子表示每星期六的11 : 00 pm重启apache。 \r\n   \r\n  * */1 * * * /usr/local/apache/bin/apachectl restart \r\n  每一小时重启apache \r\n   \r\n  * 23-7/1 * * * /usr/local/apache/bin/apachectl restart \r\n  晚上11点到早上7点之间，每隔一小时重启apache \r\n   \r\n  0 11 4 * mon-wed /usr/local/apache/bin/apachectl restart \r\n  每月的4号与每周一到周三的11点重启apache \r\n   \r\n  0 4 1 jan * /usr/local/apache/bin/apachectl restart \r\n  一月一号的4点重启apache\n', ''),
(64, 'gzip', 'gzip gzip file1 压缩一个叫做 ''file1''的文件\ngzip -9 file1 最大程度压缩\ngzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - 刻录一个压缩了的ISO镜像文件\n', ''),
(65, 'mk', 'mk mkdir dir1 创建一个叫做 ''dir1'' 的目录''\nmkdir dir1 dir2 同时创建两个目录\nmkdir -p /tmp/dir1/dir2 创建一个目录树\nmkfs /dev/hda1 在hda1分区创建一个文件系统\nmke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统\nmke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统\nmkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统\nmkswap /dev/hda3 创建一个swap文件系统\nmkswap /dev/hda3 创建一个swap文件系统\nmkisofs /dev/cdrom > cd.iso 在磁盘上创建一个光盘的iso镜像文件\nmkisofs /dev/cdrom | gzip > cd_iso.gz 在磁盘上创建一个压缩了的光盘iso镜像文件\nmkisofs -J -allow-leading-dots -R -V "Label CD" -iso-level 4 -o ./cd.iso data_cd 创建一个目录的iso镜像文件\nmksf.ext3 /dev/sdb1 把第二块硬盘的第一个主分区格式化为ext3\nmkswap /dev/sdb2 初始化swap区，此区不可格式化。\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(66, 'route', 'route route -n show routing table\nroute add -net 0/0 gw IP_Gateway configura default gateway\nroute add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 configure static route to reach network ''192.168.0.0/16''\nroute del 0/0 gw IP_gateway remove static route\nroute route详解 \r\n    为了让设备能访问另一个子网，需要在设备里增加路由到子网络，下面是一些资料。基本操作如下： \r\n   \r\n  一般来说，都是为了能访问别的子网才设置路由的，比如说，你的主机处于192.168.10.0/24，而你想访问192.168.20.0/24网的主机，当然你知道一个网关IP，例如192.168.10.1（必须和你主机处于同一子网），那么，你可以这样配置路由。 \r\n   \r\n  添加路由 \r\n   \r\n  route add -net 192.168.20.0 netmask 255.255.255.0 gw 192.168.10.1 \r\n   \r\n  查看路由状态 \r\n   \r\n  route -n \r\n   \r\n  删除路由 \r\n   \r\n  route del -net 192.168.20.0 netmask 255.255.255.0 \r\n   \r\n   \r\n   \r\n  摘自鸟哥的私房菜 \r\n  路由修改 route       \r\n      我们在网路基础的时候谈过关于路由的问题，两部主机之间一定要有路由才能够互通 TCP/IP 的协定，否则就无法进行连线啊！ \r\n  一般来说，只要有网路介面，该介面就会产生一个路由，例如在鸟哥实验室内部的主机有一个 eth0 及 lo ，所以： \r\n  [root@linux ~]# route [-nee] \r\n  [root@linux ~]# route add [-net|-host] [网域或主机] netmask [mask] [gw|dev] \r\n  [root@linux ~]# route del [-net|-host] [网域或主机] netmask [mask] [gw|dev] \r\n  观察的参数： \r\n     -n  ：不要使用通讯协定或主机名称，直接使用 IP 或 port number； \r\n     -ee ：使用更详细的资讯来显示 \r\n  增加 (add) 与删除 (del) 路由的相关参数： \r\n     -net    ：表示后面接的路由为一个网域； \r\n     -host   ：表示后面接的为连接到单部主机的路由； \r\n     netmask ：与网域有关，可以设定 netmask 决定网域的大小； \r\n     gw      ：gateway 的简写，后续接的是 IP 的数值喔，与 dev 不同； \r\n     dev     ：如果只是要指定由那一块网路卡连线出去，则使用这个设定，后面接 eth0 等 \r\n  范例一：单纯的观察路由状态 \r\n  [root@linux ~]# route -n \r\n  Kernel IP routing table \r\n  Destination     Gateway         Genmask         Flags Metric Ref    Use Iface \r\n  192.168.10.0    0.0.0.0         255.255.255.0   U     0      0        0 eth0 \r\n  169.254.0.0     0.0.0.0         255.255.0.0     U     0      0        0 eth0 \r\n  0.0.0.0         192.168.10.30   0.0.0.0         UG    0      0        0 eth0 \r\n  [root@linux ~]# route \r\n  Kernel IP routing table \r\n  Destination     Gateway         Genmask         Flags Metric Ref    Use Iface \r\n  192.168.10.0    *               255.255.255.0   U     0      0        0 eth0 \r\n  169.254.0.0     *               255.255.0.0     U     0      0        0 eth0 \r\n  default         server.cluster      0.0.0.0         UG    0      0        0 eth0 \r\n     由上面的例子当中仔细观察 route 与 route -n 的输出结果，你可以发现有加 -n参数的主要是显示出 IP ，至于使用 route 而已的话，显示的则是『主机名称』喔！也就是说，在预设的情况下， route 会去找出该 IP 的主机名称，如果找不到呢？就会显示的钝钝的(有点小慢)，所以说，鸟哥通常都直接使用 route -n 啦！由上面看起来，我们也知道 default = 0.0.0.0/0.0.0.0 ，而上面的资讯有哪些你必须要知道的呢？ \r\n                 \r\n   \r\n  · Destination, Genmask：这两个玩意儿就是分别是 network 与netmask 啦！所以这两个咚咚就组合成为一个完整的网域囉！ \r\n   \r\n  · Gateway：该网域是通过那个 gateway 连接出去的？ 如果显示 0.0.0.0 表示该路由是直接由本机传送，亦即可以透过区域网路的 MAC 直接传讯；如果有显示 IP 的话，表示该路由需要经过路由器 (通讯闸) 的帮忙才能够传送出去。 \r\n   \r\n  · Flags：总共有多个旗标，代表的意义如下：                        \r\n   \r\n  o U (route is up)：该路由是启动的；                       \r\n   \r\n  o H (target is a host)：目标是一部主机 (IP) 而非网域；                       \r\n   \r\n  o G (use gateway)：需要透过外部的主机 (gateway) 来转递封包；                       \r\n   \r\n  o R (reinstate route for dynamic routing)：使用动态路由时，恢复路由资讯的旗标；                       \r\n   \r\n  o D (dynamically installed by daemon or redirect)：已经由服务或转 port 功能设定为动态路由                       \r\n   \r\n  o M (modified from routing daemon or redirect)：路由已经被修改了；                       \r\n   \r\n  o !  (reject route)：这个路由将不会被接受(用来抵挡不安全的网域！) \r\n   \r\n  · Iface：这个路由传递封包的介面。 \r\n   \r\n  此外，观察一下上面的路由排列顺序喔，依序是由小网域(192.168.10.0/24 是 Class C)，逐渐到大网域(169.254.0.0/16 Class B) 最后则是预设路由 (0.0.0.0/0.0.0.0)。然后当我们要判断某个网路封包应该如何传送的时候，该封包会经由这个路由的过程来判断喔！举例来说，我上头仅有三个路由，若我有一个传往 192.168.10.20 的封包要传递，那首先会找 192.168.10.0/24 这个网域的路由，找到了！所以直接由 eth0 传送出去；如果是传送到 Yahoo 的主机呢？ Yahoo 的主机 IP 是 202.43.195.52，我通过判断 \r\n   \r\n  1)不是 192.168.10.0/24， \r\n         2)不是 169.254.0.0/16 结果到达 \r\n   \r\n  3)0/0 时，OK！传出去了，透过 eth0 将封包传给 192.168.10.30那部 gateway 主机啊！所以说，路由是有顺序的。因此当你重复设定多个同样的路由时，例如在你的主机上的两张网路卡设定为相同网域的 IP 时，会出现什么情况？会出现如下的情况： \r\n  Kernel IP routing table \r\n  Destination     Gateway         Genmask         Flags Metric Ref    Use Iface \r\n  192.168.10.0    0.0.0.0         255.255.255.0   U     0      0        0 eth0 \r\n  192.168.10.0    0.0.0.0         255.255.255.0   U     0      0        0 eth1 \r\n  也就是说，由于路由是依照顺序来排列与传送的，所以不论封包是由那个介面 (eth0, eth1) 所接收，都会由上述的 eth0 传送出去，所以，在一部主机上面设定两个相同网域的 IP 本身没有什么意义！有点多此一举就是了。除非是类似虚拟主机 (Xen, VMware 等软体) 所架设的多主机时，才会有这个必要～ \r\n  范例二：路由的增加与删除 \r\n  [root@linux ~]# route del -net 169.254.0.0 netmask 255.255.0.0 dev eth0 \r\n  # 上面这个动作可以删除掉 169.254.0.0/16 这个网域！ \r\n  # 请注意，在删除的时候，需要将路由表上面出现的资讯都写入 \r\n  # 包括  netmask , dev 等等参数喔！注意注意 \r\n  [root@linux ~]# route add -net 192.168.100.0 netmask 255.255.255.0 dev eth0 \r\n  # 透过 route add 来增加一个路由！请注意，这个路由必须要能够与你互通。 \r\n  # 举例来说，如果我下达底下的指令就会显示错误： \r\n  # route add -net 192.168.200.0 netmask 255.255.255.0 gw 192.168.200.254 \r\n  # 因为我的环境内仅有 192.168.10.100 这个 IP ，所以不能与 192.168.200.254 \r\n  # 这个网段直接使用 MAC 互通！这样说，可以理解喔！？ \r\n  [root@linux ~]# route add default gw 192.168.10.30 \r\n  # 增加预设路由的方法！请注意，只要有一个预设路由就够了喔！ \r\n  # 在这个地方如果您随便设定后，记得使用底下的指令重新设定你的网路 \r\n  # /etc/init.d/network restart \r\n        如果是要进行路由的删除与增加，那就得要参考上面的例子了，其实，使用 man route 里面的资料就很丰富了！仔细查阅一下囉！你只要记得，当出现『SIOCADDRT: Network is unreachable』这个错误时，肯定是由于 gw 后面接的 IP 无法直接与您的网域沟通 (Gateway 并不在你的网域内)，所以，赶紧检查一下是否输入错误啊！加油吧！ \r\n   \r\n   \r\n   \r\n  # route 命令添加的路由，机器重启或者网卡重启后就没掉了，在linux下设置永久路由的方法： \r\n  1.在/etc/rc.local里添加 \r\n  2.在/etc/sysconfig/network里添加到末尾 \r\n  3./etc/sysconfig/static-router : \r\n  any net x.x.x.x/24 gw y.y.y.y \r\n   \r\n   \r\n   \r\n  ===========================================================================================   WINDOWS下的route命令： \r\n   \r\n  简单的的操作如下， \r\n   \r\n  查看路由状态：route print \r\n   \r\n  只查看ipv4（ipv6）路由状态：route print -4(-6) \r\n   \r\n  添加路由：route add 目的网络 mask 子网掩码 网关 ——重启机器或网卡失效 \r\n   \r\n  route add 192.168.20.0 mask 255.255.255.0 192.168.10.1 \r\n   \r\n  添加永久：route -p add 目的网络 mask 子网掩码网关 \r\n   \r\n  route -p add 192.168.20.0 mask 255.255.255.0 192.168.10.1 \r\n   \r\n  删除路由：route delete 目的网络 mask 子网掩码 \r\n   \r\n  route delete 192.168.20.0 mask 255.255.255.0\n', ''),
(67, 'unix2dos', 'unix2dos unix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOS\n', ''),
(68, 'dos2unix', 'dos2unix dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIX\n', ''),
(69, 'if', 'if if 条件判断 \r\n  #!/bin/sh \r\n  SYSTEM=`uname -s`    #获取操作系统类型，我本地是linux \r\n  if [ $SYSTEM = "Linux" ] ; then     #如果是linux的话打印linux字符串 \r\n  echo "Linux" \r\n  elif [ $SYSTEM = "FreeBSD" ] ; then   \r\n  echo "FreeBSD" \r\n  elif [ $SYSTEM = "Solaris" ] ; then \r\n  echo "Solaris" \r\n  else \r\n  echo "What?" \r\n  fi     #ifend \r\n  基本上和其他脚本语言一样。没有太大区别。不过值得注意的是。[]里面的条件判断。 \r\n  1 字符串判断 \r\n  str1 = str2　　　　　　当两个串有相同内容、长度时为真 \r\n  str1 != str2　　　　　 当串str1和str2不等时为真 \r\n  -n str1　　　　　　　 当串的长度大于0时为真(串非空) \r\n  -z str1　　　　　　　 当串的长度为0时为真(空串) \r\n  str1　　　　　　　　   当串str1为非空时为真 \r\n  2 数字的判断 \r\n  int1 -eq int2　　　　两数相等为真 \r\n  int1 -ne int2　　　　两数不等为真 \r\n  int1 -gt int2　　　　int1大于int2为真 \r\n  int1 -ge int2　　　　int1大于等于int2为真 \r\n  int1 -lt int2　　　　int1小于int2为真 \r\n  int1 -le int2　　　　int1小于等于int2为真 \r\n   \r\n  3 文件的判断 \r\n  -r file　　　　　用户可读为真 \r\n  -w file　　　　　用户可写为真 \r\n  -x file　　　　　用户可执行为真 \r\n  -f file　　　　　文件为正规文件为真 \r\n  -d file　　　　　文件为目录为真 \r\n  -c file　　　　　文件为字符特殊文件为真 \r\n  -b file　　　　　文件为块特殊文件为真 \r\n  -s file　　　　　文件大小非0时为真 \r\n  -t file　　　　　当文件描述符(默认为1)指定的设备为终端时为真 \r\n  3 复杂逻辑判断 \r\n  -a 　 　　　　　 与 \r\n  -o　　　　　　　 或 \r\n  !　　　　　　　　非\n', ''),
(70, 'for', 'for for 循环语句 \r\n  EX1 for循环遍历数组: \r\n   \r\n  #!/bin/sh \r\n  WORD="a b c d e f g h i j l m n o p q r s t u v w x y z" \n  for i in $WORD ; do   // 遍历WORD变量里面的数据 \r\n  echo $i                     // 输出WORD数据集中的没有元素 \r\n  done                         // 循环结束 \r\n  程序依次读入WORD中的元素赋给变量i,然后输出i的值,有没有发现,shell的语法中,变量没有数据类型?是的,就是这样.  \r\n   \r\n  EX2 for循环遍历文件: \r\n   \r\n  #!/bin/sh \r\n  FILES=`ls /txt/*.txt` \r\n  for txt in $FILES ; do  \r\n  mv $txt /newDir/$txt \r\n  done \r\n  以上代码是将/txt/*.txt转移到新目录下，数据集来源于ls指令的结果，通过重定向输入到变量FILES中。 \r\n   \r\n   \r\n  EX3 while循环: \r\n   \r\n  #!/bin/sh \r\n  while : ; do \r\n  echo "do something forever here" \r\n  sleep 5 \r\n  done \r\n  无限循环打印"do something forever here" ，间隔5秒\n', ''),
(71, 'mount', 'mount mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 ''/ mnt/hda2'' 已经存在\nmount /dev/fd0 /mnt/floppy 挂载一个软盘\nmount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrom\nmount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrom\nmount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrom\nmount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件\nmount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统\nmount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备\nmount -t smbfs -o username=user,password=pass \nmount -o loop cd.iso /mnt/iso 挂载一个ISO镜像文件\nmount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share mount a windows network share\nmount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share mount a windows network share\n', ''),
(72, 'gdb', 'gdb gdb 简要说明\r\n \r\n  一、执行文件 \r\n   \r\n  file <文件名>   加载被调试的可执行程序文件。 \r\n  因为一般都在被调试程序所在目录下执行GDB，因而文本名不需要带路径。   \r\n  (gdb) file gdb-sample \r\n   \r\n  二、运行程序 \r\n   \r\n  r Run的简写，运行被调试的程序。 \r\n  如果此前没有下过断点，则执行完整个程序；如果有断点，则程序暂停在第一个可用断点处。  \r\n  (gdb) r \r\n   \r\n  三、继续运行 \r\n   \r\n  c   Continue的简写，继续执行被调试程序，直至下一个断点或程序结束。  \r\n  (gdb) c \r\n   \r\n  四、断点 \r\n   \r\n  b <行号> \r\n  b <函数名称> \r\n  b *<函数名称> \r\n  b *<代码地址> \r\n  d [编号] \r\n  b: Breakpoint的简写，设置断点。两可以使用“行号”“函数名称”“执行地址”等方式指定断点位置。 \r\n  其中在函数名称前面加“*”符号表示将断点设置在“由编译器生成的prolog代码处”。如果不了解汇编，可以不予理会此用法。 \r\n  d: Delete breakpoint的简写，删除指定编号的某个断点，或删除所有断点。断点编号从1开始递增。 \r\n      \r\n  (gdb) b 8 \r\n  (gdb) b main \r\n  (gdb) b *main \r\n  (gdb) b *0x804835c \r\n  (gdb) d \r\n   \r\n  五、单步调试 \r\n   \r\n  s, n    s: 执行一行源程序代码，如果此行代码中有函数调用，则进入该函数； \r\n  n: 执行一行源程序代码，此行代码中的函数调用也一并执行。 \r\n  s 相当于其它调试器中的“Step Into (单步跟踪进入)”； \r\n  n 相当于其它调试器中的“Step Over (单步跟踪)”。 \r\n  这两个命令必须在有源代码调试信息的情况下才可以使用（GCC编译时使用“-g”参数）。 \r\n  (gdb) s \r\n  (gdb) n \r\n  si, ni  si命令类似于s命令，ni命令类似于n命令。所不同的是，这两个命令（si/ni）所针对的是汇编指令，而s/n针对的是源代码。  \r\n  (gdb) si \r\n  (gdb) ni \r\n   \r\n   \r\n  六、打印变最 \r\n   \r\n  p <变量名称>    Print的简写，显示指定变量（临时变量或全局变量）的值。   \r\n  (gdb) p i \r\n   \r\n   \r\n  (gdb) p nGlobalVar \r\n  display ...  \r\n   \r\n  七、打印信息 \r\n   \r\n  undisplay <编号> \r\n  display，设置程序中断后欲显示的数据及其格式。 \r\n  例如，如果希望每次程序中断后可以看到即将被执行的下一条汇编指令，可以使用命令 \r\n  “display /i $pc” \r\n  其中 $pc 代表当前汇编指令，/i 表示以十六进行显示。当需要关心汇编代码时，此命令相当有用。 \r\n  undispaly，取消先前的display设置，编号从1开始递增。 \r\n  (gdb) display /i $pc \r\n  (gdb) undisplay 1 \r\n  i   Info的简写，用于显示各类信息，详情请查阅“help i”。 \r\n  (gdb) i r \r\n  q   Quit的简写，退出GDB调试环境。   \r\n  (gdb) q \r\n  help [命令名称]     GDB帮助命令，提供对GDB名种命令的解释说明。 \r\n  如果指定了“命令名称”参数，则显示该命令的详细说明；如果没有指定参数，则分类显示所有GDB命令，供用户进一步浏览和查询。   \r\n  (gdb)\n', ''),
(73, 'nmap', 'nmap nmap nmap 命令使用 \r\n  扫描单一的一个主机，命令如下： \r\n   \r\n  #nmap nxadmin.com \r\n   \r\n  #nmap 192.168.1.2 \r\n   \r\n  扫描整个子网,命令如下: \r\n   \r\n  #nmap 192.168.1.1/24 \r\n   \r\n  扫描多个目标,命令如下： \r\n   \r\n  #nmap 192.168.1.2 192.168.1.5 \r\n   \r\n  扫描一个范围内的目标,如下： \r\n   \r\n  #nmap 192.168.1.1-100 (扫描IP地址为192.168.1.1-192.168.1.100内的所有主机) \r\n   \r\n  如果你有一个ip地址列表，将这个保存为一个txt文件，和namp在同一目录下,扫描这个txt内的所有主机，命令如下： \r\n   \r\n  #nmap -iL target.txt \r\n   \r\n  如果你想看到你扫描的所有主机的列表，用以下命令: \r\n   \r\n  #nmap -sL 192.168.1.1/24 \r\n   \r\n  扫描除过某一个ip外的所有子网主机,命令： \r\n   \r\n  #nmap 192.168.1.1/24 -exclude 192.168.1.1 \r\n   \r\n  扫描除过某一个文件中的ip外的子网主机命令 \r\n   \r\n  #nmap 192.168.1.1/24 -exclude file xxx.txt  (xxx.txt中的文件将会从扫描的主机中排除) \r\n   \r\n  扫描特定主机上的80,21,23端口,命令如下 \r\n   \r\n  #nmap -p80,21,23 192.168.1.1 \r\n   \r\n   \r\n   \r\n   \r\n  从上面我们已经了解了Nmap的基础知识，下面我们深入的探讨一下Nmap的扫描技术.  \r\n   \r\n  Tcp SYN Scan (sS) \r\n   \r\n  这是一个基本的扫描方式,它被称为半开放扫描，因为这种技术使得Nmap不需要通过完整的握手，就能获得远程主机的信息。Nmap发送SYN包到远程主机，但是它不会产生任何会话.因此不会在目标主机上产生任何日志记录,因为没有形成会话。这个就是SYN扫描的优势.  \r\n   \r\n  如果Nmap命令中没有指出扫描类型,默认的就是Tcp SYN.但是它需要root/administrator权限.  \r\n   \r\n  #nmap -sS 192.168.1.1 \r\n   \r\n  Tcp connect() scan(sT) \r\n   \r\n  如果不选择SYN扫描,TCP connect()扫描就是默认的扫描模式.不同于Tcp SYN扫描,Tcp connect()扫描需要完成三次握手,并且要求调用系统的connect().Tcp connect()扫描技术只适用于找出TCP和UDP端口.  \r\n   \r\n  #nmap -sT 192.168.1.1 \r\n   \r\n  Udp scan(sU) \r\n   \r\n  顾名思义,这种扫描技术用来寻找目标主机打开的UDP端口.它不需要发送任何的SYN包，因为这种技术是针对UDP端口的。UDP扫描发送UDP数据包到目标主机，并等待响应,如果返回ICMP不可达的错误消息，说明端口是关闭的，如果得到正确的适当的回应，说明端口是开放的.  \r\n   \r\n  #nmap -sU 192.168.1.1 \r\n   \r\n  FIN scan (sF) \r\n   \r\n  有时候Tcp SYN扫描不是最佳的扫描模式,因为有防火墙的存在.目标主机有时候可能有IDS和IPS系统的存在,防火墙会阻止掉SYN数据包。发送一个设置了FIN标志的数据包并不需要完成TCP的握手.  \r\n   \r\n  root@bt:~# nmap -sF 192.168.1.8 \r\n   \r\n  Starting Nmap 5.51  at 2012-07-08 19:21 PKT \r\n   \r\n  Nmap scan report for 192.168.1.8 \r\n   \r\n  Host is up (0.000026s latency).  \r\n   \r\n  Not shown: 999 closed ports \r\n   \r\n  PORT STATE SERVICE \r\n   \r\n  111/tcp open|filtered rpcbind \r\n   \r\n  FIN扫描也不会在目标主机上创建日志(FIN扫描的优势之一).个类型的扫描都是具有差异性的,FIN扫描发送的包只包含FIN标识,NULL扫描不发送数据包上的任何字节,XMAS扫描发送FIN、PSH和URG标识的数据包.  \r\n   \r\n  PING Scan (sP) \r\n   \r\n  PING扫描不同于其它的扫描方式，因为它只用于找出主机是否是存在在网络中的.它不是用来发现是否开放端口的.PING扫描需要ROOT权限，如果用户没有ROOT权限,PING扫描将会使用connect()调用.  \r\n   \r\n  #nmap -sP 192.168.1.1 \r\n   \r\n  版本检测(sV) \r\n   \r\n  版本检测是用来扫描目标主机和端口上运行的软件的版本.它不同于其它的扫描技术，它不是用来扫描目标主机上开放的端口，不过它需要从开放的端口获取信息来判断软件的版本.使用版本检测扫描之前需要先用TCP SYN扫描开放了哪些端口.  \r\n   \r\n  #nmap -sV 192.168.1.1 \r\n   \r\n  Idle scan (sL) \r\n   \r\n  Idle scan是一种先进的扫描技术，它不是用你真实的主机Ip发送数据包，而是使用另外一个目标网络的主机发送数据包.  \r\n   \r\n  #nmap -sL 192.168.1.6 192.168.1.1 \r\n   \r\n  Idle scan是一种理想的匿名扫描技术,通过目标网络中的192.168.1.6向主机192.168.1.1发送数据，来获取192.168.1.1开放的端口 \r\n   \r\n  有需要其它的扫描技术，如FTP bounce（FTP反弹）, fragmentation scan（碎片扫描）, IP protocol scan（IP协议扫描）,以上讨论的是几种最主要的扫描方式.  \r\n   \r\n  Nmap的OS检测（O） \r\n   \r\n  Nmap最重要的特点之一是能够远程检测操作系统和软件，Nmap的OS检测技术在渗透测试中用来了解远程主机的操作系统和软件是非常有用的，通过获取的信息你可以知道已知的漏洞。Nmap有一个名为的nmap-OS-DB数据库，该数据库包含超过2600操作系统的信息。Nmap把TCP和UDP数据包发送到目标机器上，然后检查结果和数据库对照。 \r\n   \r\n  Initiating SYN Stealth Scan at 10:21 \r\n  Scanning localhost (127.0.0.1) [1000 ports] \r\n  Discovered open port 111/tcp on 127.0.0.1 \r\n  Completed SYN Stealth Scan at 10:21, 0.08s elapsed (1000 total ports) \r\n  Initiating OS detection (try #1) against localhost (127.0.0.1) \r\n  Retrying OS detection (try #2) against localhost (127.0.0.1) \r\n   \r\n  上面的例子清楚地表明，Nmap的首次发现开放的端口，然后发送数据包发现远程操作系统。操作系统检测参数是O（大写O） \r\n   \r\n   \r\n   \r\n   \r\n  Nmap的操作系统指纹识别技术： \r\n   \r\n  设备类型（路由器，工作组等） \r\n  运行（运行的操作系统） \r\n  操作系统的详细信息（操作系统的名称和版本） \r\n  网络距离（目标和攻击者之间的距离跳） \r\n   \r\n  如果远程主机有防火墙，IDS和IPS系统，你可以使用-PN命令来确保不ping远程主机，因为有时候防火墙会组织掉ping请求.-PN命令告诉Nmap不用ping远程主机。 \r\n   \r\n  # nmap -O -PN 192.168.1.1/24 \r\n   \r\n  以上命令告诉发信主机远程主机是存活在网络上的，所以没有必要发送ping请求,使用-PN参数可以绕过PING命令,但是不影响主机的系统的发现.  \r\n   \r\n  Nmap的操作系统检测的基础是有开放和关闭的端口，如果OS scan无法检测到至少一个开放或者关闭的端口，会返回以下错误： www.2cto.com \r\n   \r\n  Warning: OSScan results may be unreliable because we could not find at least 1 open and 1 closed port \r\n   \r\n  OS Scan的结果是不可靠的，因为没有发现至少一个开放或者关闭的端口.  \r\n   \r\n  这种情况是非常不理想的，应该是远程主机做了针对操作系统检测的防范。如果Nmap不能检测到远程操作系统类型，那么就没有必要使用-osscan_limit检测。 \r\n   \r\n   \r\n   \r\n  想好通过Nmap准确的检测到远程操作系统是比较困难的，需要使用到Nmap的猜测功能选项, –osscan-guess 猜测认为最接近目标的匹配操作系统类型。 \r\n   \r\n  # nmap -O --osscan-guess 192.168.1.1 \r\n   \r\n  总结 \r\n   \r\n  Nmap是一个非常强大的工具，它具有覆盖渗透测试的第一方面的能力，其中包括信息的收集和统计。本文从初级到高级的讲解了Nmap入侵扫描工具的使用.希望对大家有所帮助.\n', ''),
(74, 'chattr', 'chattr chattr +a file1 只允许以追加方式读写文件\nchattr +c file1 允许这个文件能被内核自动压缩/解压\nchattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件\nchattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接\nchattr +s file1 允许一个文件被安全地删除\nchattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘\nchattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件\n', ''),
(75, 'chage', 'chage chage -E 2005-12-31 user1 设置用户口令的失效期限\n', ''),
(76, 'vsftp', 'vsftp vsftp vsftpd配置\r\n \r\n  之前配置的vsftp，为了省事和方便，都是用系统用户。今天有人找我配置一个采用虚拟用户的系统 \r\n  CU看了看精华帖子，然后照做之，很容易就成功了 \r\n  需要说明的是，如果系统已经安装了rpm，可以直接修改rpm的配置文件 \r\n  rpm的配置文件在/etc/vsftpd/vsftpd.conf \r\n  如果是tar源码安装，配置文件在/etc/vsftpd.conf \r\n  rpm的可执行文件在/usr/sbin/vsftpd \r\n  tar的可执行文件在/usr/local/sbin/vsftpd \r\n  不要在已经安装了rpm的情况下去用tar编译，我就是这么干的，结果弄的我晕死 \r\n  因为默认的PATH搜索路径中，/usr/sbin/ 是比/usr/local/sbin/优先的。 \r\n  rpm安装很简单，tar安装也很简单，需要做的工作就是修改配置文件 \r\n  如果从源码安装，我们可以打开一些功能 \r\n  # vi builddefs.h  \\\\编辑builddefs.h 文件，文件内容如下： \r\n  #ifndef VSF_BUILDDEFS_H \r\n  #define VSF_BUILDDEFS_H \r\n  #undef VSF_BUILD_TCPWRAPPERS \r\n  #define VSF_BUILD_PAM \r\n  #undef VSF_BUILD_SSL \r\n  把需要的功能前面的undef 改成define，然后编译就可以用了。 \r\n  tcp_wrappers是一个比较有用的功能， \r\n  创建必要的帐号，目录： \r\n  # useradd nobody  \n  # mkdir /usr/share/empty  //可能你的系统已经存在此目录，那就不用建立 \r\n  # mkdir /var/ftp  //可能你的系统已经存在此目录，那就不用建立 \r\n  # useradd -d /var/ftp ftp  \n  # chown root:root /var/ftp \r\n  # chmod og-w /var/ftp \r\n  请记住，如果你不想让用户在本地登陆，那么你需要把他的登陆SHELL设置成/sbin/nologin，比如以上的nobody和ftp我就设置成/sbin/nologin \r\n  #make \r\n  #make install \r\n  这样就安装完成了。接下来要做的事情就是修改配置文件 \r\n  虚拟用户形式实现（db及mysql形式） \r\n  虚拟用户可以采用两种方法，一种是db，一种是mysql集成 \r\n  db方式 \r\n   \r\n  1)先看系统是否安装了db的软件包。默认应该是有了 \r\n  # rpm –qa | grep db4 \r\n  db4-devel-4.2.52-7.1 \r\n  db4-4.2.52-7.1 \r\n  db4-utils-4.2.52-7.1 \r\n   \r\n  2)建立一个logins.txt的文件，单行为用户名，双行为密码，例如 \r\n  # vi /home/logins.txt \r\n  coolerfeng \r\n  12345 \r\n   \r\n  (3)建立数据库文件并设置文件属性 \r\n  # db_load -T -t hash -f /home/logins.txt /etc/vsftpd_login.db \r\n  # chmod 600 /etc/vsftpd_login.db \r\n   \r\n  (4)建立认证文件 \r\n  # vi /etc/pam.d/ftp 插入如下两行 \r\n  auth required /lib/security/pam_userdb.so db=/etc/vsftpd_login \r\n  account required /lib/security/pam_userdb.so db=/etc/vsftpd_login \r\n   \r\n  (5)建立一个虚拟用户 \r\n  useradd -d /home/vsftpd -s /sbin/nologin vsftpd \r\n  ls -ld /home/vsftpd \r\n  drwx------  3 vsftpd vsftpd 1024 Jun  6 22:55 /home/vsftpd/ \r\n   \r\n  (6)编写配置文件(注意事项请参看匿名用户的配置，这里不再赘述) \r\n  # vi /etc/vsftpd-pam.conf \r\n  listen=YES \r\n  listen_port=21 \r\n  tcp_wrappers=YES //支持tcp_wrappers,限制访问(/etc/hosts.allow,/etc/hosts.deny) \r\n  listen=YES的意思是使用standalone启动vsftpd，而不是super daemon(xinetd)控制它 (vsftpd推荐使用standalone方式) \r\n  anonymous_enable=NO \r\n  local_enable=YES  //PAM方式此处必须为YES，如果不是将出现如下错误： \r\n  500 OOPS: vsftpd: both local and anonymous access disabled!  \r\n  write_enable=NO \r\n  anon_upload_enable=NO \r\n  anon_mkdir_write_enable=NO \r\n  anon_other_write_enable=NO \r\n  chroot_local_user=YES \r\n  guest_enable=YES \r\n  guest_username=vsftpd //这两行的意思是采用虚拟用户形式 \r\n  virtual_use_local_privs=YES //虚拟用户和本地用户权限相同 \r\n  pasv_enable=YES //建立资料联机采用被动方式 \r\n  pasv_min_port=30000 //建立资料联机所可以使用port 范围的上界，0表示任意。默认值为0。 \r\n  pasv_max_port=30999 //建立资料联机所可以使用port 范围的下界，0表示任意。默认值为0。 \r\n   \r\n  (7)启动程序 \r\n  # /usr/local/sbin/vsftpd-pam /etc/vsftpd-pam.conf & \r\n   \r\n  (8)测试连通及功能 \r\n  # vi /home/vsftpd/test //建立一个文件，内容如下 \r\n  1234567890 \r\n  # chown vsftpd.vsftpd /home/vsftpd/test \r\n  # ftp 127.0.0.1 \r\n  Connected to 127.0.0.1.  \r\n  220 (vsFTPd 2.0.3) \r\n  530 Please login with USER and PASS.  \r\n  530 Please login with USER and PASS.  \r\n  KERBEROS_V4 rejected as an authentication type \r\n  Name (127.0.0.1:root): xuchen \r\n  331 Please specify the password.  \r\n  Password: \r\n  230 Login successful.  \r\n  Remote system type is UNIX.  \r\n  Using binary mode to transfer files.  \r\n  ftp>; pwd \r\n  257 "/" \r\n  ftp>; size test \r\n  213 11 \r\n  ftp>; quit \r\n  221 Goodbye.  \r\n  OK，用户名为xuchen,密码为12345可以连接到FTP服务器，看不到文件列表，但可以下载已知文件名的文件，不能上传文件，非常安全吧！！ \r\n  如果我们需要用户看到文件，怎么办？也好办,在配置文件中加入如下语句： \r\n  anon_world_readable_only=NO  //匿名登入者不能下载可阅读的档案，默认值为YES \r\n  如果需要让用户上传文件和下载文件分开，建议如下这么做 \r\n  # vi /home/logins.txt \r\n  xuchen \r\n  12345 \r\n  upload \r\n  45678 \r\n  //首先建立虚拟用户upload，密码为45678 \r\n  # db_load -T -t hash -f /home/logins.txt /etc/vsftpd_login.db //更新数据文件 \r\n  # mkdir /home/vsftpd/upload \r\n  # vi /etc/vsftpd-pam.conf 加入如下语句 \r\n  user_config_dir=/etc/vsftpd_user_conf \r\n  # mkdir /etc/vsftpd_user_conf \r\n  # vi /etc/vsftpd_user_conf/upload 文件内容如下 \r\n  local_root=/home/vsftpd/upload \r\n  write_enable=YES \r\n  anon_world_readable_only=NO \r\n  anon_upload_enable=YES \r\n  anon_mkdir_write_enable=YES \r\n  anon_other_write_enable=YES \r\n  # chmod 700 /home/vsftpd/upload \r\n  # chown vsftpd.vsftpd /home/vsftpd/upload/ \r\n  这样，xuchen用户可以下载/home/vsftpd里的文件及upload里的文件，而upload用户可以上传和下载/home/vsftpd/upload文件夹的东西，但不能到/home/vsftpd里下载文件，很简单得实现了分用户上传和下载 \r\n  对于用Mysql库存储用户名及密码的方式来说： \r\n  就是把用户名和密码放在mysql库里，实现起来也相当简单 \r\n  （1）建立一个库并设置相应权限 \r\n  # mysql –p \r\n  mysql>;create database ftpd; \r\n  mysql>;use ftpd; \r\n  mysql>;create table user(name char(20) binary,passwd char(20) binary); \r\n  mysql>;insert into user (name,passwd) values (''test1'',''12345''); \r\n  mysql>;insert into user (name,passwd) values (''test2'',''54321''); \r\n  mysql>;grant select on ftpd.user to ftpd@localhost identified by ''123456''; \r\n  mysql>;flush privileges; 刷新权限设置 \r\n  mysql>;quit \r\n  （2）下载libpam-mysql进行安装编译 \r\n  下载地址如下： \r\n  [url]http://nchc.dl.sourceforge.net/sourceforge/pam-mysql/pam_mysql-0.5.tar.gz[/url] \r\n  假设我们把它放在了/home/xuchen目录下 \r\n  # cd /home/xuchen \r\n  # tar xzvf pam_mysql-0.5.tar.gz \r\n  # cd pam_mysql \r\n  # make \r\n  # cp pam_mysql.so /lib/security \r\n  （3）建立PAM认证信息 \r\n  # vi /etc/pam.d/ftp ,内容如下 \r\n  auth required /lib/security/pam_mysql.so user=ftpd passwd=123456 host=localhost db=ftpd table=user usercolumn=name passwdcolumn=passwd crypt=0 \r\n  account required /lib/security/pam_mysql.so user=ftpd passwd=123456 host=localhost db=ftpd table=user usercolumn=name passwdcolumn=passwd crypt=0 \r\n  注意： \r\n  crypt= n \r\n  crypt=0: 明文密码 \r\n  crypt=1: 使用crpyt()函数(对应SQL数据里的encrypt()，encrypt()随机产生salt) \r\n  crypt=2: 使用MYSQL中的password()函数加密 \r\n  crypt=3：表示使用md5的散列方式 \r\n  （4）建立本地虚拟用户 \r\n  # useradd -d /home/ftpd -s /sbin/nologin ftpd \r\n  （5）下面就差修改vsftpd.conf文件了，我把我的提供给大家参考吧：） \r\n  # vi /etc/vsftpd-pam1.conf \r\n  anonymous_enable=NO \r\n  local_enable=YES \r\n  write_enable=YES \r\n  local_umask=022 \r\n  anon_upload_enable=YES \r\n  anon_mkdir_write_enable=YES \r\n  anon_other_write_enable=YES \r\n  chroot_local_user=YES \r\n  guest_enable=YES \r\n  guest_username=ftpd \r\n  listen=YES \r\n  listen_port=21 \r\n  pasv_enable=YES \r\n  pasv_min_port=30000 \r\n  pasv_max_port=30999 \r\n  anon_world_readable_only=NO \r\n  virtual_use_local_privs=YES \r\n  #user_config_dir=/etc/vsftpd_user_conf \r\n  可以看出，和前面的用db库来验证没有多大区别，其实就是一个东西，一个用mysql来验证，一个用db库，我个人比较倾向于用db库来验证，在这个环境下，相对于Mysql来说，安全系数更高一点。 \r\n   \r\n  (6)# /usr/local/sbin/vsftpd-pam /etc/vsftpd-pam1.conf &   //以后台方式启动 \r\n   \r\n  (7)测试连通 \r\n  # ftp 127.0.0.1 \r\n  Connected to 127.0.0.1.  \r\n  220 (vsFTPd 2.0.3) \r\n  530 Please login with USER and PASS.  \r\n  530 Please login with USER and PASS.  \r\n  KERBEROS_V4 rejected as an authentication type \r\n  Name (127.0.0.1:root): test1 \r\n  331 Please specify the password.  \r\n  Password: \r\n  230 Login successful.  \r\n  Remote system type is UNIX.  \r\n  Using binary mode to transfer files.  \r\n  ftp>; pwd \r\n  257 "/" \r\n  ftp>; quit \r\n  221 Goodbye.\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(77, 'ruby', 'ruby \r\nwhile\r\n	Ruby while声明：\r\n	语法：\r\n\r\n\r\n	while conditional [do]\r\n	   code\r\n	end\r\n\r\n	执行while的条件是真实的的的的代码。一个while循环的条件是保留字做，换行，反斜杠\\，或分号分隔的代码;\r\n	例如：\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	$i = 0;\r\n	$num = 5;\r\n\r\n	while $i < $num  do\r\n	   puts("Inside the loop i = #$i" );\r\n	   $i +=1;\r\n	end\r\n\r\n	这将输出结果如下：\r\n\r\n	Inside the loop i = 0\r\n	Inside the loop i = 1\r\n	Inside the loop i = 2\r\n	Inside the loop i = 3\r\n	Inside the loop i = 4\r\n\r\nif \r\n\r\n	 Ruby if...else语句：\r\n\r\n	语法：\r\n\r\n	if conditional [then]\r\n		  code...\r\n	[elsif conditional [then]\r\n		  code...]...\r\n	[else\r\n		  code...]\r\n	end\r\n\r\n	如果表达式是用于条件执行。值false和nil是假的，一切是真实的。公告Ruby使用ELSIF，不是别的，如果也不ELIF。\r\n\r\n	如果条件为真执行代码。如果条件是不正确的，执行else子句中指定的代码。\r\n	一个表达的条件是从代码分离的保留字，那么，一个换行符或分号。\r\n\r\n	例如：\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	x=1\r\n	if x > 2\r\n	   puts "x is greater than 2"\r\n	elsif x <= 2 and x!=0\r\n	   puts "x is 1"\r\n	else\r\n	   puts "I can''t guess the number"\r\n	end\r\n\r\n\r\n\r\narray\r\n\r\n	 Ruby的数组是有序的，任何对象的整数索引的集合。数组中的每个元素与指数。\r\n	数组索引从0开始，如C或Java。负指数假设数组的末尾---是，指数为-1表示最后一个元素，-2是数组中的最后一个元素，等等。\r\n	Ruby的数组能容纳的对象，如字符串，整数，Fixnum对象，哈希，符号，甚至其他的Array对象。 Ruby的数组是没有像在其他语言的阵列刚性。 Ruby的数组自动增长，同时增加他们的元素.\r\n	创建数组:\r\n\r\n	有许多方法来创建或初始化数组。一种方法是用新的类方法:\r\n\r\n	names = Array.new\r\n\r\n	在创建阵列时，您可以设置一个数组的大小:\r\n\r\n	names = Array.new(20)\r\n\r\n	该数组的名称现在有一个的20元素的的的的的大小或的长度。你可以返回一个数组的大小与大小或长度的方法:\r\n\r\n	months.size  # This returns 20\r\n	months.length # This also returns 20\r\n\r\n	您可以指定阵列中的每个元素值如下:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	names = Array.new(4, "mac")\r\n\r\n	puts "#{names}"\r\n\r\n	This will produce following result:\r\n\r\n	macmacmacmac\r\n\r\n	您还可以使用新块，填充块评估的每个元素:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	nums = Array.new(10) { |e| e = e * 2 }\r\n\r\n	puts "#{nums}"\r\n\r\n	这将产生以下结果:\r\n\r\n	024681012141618\r\n\r\n	还有另一个阵列的方法，[]。它是这样工作:\r\n\r\n	nums = Array.[](1, 2, 3, 4,5)\r\n\r\n	创建数组的形式如下 :\r\n\r\n	nums = Array[1, 2, 3, 4,5]\r\n\r\n	内核模块的核心Ruby，有一个阵列的方法，该方法只接受一个参数。这里的方法作为参数的范围，以创建一个数字数组:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	digits = Array(0..9)\r\n\r\n	puts "#{digits}"\r\n\r\n	这将产生以下结果:\r\n\r\n	0123456789\r\n\r\n	数组内建方法:\r\n\r\n	我们需要有一个Array对象的实例，调用一个数组的方法。正如我们所看到的，下面是创建一个Array对象的实例:\r\n\r\n	Array.[](...) [or] Array[...] [or] [...]\r\n\r\n	这将返回给定对象的填充一个新的数组。现在我们可以使用创建的对象调用任何可用的实例方法。例如:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	digits = Array(0..9)\r\n\r\n	num = digits.at(6)\r\n\r\n	puts "#{num}"\r\n\r\n	这将产生以下结果:\r\n\r\n\r\n	尝试下面的例子来包装各种数据.\r\n\r\n	a = [ "a", "b", "c" ]\r\n	n = [ 65, 66, 67 ]\r\n	a.pack("A3A3A3")   #=> "a  b  c  "\r\n	a.pack("a3a3a3")   #=> "a\\000\\000b\\000\\000c\\000\\000"\r\n	n.pack("ccc")      #=> "ABC"\r\n\r\n\r\nhash\r\n\r\n\r\n\r\n	哈希是这样一个键 - 值对的集合：“雇员”=>“工资”。它是一个数组类似，除了通过任何类型的对象，不是一个整数索引的任意键进行索引。\r\n\r\n	以便在其中任一键或值遍历哈希看似随意，一般不会在插入顺序。如果您尝试访问一个不存在一个关键的哈希值，该方法将返回nil\r\n	创建哈希:\r\n\r\n	阵列，有各种各样的方式来创建哈希。你可以创建一个新的类方法的空哈希:\r\n\r\n	months = Hash.new\r\n\r\n	您还可以使用新创建一个默认值，否则只是nil:\r\n\r\n	months = Hash.new( "month" )\r\n	or\r\n	months = Hash.new "month"\r\n\r\n	当您访问任何一个哈希键有一个默认值，如果键或值不存在，访问哈希将返回默认值:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	months = Hash.new( "month" )\r\n\r\n	puts "#{months[0]}"\r\n	puts "#{months[72]}"\r\n\r\n	这将产生结果如下:\r\n\r\n	month\r\n	month\r\n\r\n	这里是一个简单的方式创建和访问哈希的键/值:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	H = Hash["a" => 100, "b" => 200]\r\n\r\n	puts "#{H[''a'']}"\r\n	puts "#{H[''b'']}"\r\n\r\n	这将产生结果如下:\r\n\r\n	100\r\n	200\r\n\r\n	你可以使用任何一个键或值，甚至数组Ruby对象，所以下面的例子是一个有效的:\r\n\r\n	[1,"jan"] => "January"\r\n\r\n	哈希内建方法:\r\n\r\n	我们需要有一个Hash对象的实例，调用哈希方法。正如我们已经看到，下面的方式来创建一个Hash对象的实例:\r\n\r\n	Hash[[key =>|, value]* ] or\r\n\r\n	Hash.new [or] Hash.new(obj) [or]\r\n\r\n	Hash.new { |hash, key| block }\r\n\r\n	这将返回给定对象的填充一个新的哈希。现在我们可以使用创建的对象调用任何可用的实例方法。例如:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	$, = ", "\r\n	months = Hash.new( "month" )\r\n\r\n	months = {"1" => "January", "2" => "February"}\r\n\r\n	keys = months.keys\r\n\r\n	puts "#{keys}"\r\n\r\n\r\n\r\neach & collect\r\n\r\n\r\n\r\n\r\n	迭代器是什么也不是，但集合的方法支持。存储一组数据成员的对象被称为集合。在Ruby中，数组和哈希可以被称为集合.\r\n\r\n	迭代器返回一个集合的所有元素，一前一后。我们将讨论两个迭代器，在这里，每个收集。让我们来看看这些细节.\r\n	Ruby each 迭代:\r\n\r\n	每个迭代器返回一个数组的所有元素或哈希.\r\n	语法:\r\n\r\n	collection.each do |variable|\r\n	   code\r\n	end\r\n\r\n	在集合中的每个元素执行的代码。这里收集可能是一个数组或ruby哈希.\r\n	例子:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	ary = [1,2,3,4,5]\r\n	ary.each do |i|\r\n	   puts i\r\n	end\r\n\r\n	这将产生结果如下:\r\n\r\n	1\r\n	2\r\n	3\r\n	4\r\n	5\r\n\r\n	你总是与块关联的每个迭代。它返回数组的每个值，逐个块。该值存储在变量i，然后在屏幕上显示.\r\n	Ruby collect 迭代:\r\n\r\n	收集的迭代器返回一个集合的所有元素.\r\n	语法:\r\n\r\n	collection = collection.collect\r\n\r\n	收集方法并不总是需要块。收集方法返回整个集合，无论它是一个数组或哈希.\r\n	例如:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	a = [1,2,3,4,5]\r\n	b = Array.new\r\n	b = a.collect\r\n	puts b\r\n\r\n	这将产生以下结果:\r\n\r\n	1\r\n	2\r\n	3\r\n	4\r\n	5\r\n\r\n	注: 收集方法是不正确的方式做阵列之间的复制。还有另一种方法称为克隆，应使用一个数组复制到另一个阵列.\r\n\r\n	您通常使用的收集方法，当你想要做的东西与每个值，以获取新的阵列。例如，这段代码包含在每个值的10倍，产生一个数组b.\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	a = [1,2,3,4,5]\r\n	b = a.collect{|x| 10*x}\r\n	puts b\r\n\r\n	这将产生以下结果:\r\n\r\n	10\r\n	20\r\n	30\r\n	40\r\n	50\r\n\r\n\r\n\r\n\r\n\r\nclass \r\n\r\n	这些功能已被讨论了面向对象的Ruby。\r\n\r\n	一个面向对象的程序，涉及到的类和对象。一类是从个别对象的创建蓝图。在面向对象的条件，我们说，你的自行车是自行车作为已知的对象类的一个实例。\r\n\r\n	采取的任何车辆的例子。它包括车轮，马力，燃油或燃气罐容量。这些特点形成的类车辆的数据成员。帮助这些特点可以区别于其他一辆车。\r\n\r\n	车辆也有一定的功能，如制止，驾驶，加快。即使这些功能形成类车辆的数据成员。因此，您可以定义类的特点和功能相结合。\r\n\r\n	A级车可以被定义为：\r\n\r\n	Class Vehicle\r\n	{\r\n	   Number no_of_wheels\r\n	   Number horsepower\r\n	   Characters type_of_tank\r\n	   Number Capacity\r\n	   Function speeding{\r\n\r\n	   }\r\n	   Function driving{\r\n\r\n	   }\r\n	   Function halting{\r\n\r\n	   }\r\n	} \r\n\r\n	通过这些数据成员分配不同的值，可以形成类车辆的几个实例。例如，飞机上有三个轮子，1000马力，燃油型坦克，和一个100升的容量。以同样的方式，有车有四个轮子，200马力，天然气作为坦克的类型，容量为25升。\r\n\r\n	Ruby中定义 类：\r\n\r\n	通过使用Ruby来实现面向对象编程，你需要先学习如何创建对象和Ruby类。\r\n	在Ruby中的类总是启动关键字类与类的名称。这个名字应该总是在最初的资本。一流的定制可以显示如下：\r\n\r\n	lass Customer\r\n	end \r\n\r\n	 \r\n	Ruby类的变量：\r\n\r\n	Ruby提供了四种类型的变量：\r\n\r\n	    * 局部变量：局部变量是在一个方法中定义的变量。局部变量以外的方法。你会看到更多有关方法在后续章节的细节。局部变量用小写字母或_开始。\r\n	    * 实例变量：实例变量是在任何特定的实例或对象的方法。这意味着，从对象到对象的实例变量改变。实例变量的变量名的符号（@）之前。\r\n	    * 类变量：类变量是在不同的对象。 A类变量属于类是类的一个特点。他们都是由前面的符号@ @变量名。\r\n	    * 全局变量：类变量是不能跨类。如果你想有一个单独的变量，这是可跨类，你需要定义一个全局变量。全局变量总是先用美元符号（$）。\r\n	例如：\r\n	使用类变量@@ no_of_customers，你可确定正在创建的对象的数量。这使中获得的客户数量。\r\n\r\n	class Customer\r\n	   @@no_of_customers=0\r\n	end \r\n\r\n\r\n	在Ruby中创建的对象使用new方法：\r\n\r\n	对象是类的实例。现在，您将学习如何创建一个Ruby类的对象。在Ruby中，你可以通过使用新的类的方法创建对象。\r\n	新的方法是一个独特的方法，这是Ruby库中的预定义类型。新的方法属于类的方法。\r\n	下面是创建两个对象cust1和一流的客户cust2的例子：\r\n\r\n	cust1 = Customer. new\r\n	cust2 = Customer. new \r\n\r\n	在这里，cust1和cust2是两个对象的名字。等于符号（=）后的类的名称将按照你写的对象的名称。然后，点运算和新的关键字将随之而来。\r\n	 \r\n	自定义的方法来创建Ruby对象：\r\n\r\n	您可以通过新方法的参数，这些参数可以被用来初始化类变量。\r\n	当你计划申报与参数的新方法，您需要申报的方法初始化类的创建时间。\r\n	initialize方法是特殊类型的方法，将类的新方法与参数调用时执行。\r\n	下面是创建初始化方法的例子：\r\n\r\n	class Customer\r\n	   @@no_of_customers=0\r\n	   def initialize(id, name, addr)\r\n	      @cust_id=id\r\n	      @cust_name=name\r\n	      @cust_addr=addr\r\n	   end\r\n	end \r\n\r\n	在这个例子中，你声明为局部变量initialize方法的ID，name，addr。这里def和结束被用来定义一个Ruby方法Initialize。您将了解在以后的章节中的方法。\r\n\r\n	在initialize方法，通过对这些局部变量的值的实例变量@ CUST_ID，CUST_NAME，@ cust_addr。这里的局部变量持有值，通过用新的方法。\r\n\r\n	现在你可以创建对象如下：\r\n\r\n	cust1=Customer.new("1", "John", "Wisdom Apartments, Ludhiya")\r\n	cust2=Customer.new("2", "Poul", "New Empire road, Khandala")\r\n\r\n	Ruby类的成员函数：\r\n\r\n	在Ruby中，函数调用的方法。每一类中的方法，方法名称关键字def开始。\r\n	总是首选的方法名称以小写字母。你在Ruby中的方法使用关键字年底结束。\r\n	下面是定义一个Ruby方法的例子：\r\n\r\n	class Sample\r\n	   def function\r\n	      statement 1\r\n	      statement 2\r\n	   end\r\n	end \r\n\r\n	这里语句1和语句2类内样本的方法函数体的一部分。这些statments可以是任何有效的Ruby语句。例如，我们可以提出一个方法使打印您好红宝石如下：\r\n\r\n	class Sample\r\n	   def hello\r\n	      puts "Hello Ruby!"\r\n	   end\r\n	end \r\n\r\n	现在在下面的例子创建Sample类的一个对象，并调用hello方法和看到的结果：\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	class Sample\r\n	   def hello\r\n	      puts "Hello Ruby!"\r\n	   end\r\n	end\r\n\r\n	# Now using above class to create objects\r\n	object = Sample. new\r\n	object.hello \r\n\r\n	以上代码将输出结果如下：\r\n\r\n	Hello Ruby!\r\n	\r\nIO\r\n\r\n	 Ruby提供了一整套的I / O相关的内核模块中实现的方法。所有的I / O方法都来源于类IO。\r\n	IO类提供所有的基本方法，如读，写，获取，readline时，getc和printf.\r\n\r\n	本章将覆盖所有ithe基本I/O功能，在Ruby中，更多的功能，请引用一个Ruby的IO类.\r\n	puts 语句:\r\n\r\n	在前面的章节中，您指定的值到变量，然后打印输出使用了puts语句.\r\n\r\n	puts语句指示的程序来显示存储在变量中的值。这将添加一个新行，在每行写入结束.\r\n	例子:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	val1 = "This is variable one"\r\n	val2 = "This is variable two"\r\n	puts val1\r\n	puts val2\r\n\r\n	这将产生以下结果:\r\n\r\n	This is variable one\r\n	This is variable two\r\n\r\n	gets 语句:\r\n\r\n	gets语句可用于任何输入，从用户称为stdin标准屏幕.\r\n	例子:\r\n\r\n	下面的代码显示了如何使用获得的声明。此代码将提示用户输入一个值，将存储在变量val，终于将stdout（标准输出）上打印.\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	puts "Enter a value :"\r\n	val = gets\r\n	puts val\r\n\r\n	这将产生以下结果:\r\n\r\n	Enter a value :\r\n	This is entered value\r\n	This is entered value\r\n\r\n	putc 语句:\r\n\r\n	不同于puts语句，输出到屏幕上的整个字符串，的putc可以用来输出一个字符.\r\n	例子:\r\n\r\n	下面的代码的输出仅仅是字符H:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	str="Hello Ruby!"\r\n	putc str\r\n\r\n	这将产生以下结果:\r\n\r\n	H\r\n\r\n	print 语句:\r\n\r\n	print语句是类似puts语句。唯一不同的是，puts到下一行，而与print光标定位在同一行上打印的内容后.\r\n	例子:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	print "Hello World"\r\n	print "Good Morning"\r\n\r\n	这将产生以下结果:\r\n\r\n	Hello WorldGood Morning\r\n\r\n	打开和关闭文件:\r\n\r\n	到现在为止，您已经阅读和写作的标准输入和输出。现在，我们将看到如何发挥与实际的数据文件.\r\n	File.new 方法:\r\n\r\n	你可以创建一个文件对象，读，写，或同时使用File.new方法，根据模式字符串。最后可以使用File.close的方法来关闭该文件.\r\n	语法:\r\n\r\n	aFile = File.new("filename", "mode")\r\n	   # ... process the file\r\n	aFile.close\r\n\r\n	File.open 方法:\r\n\r\n	你可以使用File.Open方法创建一个新的文件对象，并分配到一个文件，文件对象。然而，有一个的File.Open和File.new方法之间的差异。所不同的是File.Open方法可以用块，而你不能这样做的同时使用File.new方法.\r\n\r\n	File.open("filename", "mode") do |aFile|\r\n	   # ... process the file\r\n	end\r\n\r\n	这里是一个不同的模式打开一个文件列表:\r\n	模式 	描述\r\n	r 	只读模式. 文件指针放置在文件的开头,这是默认模式.\r\n	r+ 	读写模式。文件指针将会在文件的开头.\r\n	w 	只写模式。如果该文件存在，覆盖该文件。如果该文件不存在，创建一个新的书面文件.\r\n	w+ 	读写模式。如果该文件存在，将覆盖现有的文件。如果该文件不存在，创建一个新的文件读和写.\r\n	a 	只写模式。文件指针是在结束的文件，如果该文件存在。也就是说，该文件是在追加模式。如果该文件不存在，它创建了一个新的书面文件.\r\n	a+ 	读写模式。文件指针是在结束的文件，如果该文件存在。在追加模式打开该文件。如果该文件不存在，它会创建一个新的文件阅读和写作.\r\n	读和写文件:\r\n\r\n	同样的方法，我们一直在使用“简单”的I / O可用于所有文件对象。因此，获取从标准输入中读取行，aFile.gets读取的文件对象aFile行.\r\n\r\n	然而，I/O对象的访问方法提供了另外一组，以使我们的更轻松.\r\n	sysread 方法:\r\n\r\n	你可以使用该方法sysread读文件的内容。你可以在任何模式中打开文件时使用的方法sysread。例如 :\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	aFile = File.new("/var/www/yiibai.com/ruby/test", "r")\r\n	if aFile\r\n	   content = aFile.sysread(20)\r\n	   puts content\r\n	else\r\n	   puts "Unable to open file!"\r\n	end\r\n\r\n	这条语句将输出文件的前20个字符。文件指针将被放置在文件中的第21字符.\r\n	syswrite 方法:\r\n\r\n	你可以使用方法syswrite，写入到一个文件的内容。你需要在写入模式打开文件使用方法syswrite时。例如 :\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	aFile = File.new("/var/www/yiibai.com/ruby/test", "r+")\r\n	if aFile\r\n	   aFile.syswrite("ABCDEF")\r\n	else\r\n	   puts "Unable to open file!"\r\n	end\r\n\r\n	本声明将写入文件“ABCDEF的”.\r\n	each_byte 方法:\r\n\r\n	这种方法属于类文件。方法each_byte总是与一个块。请看下面的代码示例：:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	aFile = File.new("/var/www/yiibai.com/ruby/test", "r")\r\n	if aFile\r\n	   aFile.syswrite("ABCDEF")\r\n	   aFile.each_byte {|ch| putc ch; putc ?. }\r\n	else\r\n	   puts "Unable to open file!"\r\n	end\r\n\r\n	字符通过一个个变量ch，然后如下的屏幕上显示:\r\n\r\n	T.h.i.s. .i.s. .l.i.n.e. .o.n.e.\r\n	.T.h.i.s. .i.s. .l.i.n.e. .t.w.o.\r\n	.T.h.i.s. .i.s. .l.i.n.e. .t.h.r.e.e.\r\n	.A.n.d. .s.o. .o.n.......\r\n\r\n	IO.readlines 方法:\r\n\r\n	类文件的类IO的一个子类。类IO也有一些方法可用于对文件进行操作.\r\n\r\n	IO类的方法之一是IO.readlines。此方法返回行的文件的内容，下面的代码显示使用方法IO.readlines:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	arr = IO.readlines("/var/www/yiibai.com/ruby/test")\r\n	puts arr[0]\r\n	puts arr[1]\r\n\r\n	在这段代码中，变量arr是一个数组。文件测试的每一行，将是一个数组arr的元素。因此，arr[0]将包含首行，而arr[1]将包含文件的第二行.\r\n	IO.foreach 方法:\r\n\r\n	这种方法也返回逐行输出。该方法之间的差异foreachand readlines方法的方法是该方法的foreach块。然而，不同的方法readlines方法，该方法的foreach不返回一个数组。例如:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	IO.foreach("test"){|block| puts block}\r\n\r\n	此代码将通过的文件测试线，由线到可变块的内容，然后输出将显示在屏幕上.\r\n	重命名和删除文件:\r\n\r\n	你可以重命名和删除文件与红宝石，重命名和删除方法编程。\r\n	以下是示例重命名现有的文件test1.txt:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	# Rename a file from test1.txt to test2.txt\r\n	File.rename( "test1.txt", "test2.txt" )\r\n\r\n	以下是示例删除一个现有的文件test2.txt的:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	# Delete file test2.txt\r\n	File.delete("text2.txt")\r\n\r\n	文件模式和所有权:\r\n\r\n	使用掩码的的CHMOD方法改变的模式或文件的权限/访问列表：\r\n	以下是示例模式，以改变现有的文件test.txt一个掩码值:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	file = File.new( "test.txt", "w" )\r\n	file.chmod( 0755 )\r\n\r\n	以下为表中，它可以帮助您选择不同的面具chmod的方法:\r\n	Mask 	Description\r\n	0700 	rwx mask for owner\r\n	0400 	r for owner\r\n	0200 	w for owner\r\n	0100 	x for owner\r\n	0070 	rwx mask for group\r\n	0040 	r for group\r\n	0020 	w for group\r\n	0010 	x for group\r\n	0007 	rwx mask for other\r\n	0004 	r for other\r\n	0002 	w for other\r\n	0001 	x for other\r\n	4000 	Set user ID on execution\r\n	2000 	Set group ID on execution\r\n	1000 	Save swapped text, even after use\r\n	文件查询:\r\n\r\n	下面的命令测试文件是否存在打开它之前:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	File.open("file.rb") if File::exists?( "file.rb" )\r\n\r\n	下面的命令查询文件是否是一个真正的文件:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	# This returns either true or false File.file?( "text.txt" ) \r\n\r\n	下面的命令找出，是否给定的文件名是一个目录:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	# a directory\r\n	File::directory?( "/usr/local/bin" ) # => true\r\n\r\n	# a file\r\n	File::directory?( "file.rb" ) # => false\r\n\r\n	下面的命令找出，是否给定的文件可读, 可写或可执行:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	File.readable?( "test.txt" )   # => true\r\n	File.writable?( "test.txt" )   # => true\r\n	File.executable?( "test.txt" ) # => false\r\n\r\n	下面的命令查找该文件是否有大小为零或非:\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	File.zero?( "test.txt" )      # => true\r\n\r\n	以下的命令查找返回文件的大小 :\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	File.size?( "text.txt" )     # => 1002\r\n\r\n	下面的命令可以用来找出一个文件类型 :\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	File::ftype( "test.txt" )     # => file\r\n\r\n	ftype方法识别的文件类型返回下列之一：文件，目录，characterSpecial，blockSpecial，fifo，link，socket，或未知.\r\n\r\n	下面的命令可以用来发现，当一个文件被创建，修改或上次访问 :\r\n\r\n	#!/usr/bin/ruby\r\n\r\n	File::ctime( "test.txt" ) # => Fri May 09 10:06:37 -0700 2008\r\n	File::mtime( "text.txt" ) # => Fri May 09 10:44:44 -0700 2008\r\n	File::atime( "text.txt" ) # => Fri May 09 10:45:01 -0700 2008\r\n\r\n	Ruby 中的目录:\r\n\r\n	所有文件都包含在不同的目录，Ruby没有处理这些问题。而File类处理文件，目录与Dirclass处理.\r\n	通过目录浏览:\r\n\r\n	要改变在一个Ruby程序的目录，使用如下Dir.chdir。这个例子改变当前目录到/usr/bin中.\r\n\r\n	Dir.chdir("/usr/bin")\r\n\r\n	你可以用Dir.pwd找出哪些当前目录:\r\n\r\n	puts Dir.pwd # This will return something like /usr/bin\r\n\r\n	你可以得到特定使用Dir.entries目录内的文件和目录列表:\r\n\r\n	puts Dir.entries("/usr/bin").join('' '')\r\n\r\n	dir.entries返回一个数组指定的目录内的所有条目。 Dir.foreachprovides的相同的功能:\r\n\r\n	Dir.foreach("/usr/bin") do |entry|\r\n	   puts entry\r\n	end\r\n\r\n	一个更简洁的方式是使用目录类数组的方法得到目录列表:\r\n\r\n	Dir["/usr/bin/*"]\r\n\r\n	创建一个目录:\r\n\r\n	Dir.mkdir可以用来创建目录:\r\n\r\n	Dir.mkdir("mynewdir")\r\n\r\n	您还可以用mkdir设置一个新的目录（不是一个已经存在的权限）:\r\n\r\n	注: 面具755设置权限，所有者，组，word[anyone] rwxr-XR-X，r=读，w=写，x=执行.\r\n\r\n	Dir.mkdir( "mynewdir", 755 )\r\n\r\n	删除目录:\r\n\r\n	Dir.delete可以用来删除一个目录。 Dir.unlink和Dir.rmdir执行完全相同的功能，并提供了方便.\r\n\r\n	Dir.delete("testdir")\r\n\r\n	创建文件和临时目录:\r\n\r\n	临时文件，可能会创建程序的执行过程中短暂的，但不是永久存储的信息。\r\n	dir.tmpdir提供对当前系统的临时目录的路径，虽然方法不是默认可用的。到使Dir.tmpdir可用它有必要使用规定“tmpdir”.\r\n\r\n	可以使用与File.join Dir.tmpdir，创建一个平台独立的临时文件:\r\n\r\n	require ''tmpdir''\r\n	   tempfilename = File.join(Dir.tmpdir, "tingtong")\r\n	   tempfile = File.new(tempfilename, "w")\r\n	   tempfile.puts "This is a temporary file"\r\n	   tempfile.close\r\n	   File.delete(tempfilename)\r\n\r\n	此代码创建一个临时文件，写入数据，并删除它。 Ruby的标准库还包括称为Tempfile必须是一个库，可以为您创建的临时文件:\r\n\r\n	require ''tempfile''\r\n	   f = Tempfile.new(''tingtong'')\r\n	   f.puts "Hello"\r\n	   puts f.path\r\n	   f.close\r\n', ''),
(78, 'zabbix_get', 'zabbix_get -s 127.0.0.1 -p 10050 -k system.cpu.load[all,avg1]', ''),
(80, 'iconv', 'iconv iconv -t utf-8 -f gb2312 -c my_database.sql > new.sql\n\n-f  原编码\n-t  目标编码\n-c 忽略无法转换的字符\n', ''),
(82, 'zabbix', 'zabbix 以前使用nagios比较多，zabbix用得相对少一些。 发现zabbix对比nagios+cacti还是有些区别的：\r\n\r\n1. zabbix的监控结果和数据全是存在数据库内，cacti是用一种rrd的文件DB。\r\n\r\n2.zabbix有触发器，写监控脚本时只要把数据抓过来就行了，然后再去zabbix内配置触发器，做不同的报警。而nagios一般是直接写在脚本内了。\r\n\r\n3.其它…以后再补充\r\n\r\nzabbix的内置了很多key，如：\r\n\r\n1、监控进程\r\n	/usr/local/zabbix/bin/zabbix_get -s 127.0.0.1 -k "net.tcp.service[http]"\r\n\r\n2、监控端口\r\n	/usr/local/zabbix/bin/zabbix_get -s 127.0.0.1 -k "net.tcp.port[,80]" 结果：1存在，0不存在；\r\n\r\n3、进程数量\r\n	/usr/local/zabbix/bin/zabbix_get -s 127.0.0.1 -k "proc.num[]"\r\n	/usr/local/zabbix/bin/zabbix_get -s 127.0.0.1 -k "proc.num[httpd]"\r\n\r\n4、执行命令\r\n\r\n	/usr/local/zabbix/bin/zabbix_get -s 127.0.0.1 -k "system.run[curl -s  "http:\n\r\n	/usr/local/zabbix/bin/zabbix_get -s 127.0.0.1 -k "system.run[ps auxw | grep ‘httpd’ | grep -v ‘grep’ -c]"\r\n\r\n5、其他\r\n	vm.memory.size[available]\r\n	vfs.file.cksum[/etc/passwd]\r\n	system.cpu.switches\r\n	system.cpu.num\r\n	system.cpu.util[,user]\r\n	system.cpu.util[,nice]\r\n	system.cpu.util[,system]\r\n	system.cpu.util[,iowait]\r\n	system.cpu.util[,idle]\r\n	system.cpu.util[,interrupt]\r\n	system.cpu.util[,steal]\r\n	system.cpu.util[,softirq]\r\n	system.swap.size[,free]\r\n	system.swap.size[,pfree]\r\n	system.boottime\r\n	system.localtime\r\n	system.hostname\r\n	system.cpu.intr\r\n	kernel.maxfiles\r\n	kernel.maxproc\r\n	system.users.num\r\n	proc.num[]\r\n	proc.num[,,run]\r\n	system.cpu.load[percpu,avg1]\r\n	system.cpu.load[percpu,avg5]\r\n	system.cpu.load[percpu,avg15]\r\n	system.uname\r\n	system.uptime\r\n	vm.memory.size[total]\r\n	system.swap.size[,total]\r\n	net.tcp.service[ftp,,155]\r\n	net.tcp.service[http]\r\n	net.tcp.service.perf[http,,8080]\r\n	net.tcp.service[service,, ]\r\n\r\n6、怎么自定义一些key呢？\r\n\r\n	要先启用自定义key，需要在客户端的配置文件zabbix_agentd.conf中启用UnsafeUserParameters=1参数，然后在配置文件的最下面来定义key，如：\r\n\r\n	UnsafeUserParameters=0 => UnsafeUserParameters=1并去掉前面的注释符\r\n	UserParameter=         => UserParameter=aaa.bbb[*], /usr/local/script/monitor.sh $1 $2 …\r\n\r\n	说明：  aaa.bbb[*] —zabbix服务器添加监控信息时需要用到的key值，\r\n	格式：aaa.bbb[*](例：system.file.size[*])\r\n	/usr/local/script/monitor.sh —-监控脚本绝对路径\r\n	为了便于灵活监控，有时脚本需要传入参数，此参数可从zabbix服务器端传入，所有参数按顺序分别从$1-$9表示\r\n	注：   (1)若无需传入参数，则红色部分可省略\r\n	(2)该自定义脚本可由zabbix服务器控制收集数据的频率（如：每30s运行一次），无需再添加计划任务\r\n\r\n	(3)以上参数请根据实际情况填写，并注意去除参数前注释符(#)\r\n\r\n	(4)注意在key值和后面的脚本之间有个逗号隔开', ''),
(83, 'fpm', 'fpm 许多朋友始终觉得RPM难做，主要是因为SPEC规则比较多，需要花精力去了解和熟悉。之前试用一个叫checkinstall的工具，可以自动打RPM包。很久没有维护了，在CentOS6上编译有问题。虽然也有网友给打了Patch，最终能用起来，可惜使用过程中还是会遇到诸多错误。\r\n\r\n如今巧遇FPM，一行命令就搞定RPM包！\r\n\r\n一、我们来先安装FPM：\r\n\r\n	# FPM是Ruby模块\r\n	yum -y install ruby rubygems ruby-devel\r\n	# 添加淘宝的Ruby仓库\r\n	gem sources -a http:\n	# 移除原生的Ruby仓库\r\n	gem sources --remove http://rubygems.org/\r\n	# 安装fpm\r\n	gem install fpm\r\n\r\n二、官网介绍了用FPM打deb包，我来翻译成rpm版：\r\n\r\n	# 去nodejs官网下载最新源码包\r\n	wget http://nodejs.org/dist/v0.10.12/node-v0.10.12.tar.gz\r\n	# 解压\r\n	tar zxvf node-v0.10.12.tar.gz -C /dev/shm/\r\n	# 进入源码目录\r\n	cd /dev/shm/node-v0.10.12/\r\n	# 指定配置参数\r\n	./configure --prefix=/usr --dest-cpu=x64 --dest-os=linux\r\n	# 使用多核编译\r\n	make -j24\r\n	mkdir /dev/shm/node-root\r\n	# 指定安装路径\r\n	make -j24 install DESTDIR=/dev/shm/node-root\r\n	# 生成RPM\r\n	fpm -f -s dir -t rpm -n nodejs --epoch 0-v 0.10.12--iteration 1.el6-C /dev/shm/node-root -p ~/rpmbuild/RPMS/x86_64/-d ''openssl >= 0.9.8''-d ''libstdc++ >= 4.4.3''--verbose --category ''Development/Languages''--description ''Node.js real-time applications''--url ''nodejs.org''--license ''BSD''-m ''higkoo''--no-rpm-sign --workdir /dev/shm usr/bin usr/lib usr/share\r\n	# 查看RPM包信息\r\n	rpm -qpi ~/rpmbuild/RPMS/x86_64/nodejs-0.10.12-1.el6.x86_64.rpm\r\n\r\n三、查看安装包信息：\r\n\r\n	小技巧：''-e'' 参数支持打包之前手动修改FPM自动生成的SPEC文件，然后再打包。不过注意CentOS5和CentOS6之间的rpm包不能混用，因为他们之间的glibc版本不同，动态库链接不上。\r\n\r\n	OK，没玩过就赶紧动手吧！\r\n\r\n四、参数含义\r\n\r\n	-s 指定INPUT的数据类型\r\n\r\n	-t 指定需要制作成什么包,可选项有(deb, rpm, solaris, etc)\r\n\r\n	-n 包名\r\n\r\n	--iteration 也就是rpm包里面的release\r\n\r\n	-C 就是打包的相对路径，类似于buildroot。譬如-C /dev/shm/node-root/ 而打包机器的数据包路径是/dev/shm/node-root/usr/bin/node 那安装这个rpm包后，在本地的数据就是/usr/bin/node', ''),
(88, 'rpm2cpio', 'rpm2cpio wget-1.12-5.el6_6.1.x86_64.rpm | cpio -ivd ', ''),
(89, 'cpio', 'cpio \n\nrpm2cpio言下之意就是把RPM包转化成CPIO归档档案！\n最简单的例子如下，该命令功能同rpm -qpl package.rpm，为查看RPM中的文件内容，\nrpm2cpio package.rpm | cpio -t\n把RPM包转化为cpio包，cpio包的使用范围和可用性会比RPM更广！\nrpm2cpio package.rpm > package.cpio\n相信在UNIX下CPIO会比RPM有用的多！\n\nrpm2cpio logrotate-1.0-1.i386.rpm |cpio -ivd 抽取文件！\n\n更多的rpm2cpio的用法可以查阅cpio的手册！\n\ncpio - 存取归档包中的文件 \n语法 Syntax \ncpio -o [ -aBLuvV ] [ -C bufsize ] [ -c | -H format ][ -K volumesize ] [ [ -O file [, file ... ] ] [ -M message ] ] [ -Pifd,ofd ] \n\ncpio -i [ -6AbBcdfkmnqrsStTuvV ] [-C bufsize ] [ [ -I file [, file ... ] ] \n[ -M message ] ] [ -Pifd,ofd ] [ pattern ... ] \n\ncpio -p [ -adlLmruvV ] [ -Pifd,ofd ] directory \n\n描述 (DEscriptION) \n　　cpio 可以从 cpio 或 tar 格式的归档包中存入和读取文件, 归档包是一种包含其他文件和有关信息的文件。 有关信息包括：文件名, 属主, 时标(timestamp), 和访问权限。 归档包可以是磁盘上的 其他文件, 也可以是磁带或管道。 \n\ncpio 有三种操作模式: \n　　在copy-out模式中, cpio 把文件复制到归档包中。它从标准输入获得文件名列表 (一行一个), 把归档包写到标准输出。生成文件名列表的典型方法是使用find 命令; 你可能要在 find 后面用上 -depth选项, 减少因为进入没有访问权限的目录而引起的麻烦。 \n\n　　在copy-in模式中, cpio 从归档包里读取文件, 或者列出归档包里的内容。它从标准输入读入归档包。任何不是选项的命令行参数被视为shell的通配符模式串 (globbing pattern); 在归档包中, 只有文件名匹配这些模式串的文件才能复制出来。 和 shell 中不一样, 文件名起始处的 ''.'' 可以匹配模式串起始处的通配符, 文件名中的 ''/'' 也可以匹配通配符。 如果没有给出模式串, 那么将读出所有文件。 \n\n　　在copy-pass模式中, cpio把文件从一棵目录树复制到另一棵, 它结合了 copy-in 和 copy-out 的操作, 但不使用归档包。 cpio从标准输入读取欲复制的文件名列表; 目标目录作为非选项的命令行参数给出。 \n\n　　cpio支持下列的归档格式: binary, old ASCII, new ASCII, crc, HPUX binary, HPUX old ASCII, old tar, 和 POSIX.1 tar。 \n\n　　"binary"格式是过时格式, 因为它保存文件信息的方法无法应用在不同体系的机器间移植。"old ASCII" 格式可以跨平台使用, 但是不能用于超过 65536 个 i 节点的文件系统中。 "new ASCII" 格式可以跨平台使用, 也适用于任意大小的文件系统, 但不是所有版本的 cpio 都支持; 目前只有 GNU 和 System VR4 的 cpio 支持。"crc" 格式 类似于 "new ASCII" 格式, 同时对每个文件计算校验和。cpio 在创建归档包时算出校验和, 解开文件时进行校验。 "HPUX" 格式用于兼容 HP UNIX 的 cpio, 它用了独特的方法来保存设备文件。 \n\n　　"tar" 格式用以兼容 tar 程序。它不能归档文件名超过 100 个字符的文件, 也不能归档特殊文件 (块设备或字符设备)。 "POSIX.1 tar" 格式不能归档文件名超过 255 个字符的文件(小于, 除非文件名的最右边有一个 "/")。 \n\n　　缺省情况下, cpio 为了兼容老式的 cpio 程序, 创建 "binary" 格式的归档包。当展开归档包时, cpio 能够自动识别归档包的格式, 而且可以读取在其他字节顺序的机器上创建的归档包。 \n　　cpio 的某些选项只能用在对应的操作模式上; 参见总览小节, 里面列出了什么选项可以用在什么模式上。 \n\n\n选项 (OPTIONS) \n	-0, --null 在copy-out 和 copy-pass 模式中, 认为输入的文件名以 null字符结尾,而不是换行符, 这样即使文件名中包含换行符, 也不影响归档。 GNU find 是生成 null 结尾文件名列表的方法之一。 \n	\n	-a, --reset-access-time 读取完文件后重置文件的访问时间, 这样看上去就象没被访问过一样。 \n	\n	-A, --append 追加到已经存在的归档包中。仅用于 copy-out模式。该归档包必须是用 -O 或 -F (--file) 选项指定的磁盘文件。 \n	\n	-b, --swap 在 copy-in 模式中, 颠倒数据中字中的半字和半字中的字节顺序。 相当于 -sS 使用这个选项，可以在大端数和小端数机器之间转换 32 位整数。 \n	\n	-B 把 I/O 块大小设置成 5120 字节，最初的块大小是 512 字节。 \n	\n	--block-size=BLOCK-SIZE \n	设置 I/O 块 大小 为 BLOCK-SIZE * 512 字节。 \n	\n	-c 使用老式的跨平台 (ASCII) 归档格式。 \n	\n	-C IO-SIZE, --io-size=IO-SIZE 设置 I/O 块大小为 IO-SIZE 字节。 \n	\n	-d, --make-directories 在需要的地方创建开始目录。 \n	\n	-E FILE, --pattern-file=FILE 在 copy-in 模式中, 从 FILE 中读取用于匹配文件名的模式串, FILE 中的内容就象 cpio 的非选项参数一样看待。 \n	\n	-f, --nonmatching 只复制那些不匹配任何给定的模式串的文件。 \n	\n	-F, --file=archive 使用归档文件名, 而不是标准输入或输出。 如果把其他机器上的磁带机作成归档文件使用, 文件名要用 "HOSTNAME:" 开始。 主机名前面可以加上用户名和一个 ''@'', 作为访问远程磁带机的用户 (如果你有这样的权限, 一般在用户的 ~/.rhosts 文件中会有这么一项)。 \n	\n	--force-local 和 -F, -I, 或 -O, 一起用, 即使文件名中含有一个冒号,也把归档文件看作本地文件, 一般说来冒号指出一个远程主机名字。 \n	\n	-H FORMAT, --format=FORMAT 使用归档格式 FORMAT。 有效的格式在下面列出, 大小写均可. "copy-in" 模式的缺省动作是自动检测归档格式, "copy-out" 的缺省格式是 "bin"。 \n	　　bin 老式的 binary 格式。 \n	　　odc 老式的 (POSIX.1) 跨平台格式。 \n	　　newc 新型 (SVR4) 跨平台格式, 支持大于 65536 i节点的文件系统。 \n	　　crc　新型 (SVR4) 跨平台格式, 并且计算校验和。 \n	　　tar 老式的 tar 格式。 \n	　　ustar POSIX.1 tar 格式, 也能识别 GNU tar 归档文件, 它们相似但不全相同。 \n	　　hpbin HP UNIX 上的 cpio 使用的老式的 binary 格式。(用独特的方法储存设备文件) \n	　　hpodc HP UNIX 上的 cpio 使用的跨平台格式。 (用独特的方法储存设备文件) \n	\n	-i, --extract 进入 copy-in 模式。 \n	-I archive 使用归档文件名, 而不是标准输入。 如果把其他机器上的磁带机作成归档文件, 文件名要用 "HOSTNAME:" 开始。 主机名前面可以加上用户名和一个 ''@'', 作为 访问远程 磁带机的用户 (如果你有这样的权限, 一般在用户的 ~/.rhosts 文件中会有这么一项)。 \n	\n	-k 无效操作; 只是用来兼容其他版本的 cpio。 \n	\n	-l, --link 如果有可能, 连接文件, 而不是复制。 \n	\n	-L, --dereference 解除符号连接的关联 (复制符号连接指向的 文件, 而不是连接本身)。 \n	\n	-m, --preserve-modification-time 当创建文件时, 保留以前的文件修改时间。 \n	\n	-M MESSAGE, --message=MESSAGE当备份介质(例如 磁带或软盘) 到达卷尾时, 显示一条消息, 提醒用户插入下一卷。如果 MESSAGE 包含字符串 "%d", 它被替换成当前卷号 (从 1 开始)。 \n	\n	-n, --numeric-uid-gid 以详细方式 (verbose) 显示内容时, 用数字显示 UID 和 GID, 而不是翻译成名称。 \n	\n	--no-absolute-filenames 在copy-in模式中, 即使它们在归档包中有绝对路径名。也在当前目录中创建所有相关文件, \n	\n	--no-preserve-owner 在 copy-in 和 copy-pass 模式中, 不改变文件的属主关系 (译注: 疑为不保留); 使它们属于展开它们的用户。这是普通用户的缺省行为, 因此 System V 的用户不致于无意中把文件泄露(give away)。 \n	\n	-o, --create 进入 copy-out 模式。 \n	-O archive 使用归档文件名, 而不是标准输出。 如果把其他机器上的磁带机作成归档文件, 文件名要用 "HOSTNAME:" 开始。 主机名前面可以加上用户名和一个 ''@'', 作为访问远程磁带机的用户 (如果你有这样的权限, 一般在用户的 ~/.rhosts 文件中会有这么一项)。 \n	\n	--only-verify-crc 当在 copy-in 模式读入 CRC 格式的归档包时, 不展开里面的文件, 而只是测试文件的 CRC 码。 \n	\n	-p, --pass-through 进入 copy-pass 模式。 \n	--quiet 不显示复制的块数。 \n	-r, --rename 交互式文件改名。 \n	-R [user][:.][group], --owner [user][:.][group] 在 copy-out 和 copy-pass 模式中, 把所有文件的属主设置为指定的用户和/或用户组。 无论用户还是用户组都必须存在。 如果省略用户组, 但是给出了分隔符 ":" 或 "。'', 则使用给定用户登录时的用户组。 只有超级用户能够改变文件的属主。 \n	\n	--sparse 在 copy-out 和 copy-pass 模式中, 把大块数据 0 的文件写成稀疏文件 (sparse file)。 \n	\n	-s, --swap-bytes 在 copy-in 模式中, 交换文件中每一个半字(字节对) 中的字节。 \n	-S, --swap-halfwords 在 copy-in 模式中, 交换文件中每一个字(4字节) 中的半字。 \n	-t, --list 显示输入归档包的内容。 \n	\n	-u, --unconditional 替换所有文件, 不再提问是否用旧文件替换已经存在的新文件。 \n	-v, --verbose 列出处理的文件, 加上 -t 选项可以列出一个 ''ls -l'' 风格的列表。在一个归档包内容的详细列表 (verbose) 中, 如果本地系统不存在归档文件的用户和用户组名称, 它们将被替换成其数字 UID和GID 对应于本地系统的用户和用户组名称。 \n	\n	-V --dot 每处理一个文件, 显示一个 "."。 \n	--version 显示 cpio 程序的版本号, 然后退出。\n', ''),
(90, 'mysqld', 'mysqld /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/data/mysql/data --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --log-error=/data/mysql/mysql-error.log --open-files-limit=65535 --pid-file=/data/mysql/mysql.pid --socket=/var/lib/mysql/mysql.sock --port=3306', ''),
(91, 'zabbix', 'zabbix ./configure --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2', ''),
(92, 'cobbler', 'cobbler cobbler system add --name=192.168.98.136 --profile=centos6.6 --hostname=test136 --interface=bond0 --interface-type=bond --bonding-opts="mode=active-backup miimon=100" --ip-address=192.168.98.136 --subnet=255.255.255.0 --gateway=192.168.98.128 --static=1 --static-routes="192.168.1.0/16:192.168.1.1 172.16.0.0/16:172.16.0.1"\ncobbler system edit --name=192.168.98.136 --interface=eth0 --mac=00:50:56:33:77:19 --interface-type=bond_slave --interface-master=bond0\ncobbler system edit --name=192.168.98.136 --interface=eth1 --mac=00:50:56:33:FC:99 --interface-type=bond_slave --interface-master=bond0 \n', ''),
(95, 'abc', 'abc ls', ''),
(97, 'find', 'find ./ -name cfg.example.json |xargs rename ''s/example\\.', ''),
(98, 'ip', 'ip link set virbr0 up', ''),
(99, 'find', 'find |xargs  -i basename {} ', ''),
(100, 'iptables', 'iptables -I INPUT -s 172.16.0.0/16 -p tcp --dport 8787 -m state --state NEW,ESTABLISHED -j ACCEPT', ''),
(101, 'shell', 'shell shell 的$! ,$?, $$,$@\r\n\r\n\r\n    $n        $1 the first parameter,$2 the second...\r\n\r\n    $#        The number of command-line parameters.\r\n\r\n    $0        The name of current program.\r\n\r\n    $?        Last command or function''s return value.\r\n\r\n    $$        The program''s PID.\r\n\r\n    $!        Last program''s PID.\r\n\r\n    $@        Save all the parameters.\r\n\r\n\r\nalmost any shell book will talk about them,from which you can get their detail usages.\r\n\r\n2    Linux SHELL if 命令参数说明\r\n\r\n    –b 当file存在并且是块文件时返回真\r\n    -c 当file存在并且是字符文件时返回真\r\n    -d 当pathname存在并且是一个目录时返回真\r\n    -e 当pathname指定的文件或目录存在时返回真\r\n    -f 当file存在并且是正规文件时返回真\r\n    -g 当由pathname指定的文件或目录存在并且设置了SGID位时返回为真\r\n    -h 当file存在并且是符号链接文件时返回真，该选项在一些老系统上无效\r\n    -k 当由pathname指定的文件或目录存在并且设置了“粘滞”位时返回真\r\n    -p 当file存在并且是命令管道时返回为真\r\n    -r 当由pathname指定的文件或目录存在并且可读时返回为真\r\n    -s 当file存在文件大小大于0时返回真\r\n    -u 当由pathname指定的文件或目录存在并且设置了SUID位时返回真\r\n    -w 当由pathname指定的文件或目录存在并且可执行时返回真。一个目录为了它的内容被访问必然是可执行的。\r\n    -o 当由pathname指定的文件或目录存在并且被子当前进程的有效用户ID所指定的用户拥有时返回真。\r\n\r\nUNIX Shell 里面比较字符写法：\r\n\r\n    -eq   等于\r\n    -ne    不等于\r\n    -gt    大于\r\n    -lt    小于\r\n    -le    小于等于\r\n    -ge   大于等于\r\n    -z    空串\r\n    =     两个字符相等\r\n    !=    两个字符不等\r\n    -n    非空串\r\n\r\n总结：\r\n\r\n文档比较运算符  \r\n-e filename  假如 filename存在，则为真  [ -e /var/log/syslog ] \r\n-d filename  假如 filename为目录，则为真  [ -d /tmp/mydir ] \r\n-f filename  假如 filename为常规文档，则为真  [ -f /usr/bin/grep ] \r\n-L filename  假如 filename为符号链接，则为真  [ -L /usr/bin/grep ] \r\n-r filename  假如 filename可读，则为真  [ -r /var/log/syslog ] \r\n-w filename  假如 filename可写，则为真  [ -w /var/mytmp.txt ] \r\n-x filename  假如 filename可执行，则为真  [ -L /usr/bin/grep ] \r\nfilename1-nt filename2  假如 filename1比 filename2新，则为真  [ /tmp/install/etc/services -nt /etc/services ] \r\nfilename1-ot filename2  假如 filename1比 filename2旧，则为真  [ /boot/bzImage -ot arch/i386/boot/bzImage ] \r\n字符串比较运算符 （请注意引号的使用，这是防止空格扰乱代码的好方法）  \r\n-z string  假如 string长度为零，则为真  [ -z "$myvar" ] \r\n-n string  假如 string长度非零，则为真  [ -n "$myvar" ] \r\nstring1= string2  假如 string1和 string2相同，则为真  [ "$myvar" = "one two three" ] \r\nstring1!= string2  假如 string1和 string2不同，则为真  [ "$myvar" != "one two three" ] \r\n算术比较运算符  \r\nnum1-eq num2  等于 [ 3 -eq $mynum ] \r\nnum1-ne num2  不等于 [ 3 -ne $mynum ] \r\nnum1-lt num2  小于 [ 3 -lt $mynum ] \r\nnum1-le num2  小于或等于 [ 3 -le $mynum ] \r\nnum1-gt num2  大于 [ 3 -gt $mynum ] \r\nnum1-ge num2  大于或等于 [ 3 -ge $mynum ]\r\n\r\n本文摘自网络\r\n\r\n+++++++++++++++++++++++++++++++++++++++++++\r\nshell判断文件,目录是否存在或者具有权限\r\n文章来源:http:\n#!/bin/sh \r\nmyPath="/var/log/httpd/" \r\nmyFile="/var /log/httpd/access.log" \r\n#这里的-x 参数判断$myPath是否存在并且是否具有可执行权限 \r\nif [ ! -x "$myPath" ]; then \r\n     mkdir "$myPath" \r\nfi \r\n#这里的-d 参数判断$myPath是否存在 \r\nif [ ! -d "$myPath" ]; then \r\n     mkdir "$myPath" \r\nfi \r\n#这里的-f参数判断$myFile是否存在 \r\nif [ ! -f "$myFile" ]; then \r\n     touch "$myFile" \r\nfi \r\n#其他参数还有-n,-n是判断一个变量是否是否有值 \r\nif [ ! -n "$myVar" ]; then \r\n      echo "$myVar is empty" \r\n      exit 0 \r\nfi \r\n#两个变量判断是否相等 \r\nif [ "$var1" = "$var2" ]; then \r\necho ''$var1 eq $var2'' \r\nelse \r\necho ''$var1 not eq $var2'' \r\nfi\r\n注意：if 的格式，语句中的空格不能少。\r\n========================================\r\nshell 判断语句\r\n\r\n流程控制 "if" 表达式 如果条件为真则执行then后面的部分： if ....; then\r\n....\r\nelif ....; then\r\n....\r\nelse\r\n....\r\nfi\r\n大多数情况下，可以使用测试命令来对条件进行测试。比如可以比较字符串、判断文件是否存在及是否可读等等… 　　通常用" [ ] "来表示条件测试。注意这里的空格很重要。要确保方括号的空格。 \r\n[ -f "somefile" ] ：判断是否是一个文件\r\n[ -x "/bin/ls" ] ：判断/bin/ls是否存在并有可执行权限\r\n[ -n "$var" ] ：判断$var变量是否有值\r\n[ "$a" = "$b" ] ：判断$a和$b是否相等          -r file　　　　　用户可读为真\r\n-w file　　　　　用户可写为真\r\n-x file　　　　　用户可执行为真\r\n-f file　　　　　文件为正规文件为真\r\n-d file　　　　　文件为目录为真\r\n-c file　　　　　文件为字符特殊文件为真\r\n-b file　　　　　文件为块特殊文件为真\r\n-s file　　　　　文件大小非0时为真\r\n-t file　　　　　当文件描述符(默认为1)指定的设备为终端时为真 \r\n#########################################################\r\n含条件选择的shell脚本\r\n    对于不含变量的任务简单shell脚本一般能胜任。但在执行一些决策任务时，就需要包含if/then的条件判断了。shell脚本编程支持此类运算，包括比较运算、判断文件是否存在等。基本的if条件命令选项有： -eq —比较两个参数是否相等（例如，if [ 2 –eq 5 ]）\r\n-ne —比较两个参数是否不相等\r\n-lt —参数1是否小于参数2\r\n-le —参数1是否小于等于参数2\r\n-gt —参数1是否大于参数2\r\n-ge —参数1是否大于等于参数2\r\n-f — 检查某文件是否存在（例如，if [ -f "filename" ]）\r\n-d — 检查目录是否存在\r\n几 乎所有的判断都可以用这些比较运算符实现。脚本中常用-f命令选项在执行某一文件之前检查它是否存在。 ################################################################## 判断文件是否存在\r\n #!/bin/sh\r\ntoday=`date -d yesterday +%%y%%m%%d`\r\nfile="apache_$today.tar.gz"\r\ncd /home/chenshuo/shell\r\nif [ -f "$file" ];then\r\necho "OK"\r\nelse\r\necho "error $file" >error.log\r\nmail -s "fail backup from test" test@test.com <error.log\r\nfi', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(102, 'libvirt-bootstrap', 'libvirt-bootstrap #!/bin/sh -\n#===============================================================================\n# vim: softtabstop=4 shiftwidth=4 expandtab fenc=utf-8 spell spelllang=en cc=81\n#===============================================================================\n#\n#          FILE: bootstrap-webvirtmgr.sh\n#\n#   DESCRIPTION: Bootstrap webvirtmgr installation for various distributions\n#\n#          BUGS: https:\n#\n#     COPYRIGHT: (c) 2013 by the WebVirtMgr Team\n#\n#       LICENSE: Apache 2.0\n#  ORGANIZATION: WebVirtMgr (webvirtmgr.net)\n#       CREATED: 11/11/2013 11:00:00 EET\n#===============================================================================\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  echoerr\n#   DESCRIPTION:  Echo errors to stderr.\n#-------------------------------------------------------------------------------\nechoerror() {\n    printf "${RC} * ERROR${EC}: $@\\n" 1>&2;\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  echoinfo\n#   DESCRIPTION:  Echo information to stdout.\n#-------------------------------------------------------------------------------\nechoinfo() {\n    printf "${GC} *  INFO${EC}: %%s\\n" "$@";\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  echowarn\n#   DESCRIPTION:  Echo warning informations to stdout.\n#-------------------------------------------------------------------------------\nechowarn() {\n    printf "${YC} *  WARN${EC}: %%s\\n" "$@";\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  echodebug\n#   DESCRIPTION:  Echo debug information to stdout.\n#-------------------------------------------------------------------------------\nechodebug() {\n    if [ $_ECHO_DEBUG -eq $BS_TRUE ]; then\n        printf "${BC} * DEBUG${EC}: %%s\\n" "$@";\n    fi\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  __test_distro_arch\n#   DESCRIPTION:  Echo errors to stderr.\n#-------------------------------------------------------------------------------\n__test_distro_arch() {\n    ARCH=$(uname -m | sed ''s/x86_//;s/i[3-6]86/32/'')\n    if [ "$ARCH" = 32 ]; then\n        echoerror "32-bit Arch kernel does not support"\n        exit 1\n    fi\n}\n__test_distro_arch\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  __strip_duplicates\n#   DESCRIPTION:  Strip duplicate strings\n#-------------------------------------------------------------------------------\n__strip_duplicates() {\n    echo $@ | tr -s ''[:space:]'' ''\\n'' | awk ''!x[$0]++''\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  __function_defined\n#   DESCRIPTION:  Checks if a function is defined within this scripts scope\n#    PARAMETERS:  function name\n#       RETURNS:  0 or 1 as in defined or not defined\n#-------------------------------------------------------------------------------\n__function_defined() {\n    FUNC_NAME=$1\n    if [ "$(command -v $FUNC_NAME)x" != "x" ]; then\n        echoinfo "Found function $FUNC_NAME"\n        return 0\n    fi\n    echodebug "$FUNC_NAME not found...."\n    return 1\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  __parse_version_string\n#   DESCRIPTION:  Parse version strings ignoring the revision.\n#                 MAJOR.MINOR.REVISION becomes MAJOR.MINOR\n#-------------------------------------------------------------------------------\n__parse_version_string() {\n    VERSION_STRING="$1"\n    PARSED_VERSION=$(\n        echo $VERSION_STRING |\n        sed -e ''s/^/#/'' \\\n            -e ''s/^#[^0-9]*\\([0-9][0-9]*\\.[0-9][0-9]*\\)\\(\\.[0-9][0-9]*\\).*$/\\1/'' \\\n            -e ''s/^#[^0-9]*\\([0-9][0-9]*\\.[0-9][0-9]*\\).*$/\\1/'' \\\n            -e ''s/^#[^0-9]*\\([0-9][0-9]*\\).*$/\\1/'' \\\n            -e ''s/^#.*$//''\n    )\n    echo $PARSED_VERSION\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  __sort_release_files\n#   DESCRIPTION:  Custom sort function. Alphabetical or numerical sort is not\n#                 enough.\n#-------------------------------------------------------------------------------\n__sort_release_files() {\n    KNOWN_RELEASE_FILES=$(echo "(arch|centos|debian|ubuntu|fedora|redhat|suse|\\\n        mandrake|mandriva|gentoo|slackware|turbolinux|unitedlinux|lsb|system|\\\n        os)(-|_)(release|version)" | sed -r ''s:[[:space:]]::g'')\n    primary_release_files=""\n    secondary_release_files=""\n    # Sort know VS un-known files first\n    for release_file in $(echo $@ | sed -r ''s:[[:space:]]:\\n:g'' | sort --unique --ignore-case); do\n        match=$(echo $release_file | egrep -i ${KNOWN_RELEASE_FILES})\n        if [ "x${match}" != "x" ]; then\n            primary_release_files="${primary_release_files} ${release_file}"\n        else\n            secondary_release_files="${secondary_release_files} ${release_file}"\n        fi\n    done\n\n    # Now let''s sort by know files importance, max important goes last in the max_prio list\n    max_prio="redhat-release centos-release"\n    for entry in $max_prio; do\n        if [ "x$(echo ${primary_release_files} | grep $entry)" != "x" ]; then\n            primary_release_files=$(echo ${primary_release_files} | sed -e "s:\\(.*\\)\\($entry\\)\\(.*\\):\\2 \\1 \\3:g")\n        fi\n    done\n    # Now, least important goes last in the min_prio list\n    min_prio="lsb-release"\n    for entry in $max_prio; do\n        if [ "x$(echo ${primary_release_files} | grep $entry)" != "x" ]; then\n            primary_release_files=$(echo ${primary_release_files} | sed -e "s:\\(.*\\)\\($entry\\)\\(.*\\):\\1 \\3 \\2:g")\n        fi\n    done\n\n    # Echo the results collapsing multiple white-space into a single white-space\n    echo "${primary_release_files} ${secondary_release_files}" | sed -r ''s:[[:space:]]:\\n:g''\n}\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  __gather_linux_system_info\n#   DESCRIPTION:  Discover Linux system information\n#-------------------------------------------------------------------------------\n__gather_linux_system_info() {\n    DISTRO_NAME=""\n    DISTRO_VERSION=""\n\n    # Let''s test if the lsb_release binary is available\n    rv=$(lsb_release >/dev/null 2>&1)\n    if [ $? -eq 0 ]; then\n        DISTRO_NAME=$(lsb_release -si)\n        if [ "x$(echo "$DISTRO_NAME" | grep RedHat)" != "x" ]; then\n            # Let''s convert CamelCase to Camel Case\n            DISTRO_NAME=$(__camelcase_split "$DISTRO_NAME")\n        fi\n        if [ "${DISTRO_NAME}" = "openSUSE project" ]; then\n            # lsb_release -si returns "openSUSE project" on openSUSE 12.3\n            DISTRO_NAME="opensuse"\n        fi\n        if [ "${DISTRO_NAME}" = "SUSE LINUX" ]; then\n            # lsb_release -si returns "SUSE LINUX" on SLES 11 SP3\n            DISTRO_NAME="suse"\n        fi\n        rv=$(lsb_release -sr)\n        [ "${rv}x" != "x" ] && DISTRO_VERSION=$(__parse_version_string "$rv")\n    elif [ -f /etc/lsb-release ]; then\n        # We don''t have the lsb_release binary, though, we do have the file it parses\n        DISTRO_NAME=$(grep DISTRIB_ID /etc/lsb-release | sed -e ''s/.*=//'')\n        rv=$(grep DISTRIB_RELEASE /etc/lsb-release | sed -e ''s/.*=//'')\n        [ "${rv}x" != "x" ] && DISTRO_VERSION=$(__parse_version_string "$rv")\n    fi\n\n    if [ "x$DISTRO_NAME" != "x" ] && [ "x$DISTRO_VERSION" != "x" ]; then\n        # We already have the distribution name and version\n        return\n    fi\n\n    for rsource in $(__sort_release_files $(\n            cd /etc && /bin/ls *[_-]release *[_-]version 2>/dev/null | env -i sort | \\\n            sed -e ''/^redhat-release$/d'' -e ''/^lsb-release$/d''; \\\n            echo redhat-release lsb-release\n            )); do\n\n        [ -L "/etc/${rsource}" ] && continue        # Don''t follow symlinks\n        [ ! -f "/etc/${rsource}" ] && continue      # Does not exist\n\n        n=$(echo ${rsource} | sed -e ''s/[_-]release$//'' -e ''s/[_-]version$//'')\n        rv=$( (grep VERSION /etc/${rsource}; cat /etc/${rsource}) | grep ''[0-9]'' | sed -e ''q'' )\n        [ "${rv}x" = "x" ] && continue  # There''s no version information. Continue to next rsource\n        v=$(__parse_version_string "$rv")\n        case $(echo ${n} | tr ''[:upper:]'' ''[:lower:]'') in\n            redhat             )\n                if [ ".$(egrep ''CentOS'' /etc/${rsource})" != . ]; then\n                    n="CentOS"\n                elif [ ".$(egrep ''Red Hat Enterprise Linux'' /etc/${rsource})" != . ]; then\n                    n="<R>ed <H>at <E>nterprise <L>inux"\n                else\n                    n="<R>ed <H>at <L>inux"\n                fi\n                ;;\n            arch               ) n="Arch Linux"     ;;\n            centos             ) n="CentOS"         ;;\n            debian             ) n="Debian"         ;;\n            ubuntu             ) n="Ubuntu"         ;;\n            fedora             ) n="Fedora"         ;;\n            suse               ) n="SUSE"           ;;\n            system             )\n                while read -r line; do\n                    [ "${n}x" != "systemx" ] && break\n                    case "$line" in\n                        *Amazon*Linux*AMI*)\n                            n="Amazon Linux AMI"\n                            break\n                    esac\n                done < /etc/${rsource}\n                ;;\n            os                 )\n                nn=$(grep ''^ID='' /etc/os-release | sed -e ''s/^ID=\\(.*\\)$/\\1/g'')\n                rv=$(grep ''^VERSION_ID='' /etc/os-release | sed -e ''s/^VERSION_ID=\\(.*\\)$/\\1/g'')\n                [ "${rv}x" != "x" ] && v=$(__parse_version_string "$rv") || v=""\n                case $(echo ${nn} | tr ''[:upper:]'' ''[:lower:]'') in\n                    arch        )\n                        n="Arch Linux"\n                        v=""  # Arch Linux does not provide a version.\n                        ;;\n                    debian      )\n                        n="Debian"\n                        if [ "${v}x" = "x" ]; then\n                            if [ "$(cat /etc/debian_version)" = "wheezy/sid" ]; then\n                                # I''ve found an EC2 wheezy image which did not tell its version\n                                v=$(__parse_version_string "7.0")\n                            fi\n                        else\n                            echowarn "Unable to parse the Debian Version"\n                        fi\n                        ;;\n                    *           )\n                        n=${nn}\n                        ;;\n                esac\n                ;;\n            *                  ) n="${n}"           ;\n        esac\n        DISTRO_NAME=$n\n        DISTRO_VERSION=$v\n        break\n    done\n}\n__gather_linux_system_info\n\n# Simplify distro name naming on functions\nDISTRO_NAME_L=$(echo $DISTRO_NAME | tr ''[:upper:]'' ''[:lower:]'' | sed ''s/[^a-zA-Z0-9_ ]//g'' | sed -re ''s/([[:space:]])+/_/g'')\nDISTRO_MAJOR_VERSION="$(echo $DISTRO_VERSION | sed ''s/^\\([0-9]*\\).*/\\1/g'')"\nDISTRO_MINOR_VERSION="$(echo $DISTRO_VERSION | sed ''s/^\\([0-9]*\\).\\([0-9]*\\).*/\\2/g'')"\nPREFIXED_DISTRO_MAJOR_VERSION="_${DISTRO_MAJOR_VERSION}"\nif [ "${PREFIXED_DISTRO_MAJOR_VERSION}" = "_" ]; then\n    PREFIXED_DISTRO_MAJOR_VERSION=""\nfi\nPREFIXED_DISTRO_MINOR_VERSION="_${DISTRO_MINOR_VERSION}"\nif [ "${PREFIXED_DISTRO_MINOR_VERSION}" = "_" ]; then\n    PREFIXED_DISTRO_MINOR_VERSION=""\nfi\n\n#---  FUNCTION  ----------------------------------------------------------------\n#          NAME:  __check_end_of_life_versions\n#   DESCRIPTION:  Check for end of life distribution versions\n#-------------------------------------------------------------------------------\n__check_end_of_life_versions() {\n\n    case "${DISTRO_NAME_L}" in\n        debian)\n            # Debian versions bellow 6 are not supported\n            if [ $DISTRO_MAJOR_VERSION -lt 6 ]; then\n                echoerror "End of life distributions are not supported."\n                echoerror "Please consider upgrading to the next stable. See:"\n                echoerror "    https://wiki.debian.org/DebianReleases"\n                exit 1\n            fi\n            ;;\n\n        ubuntu)\n            # Ubuntu versions not supported\n            #\n            #  < 10\n            #  = 10.10\n            #  = 11.04\n            #  = 11.10\n            if ([ $DISTRO_MAJOR_VERSION -eq 10 ] && [ $DISTRO_MINOR_VERSION -eq 10 ]) || \\\n               ([ $DISTRO_MAJOR_VERSION -eq 11 ] && [ $DISTRO_MINOR_VERSION -eq 04 ]) || \\\n               ([ $DISTRO_MAJOR_VERSION -eq 11 ] && [ $DISTRO_MINOR_VERSION -eq 10 ]) || \\\n               [ $DISTRO_MAJOR_VERSION -lt 10 ]; then\n                echoerror "End of life distributions are not supported."\n                echoerror "Please consider upgrading to the next stable. See:"\n                echoerror "    https://wiki.ubuntu.com/Releases"\n                exit 1\n            fi\n            ;;\n\n        opensuse)\n            # openSUSE versions not supported\n            #\n            #  <= 12.1\n            if ([ $DISTRO_MAJOR_VERSION -eq 12 ] && [ $DISTRO_MINOR_VERSION -eq 1 ]) || [ $DISTRO_MAJOR_VERSION -lt 12 ]; then\n                echoerror "End of life distributions are not supported."\n                echoerror "Please consider upgrading to the next stable. See:"\n                echoerror "    http://en.opensuse.org/Lifetime"\n                exit 1\n            fi\n            ;;\n\n        suse)\n            # SuSE versions not supported\n            #\n            # < 11 SP2\n            SUSE_PATCHLEVEL=$(awk ''/PATCHLEVEL/ {print $3}'' /etc/SuSE-release )\n            if [ "x${SUSE_PATCHLEVEL}" = "x" ]; then\n                SUSE_PATCHLEVEL="00"\n            fi\n            if ([ $DISTRO_MAJOR_VERSION -eq 11 ] && [ $SUSE_PATCHLEVEL -lt 02 ]) || [ $DISTRO_MAJOR_VERSION -lt 11 ]; then\n                echoerror "Versions lower than SuSE 11 SP2 are not supported."\n                echoerror "Please consider upgrading to the next stable"\n                exit 1\n            fi\n            ;;\n\n        fedora)\n            # Fedora lower than 18 are no longer supported\n            if [ $DISTRO_MAJOR_VERSION -lt 18 ]; then\n                echoerror "End of life distributions are not supported."\n                echoerror "Please consider upgrading to the next stable. See:"\n                echoerror "    https://fedoraproject.org/wiki/Releases"\n                exit 1\n            fi\n            ;;\n\n        centos)\n            # CentOS versions lower than 5 are no longer supported\n            if ([ $DISTRO_MAJOR_VERSION -eq 6 ] && [ $DISTRO_MINOR_VERSION -lt 3 ]) || [ $DISTRO_MAJOR_VERSION -lt 5 ]; then\n                echoerror "End of life distributions are not supported."\n                echoerror "Please consider upgrading to the next stable. See:"\n                echoerror "    http://wiki.centos.org/Download"\n                exit 1\n            fi\n            ;;\n\n        red_hat*linux)\n            # Red Hat (Enterprise) Linux versions lower than 5 are no longer supported\n            if ([ $DISTRO_MAJOR_VERSION -eq 6 ] && [ $DISTRO_MINOR_VERSION -lt 3 ]) || [ $DISTRO_MAJOR_VERSION -lt 5 ]; then\n                echoerror "End of life distributions are not supported."\n                echoerror "Please consider upgrading to the next stable. See:"\n                echoerror "    https://access.redhat.com/support/policy/updates/errata/"\n                exit 1\n            fi\n            ;;\n\n        *)\n            ;;\n    esac\n}\n# Fail soon for end of life versions\n__check_end_of_life_versions\n\n\n##############################################################################\n#\n#   CentOS Install Functions\n#\ninstall_centos() {\n    if [ $DISTRO_MAJOR_VERSION -ge 6 ]; then\n        yum -y install qemu-kvm libvirt bridge-utils || return 1\n    fi\n    return 0\n}\n\ninstall_centos_post() {\n    if [ -f /etc/sysconfig/libvirtd ]; then\n        sed -i ''s/#LIBVIRTD_ARGS/LIBVIRTD_ARGS/g'' /etc/sysconfig/libvirtd\n    else\n        echoerror "/etc/sysconfig/libvirtd not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/libvirtd.conf ]; then\n        sed -i ''s/#listen_tls/listen_tls/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#listen_tcp/listen_tcp/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#auth_tcp/auth_tcp/g'' /etc/libvirt/libvirtd.conf\n    else\n        echoerror "/etc/libvirt/libvirtd.conf not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/qemu.conf ]; then\n        sed -i ''s/#vnc_listen/vnc_listen/g'' /etc/libvirt/qemu.conf\n    else\n        echoerror "/etc/libvirt/qemu.conf not found. Exiting..."\n        exit 1\n    fi\n    return 0\n}\n\ndaemons_running_centos() {\n    if [ -f /etc/init.d/libvirtd ]; then\n        service libvirtd stop > /dev/null 2>&1\n        service libvirtd start\n    fi\n    if [ -f /etc/init.d/libvirt-guests ]; then\n        service libvirt-guests stop > /dev/null 2>&1\n        service libvirt-guests start\n    fi\n    if [ -f /usr/lib/systemd/system/libvirtd.service ]; then\n        systemctl stop libvirtd.service > /dev/null 2>&1\n        systemctl start libvirtd.service\n    fi\n    if [ -f /usr/lib/systemd/system/libvirt-guests.service ]; then\n        systemctl stop libvirt-guests.service > /dev/null 2>&1\n        systemctl start libvirt-guests.service\n    fi\n    return 0\n} \n#\n#   Ended CentOS Install Functions\n#\n##############################################################################\n\n##############################################################################\n#\n#   Fedora Install Functions\n#\ninstall_fedora() {\n    yum -y install kvm libvirt bridge-utils || return 1\n    return 0\n}\n\ninstall_fedora_post() {\n    if [ -f /etc/sysconfig/libvirtd ]; then\n        sed -i ''s/#LIBVIRTD_ARGS/LIBVIRTD_ARGS/g'' /etc/sysconfig/libvirtd\n    else\n        echoerror "/etc/sysconfig/libvirtd not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/libvirtd.conf ]; then\n        sed -i ''s/#listen_tls/listen_tls/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#listen_tcp/listen_tcp/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#auth_tcp/auth_tcp/g'' /etc/libvirt/libvirtd.conf\n    else\n        echoerror "/etc/libvirt/libvirtd.conf not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/qemu.conf ]; then\n        sed -i ''s/#vnc_listen/vnc_listen/g'' /etc/libvirt/qemu.conf\n    else\n        echoerror "/etc/libvirt/qemu.conf not found. Exiting..."\n        exit 1\n    fi\n    return 0\n}\n\ndaemons_running_fedora() {\n    if [ -f /usr/lib/systemd/system/libvirtd.service ]; then\n        systemctl stop libvirtd.service > /dev/null 2>&1\n        systemctl start libvirtd.service\n    fi\n    if [ -f /usr/lib/systemd/system/libvirt-guests.service ]; then\n        systemctl stop libvirt-guests.service > /dev/null 2>&1\n        systemctl start libvirt-guests.service\n    fi\n    return 0\n} \n#\n#   Ended Fedora Install Functions\n#\n##############################################################################\n\n##############################################################################\n#\n#   Opensuse Install Functions\n#\ninstall_opensuse() {\n    zypper -n install -l kvm libvirt bridge-utils || return 1\n    return 0\n}\n\ninstall_opensuse_post() {\n    if [ -f /etc/sysconfig/libvirtd ]; then\n        sed -i ''s/#LIBVIRTD_ARGS/LIBVIRTD_ARGS/g'' /etc/sysconfig/libvirtd\n    else\n        echoerror "/etc/sysconfig/libvirtd not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/libvirtd.conf ]; then\n        sed -i ''s/#listen_tls/listen_tls/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#listen_tcp/listen_tcp/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#auth_tcp/auth_tcp/g'' /etc/libvirt/libvirtd.conf\n    else\n        echoerror "/etc/libvirt/libvirtd.conf not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/qemu.conf ]; then\n        sed -i ''s/#vnc_listen/vnc_listen/g'' /etc/libvirt/qemu.conf\n    else\n        echoerror "/etc/libvirt/qemu.conf not found. Exiting..."\n        exit 1\n    fi\n    return 0\n}\n\ndaemons_running_opensuse() {\n    if [ -f /usr/lib/systemd/system/libvirtd.service ]; then\n        systemctl stop libvirtd.service > /dev/null 2>&1\n        systemctl start libvirtd.service\n    fi\n    if [ -f /usr/lib/systemd/system/libvirt-guests.service ]; then\n        systemctl stop libvirt-guests.service > /dev/null 2>&1\n        systemctl start libvirt-guests.service\n    fi\n    return 0\n}\n#\n#   Ended openSUSE Install Functions\n#\n##############################################################################\n\n##############################################################################\n#\n#   Ubuntu Install Functions\n#\ninstall_ubuntu() {\n    apt-get update || return 1\n    apt-get -y install kvm libvirt-bin bridge-utils sasl2-bin || return 1\n    return 0\n}\n\ninstall_ubuntu_post() {\n    if [ -f /etc/default/libvirt-bin ]; then\n        sed -i ''s/libvirtd_opts="-d"/libvirtd_opts="-d -l"/g'' /etc/default/libvirt-bin\n    else\n        echoerror "/etc/default/libvirt-bin not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/libvirtd.conf ]; then\n        sed -i ''s/#listen_tls/listen_tls/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#listen_tcp/listen_tcp/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#auth_tcp/auth_tcp/g'' /etc/libvirt/libvirtd.conf\n    else\n        echoerror "/etc/libvirt/libvirtd.conf not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/qemu.conf ]; then\n        if ([ $DISTRO_MAJOR_VERSION -eq 12 ] && [ $DISTRO_MINOR_VERSION -eq 04 ]); then\n            sed -i ''s/# vnc_listen/vnc_listen/g'' /etc/libvirt/qemu.conf\n        else\n            sed -i ''s/#vnc_listen/vnc_listen/g'' /etc/libvirt/qemu.conf\n        fi\n    else\n        echoerror "/etc/libvirt/qemu.conf not found. Exiting..."\n        exit 1\n    fi\n    return 0\n}\n\ndaemons_running_ubuntu() {\n    if [ -f /etc/init.d/libvirt-bin ]; then\n        # Still in SysV init!?\n        service libvirt-bin stop > /dev/null 2>&1\n        service libvirt-bin start\n    fi\n    return 0\n} \n#\n#   Ended Ubuntu Install Functions\n#\n##############################################################################\n\n##############################################################################\n#\n#   Debian Install Functions\n#\ninstall_debian() {\n    apt-get update || return 1\n    apt-get -y install kvm libvirt-bin bridge-utils sasl2-bin || return 1\n    return 0\n}\n\ninstall_debian_post() {\n    if [ $DISTRO_MAJOR_VERSION -ge 8 ]; then\n        LIBVIRTSVC=libvirtd\n    else\n        LIBVIRTSVC=libvirt-bin\n    fi\n    if [ -f /etc/default/$LIBVIRTSVC ]; then\n        if [ "$( grep -c ''^libvirtd_opts *='' /etc/default/$LIBVIRTSVC )" -gt 0 ]; then\n            if [ $( grep -c ''^libvirtd_opts *=.*-l'' /etc/default/$LIBVIRTSVC ) -eq 0 ]; then\n                sed -i ''s/^libvirtd_opts="\\([^"]*\\)"/libvirtd_opts="\\1 -l"/g'' /etc/default/$LIBVIRTSVC\n            fi\n        else\n            sed -i ''s/^#libvirtd_opts=.*$/libvirtd_opts="-l"/g'' /etc/default/$LIBVIRTSVC\n        fi\n    else\n        echoerror "/etc/default/$LIBVIRTSVC not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/libvirtd.conf ]; then\n        sed -i ''s/#listen_tls/listen_tls/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#listen_tcp/listen_tcp/g'' /etc/libvirt/libvirtd.conf\n        sed -i ''s/#auth_tcp/auth_tcp/g'' /etc/libvirt/libvirtd.conf\n    else\n        echoerror "/etc/libvirt/libvirtd.conf not found. Exiting..."\n        exit 1\n    fi\n    if [ -f /etc/libvirt/qemu.conf ]; then\n        sed -i ''s/# vnc_listen/vnc_listen/g'' /etc/libvirt/qemu.conf\n    else\n        echoerror "/etc/libvirt/qemu.conf not found. Exiting..."\n        exit 1\n    fi\n    return 0\n}\n\ndaemons_running_debian() {\n    if [ $DISTRO_MAJOR_VERSION -ge 8 ]; then\n        LIBVIRTSVC=libvirtd\n    else\n        LIBVIRTSVC=libvirt-bin\n    fi\n    if [ -f /etc/init.d/$LIBVIRTSVC ]; then\n        /etc/init.d/$LIBVIRTSVC stop > /dev/null 2>&1\n        /etc/init.d/$LIBVIRTSVC start\n    fi\n    return 0\n} \n#\n#   Ended Debian Install Functions\n#\n##############################################################################\n\n#=============================================================================\n# INSTALLATION\n#=============================================================================\n# Let''s get the install function\nINSTALL_FUNC_NAMES="install_${DISTRO_NAME_L}"\n\nINSTALL_FUNC="null"\nfor FUNC_NAME in $(__strip_duplicates $INSTALL_FUNC_NAMES); do\n    if __function_defined $FUNC_NAME; then\n        INSTALL_FUNC=$FUNC_NAME\n        break\n    fi\ndone\nechodebug "INSTALL_FUNC=${INSTALL_FUNC}"\n\nif [ $INSTALL_FUNC = "null" ]; then\n    echoerror "No installation function found. Exiting..."\n    exit 1\nelse\n    echoinfo "Running ${INSTALL_FUNC}()"\n    $INSTALL_FUNC\n    if [ $? -ne 0 ]; then\n        echoerror "Failed to run ${INSTALL_FUNC}()!!!"\n        exit 1\n    fi\nfi\n\n# Let''s get the post install function\nPOST_FUNC_NAMES="install_${DISTRO_NAME_L}_post"\n\nPOST_INSTALL_FUNC="null"\nfor FUNC_NAME in $(__strip_duplicates $POST_FUNC_NAMES); do\n    if __function_defined $FUNC_NAME; then\n        POST_INSTALL_FUNC=$FUNC_NAME\n        break\n    fi\ndone\nechodebug "POST_INSTALL_FUNC=${POST_INSTALL_FUNC}"\n\nif [ $POST_INSTALL_FUNC = "null" ]; then\n    echoerror "No installation function found. Exiting..."\n    exit 1\nelse\n    echoinfo "Running ${POST_INSTALL_FUNC}()"\n    $POST_INSTALL_FUNC\n    if [ $? -ne 0 ]; then\n        echoerror "Failed to run ${POST_INSTALL_FUNC}()!!!"\n        exit 1\n    fi\nfi\n\n# Let''s get the daemons running check function.\nDAEMONS_RUNNING_FUNC_NAMES="daemons_running_${DISTRO_NAME_L}"\n\nDAEMONS_RUNNING_FUNC="null"\nfor FUNC_NAME in $(__strip_duplicates $DAEMONS_RUNNING_FUNC_NAMES); do\n    if __function_defined $FUNC_NAME; then\n        DAEMONS_RUNNING_FUNC=$FUNC_NAME\n        break\n    fi\ndone\nechodebug "DAEMONS_RUNNING_FUNC=${DAEMONS_RUNNING_FUNC}"\n\nif [ $DAEMONS_RUNNING_FUNC = "null" ]; then\n    echoerror "No installation function found. Exiting..."\n    exit 1\nelse\n    echoinfo "Running ${DAEMONS_RUNNING_FUNC}()"\n    $DAEMONS_RUNNING_FUNC\n    if [ $? -ne 0 ]; then\n        echoerror "Failed to run ${DAEMONS_RUNNING_FUNC}()!!!"\n        exit 1\n    fi\nfi\n\nexit 0\n', ''),
(104, 'install_bin', 'install_bin PATH=/usr/bin:/bin\numask 022\necho_args="-e "\nlocalinstall=$1\nmore <<"EOF"\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXxx\nEOF\nagreed=\nwhile [ x$agreed = x ]; do\n    echo\n    echo "Do you agree to the above license terms? [yes or no] "\n    read reply leftover\n    case $reply in\n    y* | Y*)\n        agreed=1;;\n    n* | N*)\n    echo "If you don''t agree to the license you can''t install this software";\n    exit 1;;\n    esac\ndone\nif [ -d "$localinstall" ] ; then\n    outname=$localinstall/OUTNAME\nelse\n    outname=OUTNAME\nfi\necho "Unpacking..."\ntail -n +64 $0 > $outname    \nif [ -x /usr/bin/sum ] ; then\n    echo "Checksumming..."\n\n    sum=`/usr/bin/sum $outname`\n    index=1\n    for s in $sum\n    do\n    case $index in\n    1)  sum1=$s;\n        index=2;\n        ;;\n    2)  sum2=$s;\n        index=3;\n        ;;\n    esac\n    done\n#    if [ $sum1 != SUM1 -o $sum2 != SUM2 ] ; then\n#    echo "The download file appears to be corrupted."\n#    echo "Please do not attempt to install this archive file."\n#    exit 1\n#    fi\nelse\n    echo "Can''t find /usr/bin/sum to do checksum.  Continuing anyway."\nfi\ntar xzvf $outname\nrm $outname -rf\n\nif [ -f "install.sh" ] ; then\n\nsh install.sh\n\nfi\n\n\necho "Done."\nexit 0\n', ''),
(105, 'install_cobbler', 'install_cobbler ## Copyright 2011 Armens Movsesjans movsesjans@gmail.com\n# License: GNU General Public License, version 2 or later\n# for AwaseConfigurations Project \n# http:\n# https://github.com/AwaseConfigurations/main\n# This is a whole cobbler / fabric setup script for room 1\n\nsudo echo ''bonjour!!''\n\n#create a temp folder\nmkdir ~/cobbler_wgets\ncd ~/cobbler_wgets\n\n#download preconfigured cobbler setup files and scripts from github:awaseconfigurations\n#download ubuntu-11.04-alternate-i386.iso\nwget https://raw.github.com/AwaseConfigurations/main/master/cobbler/settings\nwget https://raw.github.com/AwaseConfigurations/main/master/cobbler/interfaces\nwget https://raw.github.com/AwaseConfigurations/main/master/cobbler/dhcp_all.template\nwget https://raw.github.com/AwaseConfigurations/main/master/cobbler/cobbler_add_systems_all.sh\n#wget https://raw.github.com/AwaseConfigurations/main/master/cobbler/cobbler_add_systems_server_1.sh\nwget https://raw.github.com/AwaseConfigurations/main/master/cobbler/ubuntu-nqa-ws.seed\n#wget https://raw.github.com/AwaseConfigurations/main/master/cobbler/ubuntu-nqa-server.seed\nwget https://raw.github.com/AwaseConfigurations/main/master/cobbler/wakeup_all.sh\nwget http://releases.ubuntu.com/natty/ubuntu-11.04-alternate-i386.iso\n#wget http://releases.ubuntu.com/natty/ubuntu-11.04-server-i386.iso\n\n#enable universe repo and install packages\nsudo software-properties-gtk -e universe\nsudo apt-get update\nsudo DEBIAN_FRONTEND=noninteractive /usr/bin/apt-get -y install dhcp3-server cobbler cobbler-common wakeonlan rcconf\n\n#start cobbler and build its configuration\nsudo service cobbler start\nsleep 1\nsudo cobbler check\n\n#copy setup files to where they belong\nsudo cp interfaces /etc/network/\nsudo /etc/init.d/networking restart\nsudo cp settings /etc/cobbler/\nsudo cp dhcp_all.template /etc/cobbler/dhcp.template\nsudo cp ubuntu-nqa-ws.seed /var/lib/cobbler/kickstarts/\n#sudo cp ubuntu-nqa-server.seed /var/lib/cobbler/kickstarts/\n\n#restart and rebuild cobbler\nsudo service cobbler restart\nsleep 1\nsudo cobbler sync\n\n#mount ubuntu images, ipport them with cobbler, and assign preconfigured preseeds\n#sudo mkdir /mnt/server\nsudo mkdir /mnt/ws\nsudo mount -o loop ubuntu-11.04-alternate-i386.iso /mnt/ws\nsudo cobbler import --name=ubuntu-alternate --path=/mnt/ws --breed=ubuntu\nsudo cobbler profile edit --name=ubuntu-alternate-i386 --kickstart=/var/lib/cobbler/kickstarts/ubuntu-nqa-ws.seed --kopts="priority=critical locale=en_US"\n\n#sudo mount -o loop ubuntu-11.04-server-i386.iso /mnt/server\n#sudo cobbler import --name=ubuntu-server --path=/mnt/server --breed=ubuntu\n#sudo cobbler profile edit --name=ubuntu-server-i386 --kickstart=/var/lib/cobbler/kickstarts/ubuntu-nqa-server.seed --kopts="priority=critical locale=en_US"\n\n#restart and rebuild cobbler\nsudo service cobbler restart\nsleep 1\nsudo cobbler sync\n\n#run the script to add systems (machines) to same profile as preseed\n#they will then pick this network install by default\nchmod u+x cobbler_add_systems_all.sh\n#chmod u+x cobbler_add_systems_server_1.sh\n./cobbler_add_systems_all.sh\n#./cobbler_add_systems_server_1.sh\n\n#restart and rebuild cobbler\nsudo service cobbler restart\nsleep 1\nsudo cobbler sync\n\n#run the script to wake all up\nchmod u+x wakeup_all.sh\n./wakeup_all.sh\n\n#make sure dhcp-server is off next time this machine is booted (our lab''s requirements)\nsudo rcconf --off isc-dhcp-server\n\n#wait for all machines to complete installation\nsleep 600\n\n#setup fabric\nwget https://raw.github.com/AwaseConfigurations/main/master/scripts/getfabric\nchmod u+x getfabric\n./getfabric\n\n#generate pair of keys [if absent], put public key to workstations\nfab pubkey_distribute\n\n#run fabrics init and main tasks\nfab init\nfab main\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(106, 'install_cobbler', 'install_cobbler #!/bin/bash\n#\n\necho "Installing cobbler"\nDIR=$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )\nsource $DIR/install.conf\nif [ -f $DIR/env.conf ]; then\n    source $DIR/env.conf\nelse\n    echo "failed to load environment"\n    exit 1\nfi\nsource $DIR/install_func.sh\n\necho "Installing cobbler related packages"\nsudo yum -y install cobbler cobbler-web createrepo mkisofs python-cheetah python-simplejson python-urlgrabber PyYAML Django cman debmirror pykickstart reprepro\nif [[ "$?" != "0" ]]; then\n    echo "failed to install cobbler related packages"\n    exit 1\nelse\n    # patch cobbler code\n    find /usr/lib -name manage_bind.py |xargs  perl -pi.old -e ''s/(\\s+)(self\\.logger\\s+\\= logger)/$1$2\\n$1if self\\.logger is None:\\n$1    import clogger\\n$1    self\\.logger = clogger.Logger\\(\\)/''\nfi\n\nsudo chkconfig cobblerd on\n\n# create backup dir\nsudo mkdir -p /root/backup/cobbler\n\n# update httpd conf\nsudo cp -rn /etc/httpd/conf.d /root/backup/cobbler/\nsudo rm -f /etc/httpd/conf.d/cobbler_web.conf\nsudo cp -rf $COMPASSDIR/misc/apache/cobbler_web.conf /etc/httpd/conf.d/cobbler_web.conf\nchmod 644 /etc/httpd/conf.d/cobbler_web.conf\nsudo rm -rf /etc/httpd/conf.d/ssl.conf\nsudo cp -rf $COMPASSDIR/misc/apache/ssl.conf /etc/httpd/conf.d/ssl.conf\nchmod 644 /etc/httpd/conf.d/ssl.conf\n\n# disable selinux\nsudo mkdir -p /root/backup/selinux\nsudo cp -rn /etc/selinux/config /root/backup/selinux/\nsudo sed -i ''/SELINUX/s/enforcing/disabled/'' /etc/selinux/config\n\n# update cobbler settings\nsudo cp -rn /etc/cobbler/settings /root/backup/cobbler/\nsudo rm -f /etc/cobbler/settings\nsudo cp -rf $ADAPTERS_HOME/cobbler/conf/settings /etc/cobbler/settings\nsudo sed -i "s/next_server:[ \\t]*\\$next_server/next_server: $NEXTSERVER/g" /etc/cobbler/settings\nsudo sed -i "s/server:[ \\t]*\\$ipaddr/server: $IPADDR/g" /etc/cobbler/settings\nsudo sed -i "s/default_name_servers:[ \\t]*\\[''\\$ipaddr''\\]/default_name_servers: \\[''$IPADDR''\\]/g" /etc/cobbler/settings\ndomains=$(echo $NAMESERVER_DOMAINS | sed "s/,/'',''/g")\nsudo sed -i "s/manage_forward_zones:[ \\t]*\\[\\]/manage_forward_zones: \\[''$domains''\\]/g" /etc/cobbler/settings\nexport cobbler_passwd=$(openssl passwd -1 -salt ''huawei'' ''123456'')\nsudo sed -i "s,^default_password_crypted:[ \\t]\\+\\"\\(.*\\)\\",default_password_crypted: \\"$cobbler_passwd\\",g" /etc/cobbler/settings\nsudo chmod 644 /etc/cobbler/settings\n\n# update dhcp.template\nsudo cp -rn /etc/cobbler/dhcp.template /root/backup/cobbler/\nsudo rm -f /etc/cobbler/dhcp.template\nsudo cp -rf $ADAPTERS_HOME/cobbler/conf/dhcp.template /etc/cobbler/dhcp.template\nexport netaddr=$(ipcalc $IPADDR $NETMASK -n |cut -f 2 -d ''='')\nexport netprefix=$(ipcalc $IPADDR $NETMASK -p |cut -f 2 -d ''='')\nexport subnet=${netaddr}/${netprefix}\nsudo sed -i "s/subnet \\$subnet netmask \\$netmask/subnet $netaddr netmask $NETMASK/g" /etc/cobbler/dhcp.template\nsudo sed -i "s/option routers \\$gateway/option routers $OPTION_ROUTER/g" /etc/cobbler/dhcp.template\nsudo sed -i "s/option subnet-mask \\$netmask/option subnet-mask $NETMASK/g" /etc/cobbler/dhcp.template\nsudo sed -i "s/option domain-name-servers \\$ipaddr/option domain-name-servers $IPADDR/g" /etc/cobbler/dhcp.template\nsudo sed -i "s/range dynamic-bootp \\$ip_range/range dynamic-bootp $IP_START $IP_END/g" /etc/cobbler/dhcp.template\nsudo sed -i "s/local-address \\$ipaddr/local-address $IPADDR/g" /etc/cobbler/dhcp.template\nsudo chmod 644 /etc/cobbler/dhcp.template\n\n# update tftpd.template\nsudo cp -rn /etc/cobbler/tftpd.template /root/backup/cobbler/\nsudo rm -f /etc/cobbler/tftpd.template\nsudo cp -rf $ADAPTERS_HOME/cobbler/conf/tftpd.template /etc/cobbler/tftpd.template\nsudo chmod 644 /etc/cobbler/tftpd.template\n\n# update named.template\nsudo cp -rn /etc/cobbler/named.template /root/backup/cobbler/\nsudo rm -f /etc/cobbler/named.template\nsudo cp -rf $ADAPTERS_HOME/cobbler/conf/named.template /etc/cobbler/named.template\nsudo sed -i "s/listen-on port 53 { \\$ipaddr; }/listen-on port 53 \\{ $IPADDR; \\}/g" /etc/cobbler/named.template\nsubnet_escaped=$(echo $subnet | sed -e ''s/[\\/&]/\\\\&/g'')\nsudo sed -i "s/allow-query { 127.0.0.0\\/8; \\$subnet; }/allow-query \\{ 127.0.0.0\\/8; $subnet_escaped; \\}/g" /etc/cobbler/named.template\nsudo chmod 644 /etc/cobbler/named.template\n\n# update zone.template\nsudo cp -rn /etc/cobbler/zone.template /root/backup/cobbler/\nsudo rm -f /etc/cobbler/zone.template\nsudo cp -rf $ADAPTERS_HOME/cobbler/conf/zone.template /etc/cobbler/zone.template\nsudo sed -i "s/\\$hostname IN A \\$ipaddr/$HOSTNAME IN A $IPADDR/g" /etc/cobbler/zone.template\nsudo sed -i "s/metrics IN A \\$ipaddr/metrics IN A $IPADDR/g" /etc/cobbler/zone.template\nsudo chmod 644 /etc/cobbler/zone.template\n\n# update modules.conf\nsudo cp -rn /etc/cobbler/modules.conf /root/backup/cobbler/\nsudo rm -f /etc/cobbler/modules.conf\nsudo cp -rf $ADAPTERS_HOME/cobbler/conf/modules.conf /etc/cobbler/modules.conf\nsudo chmod 644 /etc/cobbler/modules.conf\n\necho "setting up cobbler web password: default user is cobbler"\n\nCBLR_USER=${CBLR_USER:-"cobbler"}\nCBLR_PASSWD=${CBLR_PASSWD:-"cobbler"}\n(echo -n "$CBLR_USER:Cobbler:" && echo -n "$CBLR_USER:Cobbler:$CBLR_PASSWD" | md5sum - | cut -d'' '' -f1) > /etc/cobbler/users.digest\n\n# update cobbler config\nsudo cp -rn /var/lib/cobbler/snippets /root/backup/cobbler/\nsudo cp -rn /var/lib/cobbler/kickstarts/ /root/backup/cobbler/\nsudo cp -rn /var/lib/cobbler/triggers /root/backup/cobbler/\nsudo rm -rf /var/lib/cobbler/snippets/*\nsudo cp -rf $ADAPTERS_HOME/cobbler/snippets/* /var/lib/cobbler/snippets/\nsudo cp -rf $ADAPTERS_HOME/cobbler/triggers/* /var/lib/cobbler/triggers/\nsudo chmod 777 /var/lib/cobbler/snippets\nsudo chmod -R 666 /var/lib/cobbler/snippets/*\nsudo chmod -R 755 /var/lib/cobbler/triggers\nsudo rm -f /var/lib/cobbler/kickstarts/default.ks\nsudo rm -f /var/lib/cobbler/kickstarts/default.seed\nsudo cp -rf $ADAPTERS_HOME/cobbler/kickstarts/default.ks /var/lib/cobbler/kickstarts/\nsudo cp -rf $ADAPTERS_HOME/cobbler/kickstarts/default.seed /var/lib/cobbler/kickstarts/\nsudo chmod 666 /var/lib/cobbler/kickstarts/default.ks\nsudo chmod 666 /var/lib/cobbler/kickstarts/default.seed\nsudo mkdir -p /var/www/cblr_ks\nsudo chmod 755 /var/www/cblr_ks\nsudo cp -rf $ADAPTERS_HOME/cobbler/conf/cobbler.conf /etc/httpd/conf.d/\nchmod 644 /etc/httpd/conf.d/cobbler.conf\n\nsudo cp -rn /etc/xinetd.d /root/backup/\nsudo sed -i ''s/disable\\([ \\t]\\+\\)=\\([ \\t]\\+\\)yes/disable\\1=\\2no/g'' /etc/xinetd.d/rsync\nsudo sed -i ''s/^@dists=/# @dists=/g'' /etc/debmirror.conf\nsudo sed -i ''s/^@arches=/# @arches=/g'' /etc/debmirror.conf\n\necho "disable iptables"\nsudo service iptables stop\nsudo service iptables status\nif [[ "$?" == "0" ]]; then\n    echo "iptables is running"\n    exit 1\nelse\n    echo "iptables is already stopped"\nfi\n\necho "disable selinux temporarily"\necho 0 > /selinux/enforce\n\nsudo service httpd restart\nsudo service cobblerd restart\nsudo cobbler get-loaders\nsudo cobbler sync\nsudo service xinetd restart\n\necho "Checking if httpd is running"\nsudo service httpd status\nif [[ "$?" == "0" ]]; then\n    echo "httpd is running."\nelse\n    echo "httpd is not running"\n    exit 1\nfi\n\necho "Checking if dhcpd is running"\nsudo service dhcpd status\nif [[ "$?" == "0" ]]; then\n    echo "dhcpd is running."\nelse\n    echo "dhcpd is not running"\n    exit 1\nfi\n\necho "Checking if named is running"\nsudo service named status\nif [[ "$?" == "0" ]]; then\n    echo "named is running."\nelse\n    echo "named is not running"\n    exit 1\nfi\n\necho "Checking if xinetd is running"\nsudo service xinetd status\nif [[ "$?" == "0" ]]; then\n    echo "xinetd is running."\nelse\n    echo "xinetd is not running"\n    exit 1\nfi\n\necho "Checking if cobblerd is running"\nsudo service cobblerd status\nif [[ "$?" == "0" ]]; then\n    echo "cobblerd is running."\nelse\n    echo "cobblerd is not running"\n    exit 1\nfi\n\n# create centos repo\nsudo rm -rf /var/lib/cobbler/repo_mirror/centos_ppa_repo\nsudo mkdir -p /var/lib/cobbler/repo_mirror/centos_ppa_repo\nfound_centos_ppa_repo=0\nfor repo in $(cobbler repo list); do\n    if [ "$repo" == "centos_ppa_repo" ]; then\n        found_centos_ppa_repo=1\n    fi\ndone\n\nif [ "$found_centos_ppa_repo" == "0" ]; then\n    sudo cobbler repo add --mirror=/var/lib/cobbler/repo_mirror/centos_ppa_repo --name=centos_ppa_repo --mirror-locally=Y --arch=${CENTOS_IMAGE_ARCH}\n    if [[ "$?" != "0" ]]; then\n        echo "failed to add centos_ppa_repo"\n        exit 1\n    else\n        echo "centos_ppa_repo is added"\n    fi\nelse\n    echo "repo centos_ppa_repo has already existed."\nfi\n\n# download packages\ncd /var/lib/cobbler/repo_mirror/centos_ppa_repo/\ncentos_ppa_repo_packages="\nntp-4.2.6p5-1.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_TYPE,,}.${CENTOS_IMAGE_ARCH}.rpm\nopenssh-clients-5.3p1-94.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\nopenssh-5.3p1-94.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\niproute-2.6.32-31.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\nwget-1.12-1.8.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\nntpdate-4.2.6p5-1.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_TYPE,,}.${CENTOS_IMAGE_ARCH}.rpm\nyum-plugin-priorities-1.1.30-14.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.noarch.rpm"\nfor f in $centos_ppa_repo_packages; do\n    if [ "$REGION" == "asia" ]; then\n        download http:\n    else\n        download ftp://rpmfind.net/linux/${CENTOS_IMAGE_TYPE,,}/${CENTOS_IMAGE_VERSION}/os/${CENTOS_IMAGE_ARCH}/Packages/$f $f copy /var/lib/cobbler/repo_mirror/centos_ppa_repo/ || exit $?\n    fi\ndone\n\ncentos_ppa_repo_rsyslog_packages="\njson-c-0.10-2.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\nlibestr-0.1.9-1.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\nlibgt-0.3.11-1.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\nliblogging-1.0.4-1.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm\nrsyslog-7.6.3-1.${CENTOS_IMAGE_TYPE_OTHER}${CENTOS_IMAGE_VERSION_MAJOR}.${CENTOS_IMAGE_ARCH}.rpm"\nfor f in $centos_ppa_repo_rsyslog_packages; do\n    download http://rpms.adiscon.com/v7-stable/epel-${CENTOS_IMAGE_VERSION_MAJOR}/${CENTOS_IMAGE_ARCH}/RPMS/$f $f copy /var/lib/cobbler/repo_mirror/centos_ppa_repo/ || exit $?\ndone\n\n# download chef client for centos ppa repo\ndownload $CENTOS_CHEF_CLIENT `basename $CENTOS_CHEF_CLIENT` copy /var/lib/cobbler/repo_mirror/centos_ppa_repo/\n\n# create centos repo\ncd ..\nsudo createrepo centos_ppa_repo\nif [[ "$?" != "0" ]]; then\n    echo "failed to createrepo centos_ppa_repo"\n    exit 1\nelse\n    echo "centos_ppa_repo is created"\nfi\n\n# create ubuntu repo\nsudo rm -rf /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo\nsudo mkdir -p /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo\nfound_ubuntu_ppa_repo=0\nfor repo in $(cobbler repo list); do\n    if [ "$repo" == "ubuntu_ppa_repo" ]; then\n        found_ubuntu_ppa_repo=1\n    fi\ndone\n\nif [ "$found_ubuntu_ppa_repo" == "0" ]; then\n    sudo cobbler repo add --mirror=/var/lib/cobbler/repo_mirror/ubuntu_ppa_repo --name=ubuntu_ppa_repo --mirror-locally=Y --arch=${UBUNTU_IMAGE_ARCH} --apt-dists=ppa --apt-components=main\n    if [[ "$?" != "0" ]]; then\n        echo "failed to add ubuntu_ppa_repo"\n        exit 1\n    else\n        echo "ubuntu_ppa_repo is added"\n    fi\nelse\n    echo "repo ubuntu_ppa_repo has already existed."\nfi\n\ncd /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo/\nif [ ! -e /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo/conf/distributions ]; then\n    echo "create ubuntu ppa repo distribution"\n    mkdir -p /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo/conf\n    cat << EOF > /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo/conf/distributions\nOrigin: ppa\nLabel: ppa_repo\nSuite: stable\nCodename: ppa\nVersion: 0.1\nArchitectures: i386 amd64 source\nComponents: main\nDescription: ppa repo\nEOF\n    chmod 644 /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo/conf/distributions\nelse\n    echo "ubuntu ppa repo distribution file exists."\nfi\n\n# download chef client for ubuntu ppa repo\ndownload $UBUNTU_CHEF_CLIENT `basename $UBUNTU_CHEF_CLIENT` copy /var/lib/cobbler/repo_mirror/ubuntu_ppa_repo/ || exit $?\n\ncd ..\nfind ubuntu_ppa_repo -name \\*.deb -exec reprepro -Vb ubuntu_ppa_repo includedeb ppa {} \\;\nif [ "$?" != "0" ]; then\n    echo "failed to create ubuntu_ppa_repo"\n    exit 1\nelse\n    echo  "ubuntu_ppa_repo is created"\nfi\n\nsudo cobbler reposync\nif [[ "$?" != "0" ]]; then\n    echo "cobbler reposync failed"\n    exit 1\nelse\n    echo "cobbler repos are synced"\nfi\n\n# import cobbler distro\nsudo mkdir -p /var/lib/cobbler/iso\nif [ "$REGION" == "asia" ]; then\n    download "$CENTOS_IMAGE_SOURCE_ASIA" ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}.iso copy /var/lib/cobbler/iso/ || exit $?\nelse\n    download "$CENTOS_IMAGE_SOURCE" ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}.iso copy /var/lib/cobbler/iso/ || exit $?\nfi\nsudo mkdir -p /mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}\nif [ $(mount | grep -c "/mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} ") -eq 0 ]; then\n    sudo mount -o loop /var/lib/cobbler/iso/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}.iso /mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}\n    if [[ "$?" != "0" ]]; then\n        echo "failed to mount image /mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "/mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} is mounted"\n    fi\nelse\n    echo "/mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} has already mounted"\nfi\nif [ "$REGION" == "asia" ]; then\n    download "$UBUNTU_IMAGE_SOURCE_ASIA" ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}.iso copy /var/lib/cobbler/iso/ || exit $?\nelse\n    download "$UBUNTU_IMAGE_SOURCE" ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}.iso copy /var/lib/cobbler/iso/ || exit $?\nfi\nsudo mkdir -p /mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}\nif [ $(mount | grep -c "/mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} ") -eq 0 ]; then\n    sudo mount -o loop /var/lib/cobbler/iso/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}.iso /mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}\n    if [[ "$?" != "0" ]]; then\n        echo "failed to mount image /mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "/mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} is mounted"\n    fi\nelse\n    echo "/mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} has already mounted"\nfi\n\n# add distro\nfound_centos_distro=0\nfor distro in $(cobbler distro list); do\n    if [ "$distro" == "${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" ]; then\n        found_centos_distro=1\n    fi\ndone\n\nif [ "$found_centos_distro" == "0" ]; then\n    sudo cobbler import --path=/mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} --name=${CENTOS_IMAGE_NAME} --arch=${CENTOS_IMAGE_ARCH} --kickstart=/var/lib/cobbler/kickstarts/default.ks --breed=redhat\n    if [[ "$?" != "0" ]]; then\n        echo "failed to import /mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "/mnt/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} is imported" \n    fi\nelse\n    echo "distro ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} has already existed"\n    sudo cobbler distro edit --name=${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} --arch=${CENTOS_IMAGE_ARCH} --breed=redhat\n    if [[ "$?" != "0" ]]; then\n        echo "failed to edit distro ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "distro ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} is updated"\n    fi\nfi\n\nfound_ubuntu_distro=0\nfor distro in $(cobbler distro list); do\n    if [ "$distro" == "${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" ]; then\n        found_ubuntu_distro=1\n    fi\ndone\n\nif [ "$found_ubuntu_distro" == "0" ]; then\n    sudo cobbler import --path=/mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} --name=${UBUNTU_IMAGE_NAME} --arch=${UBUNTU_IMAGE_ARCH} --kickstart=/var/lib/cobbler/kickstarts/default.seed --breed=ubuntu\n    if [[ "$?" != "0" ]]; then\n        echo "failed to import /mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "/mnt/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} is imported" \n    fi\nelse\n    echo "distro ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} has already existed"\n    sudo cobbler distro edit --name=${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} --arch=${UBUNTU_IMAGE_ARCH} --breed=ubuntu\n    if [[ "$?" != "0" ]]; then\n        echo "failed to edit distro ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "distro ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} is updated"\n    fi\nfi\n\n# add profile\ncentos_found_profile=0\nfor profile in $(cobbler profile list); do\n    if [ "$profile" == "${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" ]; then\n        centos_found_profile=1\n    fi\ndone\n\nif [ "$centos_found_profile" == "0" ]; then\n    sudo cobbler profile add --name="${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" --repo=centos_ppa_repo --distro="${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" --ksmeta="tree=http://$IPADDR/cobbler/ks_mirror/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" --kickstart=/var/lib/cobbler/kickstarts/default.ks\n    if [[ "$?" != "0" ]]; then\n        echo "failed to add profile ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "profile ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} is added"\n    fi\nelse\n    echo "profile ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} has already existed."\n    sudo cobbler profile edit --name="${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" --repo=centos_ppa_repo --distro="${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" --ksmeta="tree=http://$IPADDR/cobbler/ks_mirror/${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}" --kickstart=/var/lib/cobbler/kickstarts/default.ks\n    if [[ "$?" != "0" ]]; then\n        echo "failed to edit profile ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "profile ${CENTOS_IMAGE_NAME}-${CENTOS_IMAGE_ARCH} is updated"\n    fi\nfi\n\nubuntu_found_profile=0\nfor profile in $(cobbler profile list); do\n    if [ "$profile" == "${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" ]; then\n        ubuntu_found_profile=1\n    fi\ndone\n\nif [ "$ubuntu_found_profile" == "0" ]; then\n    sudo cobbler profile add --name="${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" --repo=ubuntu_ppa_repo --distro="${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" --ksmeta="tree=http://$IPADDR/cobbler/ks_mirror/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" --kickstart=/var/lib/cobbler/kickstarts/default.seed\n    if [[ "$?" != "0" ]]; then\n        echo "failed to add profile ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "profile ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} is added"\n    fi\nelse\n    echo "profile ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} has already existed."\n    sudo cobbler profile edit --name="${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" --repo=ubuntu_ppa_repo --distro="${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" --ksmeta="tree=http://$IPADDR/cobbler/ks_mirror/${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}" --kickstart=/var/lib/cobbler/kickstarts/default.seed\n    if [[ "$?" != "0" ]]; then\n        echo "failed to edit profile ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}"\n        exit 1\n    else\n        echo "profile ${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH} is updated"\n    fi\nfi\n\n#clean ubuntu repo\nsudo cobbler repo remove --name=${UBUNTU_IMAGE_NAME}-${UBUNTU_IMAGE_ARCH}\n\nsudo cobbler reposync\nif [[ "$?" != "0" ]]; then\n    echo "cobbler reposync failed"\n    exit 1\nelse\n    echo "cobbler repos are synced"\nfi\n\necho "Checking cobbler is OK"\nsudo cobbler check\nif [[ "$?" != "0" ]]; then\n    echo "cobbler check failed"\n    exit 1\nelse\n    echo "cobbler check passed"\nfi\n\necho "Cobbler configuration complete!"\n', ''),
(107, 'install_cobbler', 'install_cobbler #!/usr/bin/env bash\n#*********************************************************#\n# @@ScriptName: cobbler_installer_for_centos.sh\n# @@Author: zhenyu<fjctlzy@gmail.com>\n# @@Create Date: 2013-08-04 17:22:12\n# @@Modify Date: 2013-08-09 16:33:03\n# @@Function:\n#*********************************************************#\nif [[ `id -u` -ne 0 ]]; then\n     echo "The script should be run using Root"\n     exit 1\nfi\n\n#get configuration\nroot_password=`awk -F= ''/root_password/ {print $2}'' config`\nhostname=`awk -F= ''/hostname/ {print $2}'' config`\ninterface=`awk -F= ''/interface/ {print $2}'' config`\n\nif [[ -z "$root_password" ]]; then\n     echo "Root Password is required, Usage: cobbler_installer your_root_password"\n     exit 1\nfi\n\nrpm -Uvh http:\nyum install -y cobbler dhcp httpd rsync tftp-server xinetd pykickstart debmirror cman cobbler-web\nservice httpd start\nservice cobblerd start\nservice xinetd start\nchkconfig httpd on\nchkconfig cobblerd on\nchkconfig dhcpd on\nchkconfig xinetd on\nchkconfig tftp on\n\n#turn off iptables\nchkconfig iptables off\nservice iptables stop\n\n#turn off selinux\nsed -i ''s;SELINUX=enforcing;SELINUX=disabled;g'' /etc/sysconfig/selinux\nsed -i ''s;SELINUX=enforcing;SELINUX=disabled;g'' /etc/selinux/config\nsetenforce 0\n\n#replace all spaces to one space\nsed -i ''s/^[[:space:]]\\+/ /'' /etc/cobbler/settings\nsed -i -e  "s;manage_dhcp: 0;manage_dhcp: 1;g" -e "s;manage_rsync: 0;manage_rsync: 1;g" -e "s;allow_dynamic_settings: 0;allow_dynamic_settings: 1;g" /etc/cobbler/settings\n\n#install loaders\ncobbler get-loaders\n\n#replace dhcp.template\nip=`ifconfig  $interface | grep "inet addr"  | awk -F: ''{print $2}'' | awk ''{print $1}''`\ngateway=`netstat -r | grep default  | awk ''{print $2}''`\nmask=`ifconfig  $interface | grep "Mask" | awk -F: ''{print $NF}''`\nA=`echo $mask | awk -F. ''{print $1}''`\nB=`echo $mask | awk -F. ''{print $2}''`\nC=`echo $mask | awk -F. ''{print $3}''`\nD=`echo $mask | awk -F. ''{print $4}''`\na=`echo $ip| awk -F. ''{print $1}''`\nb=`echo $ip| awk -F. ''{print $2}''`\nc=`echo $ip | awk -F. ''{print $3}''`\nd=`echo $ip | awk -F. ''{print $4}''`\nsubnet=`echo $(($a&$A))"."$(($b&$B))"."$(($c&$C))"."$(($d&$D))`\n\nsed -i ''s;subnet.*netmask.*;subnet ''$subnet'' netmask ''$mask'' {;g'' /etc/cobbler/dhcp.template\n#option routers\nsed -i ''s;option routers.*;option routers             ''$gateway''\\;;g'' /etc/cobbler/dhcp.template\n#subnet-mask\nsed -i ''s;option subnet-mask.*;option subnet-mask ''$mask''\\;;g'' /etc/cobbler/dhcp.template\n\n#ip range\nsed -i ''s/range dynamic-bootp.*/range dynamic-bootp ''"$a.$b.$c.10 $a.$b.$c.254"'';/g'' /etc/cobbler/dhcp.template\n\n#generate default password\ncobbler_salt_result=`openssl passwd -1 -salt ''random-phrase-here'' "$root_password"`\nsed -i ''s;default_password_crypted:.*;default_password_crypted: "''${cobbler_salt_result}''";g'' /etc/cobbler/settings\n\n#config debmirror\nsed -i -e ''s;^@dists=;#@dists;g'' -e ''s;^@arches;#@arches;g'' /etc/debmirror.conf\n\n#tftp enable\nsed -i ''s;disable.*;disable = no;g'' /etc/xinetd.d/rsync\n\n#update next_server and server\nsed -i ''s;next_server.*;next_server: ''"$ip"'' ;g''  /etc/cobbler/settings\nsed -i ''s;server:[[:space:]]\\+127.0.0.1;server: ''"$ip"'';g''  /etc/cobbler/settings\n\n#cobbler web password\necho "Set up cobbler web password"\nsed -i ''s/authn_denyall/authn_configfile/g'' /etc/cobbler/modules.conf\nhtdigest /etc/cobbler/users.digest "Cobbler" cobbler\n\n#change the hostname\ngrep ''HOSTNAME'' /etc/sysconfig/network && sed -i ''s;HOSTNAME=.*;HOSTNAME=''$hostname'';g'' /etc/sysconfig/network || echo "HOSTNAME=$hostname" >> /etc/sysconfig/network\nhostname $hostname\n\n#restart the cobbler to make settings work\nservice cobblerd restart\ncobbler sync\ncobbler check\n\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(123, 'go', '	引言\r\n\r\n	示例\r\n\r\n	格式化\r\n\r\n	注释\r\n\r\n	命名\r\n\r\n	包名\r\n\r\n	获取器\r\n\r\n	接口名\r\n\r\n	驼峰记法\r\n\r\n	分号\r\n\r\n	控制结构\r\n\r\n	If\r\n\r\n	重新声明与再次赋值\r\n\r\n	For\r\n\r\n	Switch\r\n\r\n	类型选择\r\n\r\n	函数\r\n\r\n	多值返回\r\n\r\n	可命名结果形参\r\n\r\n	Defer\r\n\r\n	数据\r\n\r\n	new 分配\r\n\r\n	构造函数与复合字面\r\n\r\n	make 分配\r\n\r\n	数组\r\n\r\n	切片\r\n\r\n	二维切片\r\n\r\n	映射\r\n\r\n	打印\r\n\r\n	追加\r\n\r\n	初始化\r\n\r\n	常量\r\n\r\n	变量\r\n\r\n	init 函数\r\n\r\n	方法\r\n\r\n	指针 vs. 值\r\n\r\n	接口与其它类型\r\n\r\n	接口\r\n\r\n	类型转换\r\n\r\n	接口转换与类型断言\r\n\r\n	通用性\r\n\r\n	接口和方法\r\n\r\n	空白标识符\r\n\r\n	多重赋值中的空白标识符\r\n\r\n	未使用的导入和变量\r\n\r\n	为副作用而导入\r\n\r\n	接口检查\r\n\r\n	内嵌\r\n\r\n	并发\r\n\r\n	通过通信共享内存\r\n\r\n	Go程\r\n\r\n	信道\r\n\r\n	信道中的信道\r\n\r\n	并行化\r\n\r\n	可能泄露的缓冲区\r\n\r\n	错误\r\n\r\n	Panic\r\n\r\n	恢复\r\n\r\n	一个Web服务器\r\n\r\n\r\n\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(108, 'cobbler', 'cobbler distro list', ''),
(109, 'cobbler', 'cobbler profile list', ''),
(111, 'cobbler', 'cobbler system add --name=web --profile=centos6.4-x86_64', ''),
(112, 'cobbler', 'cobbler system edit --name=web --interface=eth0 --mac=00:11:22:AA:BB:CC --ip-address=192.168.98.132 --netmask=255.255.255.0 --static=1 --dns-name=domain.meizu.com', ''),
(113, 'install_nginx', 'install_nginx 软件版本:\r\n\r\n   Nginx:\r\n               1.2.9\r\n   Pcre:\r\n               8.33\r\n\r\n基础环境准备:\r\n\r\n   运行账户:\r\n       useradd nginx -s /sbin/nologin -d\r\n\r\n   安装开发依赖包:\r\n       yum -y groupinstall "Development tools" "Server Platform Libraries" \r\n       yum -y install gd gd-devel pcre-devel\r\n\r\n部署路径:\r\n\r\n   Nginx:\r\n       /data/nginx\r\n\r\n   Log:\r\n       /data/log/nginx\r\n\r\n   Pcre:\r\n       /usr/local\r\n\r\n   配置:\r\n       /data/nginx/conf/vhosts/\r\n\r\nPcre安装:\r\n\r\n\r\n   ./configure\r\n   make && make install\r\n\r\nNginx安装:\r\n\r\n  ./configure \\\r\n   --prefix=/data/nginx \\\r\n   --error-log-path=/data/log/nginx/error.log \\\r\n   --http-log-path=/data/log/nginx/access.log \\\r\n   --pid-path=/var/run/nginx/nginx.pid  \\\r\n   --lock-path=/var/lock/nginx.lock \\\r\n   --user=nginx \\\r\n   --group=nginx \\\r\n   --with-http_ssl_module \\\r\n   --with-http_flv_module \\\r\n   --with-http_stub_status_module \\\r\n   --with-http_gzip_static_module \\\r\n   --http-client-body-temp-path=/var/tmp/nginx/client/ \\\r\n   --http-proxy-temp-path=/var/tmp/nginx/proxy/ \\\r\n   --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \\\r\n   --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \\\r\n   --http-scgi-temp-path=/var/tmp/nginx/scgi \\\r\n   --with-pcre=$TmpSoft/pcre-8.33 \\\r\n   --with-file-aio \\\r\n   --with-http_image_filter_module\r\n\r\n   make && make install\r\n\r\nNginx配置:\r\n\r\n   默认采用线上BBS的nginx.conf做为标准\r\n   添加系统任务：\r\n   配置Nginx日志切割并添加至Cron\r\n   添加zabbix添加Nginx的插件脚本\r\n\r\n日志格式\r\n\r\nhttp {\r\n\r\n log_format  main  ''$time_iso8601    $status    $connection    $connection_requests    $remote_addr    $http_x_forwarded_for    $remote_user    $request_length    $request_time    $request_method    $server_protocol    $http_host    $server_port    $uri    $args    $http_referer    $body_bytes_sent    $http_user_agent    $ssl_protocol    $ssl_cipher    $upstream_addr    $upstream_status    $upstream_response_time'';\r\n access_log  logs/access.log  main;\r\n\r\n}\r\n\r\n注：以上各信息间以Tab键做分隔\r\n\r\n$time_iso8601 ISO8601标准格式下的本地时间\r\n\r\n$time_local 通用日志格式下的本地时间\r\n\r\n$status 记录请求状态\r\n\r\n$connection 连接的序列号\r\n\r\n$connection_requests 当前通过一个连接获得的请求数量\r\n\r\n$remote_addr, $http_x_forwarded_for 记录客户端IP地址\r\n\r\n$remote_user 记录客户端用户名称\r\n\r\n$request_length 请求的长度(包括请求行，请求头和请求正文)\r\n\r\n$request_time 请求处理时间,单位为秒,精度毫秒。从读入客户端的第一个字节开始,直到把最后一个字符发送给客户端后进行日志写入为止\r\n\r\n$request_method 请求方法\r\n\r\n$http_host 请求地址,即浏览器中输入的地址\r\n\r\n$server_port 端口号\r\n\r\n$uri 请求的URI\r\n\r\n$args 请求的参数\r\n\r\n$http_referer 记录从哪个页面链接访问过来的\r\n\r\n$body_bytes_sent 发送给客户端的字节数,不包括响应头的大小;该变量与Apache模块mod_log_config里的“%%B”参数兼容\r\n\r\n$http_user_agent 记录客户端浏览器相关信息\r\n\r\n$ssl_protocol SSL协议版本\r\n\r\n$ssl_cipher 交换数据中的算法\r\n\r\n$upstream_addr 后台upstream的地址,即真正提供服务的主机地址\r\n\r\n$upstream_status upstream状态\r\n\r\n$upstream_response_time upstream响应时间\r\n\r\n$request 记录请求的URL和HTTP协议\r\n\r\n$bytes_sent 发送给客户端的总字节数\r\n\r\nnginx日志按天切割脚本\r\n\r\n   #!/bin/bash\r\n   log_path=/data/log/nginx/\r\n   date=`date -d "yesterday" +"%%Y%%m%%d"`\r\n   access_file=${log_path}access_${date}.log\r\n   error_file=${log_path}error_${date}.log\r\n   mv ${log_path}access.log ${access_file}\r\n   mv ${log_path}error.log ${error_file}\r\n   kill -USR1 `cat ${log_path}nginx.pid`\r\n\r\n   #脚本文件名: /data/nginx/sbin/cut_nginx_log.sh\r\n   #crontab设置: 0 0 * * * /data/nginx/sbin/cut_nginx_log.sh', ''),
(115, 'nginx_protect', 'nginx_protect  1、限制域声明\n\n     以下配置建议统一在http域中进行配置\n\n\n    #定义一个名为perip_req的limit_req_zone用来存储session，大小是10M内存，\n\n\n    #以$binary_remote_addr 为key,限制平均每分钟的请求为30个，\n\n    #1M能存储16000个状态\n\n    #以下配置每个IP每秒限制为5/s\n\n    limit_req_zone $binary_remote_addr zone=perip_req:1m rate=5r/s;\n\n    #以下配置每个server响应请求限制为3000/s\n\n    limit_req_zone $server_name zone=perserver_req:50m rate=3000r/s;\n\n\n    #定义一个名为perip_conn的limit_zone,大小10M内存来存储session，\n\n    #以$binary_remote_addr 为key\n\n    #且只能放在http作用域\n\n\n    #以下配置按ip配置一个连接 zone\n\n    limit_conn_zone $binary_remote_addr zone=perip_conn:100m;\n\n    #以下配置按server配置一个连接 zone\n\n    limit_conn_zone $server_name zone=perserver_conn:50m;\n2、请求限制\n\n    以下配置在location域中限制\n\n    #限制每ip每秒不超过20个请求，漏桶数burst为5\n\n    #brust的意思就是，如果第1秒、2,3,4秒请求为19个，\n\n    #第5秒的请求为25个是被允许的。\n\n    #但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误。\n\n    #nodelay，如果不设置该选项，严格使用平均速率限制请求数，\n\n    #第1秒25个请求时，5个请求放到第2秒执行，\n\n    #设置nodelay，25个请求将在第1秒执行。\n\n\n    limit_req zone=perip_req burst=5 nodelay;\n\n    limit_req zone=perserver_req burst=50 nodelay;\n3、连接&流量限制\n\n    以下配置在location域中限制\n\n    #连接数限制,每个IP并发请求为2\n\n    limit_conn perip_conn 2;\n\n    #服务所限制的连接数(即限制了该server并发连接数量)\n\n    limit_conn perserver_conn 1000;\n\n    #(附加限制，一般情况不需要考虑) #带宽限制,对单个连接限数，如果一个ip两个连接，就是500x2k\n\n    #limit_rate 100k;\n', ''),
(116, 'strace', 'strace -cp 11861', ''),
(118, 'vim', 'vim  命令历史\r\n	以:和/开头的命令都有历史纪录，可以首先键入:或/然后按上下箭头来选择某个历史命令。\r\n 启动vim\r\n	在命令行窗口中输入以下命令即可\r\n	vim 直接启动vim\r\n	vim filename 打开vim并创建名为filename的文件\r\n 文件命令\r\n	打开单个文件\r\n	vim file\r\n	同时打开多个文件\r\n	vim file1 file2 file3 ...\r\n	在vim窗口中打开一个新文件\r\n	:open file\r\n	在新窗口中打开文件\r\n	:split file\r\n	切换到下一个文件\r\n	:bn\r\n	切换到上一个文件\r\n	:bp\r\n	查看当前打开的文件列表，当前正在编辑的文件会用[]括起来。\r\n	:args\r\n	打开远程文件，比如ftp或者share folder\r\n	:e ftp:\n	:e \\\\qadrive\\test\\1.txt\r\n vim的模式\r\n	正常模式（按Esc或Ctrl+[进入） 左下角显示文件名或为空\r\n	插入模式（按i键进入） 左下角显示--INSERT--\r\n	可视模式（不知道如何进入） 左下角显示--VISUAL--\r\n 导航命令\r\n	%% 括号匹配\r\n 插入命令\r\n	i 在当前位置生前插入\r\n	I 在当前行首插入\r\n	a 在当前位置后插入\r\n	A 在当前行尾插入\r\n	o 在当前行之后插入一行\r\n	O 在当前行之前插入一行\r\n 查找命令\r\n	/text　　查找text，按n健查找下一个，按N健查找前一个。\r\n	?text　　查找text，反向查找，按n健查找下一个，按N健查找前一个。\r\n	vim中有一些特殊字符在查找时需要转义　　.*[]^%%/?~$\r\n	:set ignorecase　　忽略大小写的查找\r\n	:set noignorecase　　不忽略大小写的查找\r\n	查找很长的词，如果一个词很长，键入麻烦，可以将光标移动到该词上，按*或#键即可以该单词进行搜索，相当于/搜索。而#命令相当于?搜索。\r\n	:set hlsearch　　高亮搜索结果，所有结果都高亮显示，而不是只显示一个匹配。\r\n	:set nohlsearch　　关闭高亮搜索显示\r\n	:nohlsearch　　关闭当前的高亮显示，如果再次搜索或者按下n或N键，则会再次高亮。\r\n	:set incsearch　　逐步搜索模式，对当前键入的字符进行搜索而不必等待键入完成。\r\n	:set wrapscan　　重新搜索，在搜索到文件头或尾时，返回继续搜索，默认开启。\r\n 替换命令\r\n	ra 将当前字符替换为a，当期字符即光标所在字符。\r\n	s/old/new/ 用old替换new，替换当前行的第一个匹配\r\n	s/old/new/g 用old替换new，替换当前行的所有匹配\r\n	%%s/old/new/ 用old替换new，替换所有行的第一个匹配\r\n	%%s/old/new/g 用old替换new，替换整个文件的所有匹配\r\n	:10,20 s/^/    /g 在第10行知第20行每行前面加四个空格，用于缩进。\r\n	ddp 交换光标所在行和其下紧邻的一行。\r\n 移动命令\r\n	h 左移一个字符\r\n	l 右移一个字符，这个命令很少用，一般用w代替。\r\n	k 上移一个字符\r\n	j 下移一个字符\r\n	以上四个命令可以配合数字使用，比如20j就是向下移动20行，5h就是向左移动5个字符，在Vim中，很多命令都可以配合数字使用，比如删除10个字符10x，在当前位置后插入3个！，3a！<Esc>，这里的Esc是必须的，否则命令不生效。\r\n	w 向前移动一个单词（光标停在单词首部），如果已到行尾，则转至下一行行首。此命令快，可以代替l命令。\r\n	b 向后移动一个单词 2b 向后移动2个单词\r\n	e，同w，只不过是光标停在单词尾部\r\n	ge，同b，光标停在单词尾部。\r\n	^ 移动到本行第一个非空白字符上。\r\n	0（数字0）移动到本行第一个字符上，\r\n	<HOME> 移动到本行第一个字符。同0健。\r\n	$ 移动到行尾 3$ 移动到下面3行的行尾\r\n	gg 移动到文件头。 = [[ \r\n	G（shift + g） 移动到文件尾。 = ]] \r\n	f（find）命令也可以用于移动，fx将找到光标后第一个为x的字符，3fd将找到第三个为d的字符。\r\n	F 同f，反向查找。\r\n	跳到指定行，冒号+行号，回车，比如跳到240行就是 :240回车。另一个方法是行号+G，比如230G跳到230行。\r\n	Ctrl + e 向下滚动一行\r\n	Ctrl + y 向上滚动一行\r\n	Ctrl + d 向下滚动半屏\r\n	Ctrl + u 向上滚动半屏\r\n	Ctrl + f 向下滚动一屏\r\n	Ctrl + b 向上滚动一屏\r\n 撤销和重做\r\n	u 撤销（Undo）\r\n	U 撤销对整行的操作\r\n	Ctrl + r 重做（Redo），即撤销的撤销。\r\n 删除命令\r\n	x 删除当前字符\r\n	3x 删除当前光标开始向后三个字符\r\n	X 删除当前字符的前一个字符。X=dh\r\n	dl 删除当前字符， dl=x\r\n	dh 删除前一个字符\r\n	dd 删除当前行\r\n	dj 删除上一行\r\n	dk 删除下一行\r\n	10d 删除当前行开始的10行。\r\n	D 删除当前字符至行尾。D=d$\r\n	d$ 删除当前字符之后的所有字符（本行）\r\n	kdgg 删除当前行之前所有行（不包括当前行）\r\n	jdG（jd shift + g）   删除当前行之后所有行（不包括当前行）\r\n	:1,10d 删除1-10行\r\n	:11,$d 删除11行及以后所有的行\r\n	:1,$d 删除所有行\r\n	J(shift + j)　　删除两行之间的空行，实际上是合并两行。\r\n 拷贝和粘贴\r\n	yy 拷贝当前行\r\n	nyy 拷贝当前后开始的n行，比如2yy拷贝当前行及其下一行。\r\n	p  在当前光标后粘贴,如果之前使用了yy命令来复制一行，那么就在当前行的下一行粘贴。\r\n	shift+p 在当前行前粘贴\r\n	:1,10 co 20 将1-10行插入到第20行之后。\r\n	:1,$ co $ 将整个文件复制一份并添加到文件尾部。\r\n	正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按y即可复制\r\n	ddp交换当前行和其下一行\r\n	xp交换当前字符和其后一个字符\r\n 剪切命令\r\n	正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按d即可剪切\r\n	ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴\r\n	:1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。\r\n	:1, 10 m 20 将第1-10行移动到第20行之后。\r\n 退出命令\r\n	:wq 保存并退出\r\n	ZZ 保存并退出\r\n	:q! 强制退出并忽略所有更改\r\n	:e! 放弃所有修改，并打开原来文件。\r\n 窗口命令\r\n	:split或new 打开一个新窗口，光标停在顶层的窗口上\r\n	:split file或:new file 用新窗口打开文件\r\n	split打开的窗口都是横向的，使用vsplit可以纵向打开窗口。\r\n	Ctrl+ww 移动到下一个窗口\r\n	Ctrl+wj 移动到下方的窗口\r\n	Ctrl+wk 移动到上方的窗口\r\n	关闭窗口\r\n	:close 最后一个窗口不能使用此命令，可以防止意外退出vim。\r\n	:q 如果是最后一个被关闭的窗口，那么将退出vim。\r\n	ZZ 保存并退出。\r\n	关闭所有窗口，只保留当前窗口\r\n	:only\r\n	录制宏\r\n	按q键加任意字母开始录制，再按q键结束录制（这意味着vim中的宏不可嵌套），使用的时候@加宏名，比如qa。。。q录制名为a的宏，@a使用这个宏。\r\n 执行shell命令\r\n	:!command\r\n	:!ls 列出当前目录下文件\r\n	:!perl -c script.pl 检查perl脚本语法，可以不用退出vim，非常方便。\r\n	:!perl script.pl 执行perl脚本，可以不用退出vim，非常方便。\r\n	:suspend或Ctrl - Z 挂起vim，回到shell，按fg可以返回vim。\r\n 注释命令\r\n	perl程序中#开始的行为注释，所以要注释某些行，只需在行首加入#\r\n	3,5 s/^/#/g 注释第3-5行\r\n	3,5 s/^#//g 解除3-5行的注释\r\n	1,$ s/^/#/g 注释整个文档。\r\n	:%%s/^/#/g 注释整个文档，此法更快。\r\n 帮助命令\r\n	:help or F1 显示整个帮助\r\n	:help xxx 显示xxx的帮助，比如 :help i, :help CTRL-[（即Ctrl+[的帮助）。\r\n	:help ''number'' Vim选项的帮助用单引号括起\r\n	:help <Esc> 特殊键的帮助用<>扩起\r\n	:help -t Vim启动参数的帮助用-\r\n	：help i_<Esc> 插入模式下Esc的帮助，某个模式下的帮助用模式_主题的模式\r\n	帮助文件中位于||之间的内容是超链接，可以用Ctrl+]进入链接，Ctrl+o（Ctrl + t）返回\r\n 其他非编辑命令\r\n	. 重复前一次命令\r\n	:set ruler?　　查看是否设置了ruler，在.vimrc中，使用set命令设制的选项都可以通过这个命令查看\r\n	:scriptnames　　查看vim脚本文件的位置，比如.vimrc文件，语法文件及plugin等。\r\n	:set list 显示非打印字符，如tab，空格，行尾等。如果tab无法显示，请确定用set lcs=tab:>-命令设置了.vimrc文件，并确保你的文件中的确有tab，如果开启了expendtab，那么tab将被扩展为空格。\r\n	Vim教程\r\n	在Unix系统上\r\n	$ vimtutor\r\n	在Windows系统上\r\n	:help tutor\r\n	:syntax 列出已经定义的语法项\r\n	:syntax clear 清除已定义的语法规则\r\n	:syntax case match 大小写敏感，int和Int将视为不同的语法元素\r\n	:syntax case ignore 大小写无关，int和Int将视为相同的语法元素，并使用同样的配色方案\r\nVim里常见的几个不可见字符：\r\n	^@ = 0x00 Null值\r\n	^I = 0x09 水平制表\r\n	^J = 0x0A 换行\r\n	^M = 0x0D 回车  \r\n\r\n几种去除^M的方法\r\n\r\n	1、 cat filename1 | tr -d "\\r" > newfile\r\n\r\n	2、 sed -e "s/^V^M//" filename > outputfilename\r\n\r\n	3、vi： 用vi打开文件\r\n\r\n	1. 按ESC键\r\n\r\n	2. 输入 :%s/^M//g\r\n\r\n	确定 ^M是使用 "CTRL-V CTRL-M" 而不是字面上的 ^M。这个正则式将替换所有回车符前的 ^M为空($是为了保证^M出现在行尾)\r\n\r\n	4、一些linux版本有 dos2unix 程序，可以用来祛除^M', ''),
(119, 'java_jvm', 'java_jvm \r\n\r\n堆大小设置JVM 中最大堆大小有三方面限制：相关操作系统的数据模型（32-bt还是64-bit）限制；系统的可用虚拟内存限制；系统的可用物理内存限制。32位系统下，一般限制在1.5G~2G；64为操作系统对内存无限制。我在Windows Server 2003 系统，3.5G物理内存，JDK5.0下测试，最大可设置为1478m。典型设置： \r\n\r\n	java -Xmx3550m -Xms3550m -Xmn2g -Xss128k-Xmx3550m：设置JVM最大可用内存为3550M。-Xms3550m：设置JVM促使内存为3550m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。-Xmn2g：设置年轻代大小为2G。整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。-Xss128k：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小为1M，以前每个线程堆栈大小为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。\r\n	java -Xmx3550m -Xms3550m -Xss128k -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxPermSize=16m -XX:MaxTenuringThreshold=0-XX:NewRatio=4:设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5-XX:SurvivorRatio=4：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6-XX:MaxPermSize=16m:设置持久代大小为16m。-XX:MaxTenuringThreshold=0：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。\r\n	回收器选择JVM给了三种选择：串行收集器、并行收集器、并发收集器，但是串行收集器只适用于小数据量的情况，所以这里的选择主要针对并行收集器和并发收集器。默认情况下，JDK5.0以前都是使用串行收集器，如果想使用其他收集器需要在启动时加入相应参数。JDK5.0以后，JVM会根据当前系统配置进行判断。 \r\n\r\n吞吐量优先的并行收集器如上文所述，并行收集器主要以到达一定的吞吐量为目标，适用于科学技术和后台处理等。典型配置： \r\n\r\n	java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20-XX:+UseParallelGC：选择垃圾收集器为并行收集器。此配置仅对年轻代有效。即上述配置下，年轻代使用并发收集，而年老代仍旧使用串行收集。-XX:ParallelGCThreads=20：配置并行收集器的线程数，即：同时多少个线程一起进行垃圾回收。此值最好配置与处理器数目相等。\r\n	java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads=20 -XX:+UseParallelOldGC-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集。JDK6.0支持对年老代并行收集。\r\n	java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis=100-XX:MaxGCPauseMillis=100:设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM会自动调整年轻代大小，以满足此值。\r\n	java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseParallelGC  -XX:MaxGCPauseMillis=100 -XX:+UseAdaptiveSizePolicy-XX:+UseAdaptiveSizePolicy：设置此选项后，并行收集器会自动选择年轻代区大小和相应的Survivor区比例，以达到目标系统规定的最低相应时间或者收集频率等，此值建议使用并行收集器时，一直打开。\r\n\r\n\r\n响应时间优先的并发收集器如上文所述，并发收集器主要是保证系统的响应时间，减少垃圾收集时的停顿时间。适用于应用服务器、电信领域等。典型配置： \r\n\r\n	java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:ParallelGCThreads=20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC-XX:+UseConcMarkSweepGC：设置年老代为并发收集。测试中配置这个以后，-XX:NewRatio=4的配置失效了，原因不明。所以，此时年轻代大小最好用-Xmn设置。-XX:+UseParNewGC:设置年轻代为并行收集。可与CMS收集同时使用。JDK5.0以上，JVM会根据系统配置自行设置，所以无需再设置此值。\r\n	java -Xmx3550m -Xms3550m -Xmn2g -Xss128k -XX:+UseConcMarkSweepGC -XX:CMSFullGCsBeforeCompaction=5 -XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生“碎片”，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。-XX:+UseCMSCompactAtFullCollection：打开对年老代的压缩。可能会影响性能，但是可以消除碎片\r\n\r\n\r\n辅助信息JVM提供了大量命令行参数，打印信息，供调试使用。主要有以下一些： \r\n\r\n	-XX:+PrintGC输出形式：[GC 118250K->113543K(130112K), 0.0094143 secs] \r\n			[Full GC 121376K->10414K(130112K), 0.0650971 secs]\r\n	-XX:+PrintGCDetails输出形式：[GC [DefNew: 8614K->781K(9088K), 0.0123035 secs] 118250K->113543K(130112K), 0.0124633 secs] \r\n			[GC [DefNew: 8614K->8614K(9088K), 0.0000665 secs][Tenured: 112761K->10414K(121024K), 0.0433488 secs] 121376K->10414K(130112K), 0.0436268 secs]\r\n	-XX:+PrintGCTimeStamps -XX:+PrintGC：PrintGCTimeStamps可与上面两个混合使用输出形式：11.851: [GC 98328K->93620K(130112K), 0.0082960 secs]\r\n	-XX:+PrintGCApplicationConcurrentTime:打印每次垃圾回收前，程序未中断的执行时间。可与上面混合使用输出形式：Application time: 0.5291524 seconds\r\n	-XX:+PrintGCApplicationStoppedTime：打印垃圾回收期间程序暂停的时间。可与上面混合使用输出形式：Total time for which application threads were stopped: 0.0468229 seconds\r\n	-XX:PrintHeapAtGC:打印GC前后的详细堆栈信息输出形式：34.702: [GC {Heap before gc invocations=7: def new generation   total 55296K, used 52568K [0x1ebd0000, 0x227d0000, 0x227d0000)eden space 49152K,  99%% used [0x1ebd0000, 0x21bce430, 0x21bd0000)from space 6144K,  55%% used [0x221d0000, 0x22527e10, 0x227d0000)  to   space 6144K,   0%% used [0x21bd0000, 0x21bd0000, 0x221d0000) tenured generation   total 69632K, used 2696K [0x227d0000, 0x26bd0000, 0x26bd0000)the space 69632K,   3%% used [0x227d0000, 0x22a720f8, 0x22a72200, 0x26bd0000) compacting perm gen  total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)   the space 8192K,  35%% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)    ro space 8192K,  66%% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)    rw space 12288K,  46%% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)34.735: [DefNew: 52568K->3433K(55296K), 0.0072126 secs] 55264K->6615K(124928K)Heap after gc invocations=8: def new generation   total 55296K, used 3433K [0x1ebd0000, 0x227d0000, 0x227d0000)eden space 49152K,   0%% used [0x1ebd0000, 0x1ebd0000, 0x21bd0000)  from space 6144K,  55%% used [0x21bd0000, 0x21f2a5e8, 0x221d0000)  to   space 6144K,   0%% used [0x221d0000, 0x221d0000, 0x227d0000) tenured generation   total 69632K, used 3182K [0x227d0000, 0x26bd0000, 0x26bd0000)the space 69632K,   4%% used [0x227d0000, 0x22aeb958, 0x22aeba00, 0x26bd0000) compacting perm gen  total 8192K, used 2898K [0x26bd0000, 0x273d0000, 0x2abd0000)   the space 8192K,  35%% used [0x26bd0000, 0x26ea4ba8, 0x26ea4c00, 0x273d0000)    ro space 8192K,  66%% used [0x2abd0000, 0x2b12bcc0, 0x2b12be00, 0x2b3d0000)    rw space 12288K,  46%% used [0x2b3d0000, 0x2b972060, 0x2b972200, 0x2bfd0000)}, 0.0757599 secs]\r\n	-Xloggc:filename:与上面几个配合使用，把相关日志信息记录到文件以便分析。\r\n\r\n常见配置汇总 \r\n\r\n堆设置 \r\n\r\n	-Xms:初始堆大小\r\n	-Xmx:最大堆大小\r\n	-XX:NewSize=n:设置年轻代大小\r\n	-XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4\r\n	-XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5\r\n	-XX:MaxPermSize=n:设置持久代大小\r\n\r\n收集器设置 \r\n\r\n	-XX:+UseSerialGC:设置串行收集器\r\n	-XX:+UseParallelGC:设置并行收集器\r\n	-XX:+UseParalledlOldGC:设置并行年老代收集器\r\n	-XX:+UseConcMarkSweepGC:设置并发收集器\r\n\r\n垃圾回收统计信息 \r\n\r\n	-XX:+PrintGC\r\n	-XX:+PrintGCDetails\r\n	-XX:+PrintGCTimeStamps\r\n	-Xloggc:filename\r\n\r\n并行收集器设置 \r\n\r\n	-XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。\r\n	-XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间\r\n	-XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)\r\n\r\n并发收集器设置 \r\n\r\n	-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。\r\n	-XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。\r\n\r\n调优总结\r\n\r\n	年轻代大小选择 \r\n\r\n	响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。\r\n	吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。\r\n	年老代大小选择 \r\n\r\n	响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得： \r\n\r\n	并发垃圾收集信息\r\n	持久代并发收集次数\r\n	传统GC信息\r\n	花在年轻代和年老代回收上的时间比例减少年轻代和年老代花费的时间，一般会提高应用的效率\r\n	吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。\r\n	较小堆引起的碎片问题因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置： \r\n\r\n	-XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。\r\n	-XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩"\r\n\r\n设置样例\r\n\r\n	-Xmx5000m\r\n	-Xms5000m\r\n	-Xmn2000m\r\n	-XX:PermSize=256m\r\n	-server\r\n	-verbose:gc\r\n	-XX:+PrintGCDateStamps\r\n	-XX:+PrintGCTimeStamps\r\n	-XX:+PrintGCDetails\r\n	-XX:+PrintTenuringDistribution\r\n	-XX:+PrintCommandLineFlags\r\n	-XX:+DisableExplicitGC\r\n	-XX:+UseConcMarkSweepGC\r\n	-XX:ParallelCMSThreads=2\r\n	-XX:+CMSClassUnloadingEnabled\r\n	-XX:+UseCMSCompactAtFullCollection\r\n	-XX:CMSInitiatingOccupancyFraction=80\r\n	-Xloggc:logs/gc.log\r\n	-Xdebug\r\n	-Xnoagent\r\n	-Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n', ''),
(120, 'iperf', 'iperf perf 版本建议采用linux版本，事实上，windows版也很好用。\n带宽测试通常采用UDP模式，因为能测出极限带宽、时延抖动、丢包率。在进行测试时，首先以链路理论带宽作为数据发送速率进行测试，例如，从客户端到服务器之间的链路的理论带宽为100Mbps，先用 -b 100M进行测试，然后根据测试结果（包括实际带宽，时延抖动和丢包率），再以实际带宽作为数据发送速率进行测试，会发现时延抖动和丢包率比第一次好很多，重复测试几次，就能得出稳定的实际带宽。\n1、UDP 模式\n    服务器端\n    iperf -u -s\n    客户端\n    iperf -u -c 192.168.1.1 -b 100M -t 60\n    在udp模式下，以100Mbps为数据发送速率，客户端到服务器192.168.1.1上传带宽测试，测试时间为60秒。\n    iperf -u -c 192.168.1.1 -b 5M -P 30 -t 60\n    客户端同时向服务器端发起30个连接线程，以5Mbps为数据发送速率。\n    iperf -u -c 192.168.1.1 -b 100M -d -t 60\n    以100M为数据发送速率，进行上下行带宽测试。\n2、TCP模式\n    服务器端\n    iperf -s\n    客户端\n    iperf -c 192.168.1.1 -t 60\n    在tcp模式下，客户端到服务器192.168.1.1上传带宽测试，测试时间为60秒。\n\n    iperf -c 192.168.1.1 -P 30 -t 60\n    客户端同时向服务器端发起30个连接线程。\n\n    iperf -c 192.168.1.1 -d -t 60\n    进行上下行带宽测试。\n\n    另外，\n    -p 监听或者连接的端口号\n    -w tcp滑动窗口的大小\n', ''),
(121, 'linux_perf', 'linux_perf Linux Monitor\r\n\r\n	strace\r\n	lstrace\r\n	ss\r\n	netstat\r\n	sysdig\r\n	perf\r\n	mpstat\r\n	sar\r\n	dstat\r\n	perf\r\n	tiptop\r\n	ethtool\r\n	snmpget\r\n	lldptool\r\n	tcpdump\r\n	iptraf\r\n	vmstat\r\n	pidstat\r\n	top\r\n	swapon\r\n	blktrace\r\n	iostat\r\n	iotop\r\n	stap\r\n	ktap\r\n	ebpf\r\n	dtrace\r\n	ftrace\r\n	slabtop\r\n	free\r\n	ps\r\n	ip\r\n	nicestat\r\n\r\nLinux Test\r\n\r\n	ab\r\n	sysbench\r\n	wrk\r\n	jmeter\r\n	openssl\r\n	unixbench\r\n	lmbench\r\n	perfbench\r\n	ping\r\n	traceroute\r\n	mtr\r\n	ttcp\r\n	iperf\r\n	hping3\r\n	pchar\r\n	hdparm\r\n	dd\r\n	fio\r\n	gcc\r\n	llvm\r\n	ping', ''),
(125, 'python_tab', '#!/bin/bash\n#more:http://www.linuxyw.com\n#author:drfdai\n. /etc/init.d/functions\ncat>~/.pythonstartup<<EOF\nimport sys\nimport readline\nimport rlcompleter\nimport atexit\nimport os\nreadline.parse_and_bind(''tab: complete'')\nhistfile = os.path.join(os.environ[''HOME''], ''.pythonhistory'')\ntry:\n    readline.read_history_file(histfile)\nexcept IOError:\n    pass\natexit.register(readline.write_history_file, histfile)\ndel os, histfile, readline, rlcompleter\nEOF\necho "export PYTHONSTARTUP=~/.pythonstartup" >> ~/.bashrc\n\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(126, 'Python自省（反射）指南', '\n	\n		\n\n\n\n	\n		\n			[Python自省（反射）指南](http://www.cnblogs.com/huxi/archive/2011/01/02/1924317.html)\n		\n		\n\n\n		\n			\n\n```\n\n在笔者，也就是我的概念里，自省和反射是一回事，当然其实我并不十分确定一定以及肯定，所以如果这确实是两个不同的概念的话，还请多多指教 ：） 转载请注明作者、出处并附上原文链接，多谢！\n\nupdate 2011-3-10: 更正函数的func_globals属性含义。  \n\n\n\n```\n\n首先通过一个例子来看一下本文中可能用到的对象和相关概念。\n\n\n\n```\n#coding: UTF-8\nimport sys #  模块，sys指向这个模块对象\nimport inspect\ndef foo(): pass # 函数，foo指向这个函数对象\n\nclass Cat(object): # 类，Cat指向这个类对象\n    def __init__(self, name=''kitty''):\n        self.name = name\n    def sayHi(self): #  实例方法，sayHi指向这个方法对象，使用类或实例.sayHi访问\n        print self.name, ''says Hi!'' # 访问名为name的字段，使用实例.name访问\n\ncat = Cat() # cat是Cat类的实例对象\n\nprint Cat.sayHi # 使用类名访问实例方法时，方法是未绑定的(unbound)\nprint cat.sayHi # 使用实例访问实例方法时，方法是绑定的(bound)\n```\n\n有时候我们会碰到这样的需求，需要执行对象的某个方法，或是需要对对象的某个字段赋值，而方法名或是字段名在编码代码时并不能确定，需要通过参数传递字符串的形式输入。举个具体的例子：当我们需要实现一个通用的DBM框架时，可能需要对数据对象的字段赋值，但我们无法预知用到这个框架的数据对象都有些什么字段，换言之，我们在写框架的时候需要通过某种机制访问未知的属性。\n\n\n这个机制被称为反射（反过来让对象告诉我们他是什么），或是自省（让对象自己告诉我们他是什么，好吧我承认括号里是我瞎掰的- -#），用于实现在运行时获取未知对象的信息。反射是个很吓唬人的名词，听起来高深莫测，在一般的编程语言里反射相对其他概念来说稍显复杂，一般来说都是作为高级主题来讲；但在Python中反射非常简单，用起来几乎感觉不到与其他的代码有区别，使用反射获取到的函数和方法可以像平常一样加上括号直接调用，获取到类后可以直接构造实例；不过获取到的字段不能直接赋值，因为拿到的其实是另一个指向同一个地方的引用，赋值只能改变当前的这个引用而已。\n\n\n\n#### 1. 访问对象的属性\n\n\n以下列出了几个内建方法，可以用来检查或是访问对象的属性。这些方法可以用于任意对象而不仅仅是例子中的Cat实例对象；Python中一切都是对象。\n\n\n\n```\ncat = Cat(''kitty'')\n\nprint cat.name # 访问实例属性\ncat.sayHi() # 调用实例方法\n\nprint dir(cat) # 获取实例的属性名，以列表形式返回\nif hasattr(cat, ''name''): # 检查实例是否有这个属性\n    setattr(cat, ''name'', ''tiger'') # same as: a.name = ''tiger''\nprint getattr(cat, ''name'') # same as: print a.name\n\ngetattr(cat, ''sayHi'')() # same as: cat.sayHi()\n```\n\n\n\n\n\n#### dir([obj]):\n\n \n    \n\n调用这个方法将返回包含obj大多数属性名的列表（会有一些特殊的属性不包含在内）。obj的默认值是当前的模块对象。 \n\n\n\n\n#### hasattr(obj, attr): \n      \n\n\n\n这个方法用于检查obj是否有一个名为attr的值的属性，返回一个布尔值。 \n\n\n\n\n#### getattr(obj, attr): \n      \n\n\n\n调用这个方法将返回obj中名为attr值的属性的值，例如如果attr为''bar''，则返回obj.bar。 \n\n\n\n\n#### setattr(obj, attr, val):\n\n \n    \n\n调用这个方法将给obj的名为attr的值的属性赋值为val。例如如果attr为''bar''，则相当于obj.bar = val。 \n\n\n\n#### 2. 访问对象的元数据\n\n\n当你对一个你构造的对象使用dir()时，可能会发现列表中的很多属性并不是你定义的。这些属性一般保存了对象的元数据，比如类的__name__属性保存了类名。大部分这些属性都可以修改，不过改动它们意义并不是很大；修改其中某些属性如function.func_code还可能导致很难发现的问题，所以改改name什么的就好了，其他的属性不要在不了解后果的情况下修改。\n\n\n接下来列出特定对象的一些特殊属性。另外，Python的文档中有提到部分属性不一定会一直提供，下文中将以红色的星号\n\n#### *\n\n标记，使用前你可以先打开解释器确认一下。\n\n\n\n#### 2.0. 准备工作：确定对象的类型\n\n\n在types模块中定义了全部的Python内置类型，结合内置方法isinstance()就可以确定对象的具体类型了。\n\n\n\n\n\n\n#### isinstance(object, classinfo):\n\n \n    \n\n检查object是不是classinfo中列举出的类型，返回布尔值。classinfo可以是一个具体的类型，也可以是多个类型的元组或列表。 \n\n\ntypes模块中仅仅定义了类型，而inspect模块中封装了很多检查类型的方法，比直接使用types模块更为轻松，所以这里不给出关于types的更多介绍，如有需要可以直接查看types模块的文档说明。本文第3节中介绍了inspect模块。\n\n\n\n#### 2.1. 模块(module)\n\n\n\n__doc__: 文档字符串。如果模块没有文档，这个值是None。 \n\n\n\n\n#### *\n\n__name__: 始终是定义时的模块名；即使你使用import .. as 为它取了别名，或是赋值给了另一个变量名。 \n\n\n\n\n#### *\n\n__dict__: 包含了模块里可用的属性名-属性的字典；也就是可以使用模块名.属性名访问的对象。 \n\n__file__: 包含了该模块的文件路径。需要注意的是内建的模块没有这个属性，访问它会抛出异常！ \n\n\n\n```\nimport fnmatch as m\nprint m.__doc__.splitlines()[0] # Filename matching with shell patterns.\nprint m.__name__                # fnmatch\nprint m.__file__                # /usr/lib/python2.6/fnmatch.pyc\nprint m.__dict__.items()[0]     # (''fnmatchcase'', )\n```\n\n\n#### 2.2. 类(class)\n\n\n\n__doc__: 文档字符串。如果类没有文档，这个值是None。 \n\n\n\n\n#### *\n\n__name__: 始终是定义时的类名。 \n\n\n\n\n#### *\n\n__dict__: 包含了类里可用的属性名-属性的字典；也就是可以使用类名.属性名访问的对象。 \n\n__module__: 包含该类的定义的模块名；需要注意，是字符串形式的模块名而不是模块对象。 \n\n\n\n\n#### *\n\n__bases__: 直接父类对象的元组；但不包含继承树更上层的其他类，比如父类的父类。 \n\n\n\n```\nprint Cat.__doc__           # None\nprint Cat.__name__          # Cat\nprint Cat.__module__        # __main__\nprint Cat.__bases__         # (,)\nprint Cat.__dict__          # {''__module__'': ''__main__'', ...}\n```\n\n\n#### 2.3. 实例(instance)\n\n\n实例是指类实例化以后的对象。\n\n\n\n\n\n\n#### *\n\n__dict__: 包含了可用的属性名-属性字典。 \n\n\n\n\n#### *\n\n__class__: 该实例的类对象。对于类Cat，cat.__class__ == Cat 为 True。 \n\n\n\n```\nprint cat.__dict__\nprint cat.__class__\nprint cat.__class__ == Cat # True\n```\n\n\n#### 2.4. 内建函数和方法(built-in functions and methods)\n\n\n根据定义，内建的(built-in)模块是指使用C写的模块，可以通过sys模块的builtin_module_names字段查看都有哪些模块是内建的。这些模块中的函数和方法可以使用的属性比较少，不过一般也不需要在代码中查看它们的信息。\n\n\n\n__doc__: 函数或方法的文档。 \n\n__name__: 函数或方法定义时的名字。 \n\n__self__: 仅方法可用，如果是绑定的(bound)，则指向调用该方法的类（如果是类方法）或实例（如果是实例方法），否则为None。 \n\n\n\n\n#### *\n\n__module__: 函数或方法所在的模块名。 \n\n\n\n#### 2.5. 函数(function)\n\n\n这里特指非内建的函数。注意，在类中使用def定义的是方法，方法与函数虽然有相似的行为，但它们是不同的概念。\n\n\n\n__doc__: 函数的文档；另外也可以用属性名func_doc。 \n\n__name__: 函数定义时的函数名；另外也可以用属性名func_name。 \n\n\n\n\n#### *\n\n__module__: 包含该函数定义的模块名；同样注意，是模块名而不是模块对象。 \n\n\n\n\n#### *\n\n__dict__: 函数的可用属性；另外也可以用属性名func_dict。 \n    \n\n不要忘了函数也是对象，可以使用函数.属性名访问属性（赋值时如果属性不存在将新增一个），或使用内置函数has/get/setattr()访问。不过，在函数中保存属性的意义并不大。 \n\nfunc_defaults: 这个属性保存了函数的参数默认值元组；因为默认值总是靠后的参数才有，所以不使用字典的形式也是可以与参数对应上的。 \n\nfunc_code: 这个属性指向一个该函数对应的code对象，code对象中定义了其他的一些特殊属性，将在下文中另外介绍。 \n\nfunc_globals: 这个属性指向定义函数时的全局命名空间。\n\n\n\n\n#### *\n\nfunc_closure: 这个属性仅当函数是一个闭包时有效，指向一个保存了所引用到的外部函数的变量cell的元组，如果该函数不是一个内部函数，则始终为None。这个属性也是只读的。 \n\n\n下面的代码演示了func_closure：\n\n\n\n```\n#coding: UTF-8\ndef foo():\n    n = 1\n    def bar():\n        print n # 引用非全局的外部变量n，构造一个闭包\n    n = 2\n    return bar\n\nclosure = foo()\nprint closure.func_closure\n# 使用dir()得知cell对象有一个cell_contents属性可以获得值\nprint closure.func_closure[0].cell_contents # 2\n```\n\n由这个例子可以看到，遇到未知的对象使用dir()是一个很好的主意 ：）\n\n\n\n#### 2.6. 方法(method)\n\n\n方法虽然不是函数，但可以理解为在函数外面加了一层外壳；拿到方法里实际的函数以后，就可以使用2.5节的属性了。\n\n\n\n__doc__: 与函数相同。 \n\n__name__: 与函数相同。 \n\n\n\n\n#### *\n\n__module__: 与函数相同。 \n\nim_func: 使用这个属性可以拿到方法里实际的函数对象的引用。另外如果是2.6以上的版本，还可以使用属性名__func__。 \n\nim_self: 如果是绑定的(bound)，则指向调用该方法的类（如果是类方法）或实例（如果是实例方法），否则为None。如果是2.6以上的版本，还可以使用属性名__self__。 \n\nim_class: 实际调用该方法的类，或实际调用该方法的实例的类。注意不是方法的定义所在的类，如果有继承关系的话。 \n\n\n\n```\nim = cat.sayHi\nprint im.im_func\nprint im.im_self # cat\nprint im.im_class # Cat\n```\n\n\n这里讨论的是一般的实例方法，另外还有两种特殊的方法分别是类方法(classmethod)和静态方法(staticmethod)。类方法还是方法，不过因为需要使用类名调用，所以他始终是绑定的；而静态方法可以看成是在类的命名空间里的函数（需要使用类名调用的函数），它只能使用函数的属性，不能使用方法的属性。\n\n\n\n#### 2.7. 生成器(generator)\n\n\n生成器是调用一个生成器函数(generator function)返回的对象，多用于集合对象的迭代。\n\n\n\n__iter__: 仅仅是一个可迭代的标记。 \n\ngi_code: 生成器对应的code对象。 \n\ngi_frame: 生成器对应的frame对象。 \n\ngi_running: 生成器函数是否在执行。生成器函数在yield以后、执行yield的下一行代码前处于frozen状态，此时这个属性的值为0。 \n\nnext|close|send|throw: 这是几个可调用的方法，并不包含元数据信息，如何使用可以查看生成器的相关文档。 \n\n\n\n```\ndef gen():\n    for n in xrange(5):\n        yield n\ng = gen()\nprint g             # <generator object gen at 0x...>\nprint g.gi_code     # <code object gen at 0x...>\nprint g.gi_frame    # <frame object at 0x...>\nprint g.gi_running  # 0\nprint g.next()      # 0\nprint g.next()      # 1\nfor n in g:\n    print n,        # 2 3 4\n```\n\n接下来讨论的是几个不常用到的内置对象类型。这些类型在正常的编码过程中应该很少接触，除非你正在自己实现一个解释器或开发环境之类。所以这里只列出一部分属性，如果需要一份完整的属性表或想进一步了解，可以查看文末列出的参考文档。\n\n\n\n#### 2.8. 代码块(code)\n\n\n代码块可以由类源代码、函数源代码或是一个简单的语句代码编译得到。这里我们只考虑它指代一个函数时的情况；2.5节中我们曾提到可以使用函数的func_code属性获取到它。code的属性全部是只读的。\n\n\n\nco_argcount: 普通参数的总数，不包括*参数和**参数。 \n\nco_names: 所有的参数名（包括*参数和**参数）和局部变量名的元组。 \n\nco_varnames: 所有的局部变量名的元组。 \n\nco_filename: 源代码所在的文件名。 \n\nco_flags:  这是一个数值，每一个二进制位都包含了特定信息。较关注的是0b100(0x4)和0b1000(0x8)，如果co_flags & 0b100 != 0，说明使用了*args参数；如果co_flags & 0b1000 != 0，说明使用了**kwargs参数。另外，如果co_flags & 0b100000(0x20) != 0，则说明这是一个生成器函数(generator function)。 \n\n\n\n```\nco = cat.sayHi.func_code\nprint co.co_argcount        # 1\nprint co.co_names           # (''name'',)\nprint co.co_varnames        # (''self'',)\nprint co.co_flags & 0b100   # 0\n```\n\n\n#### 2.9. 栈帧(frame)\n\n\n栈帧表示程序运行时函数调用栈中的某一帧。函数没有属性可以获取它，因为它在函数调用时才会产生，而生成器则是由函数调用返回的，所以有属性指向栈帧。想要获得某个函数相关的栈帧，则必须在调用这个函数且这个函数尚未返回时获取。你可以使用sys模块的_getframe()函数、或inspect模块的currentframe()函数获取当前栈帧。这里列出来的属性全部是只读的。\n\n\n\nf_back: 调用栈的前一帧。 \n\nf_code: 栈帧对应的code对象。 \n\nf_locals: 用在当前栈帧时与内建函数locals()相同，但你可以先获取其他帧然后使用这个属性获取那个帧的locals()。 \n\nf_globals: 用在当前栈帧时与内建函数globals()相同，但你可以先获取其他帧……。 \n\n\n\n```\ndef add(x, y=1):\n    f = inspect.currentframe()\n    print f.f_locals    # same as locals()\n    print f.f_back      # <frame object at 0x...>\n    return x+y\nadd(2)\n```\n\n\n#### 2.10. 追踪(traceback)\n\n\n追踪是在出现异常时用于回溯的对象，与栈帧相反。由于异常时才会构建，而异常未捕获时会一直向外层栈帧抛出，所以需要使用try才能见到这个对象。你可以使用sys模块的exc_info()函数获得它，这个函数返回一个元组，元素分别是异常类型、异常对象、追踪。traceback的属性全部是只读的。\n\n\n\ntb_next: 追踪的下一个追踪对象。 \n\ntb_frame: 当前追踪对应的栈帧。 \n\ntb_lineno: 当前追踪的行号。 \n\n\n\n```\ndef div(x, y):\n    try:\n        return x/y\n    except:\n        tb = sys.exc_info()[2]  # return (exc_type, exc_value, traceback)\n        print tb\n        print tb.tb_lineno      # "return x/y" 的行号\ndiv(1, 0)\n```\n\n\n#### 3. 使用inspect模块\n\n\ninspect模块提供了一系列函数用于帮助使用自省。下面仅列出较常用的一些函数，想获得全部的函数资料可以查看inspect模块的文档。\n\n\n\n#### 3.1. 检查对象类型\n\n\n\n\n\n\n#### is{module|class|function|method|builtin}(obj): \n      \n\n\n\n检查对象是否为模块、类、函数、方法、内建函数或方法。 \n\n\n\n\n#### isroutine(obj): \n      \n\n\n\n用于检查对象是否为函数、方法、内建函数或方法等等可调用类型。用这个方法会比多个is*()更方便，不过它的实现仍然是用了多个is*()。 \n    \n\n\n```\nim = cat.sayHi\nif inspect.isroutine(im):\n    im()\n```\n\n\n\n对于实现了__call__的类实例，这个方法会返回False。如果目的是只要可以直接调用就需要是True的话，不妨使用\n\n#### isinstance(obj, collections.Callable)\n\n这种形式。我也不知道为什么Callable会在collections模块中，抱歉！我猜大概是因为collections模块中包含了很多其他的ABC(Abstract Base Class)的缘故吧：） \n\n\n\n#### 3.2. 获取对象信息\n\n\n\n\n\n\n#### getmembers(object[, predicate]):\n\n \n    \n\n这个方法是dir()的扩展版，它会将dir()找到的名字对应的属性一并返回，形如[(name, value), ...]。另外，predicate是一个方法的引用，如果指定，则应当接受value作为参数并返回一个布尔值，如果为False，相应的属性将不会返回。使用is*作为第二个参数可以过滤出指定类型的属性。 \n\n\n\n\n#### getmodule(object):\n\n \n    \n\n还在为第2节中的__module__属性只返回字符串而遗憾吗？这个方法一定可以满足你，它返回object的定义所在的模块对象。 \n\n\n\n\n#### get{file|sourcefile}(object):\n\n \n    \n\n获取object的定义所在的模块的文件名|源代码文件名（如果没有则返回None）。用于内建的对象（内建模块、类、函数、方法）上时会抛出TypeError异常。 \n\n\n\n\n#### get{source|sourcelines}(object):\n\n \n    \n\n获取object的定义的源代码，以字符串|字符串列表返回。代码无法访问时会抛出IOError异常。只能用于module/class/function/method/code/frame/traceack对象。 \n\n\n\n\n#### getargspec(func): \n      \n\n\n\n仅用于方法，获取方法声明的参数，返回元组，分别是(普通参数名的列表, *参数名, **参数名, 默认值元组)。如果没有值，将是空列表和3个None。如果是2.6以上版本，将返回一个命名元组(Named Tuple)，即除了索引外还可以使用属性名访问元组中的元素。  \n\n\n```\ndef add(x, y=1, *z):\n    return x + y + sum(z)\nprint inspect.getargspec(add)\n#ArgSpec(args=[''x'', ''y''], varargs=''z'', keywords=None, defaults=(1,))\n```\n\n\n\n\n\n\n#### getargvalues(frame): \n      \n\n\n\n仅用于栈帧，获取栈帧中保存的该次函数调用的参数值，返回元组，分别是(普通参数名的列表, *参数名, **参数名, 帧的locals())。如果是2.6以上版本，将返回一个命名元组(Named Tuple)，即除了索引外还可以使用属性名访问元组中的元素。 \n    \n\n\n```\ndef add(x, y=1, *z):\n    print inspect.getargvalues(inspect.currentframe())\n    return x + y + sum(z)\nadd(2)\n#ArgInfo(args=[''x'', ''y''], varargs=''z'', keywords=None, locals={''y'': 1, ''x'': 2, ''z'': ()})\n```\n\n\n\n\n\n\n#### getcallargs(func[, *args][, **kwds]): \n      \n\n\n\n返回使用args和kwds调用该方法时各参数对应的值的字典。这个方法仅在2.7版本中才有。 \n\n\n\n\n#### getmro(cls): \n      \n\n\n\n返回一个类型元组，查找类属性时按照这个元组中的顺序。如果是新式类，与cls.__mro__结果一样。但旧式类没有__mro__这个属性，直接使用这个属性会报异常，所以这个方法还是有它的价值的。 \n    \n\n\n```\nprint inspect.getmro(Cat)\n#(<class ''__main__.Cat''>, <type ''object''>)\nprint Cat.__mro__\n#(<class ''__main__.Cat''>, <type ''object''>)\nclass Dog: pass\nprint inspect.getmro(Dog)\n#(<class __main__.Dog at 0x...>,)\nprint Dog.__mro__ # AttributeError\n```\n\n\n\n\n\n\n#### currentframe(): \n      \n\n\n\n返回当前的栈帧对象。 \n\n\n其他的操作frame和traceback的函数请查阅inspect模块的文档，用的比较少，这里就不多介绍了。\n\n\n<全文完> \n  \n\n参考资料： \n  \n\n1. [The standard type hierarchy](http://docs.python.org/reference/datamodel.html#the-standard-type-hierarchy)[官方文档][英文] \n  \n\n2. [inspect — Inspect live objects](http://docs.python.org/library/inspect.html#module-inspect)[官方文档][英文]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n		\n\n\n		posted @ 2011-01-02 23:12 [AstralWind](http://www.cnblogs.com/huxi/) 阅读(...) 评论(...)  [编辑](http://i.cnblogs.com/EditPosts.aspx?postid=1924317) [收藏](#)\n\n\n\n	\n\n\n	\n\n\n\n\n\n\n\n\n\n\n\n\n\n[刷新评论](http://www.cnblogs.com/huxi/archive/2011/01/02/javascript:void(0);)[刷新页面](#)[返回顶部](#top)\n\n\n\n\n\n\n\n\n\n\n[博客园首页](http://www.cnblogs.com/)[博问](http://q.cnblogs.com/)[新闻](http://news.cnblogs.com/)[闪存](http://home.cnblogs.com/ing/)[程序员招聘](http://job.cnblogs.com/)[知识库](http://kb.cnblogs.com/)\n\n\n\n\n\n\n\n\n    \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n	\n\n\n\n	\n\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(127, 'bash_tab', '#   bash_completion - programmable completion functions for bash 3.x\n#		      (backwards compatible with bash 2.05b)\n#\n#   $Id: bash_completion,v 1.872 2006/03/01 16:20:18 ianmacd Exp $\n#\n#   Copyright (C) Ian Macdonald <ian@caliban.org>\n#\n#   This program is free software; you can redistribute it and/or modify\n#   it under the terms of the GNU General Public License as published by\n#   the Free Software Foundation; either version 2, or (at your option)\n#   any later version.\n#\n#   This program is distributed in the hope that it will be useful,\n#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#   GNU General Public License for more details.\n#\n#   You should have received a copy of the GNU General Public License\n#   along with this program; if not, write to the Free Software Foundation,\n#   Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.\n#\n#   The latest version of this software can be obtained here:\n#\n#   http://www.caliban.org/bash/index.shtml#completion\n#\n#   RELEASE: 20060301\n\n[ -n "${BASH_COMPLETION_DEBUG:-}" ] && set -v || set +v\n\n# Alter the following to reflect the location of this file.\n#\n{\n  # These declarations must go within braces in order to be able to silence\n  # readonly variable errors.\n  BASH_COMPLETION="${BASH_COMPLETION:-/etc/bash_completion}"\n  BASH_COMPLETION_DIR="${BASH_COMPLETION_DIR:=/etc/bash_completion.d}"\n} 2>/dev/null || :\nreadonly BASH_COMPLETION BASH_COMPLETION_DIR\n\n# Set a couple of useful vars\n#\nUNAME=$( uname -s )\n# strip OS type and version under Cygwin (e.g. CYGWIN_NT-5.1 => Cygwin)\nUNAME=${UNAME/CYGWIN_*/Cygwin}\nRELEASE=$( uname -r )\n\n# features supported by bash 2.05 and higher\nif [ ${BASH_VERSINFO[0]} -eq 2 ] && [[ ${BASH_VERSINFO[1]} > 04 ]] ||\n   [ ${BASH_VERSINFO[0]} -gt 2 ]; then\n	declare -r bash205=$BASH_VERSION 2>/dev/null || :\n	default="-o default"\n	dirnames="-o dirnames"\n	filenames="-o filenames"\nfi\n# features supported by bash 2.05b and higher\nif [ ${BASH_VERSINFO[0]} -eq 2 ] && [[ ${BASH_VERSINFO[1]} = "05b" ]] ||\n   [ ${BASH_VERSINFO[0]} -gt 2 ]; then\n	declare -r bash205b=$BASH_VERSION 2>/dev/null || :\n	nospace="-o nospace"\nfi\n# features supported by bash 3.0 and higher\nif [ ${BASH_VERSINFO[0]} -gt 2 ]; then\n	declare -r bash3=$BASH_VERSION 2>/dev/null || :\n	bashdefault="-o bashdefault"\n	plusdirs="-o plusdirs"\nfi\n\n# Turn on extended globbing and programmable completion\nshopt -s extglob progcomp\n\n# A lot of the following one-liners were taken directly from the\n# completion examples provided with the bash 2.04 source distribution\n\n# Make directory commands see only directories\ncomplete -d pushd\n\n# The following section lists completions that are redefined later\n# Do NOT break these over multiple lines.\n#\n# START exclude -- do NOT remove this line\ncomplete -f -X ''!*.?(t)bz?(2)'' bunzip2 bzcat bzcmp bzdiff bzegrep bzfgrep bzgrep\ncomplete -f -X ''!*.@(zip|ZIP|jar|JAR|exe|EXE|pk3|war|wsz|ear|zargo|xpi|sxw|ott)'' unzip zipinfo\ncomplete -f -X ''*.Z'' compress znew\ncomplete -f -X ''!*.@(Z|gz|tgz|Gz|dz)'' gunzip zcmp zdiff zcat zegrep zfgrep zgrep zless zmore\ncomplete -f -X ''!*.Z'' uncompress\ncomplete -f -X ''!*.@(gif|jp?(e)g|miff|tif?(f)|pn[gm]|p[bgp]m|bmp|xpm|ico|xwd|tga|pcx|GIF|JP?(E)G|MIFF|TIF?(F)|PN[GM]|P[BGP]M|BMP|XPM|ICO|XWD|TGA|PCX)'' ee display\ncomplete -f -X ''!*.@(gif|jp?(e)g|tif?(f)|png|p[bgp]m|bmp|x[bp]m|rle|rgb|pcx|fits|pm|GIF|JPG|JP?(E)G|TIF?(F)|PNG|P[BGP]M|BMP|X[BP]M|RLE|RGB|PCX|FITS|PM)'' xv qiv\ncomplete -f -X ''!*.@(@(?(e)ps|?(E)PS|pdf|PDF)?(.gz|.GZ|.bz2|.BZ2|.Z))'' gv ggv kghostview\ncomplete -f -X ''!*.@(dvi|DVI)?(.@(gz|Z|bz2))'' xdvi\ncomplete -f -X ''!*.@(dvi|DVI)'' dvips dviselect dvitype kdvi dvipdf advi\ncomplete -f -X ''!*.@(pdf|PDF)'' acroread gpdf xpdf kpdf\ncomplete -f -X ''!*.@(@(?(e)ps|?(E)PS)?(.gz|.GZ)|pdf|PDF|gif|jp?(e)g|miff|tif?(f)|pn[gm]|p[bgp]m|bmp|xpm|ico|xwd|tga|pcx|GIF|JP?(E)G|MIFF|TIF?(F)|PN[GM]|P[BGP]M|BMP|XPM|ICO|XWD|TGA|PCX)'' evince\ncomplete -f -X ''!*.@(?(e)ps|?(E)PS)'' ps2pdf\ncomplete -f -X ''!*.texi*'' makeinfo texi2html\ncomplete -f -X ''!*.@(?(la)tex|?(LA)TEX|texi|TEXI|dtx|DTX|ins|INS)'' tex latex slitex jadetex pdfjadetex pdftex pdflatex texi2dvi\ncomplete -f -X ''!*.@(mp3|MP3)'' mpg123 mpg321 madplay\ncomplete -f -X ''!*.@(mp?(e)g|MP?(E)G|wma|avi|AVI|asf|vob|VOB|bin|dat|vcd|ps|pes|fli|viv|rm|ram|yuv|mov|MOV|qt|QT|wmv|mp3|MP3|ogg|OGG|ogm|OGM|mp4|MP4|wav|WAV|asx|ASX|mng|MNG)'' xine aaxine fbxine kaffeine\ncomplete -f -X ''!*.@(avi|asf|wmv)'' aviplay\ncomplete -f -X ''!*.@(rm?(j)|ra?(m)|smi?(l))'' realplay\ncomplete -f -X ''!*.@(mpg|mpeg|avi|mov|qt)'' xanim\ncomplete -f -X ''!*.@(ogg|OGG|m3u|flac|spx)'' ogg123\ncomplete -f -X ''!*.@(mp3|MP3|ogg|OGG|pls|m3u)'' gqmpeg freeamp\ncomplete -f -X ''!*.fig'' xfig\ncomplete -f -X ''!*.@(mid?(i)|MID?(I))'' playmidi\ncomplete -f -X ''!*.@(mid?(i)|MID?(I)|rmi|RMI|rcp|RCP|[gr]36|[GR]36|g18|G18|mod|MOD|xm|XM|it|IT|x3m|X3M)'' timidity\ncomplete -f -X ''*.@(o|so|so.!(conf)|a|t@(ar?(.@(Z|gz|bz?(2)))|gz|bz?(2))|rpm|zip|ZIP|gif|GIF|jp?(e)g|JP?(E)G|mp3|MP3|mp?(e)g|MPG|avi|AVI|asf|ASF|ogg|OGG|class|CLASS)'' vi vim gvim rvim view rview rgvim rgview gview\ncomplete -f -X ''*.@(o|so|so.!(conf)|a|rpm|gif|GIF|jp?(e)g|JP?(E)G|mp3|MP3|mp?(e)g|MPG|avi|AVI|asf|ASF|ogg|OGG|class|CLASS)'' emacs\ncomplete -f -X ''!*.@(exe|EXE|com|COM|scr|SCR|exe.so)'' wine\ncomplete -f -X ''!*.@(zip|ZIP|z|Z|gz|GZ|tgz|TGZ)'' bzme\ncomplete -f -X ''!*.@(?([xX]|[sS])[hH][tT][mM]?([lL]))'' netscape mozilla lynx opera galeon curl dillo elinks amaya\ncomplete -f -X ''!*.@(sxw|stw|sxg|sgl|doc|dot|rtf|txt|htm|html|odt|ott|odm)'' oowriter\ncomplete -f -X ''!*.@(sxi|sti|pps|ppt|pot|odp|otp)'' ooimpress\ncomplete -f -X ''!*.@(sxc|stc|xls|xlw|xlt|csv|ods|ots)'' oocalc\ncomplete -f -X ''!*.@(sxd|std|sda|sdd|odg|otg)'' oodraw\ncomplete -f -X ''!*.@(sxm|smf|mml|odf)'' oomath\ncomplete -f -X ''!*.odb'' oobase\ncomplete -f -X ''!*.rpm'' rpm2cpio\n# FINISH exclude -- do not remove this line\n\n# start of section containing compspecs that can be handled within bash\n\n# user commands see only users\ncomplete -u su usermod userdel passwd chage write chfn groups slay w\n\n# group commands see only groups\n[ -n "$bash205" ] && complete -g groupmod groupdel newgrp 2>/dev/null\n\n# bg completes with stopped jobs\ncomplete -A stopped -P ''%'' bg\n\n# other job commands\ncomplete -j -P ''%'' fg jobs disown\n\n# readonly and unset complete with shell variables\ncomplete -v readonly unset\n\n# set completes with set options\ncomplete -A setopt set\n\n# shopt completes with shopt options\ncomplete -A shopt shopt\n\n# helptopics\ncomplete -A helptopic help\n\n# unalias completes with aliases\ncomplete -a unalias\n\n# bind completes with readline bindings (make this more intelligent)\ncomplete -A binding bind\n\n# type and which complete on commands\ncomplete -c command type which\n\n# builtin completes on builtins\ncomplete -b builtin\n\n# start of section containing completion functions called by other functions\n\n# This function checks whether we have a given program on the system.\n# No need for bulky functions in memory if we don''t.\n#\nhave()\n{\n	unset -v have\n	PATH=$PATH:/sbin:/usr/sbin:/usr/local/sbin type $1 &>/dev/null &&\n		have="yes"\n}\n\n# use GNU sed if we have it, since its extensions are still used in our code\n#\n[ $UNAME != Linux ] && have gsed && alias sed=gsed\n\n# This function checks whether a given readline variable\n# is `on''.\n#\n_rl_enabled() \n{\n    [[ "$( bind -v )" = *$1+([[:space:]])on* ]]\n}\n\n\n# This function performs file and directory completion. It''s better than\n# simply using ''compgen -f'', because it honours spaces in filenames.\n# If passed -d, it completes only on directories. If passed anything else,\n# it''s assumed to be a file glob to complete on.\n#\n_filedir()\n{\n	local IFS=$''\\t\\n'' xspec #glob\n\n	_expand || return 0\n\n	#glob=$(set +o|grep noglob) # save glob setting.\n	#set -f		 # disable pathname expansion (globbing)\n\n	if [ "${1:-}" = -d ]; then\n		COMPREPLY=( ${COMPREPLY[@]:-} $( compgen -d -- $cur ) )\n		#eval "$glob"    # restore glob setting.\n		return 0\n	fi\n\n	xspec=${1:+"!*.$1"}	# set only if glob passed in as $1\n	COMPREPLY=( ${COMPREPLY[@]:-} $( compgen -f -X "$xspec" -- "$cur" ) \\\n		    $( compgen -d -- "$cur" ) )\n	#eval "$glob"    # restore glob setting.\n}\n\n# This function completes on signal names\n#\n_signals()\n{\n	local i\n\n	# standard signal completion is rather braindead, so we need\n	# to hack around to get what we want here, which is to\n	# complete on a dash, followed by the signal name minus\n	# the SIG prefix\n	COMPREPLY=( $( compgen -A signal SIG${cur#-} ))\n	for (( i=0; i < ${#COMPREPLY[@]}; i++ )); do\n		COMPREPLY[i]=-${COMPREPLY[i]#SIG}\n	done\n}\n\n# This function completes on configured network interfaces\n#\n_configured_interfaces()\n{\n	if [ -f /etc/debian_version ]; then\n		# Debian system\n		COMPREPLY=( $( sed -ne ''s|^iface \\([^ ]\\+\\).*$|\\1|p'' \\\n			       /etc/network/interfaces ) )\n	elif [ -f /etc/SuSE-release ]; then\n		# SuSE system\n		COMPREPLY=( $( command ls \\\n			/etc/sysconfig/network/ifcfg-* | \\\n			sed -ne ''s|.*ifcfg-\\(''$cur''.*\\)|\\1|p'' ) )\n	elif [ -f /etc/pld-release ]; then\n		# PLD Linux\n		COMPREPLY=( $( command ls -B \\\n			/etc/sysconfig/interfaces | \\\n			sed -ne ''s|.*ifcfg-\\(''$cur''.*\\)|\\1|p'' ) )\n	else\n		# Assume Red Hat\n		COMPREPLY=( $( command ls \\\n			/etc/sysconfig/network-scripts/ifcfg-* | \\\n			sed -ne ''s|.*ifcfg-\\(''$cur''.*\\)|\\1|p'' ) )\n	fi\n}\n\n# This function completes on all available network interfaces\n# -a: restrict to active interfaces only\n# -w: restrict to wireless interfaces only\n#\n_available_interfaces()\n{\n	local cmd\n\n	if [ "${1:-}" = -w ]; then\n		cmd="iwconfig"\n	elif [ "${1:-}" = -a ]; then\n		cmd="ifconfig"\n	else\n		cmd="ifconfig -a"\n	fi\n\n	COMPREPLY=( $( eval $cmd 2>/dev/null | \\\n		sed -ne ''s|^\\(''$cur''[^[:space:][:punct:]]\\{1,\\}\\).*$|\\1|p'') )\n}\n\n# This function expands tildes in pathnames\n#\n_expand()\n{\n	[ "$cur" != "${cur%\\\\}" ] && cur="$cur\\\\"\n\n	# expand ~username type directory specifications\n	if [[ "$cur" == \\~*/* ]]; then\n		eval cur=$cur\n		\n	elif [[ "$cur" == \\~* ]]; then\n		cur=${cur#\\~}\n		COMPREPLY=( $( compgen -P ''~'' -u $cur ) )\n		return ${#COMPREPLY[@]}\n	fi\n}\n\n# This function completes on process IDs.\n# AIX and Solaris ps prefers X/Open syntax.\n[ $UNAME = SunOS -o $UNAME = AIX ] &&\n_pids()\n{\n	COMPREPLY=( $( compgen -W ''$( command ps -efo pid | sed 1d )'' -- $cur ))\n} ||\n_pids()\n{\n	COMPREPLY=( $( compgen -W ''$( command ps axo pid | sed 1d )'' -- $cur ) )\n}\n\n# This function completes on process group IDs.\n# AIX and SunOS prefer X/Open, all else should be BSD.\n[ $UNAME = SunOS -o $UNAME = AIX ] &&\n_pgids()\n{\n	COMPREPLY=( $( compgen -W ''$( command ps -efo pgid | sed 1d )'' -- $cur ))\n} ||\n_pgids()\n{\n	COMPREPLY=( $( compgen -W ''$( command ps axo pgid | sed 1d )'' -- $cur ))\n}\n\n# This function completes on user IDs\n#\n_uids()\n{\n	if type getent &>/dev/null; then\n	    COMPREPLY=( $( getent passwd | \\\n			    awk -F: ''{if ($3 ~ /^''$cur''/) print $3}'' ) )\n	elif type perl &>/dev/null; then\n	    COMPREPLY=( $( compgen -W ''$( perl -e ''"''"''while (($uid) = (getpwent)[2]) { print $uid . "\\n" }''"''"'' )'' -- $cur ) )\n	else\n	    # make do with /etc/passwd\n	    COMPREPLY=( $( awk ''BEGIN {FS=":"} {if ($3 ~ /^''$cur''/) print $3}''\\\n			    /etc/passwd ) )\n	fi\n}\n\n# This function completes on group IDs\n#\n_gids()\n{\n	if type getent &>/dev/null; then\n	    COMPREPLY=( $( getent group | \\\n			    awk -F: ''{if ($3 ~ /^''$cur''/) print $3}'' ) )\n	elif type perl &>/dev/null; then\n	    COMPREPLY=( $( compgen -W ''$( perl -e ''"''"''while (($gid) = (getgrent)[2]) { print $gid . "\\n" }''"''"'' )'' -- $cur ) )\n	else\n	    # make do with /etc/group\n	    COMPREPLY=( $( awk ''BEGIN {FS=":"} {if ($3 ~ /^''$cur''/) print $3}''\\\n			    /etc/group ) )\n	fi\n}\n\n# This function completes on services\n#\n_services()\n{\n	local sysvdir famdir\n	[ -d /etc/rc.d/init.d ] && sysvdir=/etc/rc.d/init.d || sysvdir=/etc/init.d\n	famdir=/etc/xinetd.d\n	COMPREPLY=( $( builtin echo $sysvdir/!(*.rpmsave|*.rpmorig|*~|functions)) )\n\n	if [ -d $famdir ]; then\n		COMPREPLY=( ${COMPREPLY[@]} $( builtin echo $famdir/!(*.rpmsave|*.rpmorig|*~)) )\n	fi\n\n	COMPREPLY=( $( compgen -W ''${COMPREPLY[@]#@($sysvdir|$famdir)/}'' -- $cur ) )\n}\n\n# This function complete on modules\n#\n_modules()\n{\n	local modpath\n	modpath=/lib/modules/$1\n	COMPREPLY=( $( command ls -R $modpath | \\\n			sed -ne ''s/^\\(''$cur''.*\\)\\.k\\?o\\(\\|.gz\\)$/\\1/p'') )\n}\n\n# this function complete on user:group format\n#\n_usergroup()\n{\n	local IFS=$''\\n''\n	cur=${cur//\\\\\\\\ / }\n	if [[ $cur = *@(\\\\:|.)* ]] && [ -n "$bash205" ]; then\n		user=${cur%%*([^:.])}\n		COMPREPLY=( $(compgen -P ${user/\\\\\\\\} -g -- ${cur##*[.:]}) )\n	elif [[ $cur = *:* ]] && [ -n "$bash205" ]; then\n		COMPREPLY=( $( compgen -g -- ${cur##*[.:]} ) )\n	else\n		COMPREPLY=( $( compgen -S : -u -- $cur ) )\n	fi\n}\n\n# this function count the number of mandatory args\n#\n_count_args()\n{\n	args=1\n	for (( i=1; i < COMP_CWORD; i++ )); do\n		if [[ "${COMP_WORDS[i]}" != -* ]]; then\n			args=$(($args+1))\n		fi\n	done\n}\n\n# start of section containing completion functions for bash built-ins\n\n# bash alias completion\n#\n_alias()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[$COMP_CWORD]}\n\n	case "$COMP_LINE" in\n	*[^=])\n		COMPREPLY=( $( compgen -A alias -S ''='' -- $cur ) )\n		;;\n	*=)\n		COMPREPLY=( "$( alias ${cur%=} 2>/dev/null | \\\n			     sed -e ''s|^alias ''$cur''\\(.*\\)$|\\1|'' )" )\n		;;\n	esac\n}\ncomplete -F _alias $nospace alias\n\n# bash export completion\n#\n_export()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[$COMP_CWORD]}\n\n	case "$COMP_LINE" in\n	*=\\$*)\n		COMPREPLY=( $( compgen -v -P ''$'' -- ${cur#*=\\$} ) )\n		;;\n	*[^=])\n		COMPREPLY=( $( compgen -v -S ''='' -- $cur ) )\n		;;\n	*=)\n		COMPREPLY=( "$( eval echo -n \\"$`echo ${cur%=}`\\" |\n			( echo -n \\''\n			  sed -e ''s/''\\''''/''\\''''\\\\\\''\\''''''\\''''/g''\n			  echo -n \\'' ) )" )\n		;;\n	esac\n}\ncomplete -F _export $default $nospace export\n\n# bash shell function completion\n#\n_function()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [[ $1 == @(declare|typeset) ]]; then\n		if [ "$prev" = -f ]; then\n			COMPREPLY=( $( compgen -A function -- $cur ) )\n		elif [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''-a -f -F -i -r -x -p'' -- \\\n				       $cur ) )\n		fi\n	elif [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -A function -- $cur ) )\n	else\n		COMPREPLY=( "() $( type -- ${COMP_WORDS[1]} | sed -e 1,2d )" )\n	fi\n}\ncomplete -F _function function declare typeset\n\n# bash complete completion\n#\n_complete()\n{\n	local cur prev options\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		-o)\n			options="default dirnames filenames"\n			[ -n "$bash205b" ] && options="$options nospace"\n			[ -n "$bash3" ] && options="$options bashdefault plusdirs"\n			COMPREPLY=( $( compgen -W "$options" -- $cur ) )\n			return 0\n			;;\n\n		-A)\n			COMPREPLY=( $( compgen -W ''alias arrayvar binding \\\n				builtin command directory disabled enabled \\\n				export file function group helptopic hostname \\\n				job keyword running service setopt shopt \\\n				signal stopped user variable'' -- $cur ) )\n			return 0\n			;;\n\n		-C)\n			COMPREPLY=( $( compgen -A command -- $cur ) )\n			return 0\n			;;\n		-F)\n			COMPREPLY=( $( compgen -A function -- $cur ) )\n			return 0\n			;;\n		-@(p|r))\n			COMPREPLY=( $( complete -p | sed -e ''s|.* ||'' | \\\n					grep "^$cur" ) )\n			return 0\n			;;\n\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		# relevant options completion\n		options="-a -b -c -d -e -f -g -j -k -s -v -u -A -G -W -P -S -X -F -C"\n		[ -n "$bash205" ] && options="$options -o"\n		COMPREPLY=( $( compgen -W "$options" -- $cur ) )\n	else\n		COMPREPLY=( $( compgen -A command -- $cur ) )\n	fi\n}\ncomplete -F _complete complete\n\n# start of section containing completion functions for external programs\n\n# a little help for FreeBSD ports users\n[ $UNAME = FreeBSD ] && complete -W ''index search fetch fetch-list \\\n	extract patch configure build install reinstall \\\n	deinstall clean clean-depends kernel buildworld'' make\n\n# This completes on a list of all available service scripts for the\n# ''service'' command and/or the SysV init.d directory, followed by\n# that script''s available commands\n#\n{ have service || [ -d /etc/init.d/ ]; } &&\n_service()\n{\n	local cur sysvdir\n\n	COMPREPLY=()\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	# don''t complete for things like killall, ssh and mysql if it''s\n	# the standalone command, rather than the init script\n	[[ ${COMP_WORDS[0]} != @(*init.d/!(functions|~)|service) ]] && return 0\n\n	# don''t complete past 2nd token\n	[ $COMP_CWORD -gt 2 ] && return 0\n\n	[ -d /etc/rc.d/init.d ] && sysvdir=/etc/rc.d/init.d \\\n				|| sysvdir=/etc/init.d\n\n	if [[ $COMP_CWORD -eq 1 ]] && [[ $prev == "service" ]]; then\n		_services\n	else\n		COMPREPLY=( $( compgen -W ''`sed -ne "y/|/ /; \\\n				s/^.*Usage.*{\\(.*\\)}.*$/\\1/p" \\\n				$sysvdir/${prev##*/} 2>/dev/null`'' -- $cur ) )\n	fi\n\n	return 0\n} &&\ncomplete -F _service service\n[ -d /etc/init.d/ ] && complete -F _service $default \\\n	$(for i in /etc/init.d/*; do echo ${i##*/}; done)\n\n# chown(1) completion\n#\n_chown()\n{\n	local cur\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	# options completion\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-c -h -f -R -v --changes \\\n		--dereference --no-dereference --from= --silent --quiet \\\n		--reference= --recursive --verbose --help --version'' -- $cur ) )\n	else\n		_count_args\n\n		case $args in\n			1)\n				_usergroup\n				;;\n			*)\n				_filedir\n				;;\n		esac\n	fi\n}\ncomplete -F _chown $filenames chown\n\n# chgrp(1) completion\n#\n_chgrp()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	cur=${cur//\\\\\\\\/}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# options completion\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-c -h -f -R -v --changes \\\n		--dereference --no-dereference --silent --quiet \\\n		--reference= --recursive --verbose --help --version'' -- $cur ) )\n		return 0\n	fi\n\n	# first parameter on line or first since an option?\n	if [ $COMP_CWORD -eq 1 ] && [[ "$cur" != -* ]] || \\\n	   [[ "$prev" == -* ]] && [ -n "$bash205" ]; then\n		local IFS=$''\\n''\n		COMPREPLY=( $( compgen -g $cur 2>/dev/null ) )\n	else\n		_filedir || return 0\n	fi\n\n	return 0\n}\ncomplete -F _chgrp $filenames chgrp\n\n# umount(8) completion. This relies on the mount point being the third\n# space-delimited field in the output of mount(8)\n#\n_umount()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( compgen -W ''$( mount | cut -d" " -f 3 )'' -- $cur ) )\n\n	return 0\n}\ncomplete -F _umount $dirnames umount\n\n# mount(8) completion. This will pull a list of possible mounts out of\n# /etc/{,v}fstab, unless the word being completed contains a '':'', which\n# would indicate the specification of an NFS server. In that case, we\n# query the server for a list of all available exports and complete on\n# that instead.\n#\n_mount()\n{       local cur i sm host\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	[[ "$cur" == \\\\ ]] && cur="/"\n\n	for i in {,/usr}/{,s}bin/showmount; do [ -x $i ] && sm=$i && break; done\n\n	if [ -n "$sm" ] && [[ "$cur" == *:* ]]; then\n		COMPREPLY=( $( $sm -e ${cur%%:*} | sed 1d | \\\n			       grep ^${cur#*:} | awk ''{print $1}'' ) )\n	elif [[ "$cur" == //* ]]; then\n		host=${cur#//}\n		host=${host%%/*}\n		if [ -n "$host" ]; then\n			COMPREPLY=( $( compgen -W "$( echo $( smbclient -d 0 -NL $host 2>/dev/null|\n			sed -ne ''/^[''"$''\\t ''"'']*Sharename/,/^$/p'' |\n			sed -ne ''3,$s|^[^A-Za-z]*\\([^''"$''\\t ''"'']*\\).*$|//''$host''/\\1|p'' ) )" -- "$cur" ) )\n		fi\n	elif [ -r /etc/vfstab ]; then\n		# Solaris\n		COMPREPLY=( $( awk ''! /^[ \\t]*#/ {if ($3 ~ /\\//) print $3}'' \\\n				/etc/vfstab | grep "^$cur" ) )\n	elif [ ! -e /etc/fstab ]; then\n		# probably Cygwin\n		COMPREPLY=( $( mount | awk ''! /^[ \\t]*#/ {if ($3 ~ /\\//) print $3}'' \\\n				 | grep "^$cur" ) )\n	else\n		# probably Linux\n		COMPREPLY=( $( awk ''! /^[ \\t]*#/ {if ($2 ~ /\\//) print $2}'' \\\n				/etc/fstab | grep "^$cur" ) )\n	fi\n\n	return 0\n}\ncomplete -F _mount $default $filenames mount\n\n# Linux rmmod(8) completion. This completes on a list of all currently\n# installed kernel modules.\n#\nhave rmmod && {\n_rmmod()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( /sbin/lsmod | \\\n		  awk ''{if (NR != 1 && $1 ~ /^''$cur''/) print $1}'' 2>/dev/null ))\n	return 0\n}\ncomplete -F _rmmod rmmod\n\n# Linux insmod(8), modprobe(8) and modinfo(8) completion. This completes on a\n# list of all available modules for the version of the kernel currently\n# running.\n#\n_insmod()\n{\n	local cur prev modpath\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# behave like lsmod for modprobe -r\n	if [ $1 = "modprobe" ] &&\n	   [ "${COMP_WORDS[1]}" = "-r" ]; then\n		COMPREPLY=( $( /sbin/lsmod | \\\n				awk ''{if (NR != 1 && $1 ~ /^''$cur''/) print $1}'' ) )\n		return 0\n	fi\n\n	# do filename completion if we''re giving a path to a module\n	if [[ "$cur" == */* ]]; then\n		_filedir ''@(?(k)o?(.gz))''\n		return 0\n	fi\n\n	if [ $COMP_CWORD -gt 1 ] && \n	   [[ "${COMP_WORDS[COMP_CWORD-1]}" != -* ]]; then\n		# do module parameter completion\n		COMPREPLY=( $( /sbin/modinfo -p ${COMP_WORDS[1]} 2>/dev/null | \\\n		       awk ''{if ($1 ~ /^parm:/ && $2 ~ /^''$cur''/) { print $2 } \\\n			else if ($1 !~ /:/ && $1 ~ /^''$cur''/) { print $1 }}'' ) )\n	else\n		_modules $(uname -r)\n	fi\n\n	return 0\n}\ncomplete -F _insmod $filenames insmod modprobe modinfo\n}\n\n# man(1) completion\n#\n[ $UNAME = GNU -o $UNAME = Linux -o $UNAME = Darwin \\\n  -o $UNAME = FreeBSD -o $UNAME = SunOS -o $UNAME = Cygwin \\\n  -o $UNAME = OpenBSD ] &&\n_man()\n{\n	local cur prev sect manpath UNAME\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	_expand || return 0\n\n	# default completion if parameter contains /\n	if [[ "$cur" == */* ]]; then\n		_filedir\n		return 0\n	fi\n\n	UNAME=$( uname -s )\n	# strip OS type and version under Cygwin\n	UNAME=${UNAME/CYGWIN_*/Cygwin}\n	if [ $UNAME = GNU -o $UNAME = Linux -o $UNAME = FreeBSD \\\n	     -o $UNAME = Cygwin ]; then\n		manpath=$( manpath 2>/dev/null || command man --path )\n	else\n		manpath=$MANPATH\n	fi\n\n	if [ -z "$manpath" ]; then\n		COMPREPLY=( $( compgen -c -- $cur ) )\n		return 0\n	fi\n\n	# determine manual section to search\n	[[ "$prev" == [0-9ln] ]] && sect=$prev || sect=''*''\n\n	manpath=$manpath:\n	if [ -n "$cur" ]; then\n		manpath="${manpath//://*man$sect/$cur* } ${manpath//://*cat$sect/$cur* }"\n	else\n		manpath="${manpath//://*man$sect/ } ${manpath//://*cat$sect/ }"\n	fi\n		\n	# redirect stderr for when path doesn''t exist\n	COMPREPLY=( $( eval command ls "$manpath" 2>/dev/null ) )\n	# weed out directory path names and paths to man pages\n	COMPREPLY=( ${COMPREPLY[@]##*/?(:)} )\n	# strip suffix from man pages\n	COMPREPLY=( ${COMPREPLY[@]%.@(gz|bz2)} )\n	COMPREPLY=( $( compgen -W ''${COMPREPLY[@]%.*}'' -- "${cur//\\\\\\\\/}" ) )\n\n	[[ "$prev" != [0-9ln] ]] && _filedir ''[0-9ln]''\n\n	return 0\n}\n[ $UNAME = GNU -o $UNAME = Linux -o $UNAME = Darwin \\\n  -o $UNAME = FreeBSD -o $UNAME = SunOS -o $UNAME = Cygwin \\\n  -o $UNAME = OpenBSD ] && \\\ncomplete -F _man $filenames man\n\n# renice(8) completion\n#\n_renice()\n{\n	local command cur curopt i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	command=$1\n\n	i=0\n	# walk back through command line and find last option\n	while [ $i -le $COMP_CWORD -a ${#COMPREPLY[@]} -eq 0 ]; do\n		curopt=${COMP_WORDS[COMP_CWORD-$i]}\n		case "$curopt" in\n		-u)\n			COMPREPLY=( $( compgen -u -- $cur ) )\n			;;\n		-g)\n			_pgids\n			;;\n		-p|$command)\n			_pids\n			;;\n		esac\n		i=$(( ++i ))\n	done\n}\ncomplete -F _renice renice\n\n# kill(1) completion\n#\n_kill()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ] && [[ "$cur" == -* ]]; then\n		# return list of available signals\n		_signals\n	else\n		# return list of available PIDs\n		_pids\n	fi\n}\ncomplete -F _kill kill\n\n# Linux and FreeBSD killall(1) completion.\n#\n[ $UNAME = Linux -o $UNAME = FreeBSD ] &&\n_killall()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ] && [[ "$cur" == -* ]]; then\n		_signals\n	else\n		COMPREPLY=( $( compgen -W ''$( command ps axo command | \\\n			      sed -ne "1d; s/^\\[\\?\\([^-][^] ]*\\).*$/\\1/p" | \\\n			      sed -e "s/.*\\///" )'' -- $cur ) )\n	fi\n\n	return 0\n}\n[ $UNAME = Linux -o $UNAME = FreeBSD ] && complete -F _killall killall pkill\n\n# Linux and FreeBSD pgrep(1) completion.\n#\n[ $UNAME = Linux -o $UNAME = FreeBSD ] &&\n_pgrep()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( compgen -W ''$( command ps axo command | \\\n		      sed -ne "1d; s/^\\[\\?\\([^-][^] ]*\\).*$/\\1/p" | \\\n		      sed -e "s/.*\\///" )'' -- $cur ) )\n\n	return 0\n}\n[ $UNAME = Linux -o $UNAME = FreeBSD ] && complete -F _pgrep pgrep\n# Linux pidof(8) completion.\n[ $UNAME = Linux ] && complete -F _pgrep pidof\n\n# GNU find(1) completion. This makes heavy use of ksh style extended\n# globs and contains Linux specific code for completing the parameter\n# to the -fstype option.\n#\n_find()\n{\n	local cur prev i exprfound onlyonce\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-@(max|min)depth)\n		COMPREPLY=( $( compgen -W ''0 1 2 3 4 5 6 7 8 9'' -- $cur ) )\n		return 0\n		;;\n	-?(a|c)newer|-fls|-fprint?(0|f)|-?(i)?(l)name)\n		_filedir\n		return 0\n		;;\n	-fstype)\n		# this is highly non-portable\n		[ -e /proc/filesystems ] &&\n		COMPREPLY=( $( cut -d$''\\t'' -f 2 /proc/filesystems | \\\n				grep "^$cur" ) )\n		return 0\n		;;\n	-gid)\n		_gids\n		return 0\n		;;\n	-group)\n		if [ -n "$bash205" ]; then\n			COMPREPLY=( $( compgen -g -- $cur 2>/dev/null) )\n		fi\n		return 0\n		;;\n	-?(x)type)\n		COMPREPLY=( $( compgen -W ''b c d p f l s'' -- $cur ) )\n		return 0\n		;;\n	-uid)\n		_uids\n		return 0\n		;;\n	-user)\n		COMPREPLY=( $( compgen -u -- $cur ) )\n		return 0\n		;;\n	-exec|-ok)\n		COMP_WORDS=(COMP_WORDS[0] $cur)\n		COMP_CWORD=1\n		_command\n		return 0\n		;;\n	-[acm]min|-[acm]time|-?(i)?(l)name|-inum|-?(i)path|-?(i)regex| \\\n	-links|-perm|-size|-used|-printf)\n		# do nothing, just wait for a parameter to be given\n		return 0\n		;;\n	esac\n\n	_expand || return 0\n\n	# set exprfound to 1 if there is already an expression present\n	for i in ${COMP_WORDS[@]}; do\n		[[ "$i" = [-\\(\\),\\!]* ]] && exprfound=1 && break\n	done\n\n	# handle case where first parameter is not a dash option\n	if [ "$exprfound" != 1 ] && [[ "$cur" != [-\\(\\),\\!]* ]]; then\n		_filedir -d\n		return 0\n	fi\n\n	# complete using basic options\n	COMPREPLY=( $( compgen -W ''-daystart -depth -follow -help -maxdepth \\\n			-mindepth -mount -noleaf -version -xdev -amin -anewer \\\n			-atime -cmin -cnewer -ctime -empty -false -fstype \\\n			-gid -group -ilname -iname -inum -ipath -iregex \\\n			-links -lname -mmin -mtime -name -newer -nouser \\\n			-nogroup -perm -regex -size -true -type -uid -used \\\n			-user -xtype -exec -fls -fprint -fprint0 -fprintf -ok \\\n			-print -print0 -printf -prune -ls'' -- $cur ) )\n\n	# this removes any options from the list of completions that have\n	# already been specified somewhere on the command line, as long as\n	# these options can only be used once (in a word, "options", in\n	# opposition to "tests" and "actions", as in the find(1) manpage).\n	onlyonce='' -daystart -depth -follow -help -maxdepth -mindepth -mount \\\n		   -noleaf -version -xdev ''\n	COMPREPLY=( $( echo "${COMP_WORDS[@]}" | \\\n		       (while read -d '' '' i; do\n			    [ "$i" == "" ] ||\n			    [ "${onlyonce/ ${i%% *} / }" == "$onlyonce" ] &&\n			    continue\n			    # flatten array with spaces on either side,\n			    # otherwise we cannot grep on word boundaries of\n			    # first and last word\n			    COMPREPLY=" ${COMPREPLY[@]} "\n			    # remove word from list of completions\n			    COMPREPLY=( ${COMPREPLY/ ${i%% *} / } )\n			done\n			echo ${COMPREPLY[@]})\n		  ) )\n	\n	_filedir\n	\n	return 0\n}\ncomplete -F _find $filenames find\n\n# Linux iwconfig(8) completion\n#\n[ $UNAME = Linux ] && have iwconfig &&\n_iwconfig()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	\n	case $prev in\n		mode)\n			COMPREPLY=( $( compgen -W ''managed ad-hoc master \\\n				repeater secondary monitor'' -- $cur ) )\n			return 0\n			;;\n		essid)\n			COMPREPLY=( $( compgen -W ''on off any'' -- $cur ) )\n			if [ -n "${COMP_IWLIST_SCAN:-}" ]; then\n				COMPREPLY=( ${COMPREPLY[@]:-} \\\n					$( iwlist ${COMP_WORDS[1]} scan | \\\n					awk -F ''"'' ''/ESSID/ {print $2}'' | \\\n					grep "^$cur" ))\n			fi\n			return 0\n			;;\n		nwid)\n			COMPREPLY=( $( compgen -W ''on off'' -- $cur ) )\n			return 0\n			;;\n		channel)\n			COMPREPLY=( $( iwlist ${COMP_WORDS[1]} channel | \\\n				awk ''/^[[:space:]]*Channel/ {print $2}'' | \\\n				grep "^$cur" ) )\n			return 0\n			;;\n\n		freq)\n			COMPREPLY=( $( iwlist ${COMP_WORDS[1]} channel | \\\n				awk ''/^[[:space:]]*Channel/ {print $4"G"}'' | \\\n				grep "^$cur" ) )\n			return 0\n			;;\n		ap)\n			COMPREPLY=( $( compgen -W ''on off any'' -- $cur ) )\n			if [ -n "${COMP_IWLIST_SCAN:-}" ]; then\n				COMPREPLY=( ${COMPREPLY[@]:-} \\\n					$( iwlist ${COMP_WORDS[1]} scan | \\\n					awk -F '': '' ''/Address/ {print $2}'' | \\\n					grep "^$cur" ) )\n			fi\n			return 0\n			;;\n		rate)\n			COMPREPLY=( $( compgen -W ''auto fixed'' -- $cur ) )\n			COMPREPLY=( ${COMPREPLY[@]:-} \\\n				$( iwlist ${COMP_WORDS[1]} rate | \\\n				awk ''/^[[:space:]]*[0-9]/ {print $1"M"}'' | \\\n				grep "^$cur" ) )\n			return 0\n			;;\n		rts)\n			COMPREPLY=( $( compgen -W ''auto fixed off'' -- $cur ) )\n			return 0\n			;;\n		frag)\n			COMPREPLY=( $( compgen -W ''auto fixed off'' -- $cur ) )\n			return 0\n			;;\n		key)\n			COMPREPLY=( $( compgen -W ''off on open restricted'' -- $cur ) )\n			return 0\n			;;\n		enc)\n			COMPREPLY=( $( compgen -W ''off on open restricted'' -- $cur ) )\n			return 0\n			;;\n		power)\n			COMPREPLY=( $( compgen -W ''period timeout off on'' -- $cur ) )\n			return 0\n			;;\n		txpower)\n			COMPREPLY=( $( compgen -W ''off on auto'' -- $cur ) )\n			return 0\n			;;\n		retry)\n			COMPREPLY=( $( compgen -W ''limit lifetime'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--help --version'' -- $cur ) ) \n		else\n			_available_interfaces -w\n		fi\n	else\n		COMPREPLY=( $( compgen -W ''essid nwid mode freq channel sens mode \\\n			ap nick rate rts frag enc key power txpower commit'' -- $cur ) ) \n	fi\n\n} &&\ncomplete -F _iwconfig iwconfig\n\n# Linux iwlist(8) completion\n#\n[ $UNAME = Linux ] && have iwlist &&\n_iwlist()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	\n	if [ $COMP_CWORD -eq 1 ]; then\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--help --version'' -- $cur ) ) \n		else\n			_available_interfaces -w\n		fi\n	else\n		COMPREPLY=( $( compgen -W ''scan scanning freq frequency \\\n			channel rate bit bitrate key enc encryption power \\\n			txpower retry ap accesspoint peers event'' -- $cur ) ) \n	fi\n} &&\ncomplete -F _iwlist iwlist\n\n# Linux iwspy(8) completion\n#\n[ $UNAME = Linux ] && have iwspy &&\n_iwspy()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--help --version'' -- $cur ) ) \n		else\n			_available_interfaces -w\n		fi\n	else\n		COMPREPLY=( $( compgen -W ''setthr getthr off'' -- $cur ) ) \n	fi\n} &&\ncomplete -F _iwspy iwspy\n\n# Linux iwpriv(8) completion\n#\n[ $UNAME = Linux ] && have iwpriv &&\n_iwpriv()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		roam)\n			COMPREPLY=( $( compgen -W ''on off'' -- $cur ) )\n			return 0\n			;;\n		port)\n			COMPREPLY=( $( compgen -W ''ad-hoc managed'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--help --version'' -- $cur ) ) \n		else\n			_available_interfaces -w\n		fi\n	else\n		COMPREPLY=( $( compgen -W ''--all roam port'' -- $cur ) ) \n	fi\n} &&\ncomplete -F _iwpriv iwpriv\n\n# RedHat & Debian GNU/Linux if{up,down} completion\n#\n[ $UNAME = Linux ] && { have ifup || have ifdown; } &&\n_ifupdown()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		_configured_interfaces\n       fi\n\n       return 0\n} &&\ncomplete -F _ifupdown ifup ifdown\n[ $UNAME = Linux ] && have ifstatus && complete -F _ifupdown ifstatus\n\n# Linux ipsec(8) completion (for FreeS/WAN)\n#\n[ $UNAME = Linux ] && have ipsec &&\n_ipsec()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -W ''auto barf eroute klipsdebug look \\\n					   manual pluto ranbits rsasigkey \\\n					   setup showdefaults showhostkey spi \\\n					   spigrp tncfg whack'' -- $cur ) )\n		return 0\n	fi\n\n	case ${COMP_WORDS[1]} in\n	auto)\n		COMPREPLY=( $( compgen -W ''--asynchronous --up --add --delete \\\n					   --replace --down --route --unroute \\\n					   --ready --status --rereadsecrets'' \\\n					-- $cur ) )\n		;;\n	manual)\n		COMPREPLY=( $( compgen -W ''--up --down --route --unroute \\\n					   --union'' -- $cur ) )\n		;;\n	ranbits)\n		COMPREPLY=( $( compgen -W ''--quick --continuous --bytes'' \\\n					  -- $cur ) )\n		;;\n	setup)\n		COMPREPLY=( $( compgen -W ''--start --stop --restart'' -- $cur ) )\n		;;\n\n	*)\n		;;\n	esac\n\n	return 0\n} &&\ncomplete -F _ipsec ipsec\n\n# Postfix completion.\n#\nhave postfix && {\n# postfix(1)\n#\n_postfix()\n{\n	local cur prev\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [[ $cur == ''-'' ]]; then\n		COMPREPLY=(-c -D -v)\n		return 0\n	fi\n	if [[ $prev == ''-c'' ]]; then\n		_filedir -d\n		return 0\n	fi\n	if [[ $prev == ''-D'' ]]; then\n		COMPREPLY=( $( compgen -W ''start'' -- "${COMP_WORDS[COMP_CWORD]}" ) )\n		return 0\n	fi\n	COMPREPLY=( $( compgen -W ''start stop reload abort flush check'' -- \\\n		"${COMP_WORDS[COMP_CWORD]}" ) )\n}\ncomplete -F _postfix postfix\n\n# postalias(1) and postmap(1)\n#\n_postmap()\n{\n	local cur prev len idx\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [[ $cur == ''-'' ]]; then\n		COMPREPLY=(-N -f -i -n -o -p -r -v -w -c -d -q)\n		return 0\n	fi\n	if [[ $prev == ''-c'' ]]; then\n		_filedir -d\n		return 0\n	fi\n	if [[ $prev == -[dq] ]]; then\n		return 0\n	fi\n\n	if [[ "$cur" == *:* ]]; then\n	       	COMPREPLY=( $( compgen -f -- ${cur#*:} ) )\n	else\n		len=${#cur}\n		idx=0\n		for pval in $( /usr/sbin/postconf -m ); do\n			if [[ "$cur" == "${pval:0:$len}" ]]; then\n				COMPREPLY[$idx]="$pval:"\n				idx=$(($idx+1))\n			fi\n		done\n		if [[ $idx -eq 0 ]]; then\n			COMPREPLY=( $( compgen -f -- "$cur" ) )\n		fi\n	fi\n	return 0\n}\ncomplete -F _postmap postmap postalias\n\n# postcat(1)\n#\n_postcat()\n{\n	local cur prev pval len idx qfile\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [[ $cur == ''-'' ]]; then\n		COMPREPLY=(-c -q -v)\n		return 0\n	fi\n	if [[ $prev == ''-c'' ]]; then\n		_filedir -d\n		return 0\n	fi\n\n	qfile=0\n	for idx in ${COMP_WORDS[@]}; do\n		[[ "$idx" = -q ]] && qfile=1 && break\n	done\n	if [[ $qfile == 1 ]]; then\n		len=${#cur}\n		idx=0\n		for pval in $( mailq | \\\n			sed -e ''1d; $d; /^[^0-9A-Z]\\|^$/d; s/[* !].*$//'' ); do\n			if [[ "$cur" == "${pval:0:$len}" ]]; then\n				COMPREPLY[$idx]=$pval\n				idx=$(($idx+1))\n			fi\n		done\n		return 0\n	else\n		_filedir\n		return 0\n	fi\n}\ncomplete -F _postcat postcat\n\n# postconf(1)\n#\n_postconf()\n{\n	local cur prev pval len idx eqext\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	if [[ $cur == ''-'' ]]; then\n		COMPREPLY=(-c -d -e -h -m -l -n -v)\n		return 0\n	fi\n	if [[ $prev == ''-c'' ]]; then\n		_filedir -d\n		return 0\n	fi\n	if [[ $prev == ''-e'' ]]; then\n		cur=${cur#[\\"\\'']}\n		eqext=''=''\n	fi\n	len=${#cur}\n	idx=0\n	for pval in $( /usr/sbin/postconf | cut -d '' '' -f 1 ); do\n		if [[ "$cur" == "${pval:0:$len}" ]]; then\n			COMPREPLY[$idx]="$pval$eqext"\n			idx=$(($idx+1))\n		fi\n	done\n	return 0\n}\ncomplete -F _postconf postconf\n\n# postsuper(1)\n#\n_postsuper()\n{\n	local cur prev pval len idx\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [[ $cur == ''-'' ]]; then\n		COMPREPLY=(-c -d -h -H -p -r -s -v)\n		return 0\n	fi\n	case $prev in\n	-[dr])\n		len=${#cur}\n		idx=0\n		for pval in $( echo ALL; mailq | \\\n			sed -e ''1d; $d; /^[^0-9A-Z]\\|^$/d; s/[* !].*$//'' ); do\n			if [[ "$cur" == "${pval:0:$len}" ]]; then\n				COMPREPLY[$idx]=$pval\n				idx=$(($idx+1))\n			fi\n		done\n		return 0\n		;;\n	-h)\n		len=${#cur}\n		idx=0\n		for pval in $( echo ALL; mailq | \\\n			sed -e ''1d; $d; /^[^0-9A-Z]\\|^$/d; s/[* ].*$//; /!$/d'' ); do\n			if [[ "$cur" == "${pval:0:$len}" ]]; then\n				COMPREPLY[$idx]=$pval\n				idx=$(($idx+1))\n			fi\n		done\n		return 0\n		;;\n	-H)\n		len=${#cur}\n		idx=0\n		for pval in $( echo ALL; mailq | \\\n			sed -e ''1d; $d; /^[^0-9A-Z]\\|^$/d; /^[0-9A-Z]*[* ]/d; s/!.*$//'' ); do\n			if [[ "$cur" == "${pval:0:$len}" ]]; then\n				COMPREPLY[$idx]=$pval\n				idx=$(($idx+1))\n			fi\n		done\n		return 0\n		;;\n	esac\n	COMPREPLY=( $( compgen -W ''hold incoming active deferred'' -- $cur ) )\n	return 0\n}\ncomplete -F _postsuper postsuper\n}\n\n# cvs(1) completion\n#\nhave cvs && {\nset_prefix()\n{\n	[ -z ${prefix:-} ] || prefix=${cur%/*}/\n	[ -r ${prefix:-}CVS/Entries ] || prefix=""\n}\n\nget_entries()\n{\n	local IFS=$''\\n''\n	[ -r ${prefix:-}CVS/Entries ] && \\\n	entries=$(cut -d/ -f2 -s ${prefix:-}CVS/Entries)\n}\n\nget_modules()\n{\n	if [ -n "$prefix" ]; then \n		COMPREPLY=( $( command ls -d ${cvsroot}/${prefix}/!(CVSROOT) ) )\n	else\n		COMPREPLY=( $( command ls -d ${cvsroot}/!(CVSROOT) ) )\n	fi\n}\n\n_cvs()\n{\n	local cur count mode i cvsroot cvsroots pwd\n	local -a flags miss files entries changed newremoved\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	count=0\n	for i in ${COMP_WORDS[@]}; do\n		[ $count -eq $COMP_CWORD ] && break\n		# Last parameter was the CVSROOT, now go back to mode selection\n		if [ "${COMP_WORDS[((count))]}" == "$cvsroot" -a "$mode" == "cvsroot" ]; then\n			mode=""\n		fi\n		if [ -z "$mode" ]; then\n			case $i in\n			-d)\n				mode=cvsroot\n				cvsroot=${COMP_WORDS[((count+1))]}\n				;;\n			@(ad?(d)|new))\n				mode=add\n				;;\n			@(adm?(in)|rcs))\n				mode=admin\n				;;\n			ann?(notate))\n				mode=annotate\n				;;\n			@(checkout|co|get))\n				mode=checkout\n				;;\n			@(com?(mit)|ci))\n				mode=commit\n				;;\n			di?(f?(f)))\n				mode=diff\n				;;\n			ex?(p?(ort)))\n				mode=export\n				;;\n			?(un)edit)\n				mode=$i\n				;;\n			hi?(s?(tory)))\n				mode=history\n				;;\n			im?(p?(ort)))\n				mode=import\n				;;\n			re?(l?(ease)))\n				mode=release\n				;;\n			?(r)log)\n				mode=log\n				;;\n			@(rdiff|patch))\n				mode=rdiff\n				;;\n			@(remove|rm|delete))\n				mode=remove\n				;;\n			@(rtag|rfreeze))\n				mode=rtag\n				;;\n			st?(at?(us)))\n				mode=status\n				;;\n			@(tag|freeze))\n				mode=tag\n				;;\n			up?(d?(ate)))\n				mode=update\n				;;\n			*)\n				;;\n			esac\n		elif [[ "$i" = -* ]]; then\n			flags=( ${flags[@]:-} $i )\n		fi\n		count=$((++count))\n	done\n\n	case "$mode" in\n	add)\n		if [[ "$cur" != -* ]]; then\n			set_prefix\n			if [ $COMP_CWORD -gt 1 -a -r ${prefix:-}CVS/Entries ]; then\n				get_entries\n				[ -z "$cur" ] && \\\n				files=$( command ls -Ad !(CVS) ) || \\\n				files=$( command ls -d ${cur}* 2>/dev/null )\n				for i in ${entries[@]:-}; do\n					files=( ${files[@]/#$i//} )\n				done\n				COMPREPLY=( $( compgen -W ''${files[@]}'' -- \\\n					       $cur ) )\n			fi\n		else\n			COMPREPLY=( $( compgen -W ''-k -m'' -- $cur ) )\n		fi\n		;;\n	admin)\n		if [[ "$cur" = -* ]]; then\n			COMPREPLY=( $( compgen -W ''-i -a -A -e -b -c -k -l -u \\\n						   -L -U -m -M -n -N -o -q -I \\\n						   -s -t -t- -T -V -x -z'' -- \\\n					$cur ) )\n		fi\n		;;\n	annotate)\n		if [[ "$cur" = -* ]]; then\n			COMPREPLY=( $( compgen -W ''-D -F -f -l -R -r'' -- $cur ) )\n		else\n			get_entries\n			COMPREPLY=( $( compgen -W ''${entries[@]}'' -- $cur ) )\n		fi\n		;;\n	checkout)\n		if [[ "$cur" != -* ]]; then\n			[ -z "$cvsroot" ] && cvsroot=$CVSROOT\n			COMPREPLY=( $( cvs -d "$cvsroot" co -c 2> /dev/null | \\\n					awk ''{print $1}'' ) )\n			COMPREPLY=( $( compgen -W ''${COMPREPLY[@]}'' -- $cur ) )\n		else\n			COMPREPLY=( $( compgen -W ''-A -N -P -R -c -f -l -n -p \\\n						  -s -r -D -d -k -j'' -- $cur ) )\n		fi\n		;;\n	commit)\n		set_prefix\n\n		if [[ "$cur" != -* ]] && [ -r ${prefix:-}CVS/Entries ]; then\n			# if $COMP_CVS_REMOTE is not null, ''cvs commit'' will\n			# complete on remotely checked-out files (requires\n			# passwordless access to the remote repository\n			if [ -n "${COMP_CVS_REMOTE:-}" ]; then\n				# this is the least computationally intensive\n				# way found so far, but other changes\n				# (something other than changed/removed/new)\n				# may be missing\n				changed=( $( cvs -q diff --brief 2>&1 | \\\n				sed -ne ''s/^Files [^ ]* and \\([^ ]*\\) differ$/\\1/p'' ) )\n				newremoved=( $( cvs -q diff --brief 2>&1 | \\\n				sed -ne ''s/^cvs diff: \\([^ ]*\\) .*, no comparison available$/\\1/p'' ) )\n				COMPREPLY=( $( compgen -W ''${changed[@]:-} \\\n						   ${newremoved[@]:-}'' -- $cur ) )\n			else\n				_filedir\n			fi\n		else\n			COMPREPLY=( $( compgen -W ''-n -R -l -f -F -m -r'' -- \\\n				       $cur ) )\n		fi\n		;;\n	cvsroot)\n		if [ -r ~/.cvspass ]; then\n			# Ugly escaping because of bash treating '':'' specially\n			cvsroots=$( sed ''s/^[^ ]* //; s/:/\\\\:/g'' ~/.cvspass )\n			COMPREPLY=( $( compgen -W ''$cvsroots'' -- $cur ) )\n		fi\n		;;\n	export)\n		if [[ "$cur" != -* ]]; then\n			[ -z "$cvsroot" ] && cvsroot=$CVSROOT\n			COMPREPLY=( $( cvs -d "$cvsroot" co -c | awk ''{print $1}'' ) )\n			COMPREPLY=( $( compgen -W ''${COMPREPLY[@]}'' -- $cur ) )\n		else\n			COMPREPLY=( $( compgen -W ''-N -f -l -R -n \\\n						  -r -D -d -k'' -- $cur ) )\n		fi\n		;;\n	diff)\n		if [[ "$cur" == -* ]]; then\n			_longopt diff\n		else\n			get_entries\n			COMPREPLY=( $( compgen -W ''${entries[@]:-}'' -- $cur ) )\n		fi\n		;;\n	remove)\n		if [[ "$cur" != -* ]]; then\n			set_prefix\n			if [ $COMP_CWORD -gt 1 -a -r ${prefix:-}CVS/Entries ]; then\n				get_entries\n				# find out what files are missing\n				for i in ${entries[@]}; do\n					[ ! -r "$i" ] && miss=( ${miss[@]:-} $i )\n				done\n				COMPREPLY=( $(compgen -W ''${miss[@]:-}'' -- $cur) )\n			fi\n		else\n			COMPREPLY=( $( compgen -W ''-f -l -R'' -- $cur ) )\n		fi\n		;;\n	import)\n		if [[ "$cur" != -* ]]; then\n			# starts with same algorithm as checkout\n			[ -z "$cvsroot" ] && cvsroot=$CVSROOT\n			prefix=${cur%/*}\n			if [ -r ${cvsroot}/${prefix} ]; then\n				get_modules\n				COMPREPLY=( ${COMPREPLY[@]#$cvsroot} )\n				COMPREPLY=( ${COMPREPLY[@]#\\/} )\n			fi\n			pwd=$( pwd )\n			pwd=${pwd##*/}\n			COMPREPLY=( $( compgen -W ''${COMPREPLY[@]} $pwd'' -- \\\n				       $cur ) )\n		else\n			COMPREPLY=( $( compgen -W ''-d -k -I -b -m -W'' -- $cur ))\n		fi\n		;;\n	update)\n		if [[ "$cur" = -* ]]; then\n			COMPREPLY=( $( compgen -W ''-A -P -C -d -f -l -R -p \\\n						   -k -r -D -j -I -W'' -- \\\n						   $cur ) )\n		fi\n		;;\n	"")\n		COMPREPLY=( $( compgen -W ''add admin annotate checkout ci co \\\n					   commit diff delete edit export \\\n					   freeze get history import log new \\\n					   patch rcs rdiff release remove \\\n					   rfreeze rlog rm rtag stat status \\\n					   tag unedit up update -H -Q -q -b \\\n					   -d -e -f -l -n -t -r -v -w -x -z \\\n					   --help --version'' -- $cur ) )\n		;;\n	*)\n		;;\n	esac\n	\n	return 0\n}\ncomplete -F _cvs $default cvs\n}\n\nhave rpm && {\n# helper functions for rpm completion\n#\n_rpm_installed_packages()\n{\n	local ver nodig nosig\n\n	if [ -r /var/log/rpmpkgs -a \\\n		/var/log/rpmpkgs -nt /var/lib/rpm/Packages ]; then\n		# using RHL 7.2 or later - this is quicker than querying the DB\n		COMPREPLY=( $( sed -ne \\\n		''s|^\\(''$cur''.*\\)-[0-9a-zA-Z._]\\+-[0-9a-z.@]\\+.*\\.rpm$|\\1|p'' \\\n				/var/log/rpmpkgs ) )\n	else\n		nodig=""\n		nosig=""\n		ver=$(rpm --version)\n		ver=${ver##* }\n	  \n		if [[ "$ver" > "4.0.4" ]]; then\n			nodig="--nodigest"\n		fi\n		if [[ "$ver" > "4.0.99" ]]; then\n			nosig="--nosignature"\n		fi\n\n		COMPREPLY=( $( rpm -qa $nodig $nosig | sed -ne \\\n		''s|^\\(''$cur''.*\\)-[0-9a-zA-Z._]\\+-[0-9a-z.@]\\+$|\\1|p'' ) )\n	fi\n}\n\n_rpm_groups()\n{\n	local IFS=$''\\t''\n	# remove trailing backslash, or grep will complain\n	cur=${cur%"\\\\"}\n	COMPREPLY=( $( rpm -qa $nodig $nosig --queryformat ''%{group}\\n'' | \\\n		       grep "^$cur" ) )\n	# backslash escape spaces and translate newlines to tabs\n	COMPREPLY=( $( echo ${COMPREPLY[@]} | sed ''s/ /\\\\ /g'' | tr ''\\n'' ''\\t'' ) )\n}\n\n# rpm(8) completion\n# \n_rpm()\n{\n	local cur prev ver nodig nosig\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	nodig=""\n	nosig=""\n	ver=$(rpm --version); ver=${ver##* }\n  \n	if [[ "$ver" > "4.0.4" ]]; then\n		nodig="--nodigest"\n	fi\n	if [[ "$ver" > "4.0.99" ]]; then\n		nosig="--nosignature"\n	fi\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		# first parameter on line\n		case "$cur" in\n		-b*)\n			COMPREPLY=( $( compgen -W ''-ba -bb -bc -bi -bl -bp -bs''\\\n				       -- $cur ) )\n			;;\n		-t*)\n			COMPREPLY=( $( compgen -W ''-ta -tb -tc -ti -tl -tp -ts''\\\n				       -- $cur ) )\n			;;\n		--*)\n			COMPREPLY=( $( compgen -W ''--help --version --initdb \\\n			--checksig --recompile --rebuild --resign --addsign \\\n			--rebuilddb --showrc --setperms --setugids --tarbuild \\\n			--eval --install --upgrade --query --freshen --erase \\\n			--verify --querytags --rmsource --rmspec --clean \\\n			--import'' -- $cur ) )\n			;;\n		*)\n			COMPREPLY=( $( compgen -W ''-b -e -F -i -q -t -U -V'' \\\n				       -- $cur ) )\n			;;\n		esac\n\n	return 0\n	fi\n\n	case "$prev" in\n	--@(@(db|exclude)path|prefix|relocate|root))\n		_filedir -d\n		return 0\n		;;\n	--eval)\n		# get a list of macros\n		COMPREPLY=( $( sed -ne ''s|^\\(%''${cur#\\%}''[^ ''$''\\t'''']*\\).*$|\\1|p'' \\\n			       /usr/lib/rpm/macros ) )\n		return 0\n		;;\n	--pipe)\n		COMPREPLY=( $( compgen -c -- $cur ) )\n		return 0\n		;;\n	--rcfile)\n		_filedir\n		return 0\n		;;\n	--specfile)\n		# complete on .spec files\n		_filedir spec\n		return 0\n		;;\n	--whatprovides)\n		if [[ "$cur" == */* ]]; then\n			_filedir\n		else\n		# complete on capabilities\n			COMPREPLY=( $( rpm -qa $nodig $nosig --queryformat \\\n					''%{providename}\\n'' | grep "^$cur" ) )\n		fi\n		return 0\n		;;\n	--whatrequires)\n		# complete on capabilities\n		COMPREPLY=( $( rpm -qa $nodig $nosig --queryformat \\\n				''%{requirename}\\n'' | grep "^$cur" ) )\n		return 0\n		;;\n	esac\n\n	case "${COMP_WORDS[1]}" in\n	-@([iFU]*|-install|-freshen|-upgrade))\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--percent --force --test \\\n			--replacepkgs --replacefiles --root --excludedocs \\\n			--includedocs --noscripts --rcfile --ignorearch \\\n			--dbpath --prefix --ignoreos --nodeps --allfiles \\\n			--ftpproxy --ftpport --justdb --httpproxy --httpport \\\n			--noorder --relocate --badreloc --notriggers \\\n			--excludepath --ignoresize --oldpackage --define \\\n			--eval --pipe --queryformat --repackage --nosuggests \\\n			--nodigest --nosignature'' -- $cur ) )\n		else\n			_filedir ''rpm''\n		fi\n		;;\n	-@(e|-erase))\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--allmatches --noscripts \\\n			--notriggers --nodeps --test --repackage'' -- $cur ) )\n		else\n			_rpm_installed_packages\n		fi\n		;;\n	-@(q*|-query))\n		# check whether we''re doing file completion\n		if [ "${COMP_LINE#* -*([^ -])f}" != "$COMP_LINE" ]; then\n		    if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--scripts --root \\\n				--rcfile --requires --ftpport --ftpproxy \\\n				--httpproxy --httpport --provides --triggers \\\n				--dump --changelog --dbpath \\\n				--last --filesbypkg \\\n				--info --list --state \\\n				--docfiles --configfiles --queryformat \\\n				--conflicts --obsoletes \\\n				--nodigest --nosignature \\\n				--triggerscripts'' -- $cur ) )\n		    else\n			_filedir\n		    fi\n		elif [ "${COMP_LINE#* -*([^ -])g}" != "$COMP_LINE" ]; then\n			_rpm_groups\n		elif [ "${COMP_LINE#* -*([^ -])p}" != "$COMP_LINE" ]; then\n			# uninstalled package completion\n			if [[ "$cur" == -* ]]; then\n				COMPREPLY=( $( compgen -W ''--scripts --root \\\n				--rcfile --whatprovides --whatrequires \\\n				--requires --triggeredby --ftpport --ftpproxy \\\n				--httpproxy --httpport --provides --triggers \\\n				--dump --changelog --dbpath --filesbypkg \\\n				--define --eval --pipe --showrc --info --list \\\n				--state --docfiles --configfiles --queryformat\\\n				--conflicts --obsoletes --nodigest \\\n				--nosignature'' -- $cur ) )\n			else\n				_filedir ''rpm''\n			fi\n		else\n			# installed package completion\n			if [[ "$cur" == -* ]]; then\n				COMPREPLY=( $( compgen -W ''--scripts --root \\\n				--rcfile --whatprovides --whatrequires \\\n				--requires --triggeredby --ftpport --ftpproxy \\\n				--httpproxy --httpport --provides --triggers \\\n				--dump --changelog --dbpath --specfile \\\n				--querybynumber --last --filesbypkg --define \\\n				--eval --pipe --showrc --info --list --state \\\n				--docfiles --configfiles --queryformat \\\n				--conflicts --obsoletes --pkgid --hdrid \\\n				--fileid --tid --nodigest --nosignature \\\n				--triggerscripts'' -- $cur ) )\n			elif [ "${COMP_LINE#* -*([^ -])a}" == "$COMP_LINE" ]; then\n				_rpm_installed_packages\n			fi\n		fi\n		;;\n	-@(K*|-checksig))\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--nopgp --nogpg --nomd5 \\\n					--nodigest --nosignature'' -- $cur ) )\n		else\n			_filedir ''rpm''\n		fi\n		;;\n	-@([Vy]*|-verify))\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--root --rcfile --dbpath \\\n			--nodeps --nogroup --nolinkto --nomode --nomtime \\\n			--nordev --nouser --nofiles --noscripts --nomd5 \\\n			--querytags --specfile --whatrequires --whatprovides \\\n			--nodigest --nosignature'' -- $cur ) )\n		# check whether we''re doing file completion\n		elif [ "${COMP_LINE#* -*([^ -])f}" != "$COMP_LINE" ]; then\n			_filedir\n		elif [ "${COMP_LINE#* -*([^ -])g}" != "$COMP_LINE" ]; then\n			_rpm_groups\n		elif [ "${COMP_LINE#* -*([^ -])p}" != "$COMP_LINE" ]; then\n			_filedir ''rpm''\n		else\n			_rpm_installed_packages\n		fi\n		;;\n	-[bt]*)\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--short-circuit --timecheck \\\n			--clean --rmsource --rmspec --test --sign --buildroot \\\n			--target -- buildarch --buildos --nobuild --nodeps \\\n			--nodirtokens'' -- $cur ) )\n		elif [[ ${COMP_WORDS[1]} == -b* ]]; then\n			_filedir ''spec''\n		else\n			_filedir ''@(tgz|tar.@(gz|bz2))''\n		fi\n		;;\n	--re@(build|compile))\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--nodeps --rmsource \\\n			  --rmspec --sign --nodirtokens --target'' -- $cur ) )\n		else\n			_filedir ''?(no)src.rpm''\n		fi\n		;;\n	--tarbuild)\n		_filedir ''@(tgz|tar.@(gz|bz2))''\n		;;\n	--@(re|add)sign)\n		_filedir ''rpm''\n		;;\n	--set@(perms|gids))\n		_rpm_installed_packages\n		;;\n	--@(clean|rms@(ource|pec)))\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--clean --rmsource \\\n					--rmspec'' -- $cur ) )\n		else\n			_filedir ''spec''\n		fi\n		;;\n	--@(import|dbpath|root))\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--import --dbpath --root'' \\\n					-- $cur ) )\n		else\n			_filedir\n		fi\n		;;\n	esac\n\n	return 0\n}\ncomplete -F _rpm $filenames rpm rpmbuild\n}\n\n# Debian apt-get(8) completion.\n#\nhave apt-get &&\n_apt_get()\n{\n	local cur prev special i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	for (( i=0; i < ${#COMP_WORDS[@]}-1; i++ )); do\n		if [[ ${COMP_WORDS[i]} == @(install|remove|source|build-dep) ]]; then\n			special=${COMP_WORDS[i]}\n		fi\n	done\n\n	if [ -n "$special" ]; then\n		case $special in\n		remove)\n			if [ -f /etc/debian_version ]; then\n				# Debian system\n				COMPREPLY=( $( _comp_dpkg_installed_packages \\\n						$cur ) )\n			else\n				# assume RPM based\n				_rpm_installed_packages\n			fi\n			return 0\n			;;\n		*)\n			COMPREPLY=( $( apt-cache pkgnames $cur 2> /dev/null ) )\n			return 0\n			;;\n\n		esac\n	fi\n\n	case "$prev" in\n	    -@(c|-config-file))\n 		     _filedir\n		     return 0\n		     ;;\n\n	    -@(t|-target-release|-default-release))\n		     COMPREPLY=( $( apt-cache policy | \\\n				    grep "release.o=Debian,a=$cur" | \\\n				    sed -e "s/.*a=\\(\\w*\\).*/\\1/" | uniq ) )\n		     return 0\n		     ;;\n \n	esac\n\n	if [[ "$cur" == -* ]]; then\n\n		COMPREPLY=( $( compgen -W ''-d -f -h -v -m -q -s -y \\\n				-u -t -b -c -o --download-only --fix-broken \\\n				--help --version --ignore-missing \\\n				--fix-missing --no-download --quiet --simulate \\\n				--just-print --dry-run --recon --no-act --yes \\\n				--assume-yes --show-upgraded --only-source \\\n				--compile --build --ignore-hold \\\n				--target-release --no-upgrade --force-yes \\\n				--print-uris --purge --reinstall \\\n				--list-cleanup --default-release \\\n				--trivial-only --no-remove --diff-only \\\n				--tar-only --config-file --option'' -- $cur ) )\n	else\n\n		COMPREPLY=( $( compgen -W ''update upgrade dselect-upgrade \\\n				dist-upgrade install remove source build-dep \\\n				check clean autoclean'' -- $cur ) )\n\n	fi\n\n\n	return 0\n} &&\ncomplete -F _apt_get $filenames apt-get\n\n# Debian apt-cache(8) completion.\n#\nhave apt-cache &&\n_apt_cache()\n{\n	local cur prev special i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	\n	if [ "$cur" != show ]; then\n	    for (( i=0; i < ${#COMP_WORDS[@]}-1; i++ )); do\n		if [[ ${COMP_WORDS[i]} == @(add|depends|dotty|policy|rdepends|show?(pkg|src|)) ]]; then\n		    special=${COMP_WORDS[i]}\n		fi\n	    done\n	fi\n\n\n	if [ -n "$special" ]; then\n	    case $special in\n		add)\n		    _filedir\n		    return 0\n		    ;;\n		\n 		*)\n		    COMPREPLY=( $( apt-cache pkgnames $cur 2> /dev/null ) )\n		    return 0\n		    ;;\n		\n	    esac\n	fi\n\n\n	case "$prev" in\n	     -@(c|p|s|-config-file|-@(pkg|src)-cache))\n		     _filedir\n		     return 0\n		     ;;\n	     search)\n		     if [[ "$cur" != -* ]]; then\n			    return 0\n		     fi\n		     ;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n\n		COMPREPLY=( $( compgen -W ''-h -v -p -s -q -i -f -a -g -c \\\n				-o --help --version --pkg-cache --src-cache \\\n				--quiet --important --full --all-versions \\\n				--no-all-versions --generate --no-generate \\\n				--names-only --all-names --recurse \\\n				--config-file --option'' -- $cur ) )\n	else\n\n		COMPREPLY=( $( compgen -W ''add gencaches show showpkg showsrc \\\n				stats dump dumpavail unmet search search \\\n				depends rdepends pkgnames dotty xvcg \\\n				policy'' -- $cur ) )\n\n	fi\n\n\n	return 0\n} &&\ncomplete -F _apt_cache $filenames apt-cache\n\n\n# Debian aptitude(1) completion\n#\nhave aptitude && {\nhave grep-status && {\n_comp_dpkg_hold_packages()\n{\n	grep-status -P -e "^$1" -a -FStatus ''hold'' -n -s Package\n}\n} || {\n_comp_dpkg_hold_packages()\n{\n	grep -B 2 ''hold'' /var/lib/dpkg/status | grep "Package: $1" \\\n		| cut -d\\  -f2\n}\n}\n\n_aptitude()\n{\n	local cur dashoptions prev special i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n\n	dashoptions=''-S -u -i -h --help --version -s --simulate -d \\\n		     --download-only -P --prompt -y --assume-yes -F \\\n		     --display-format -O --sort -w --width -f -r -g \\\n		     --with-recommends --with-suggests -R -G \\\n		     --without-recommends --without-suggests -t \\\n		     --target-release -V --show-versions -D --show-deps\\\n		     -Z -v --verbose''\n\n	for (( i=0; i < ${#COMP_WORDS[@]}-1; i++ )); do\n	    if [[ ${COMP_WORDS[i]} == @(install|reinstall|hold|unhold|markauto|unmarkauto|dist-upgrade|download|show|forbid-version|purge|remove) ]]; then\n		special=${COMP_WORDS[i]}\n	    fi\n	    #exclude some mutually exclusive options\n	    [[ ${COMP_WORDS[i]} == ''-u'' ]] && dashoptions=${dashoptions/-i}\n	    [[ ${COMP_WORDS[i]} == ''-i'' ]] && dashoptions=${dashoptions/-u}\n	done\n\n	if [[ -n "$special" ]]; then\n	   case $special in\n	       @(install|hold|markauto|unmarkauto|dist-upgrade|download|show))\n		   COMPREPLY=( $( apt-cache pkgnames $cur 2> /dev/null ) )\n		   return 0\n		   ;;\n	       @(purge|remove|reinstall|forbid-version))\n  		   COMPREPLY=( $( _comp_dpkg_installed_packages $cur ) )\n		   return 0\n		   ;;\n	       unhold)\n  		   COMPREPLY=( $( _comp_dpkg_hold_packages $cur ) )\n		   return 0\n		   ;;\n\n	   esac\n	fi\n\n	case $prev in\n	    # don''t complete anything if these options are found\n	    @(autoclean|clean|forget-new|search|upgrade|update))\n		return 0\n		;;\n\n	    -S)\n		_filedir\n		return 0\n		;;\n\n	    -@(t|-target-release|-default-release))\n		COMPREPLY=( $( apt-cache policy | \\\n		    grep "release.o=Debian,a=$cur" | \\\n		    sed -e "s/.*a=\\(\\w*\\).*/\\1/" | uniq ) )\n		return 0\n		;;\n\n	esac\n\n	if [[ "$cur" == -* ]]; then\n	    COMPREPLY=( $( compgen -W "$dashoptions" -- $cur ) )\n	else\n	    COMPREPLY=( $( compgen -W ''update upgrade forget-new clean \\\n				       autoclean install reinstall remove \\\n				       hold unhold purge markauto unmarkauto \\\n				       dist-upgrade download search show \\\n				       forbid-version'' -- $cur ) )\n	fi\n\n\n	return 0\n}\ncomplete -F _aptitude $default aptitude\n}\n\n# Debian apt-build(1) completion.\n#\nhave apt-build &&\n_apt_build()\n{\n	local cur prev special i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	for (( i=0; i < ${#COMP_WORDS[@]}-1; i++ )); do\n		if [[ ${COMP_WORDS[i]} == @(install|remove|source|info|clean) ]]; then\n			special=${COMP_WORDS[i]}\n		fi\n	done\n\n	if [ -n "$special" ]; then\n		case $special in\n		@(install|source|info))\n			COMPREPLY=( $( apt-cache pkgnames $cur 2> /dev/null ) )\n			return 0\n			;;\n		remove)\n			COMPREPLY=( $( _comp_dpkg_installed_packages \\\n					$cur ) )\n			return 0\n			;;\n		*)\n			return 0\n			;;\n		esac\n	fi\n\n	case "$prev" in\n\n	     --@(patch|build-dir|repository-dir))\n		   _filedir\n		   return 0\n		   ;;\n \n	     -@(h|-help))\n		   return 0\n		   ;;\n\n	esac\n\n	if [[ "$cur" == -* ]]; then\n	    COMPREPLY=( $( compgen -W ''--help --show-upgraded -u --build-dir \\\n				  --repository-dir --build-only \\\n				  --build-command --reinstall --rebuild \\\n				  --remove-builddep --no-wrapper --purge \\\n				  --patch --patch-strip -p --yes -y \\\n				  --version -v --no-source'' -- $cur ) )\n\n	else\n	    COMPREPLY=( $( compgen -W ''update upgrade install remove \\\n				  source dist-upgrade world clean info \\\n				  clean-build update-repository '' -- $cur ) )\n	fi\n\n\n	return 0\n} &&\ncomplete -F _apt_build $filenames apt-build\n\n# chsh(1) completion\n#\n_chsh()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [ "$prev" = "-s" ]; then\n	  if [ -f /etc/debian_version ]; then\n	    COMPREPLY=( $( </etc/shells ) )\n	  else\n	    COMPREPLY=( $( chsh -l | grep "^$cur" ) )\n	  fi\n	else\n	  COMPREPLY=( $( compgen -u -- $cur ) )\n	fi\n\n	return 0\n}\ncomplete -F _chsh chsh\n\n# chkconfig(8) completion\n#\nhave chkconfig &&\n_chkconfig()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	@([1-6]|--@(list|add|del)))\n		_services\n		return 0\n		;;\n	--level)\n		COMPREPLY=( $( compgen -W ''1 2 3 4 5 6'' -- $cur ) )\n		return 0\n		;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--list --add --del --level'' -- $cur ) )\n	else\n		if [ $COMP_CWORD -eq 2 -o $COMP_CWORD -eq 4 ]; then\n			COMPREPLY=( $( compgen -W ''on off reset'' -- $cur ) )\n		else\n			_services\n		fi\n	fi\n} &&\ncomplete -F _chkconfig chkconfig\n\n# This function provides simple user@host completion\n#\n_user_at_host() {\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ $cur == *@* ]]; then\n		_known_hosts\n	else\n		COMPREPLY=( $( compgen -u -- "$cur" ) )\n	fi\n\n	return 0\n}\nshopt -u hostcomplete && complete -F _user_at_host $nospace talk ytalk finger\n\n# This function performs host completion based on ssh''s known_hosts files,\n# defaulting to standard host completion if they don''t exist.\n#\n_known_hosts()\n{\n       local cur curd ocur user suffix aliases global_kh user_kh hosts i host\n       local -a kh khd config\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	ocur=$cur\n\n	[ "$1" = -a ] || [ "$2" = -a ] && aliases=''yes''\n	[ "$1" = -c ] || [ "$2" = -c ] && suffix='':''\n	[[ $cur == *@* ]] && user=${cur%@*}@ && cur=${cur#*@}\n	kh=()\n\n	# ssh config files\n	[ -r /etc/ssh/ssh_config ] &&\n	  config=( ${config[@]} /etc/ssh/ssh_config )\n	[ -r ~/.ssh/config ] &&\n	  config=( ${config[@]} ~/.ssh/config )\n	[ -r ~/.ssh2/config ] &&\n	  config=( ${config[@]} ~/.ssh2/config )\n\n	if [ ${#config[@]} -gt 0 ]; then\n	    # expand path (if present) to global known hosts file\n	    global_kh=$( eval echo $( sed -ne ''s/^[Gg][Ll][Oo][Bb][Aa][Ll][Kk][Nn][Oo][Ww][Nn][Hh][Oo][Ss][Tt][Ss][Ff][Ii][Ll][Ee][''"$''\\t ''"'']*\\(.*\\)$/\\1/p'' ${config[@]} ) )\n	    # expand path (if present) to user known hosts file\n	    user_kh=$( eval echo $( sed -ne ''s/^[Uu][Ss][Ee][Rr][Kk][Nn][Oo][Ww][Nn][Hh][Oo][Ss][Tt][Ss][Ff][Ii][Ll][Ee][''"$''\\t ''"'']*\\(.*\\)$/\\1/p'' ${config[@]} ) )\n	fi\n\n	# choose which global known hosts file to use\n	if [ -r "$global_kh" ]; then\n	    kh=( "$global_kh" )\n	else\n	    [ -r /etc/ssh/ssh_known_hosts ] &&\n	      kh=( ${kh[@]} /etc/ssh/ssh_known_hosts )\n	    [ -r /etc/ssh/ssh_known_hosts2 ] &&\n	      kh=( ${kh[@]} /etc/ssh/ssh_known_hosts2 )\n	    [ -r /etc/known_hosts ] &&\n	      kh=( ${kh[@]} /etc/known_hosts )\n	    [ -r /etc/known_hosts2 ] &&\n	      kh=( ${kh[@]} /etc/known_hosts2 )\n	    [ -d /etc/ssh2/knownhosts ] &&\n	      khd=( ${khd[@]} /etc/ssh2/knownhosts/*pub )\n	fi\n\n	# choose which user known hosts file to use\n	if [ -r "$user_kh" ]; then\n	    kh=( ${kh[@]} "$user_kh" )\n	else\n	    [ -r ~/.ssh/known_hosts ] &&\n	      kh=( ${kh[@]} ~/.ssh/known_hosts )\n	    [ -r ~/.ssh/known_hosts2 ] &&\n	      kh=( ${kh[@]} ~/.ssh/known_hosts2 )\n	    [ -d ~/.ssh2/hostkeys ] &&\n	      khd=( ${khd[@]} ~/.ssh2/hostkeys/*pub )\n	fi\n\n	# If we have known_hosts files to use\n	if [ ${#kh[@]} -gt 0 -o ${#khd[@]} -gt 0 ]; then\n	    # Escape slashes and dots in paths for awk\n	    cur=${cur//\\//\\\\\\/}\n	    cur=${cur//\\./\\\\\\.}\n	    curd=$cur\n\n	    if [[ "$cur" == [0-9]*.* ]]; then\n		# Digits followed by a dot - just search for that\n		cur="^$cur.*"\n	    elif [[ "$cur" == [0-9]* ]]; then\n		# Digits followed by no dot - search for digits followed\n		# by a dot\n		cur="^$cur.*\\."\n	    elif [ -z "$cur" ]; then\n		# A blank - search for a dot or an alpha character\n		cur="[a-z.]"\n	    else\n		cur="^$cur"\n	    fi\n\n	    if [ ${#kh[@]} -gt 0 ]; then\n\n		# FS needs to look for a comma separated list\n		COMPREPLY=( $( awk ''BEGIN {FS=","}\n				{for (i=1; i<=2; ++i) { \\\n				       gsub(" .*$", "", $i); \\\n				       if ($i ~ /''$cur''/) {print $i} \\\n				}}'' ${kh[@]} 2>/dev/null ) )\n	    fi\n	    if [ ${#khd[@]} -gt 0 ]; then\n		# Needs to look for files called\n		# .../.ssh2/key_22_<hostname>.pub\n		# dont fork any processes, because in a cluster environment, \n		# there can be hundreds of hostkeys\n		for i in ${khd[@]} ; do\n		    if [[ "$i" == *key_22_$curd*.pub ]] && [ -r "$i" ] ; then\n			host=${i/#*key_22_/}\n			host=${host/%.pub/}\n			COMPREPLY=( ${COMPREPLY[@]} $host )\n		    fi\n		done\n	    fi\n	    # append any available aliases from config files\n	    if [ ${#config[@]} -gt 0 ] && [ -n "$aliases" ]; then\n		hosts=$( compgen -W "$( sed -ne ''s/^[Hh][Oo][Ss][Tt][''"$''\\t ''"'']*\\([^*?]*\\)$/\\1/p'' ${config[@]} )" -- $ocur )\n		COMPREPLY=( ${COMPREPLY[@]} $hosts )\n	    fi\n\n	    # apply suffix\n	    for (( i=0; i < ${#COMPREPLY[@]}; i++ )); do\n		COMPREPLY[i]=$user${COMPREPLY[i]}$suffix\n	    done\n	else\n	    # Just do normal hostname completion\n	    COMPREPLY=( $( compgen -A hostname -S "$suffix" -- $cur ) )\n	fi\n\n	return 0\n}\ncomplete -F _known_hosts traceroute traceroute6 tracepath tracepath6 \\\n	ping fping telnet host nslookup rsh rlogin ftp dig ssh-installkeys mtr\n\n# ssh(1) completion\n#\nhave ssh && {\n_ssh()\n{\n	local cur prev\n	local -a config\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-*c)\n	    COMPREPLY=( $( compgen -W ''blowfish 3des 3des-cbc blowfish-cbc \\\n			   arcfour cast128-cbc'' -- $cur ) )\n	    ;;\n	-*i)\n	    _filedir\n	    ;;\n	-*l)\n	    COMPREPLY=( $( compgen -u -- $cur ) )\n	    ;;\n	*)\n	    _known_hosts -a\n\n	    [ $COMP_CWORD -eq 1 ] || \\\n		COMPREPLY=( ${COMPREPLY[@]} $( compgen -c -- $cur ) )\n	esac\n\n	return 0\n}\nshopt -u hostcomplete && complete -F _ssh ssh slogin sftp xhost autossh\n\n# scp(1) completion\n#\n_scp()\n{\n	local cur userhost path\n\n	local IFS=$''\\t\\n''\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_expand || return 0\n\n	if [[ "$cur" == *:* ]]; then\n		# remove backslash escape from :\n		cur=${cur/\\\\:/:}\n		userhost=${cur%%?(\\\\):*}\n		path=${cur#*:}\n		# unescape spaces\n		path=${path//\\\\\\\\\\\\\\\\ / }\n		if [ -z "$path" ]; then\n			# default to home dir of specified user on remote host\n			path=$(ssh -o ''Batchmode yes'' $userhost pwd 2>/dev/null)\n		fi\n		# escape spaces; remove executables, aliases, pipes and sockets;\n		# add space at end of file names\n		COMPREPLY=( $( ssh -o ''Batchmode yes'' $userhost \\\n			       command ls -aF1d "$path*" 2>/dev/null | \\\n			       sed -e ''s/[][(){}<>",:;^&!$&=?`|\\ ]/\\\\\\\\\\\\&/g'' \\\n				   -e ''s/[*@|=]$//g'' -e ''s/[^\\/]$/& /g'' ) )\n		return 0\n	fi\n\n	[[ "$cur" == */* ]] || _known_hosts -c -a\n		COMPREPLY=( ${COMPREPLY[@]} $( command ls -aF1d $cur* \\\n			    2>/dev/null | sed \\\n			    -e ''s/[][(){}<>",:;^&!$&=?`|\\ ]/\\\\&/g'' \\\n			    -e ''s/[*@|=]$//g'' -e ''s/[^\\/]$/& /g'' ) )\n	return 0\n}\ncomplete -F _scp $nospace scp\n}\n\n# rsync(1) completion\n#\nhave rsync &&\n_rsync()\n{\n	local cur prev shell i userhost path\n \n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	_expand || return 0\n\n	case "$prev" in\n	--@(config|password-file|include-from|exclude-from))\n		_filedir\n		return 0\n		;;\n	-@(T|-temp-dir|-compare-dest))\n		_filedir -d\n		return 0\n		;;\n	-@(e|-rsh))\n		COMPREPLY=( $( compgen -W ''rsh ssh'' -- $cur ) )\n		return 0\n		;;\n	esac\n \n	case "$cur" in\n	-*)\n		COMPREPLY=( $( compgen -W ''-v -q  -c -a -r -R -b -u -l -L -H \\\n				-p -o -g -D -t -S -n -W -x -B -e -C -I -T -P \\\n				-z -h -4 -6 --verbose --quiet --checksum \\\n				--archive --recursive --relative --backup \\\n				--backup-dir --suffix= --update --links \\\n				--copy-links --copy-unsafe-links --safe-links \\\n				--hard-links --perms --owner --group --devices\\\n				--times --sparse --dry-run --whole-file \\\n				--no-whole-file --one-file-system \\\n				--block-size= --rsh= --rsync-path= \\\n				--cvs-exclude --existing --ignore-existing \\\n				--delete --delete-excluded --delete-after \\\n				--ignore-errors --max-delete= --partial \\\n				--force --numeric-ids --timeout= \\\n				--ignore-times --size-only --modify-window= \\\n				--temp-dir= --compare-dest= --compress \\\n				--exclude= --exclude-from= --include= \\\n				--include-from= --version --daemon --no-detach\\\n				--address= --config= --port= --blocking-io \\\n				--no-blocking-io --stats --progress \\\n				--log-format= --password-file= --bwlimit= \\\n				--write-batch= --read-batch= --help'' -- $cur ))\n		;;\n	*:*)\n		# find which remote shell is used\n		shell=rsh\n		for (( i=1; i < COMP_CWORD; i++ )); do\n			if [[ "${COMP_WORDS[i]}" == -@(e|-rsh) ]]; then\n				shell=${COMP_WORDS[i+1]}\n				break\n			fi\n		done\n		if [[ "$shell" == ssh ]]; then\n			# remove backslash escape from :\n			cur=${cur/\\\\:/:}\n			userhost=${cur%%?(\\\\):*}\n			path=${cur#*:}\n			# unescape spaces\n			path=${path//\\\\\\\\\\\\\\\\ / }\n			if [ -z "$path" ]; then\n				# default to home dir of specified\n				# user on remote host\n				path=$(ssh -o ''Batchmode yes'' \\\n					$userhost pwd 2>/dev/null)\n			fi\n			# escape spaces; remove executables, aliases, pipes\n			# and sockets; add space at end of file names\n			COMPREPLY=( $( ssh -o ''Batchmode yes'' $userhost \\\n				command ls -aF1d "$path*" 2>/dev/null | \\\n				sed -e ''s/ /\\\\\\\\\\\\\\ /g'' -e ''s/[*@|=]$//g'' \\\n				-e ''s/[^\\/]$/& /g'' ) )\n		fi\n		;;\n	*)\n		_known_hosts -c -a\n		_filedir\n		;;\n	esac\n \n	return 0\n} &&\ncomplete -F _rsync $nospace $filenames rsync\n\n# Linux route(8) completion\n#\n[ $UNAME = Linux ] &&\n_route()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [ "$prev" = dev ]; then\n	    COMPREPLY=( $( ifconfig -a | sed -ne ''s|^\\(''$cur''[^ ]*\\).*$|\\1|p'' ))\n	    return 0\n	fi\n\n	COMPREPLY=( $( compgen -W ''add del -host -net netmask metric mss \\\n				   window irtt reject mod dyn reinstate dev \\\n				   default gw'' -- $cur ) )\n\n	COMPREPLY=( $( echo " ${COMP_WORDS[@]}" | \\\n		       (while read -d '' '' i; do\n			   [ "$i" == "" ] && continue\n			   # flatten array with spaces on either side,\n			   # otherwise we cannot grep on word\n			   # boundaries of first and last word\n			   COMPREPLY=" ${COMPREPLY[@]} "\n			   # remove word from list of completions\n			   COMPREPLY=( ${COMPREPLY/ $i / } )\n			done\n		       echo ${COMPREPLY[@]})\n		  ) )\n	return 0\n}\n[ $UNAME = Linux ] && complete -F _route route\n\n# GNU make(1) completion\n#\nhave make || have gmake || have gnumake || have pmake &&\n_make()\n{\n	local file makef makef_dir="." makef_inc cur prev i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# --name value style option\n	case $prev in\n		-@(f|o|W))\n			_filedir\n			return 0\n			;;\n		-@(I|C))\n			_filedir -d\n			return 0\n			;;\n	esac\n\n	# --name=value style option\n	if [[ "$cur" == *=* ]]; then\n		prev=${cur/=*/}\n		cur=${cur/*=/}\n		case "$prev" in\n			--@(file|makefile))\n				_filedir\n				return 0\n				;;\n			--@(directory|include-dir))\n				_filedir -d\n				return 0\n				;;\n		esac\n	fi\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-b -m -B -C -d -e -f -h -i -I\\\n			-j -l -k -n -o -p -q -r -R - s -S -t -v -w -W \\\n			--always-make --directory= --debug \\\n			--environment-overrides --file= --makefile= --help \\\n			--ignore-errors --include-dir= --jobs --load-average \\\n			--max-load --keep-going --just-print --dry-run \\\n			--recon --old-file= --assume-old= --print-data-base \\\n			--question --no-builtin-rules --no-builtin-variables \\\n			--silent --quiet --no-keep-goind --stop --touch \\\n			--version --print-directory --no-print-directory \\\n			--what-if= --new-file= --assume-new= \\\n			--warn-undefined-variables'' -- $cur ) )\n	else\n		# before we check for makefiles, see if a path was specified\n		# with -C\n		for (( i=0; i < ${#COMP_WORDS[@]}; i++ )); do\n			if [[ ${COMP_WORDS[i]} == -C ]]; then\n				# eval for tilde expansion\n				eval makef_dir=${COMP_WORDS[i+1]}\n				break\n			fi\n		done\n\n		# make reads `GNUmakefile'', then `makefile'', then `Makefile''\n		if [ -f ${makef_dir}/GNUmakefile ]; then\n			makef=${makef_dir}/GNUmakefile\n		elif [ -f ${makef_dir}/makefile ]; then\n			makef=${makef_dir}/makefile\n		elif [ -f ${makef_dir}/Makefile ]; then\n			makef=${makef_dir}/Makefile\n		else\n			makef=${makef_dir}/*.mk	       # local convention\n		fi\n\n		# before we scan for targets, see if a Makefile name was\n		# specified with -f\n		for (( i=0; i < ${#COMP_WORDS[@]}; i++ )); do\n			if [[ ${COMP_WORDS[i]} == -f ]]; then\n				# eval for tilde expansion\n				eval makef=${COMP_WORDS[i+1]}\n				break\n			fi\n		done\n\n		[ ! -f $makef ] && return 0\n\n		# deal with included Makefiles\n 		makef_inc=$( grep -E ''^-?include'' $makef | sed -e "s,^.* ,"$makef_dir"/," )\n\n 		for file in $makef_inc; do\n 			[ -f $file ] && makef="$makef $file"\n 		done\n\n		COMPREPLY=( $( awk -F'':'' ''/^[a-zA-Z0-9][^$#\\/\\t=]*:([^=]|$)/ \\\n				{split($1,A,/ /);for(i in A)print A[i]}'' \\\n				$makef 2>/dev/null | command grep "^$cur" ))\n	fi\n} &&\ncomplete -f -F _make $filenames make gmake gnumake pmake\n\n# GNU tar(1) completion\n#\n_tar()\n{\n	local cur ext regex tar untar\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -W ''c t x u r d A'' -- $cur ) )\n		return 0\n	fi\n\n	case "${COMP_WORDS[1]}" in\n	?(-)c*f)\n		_filedir\n		return 0\n		;;\n	+([^IZzjy])f)\n		ext=''t@(ar?(.@(Z|gz|bz?(2)))|gz|bz?(2))''\n		regex=''t\\(ar\\(\\.\\(Z\\|gz\\|bz2\\?\\)\\)\\?\\|gz\\|bz2\\?\\)''\n		;;\n	*[Zz]*f)\n		ext=''t?(ar.)@(gz|Z)''\n		regex=''t\\(ar\\.\\)\\?\\(gz\\|Z\\)''\n		;;\n	*[Ijy]*f)\n		ext=''t?(ar.)bz?(2)''\n		regex=''t\\(ar\\.\\)\\?bz2\\?''\n		;;\n	*)\n		_filedir\n		return 0\n		;;\n		\n	esac\n\n	if [[ "$COMP_LINE" == *$ext'' '' ]]; then\n		# complete on files in tar file\n		#\n		# get name of tar file from command line\n		tar=$( echo "$COMP_LINE" | \\\n			sed -e ''s/^.* \\([^ ]*''$regex''\\) .*$/\\1/'' )\n		# devise how to untar and list it\n		untar=t${COMP_WORDS[1]//[^Izjyf]/}\n\n		COMPREPLY=( $( compgen -W "$( echo $( tar $untar $tar \\\n				2>/dev/null ) )" -- "$cur" ) )\n		return 0\n	fi\n\n	# file completion on relevant files\n	_filedir $ext\n\n	return 0\n}\n[ -n "${COMP_TAR_INTERNAL_PATHS:-}" ] && complete -F _tar $dirnames tar ||\n	complete -F _tar $filenames tar\n\n# jar(1) completion\n#\nhave jar &&\n_jar()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD = 1 ]; then\n		COMPREPLY=( $( compgen -W ''c t x u'' -- $cur ) )\n		return 0\n	fi\n\n	case "${COMP_WORDS[1]}" in\n		*c*f)\n			_filedir\n			;;\n		*f)\n			_filedir ''?(e|j|w)ar''\n			;;\n		*)\n			_filedir\n			;;\n	esac\n} &&\ncomplete -F _jar $filenames jar\n\n# Linux iptables(8) completion\n#\nhave iptables &&\n_iptables()\n{\n	local cur prev table chain\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]} \n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	chain=''s/^Chain \\([^ ]\\+\\).*$/\\1/p''\n\n	if [[ $COMP_LINE == *-t\\ *filter* ]]; then\n		table="-t filter"\n	elif [[ $COMP_LINE == *-t\\ *nat* ]]; then\n		table="-t nat"\n	elif [[ $COMP_LINE == *-t\\ *mangle* ]]; then\n		table="-t mangle"\n	fi\n\n	case "$prev" in\n	-*[AIDRPFXLZ])\n		COMPREPLY=( $( compgen -W ''`iptables $table -nL | \\\n			    sed -ne "s/^Chain \\([^ ]\\+\\).*$/\\1/p"`'' -- $cur ) )\n		;;\n	-*t)\n		COMPREPLY=( $( compgen -W ''nat filter mangle'' -- $cur ) )\n		;;\n	-j)\n		if [ "$table" = "-t filter" -o "$table" = "" ]; then\n		    COMPREPLY=( $( compgen -W ''ACCEPT DROP LOG ULOG REJECT \\\n		    `iptables $table -nL | sed -ne "$chain" \\\n		    -e "s/INPUT|OUTPUT|FORWARD|PREROUTING|POSTROUTING//"`'' -- \\\n		    $cur ) )\n		elif [ "$table" = "-t nat" ]; then\n		    COMPREPLY=( $( compgen -W ''ACCEPT DROP LOG ULOG REJECT \\\n		    MIRROR SNAT DNAT MASQUERADE `iptables $table -nL | \\\n		    sed -ne "$chain" -e "s/OUTPUT|PREROUTING|POSTROUTING//"`'' \\\n		    -- $cur ) )\n		elif [ "$table" = "-t mangle" ]; then\n		    COMPREPLY=( $( compgen -W ''ACCEPT DROP LOG ULOG REJECT \\\n		    MARK TOS `iptables $table -nL | sed -ne "$chain" \\\n		    -e "s/INPUT|OUTPUT|FORWARD|PREROUTING|POSTROUTING//"`'' -- \\\n		    $cur ) )\n		fi\n		;;\n	*)\n		if [[ "$cur" == -* ]]; then\n		    COMPREPLY=( $( compgen -W ''-i -o -s -d -p -f -m --append \\\n		    --delete --insert --replace --list --flush --zero --new \\\n		    --delete-chain --policy --rename-chain --proto --source \\\n		    --destination --in-interface --jump --match --numeric \\\n		    --out-interface --table --verbose --line-numbers --exact \\\n		    --fragment --modprobe= --set-counters --version'' -- "$cur") )\n		fi\n		;;\n	esac\n\n} &&\ncomplete -F _iptables iptables\n\n# tcpdump(8) completion\n#\nhave tcpdump &&\n_tcpdump()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(r|w|F))\n			_filedir\n			return 0\n			;;\n		-i)\n			_available_interfaces -a\n			return 0\n			;;\n	esac\n\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-a -d -e -f -l -n -N -O -p \\\n			-q -R -S -t -u -v -x -C -F -i -m -r -s -T -w \\\n			-E'' -- $cur ) )\n	fi\n\n} &&\ncomplete -F _tcpdump tcpdump\n\n# autorpm(8) completion\n#\nhave autorpm &&\n_autorpm()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( compgen -W ''--notty --debug --help --version \\\n				   auto add fullinfo info help install list \\\n				   remove set'' -- $cur ) )\n\n} &&\ncomplete -F _autorpm autorpm\n\n# This meta-cd function observes the CDPATH variable, so that cd additionally\n# completes on directories under those specified in CDPATH.\n#\n_cd()\n{\n	local IFS=$''\\t\\n'' cur=${COMP_WORDS[COMP_CWORD]} i j k\n\n	# try to allow variable completion\n	if [[ "$cur" == ?(\\\\)\\$* ]]; then\n		COMPREPLY=( $( compgen -v -P ''$'' -- "${cur#?(\\\\)$}" ) )\n		return 0\n	fi\n\n	# Use standard dir completion if no CDPATH or parameter starts with /,\n	# ./ or ../\n	if [ -z "${CDPATH:-}" ] || [[ "$cur" == ?(.)?(.)/* ]]; then\n		_filedir -d\n		return 0\n	fi\n\n	local -r mark_dirs=$(_rl_enabled mark-directories && echo y)\n	local -r mark_symdirs=$(_rl_enabled mark-symlinked-directories && echo y)\n\n	# we have a CDPATH, so loop on its contents\n	for i in ${CDPATH//:/$''\\t''}; do\n		# create an array of matched subdirs\n		k=${#COMPREPLY[@]}\n		for j in $( compgen -d $i/$cur ); do\n			if [[ ( $mark_symdirs && -h $j || $mark_dirs && ! -h $j ) && ! -d ${j#$i/} ]]; then\n				j="${j}/"\n			fi\n			COMPREPLY[k++]=${j#$i/}\n		done\n	done\n\n	_filedir -d\n\n	if [[ ${#COMPREPLY[@]} -eq 1 ]]; then\n	    i=${COMPREPLY[0]}\n	    if [ "$i" == "$cur" ] && [[ $i != "*/" ]]; then\n		COMPREPLY[0]="${i}/"\n	    fi\n	fi\n	    \n	return 0\n}\nif shopt -q cdable_vars; then\n    complete -v -F _cd $nospace $filenames cd\nelse\n    complete -F _cd $nospace $filenames cd\nfi\n\n# A meta-command completion function for commands like sudo(8), which need to\n# first complete on a command, then complete according to that command''s own\n# completion definition - currently not quite foolproof (e.g. mount and umount\n# don''t work properly), but still quite useful.\n#\n_command()\n{\n	local cur func cline cspec noglob cmd done i \\\n	      _COMMAND_FUNC _COMMAND_FUNC_ARGS\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	# If the the first arguments following our meta-command-invoker are\n	# switches, get rid of them. Most definitely not foolproof.\n	done=\n	while [ -z $done ] ; do\n	cmd=${COMP_WORDS[1]}\n	    if [[ "$cmd" == -* ]] ; then\n		for (( i=1 ; i<=COMP_CWORD ; i++)) ; do\n		    COMP_WORDS[i]=${COMP_WORDS[i+1]}\n		done\n		COMP_CWORD=$(($COMP_CWORD-1))\n	    else \n		done=1\n	    fi\n	done\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -c -- $cur ) )\n	elif complete -p $cmd &>/dev/null; then\n		cspec=$( complete -p $cmd )\n		if [ "${cspec#* -F }" != "$cspec" ]; then\n			# complete -F <function>\n			#\n			# COMP_CWORD and COMP_WORDS() are not read-only,\n			# so we can set them before handing off to regular\n			# completion routine\n\n			# set current token number to 1 less than now\n			COMP_CWORD=$(( $COMP_CWORD - 1 ))\n\n			# get function name\n			func=${cspec#*-F }\n			func=${func%% *}\n			# get current command line minus initial command\n			cline="${COMP_LINE#*( )$1 }"\n			# save noglob state\n		      	shopt -qo noglob; noglob=$?\n			# turn on noglob, as things like ''sudo ls *<Tab>''\n			# don''t work otherwise\n		  	shopt -so noglob\n			# split current command line tokens into array\n			COMP_WORDS=( $cline )\n			# reset noglob if necessary\n			[ $noglob -eq 1 ] && shopt -uo noglob\n			$func $cline\n			# This is needed in case user finished entering\n			# command and pressed tab (e.g. sudo ls <Tab>)\n			COMP_CWORD=$(( $COMP_CWORD > 0 ? $COMP_CWORD : 1 ))\n			cur=${COMP_WORDS[COMP_CWORD]}\n			_COMMAND_FUNC=$func\n			_COMMAND_FUNC_ARGS=( $cmd $2 $3 )\n			COMP_LINE=$cline\n			COMP_POINT=$(( ${COMP_POINT} - ${#1} - 1 ))\n			$func $cmd $2 $3\n			# remove any \\: generated by a command that doesn''t\n			# default to filenames or dirnames (e.g. sudo chown)\n			if [ "${cspec#*-o }" != "$cspec" ]; then\n				cspec=${cspec#*-o }\n				cspec=${cspec%% *}\n				if [[ "$cspec" != @(dir|file)names ]]; then\n					COMPREPLY=("${COMPREPLY[@]//\\\\\\\\:/:}")\n				fi\n			fi\n		elif [ -n "$cspec" ]; then\n			cspec=${cspec#complete};\n			cspec=${cspec%%$cmd};\n			COMPREPLY=( $( eval compgen "$cspec" -- "$cur" ) );\n		fi\n	fi\n\n	[ ${#COMPREPLY[@]} -eq 0 ] && _filedir\n}\ncomplete -F _command $filenames nohup exec nice eval strace time ltrace then \\\n	else do vsound command xargs\n\n_root_command()\n{\n	PATH=$PATH:/sbin:/usr/sbin:/usr/local/sbin _command $1 $2 $3\n}\ncomplete -F _root_command $filenames sudo fakeroot really\n\n# ant(1) completion\n#\nhave ant && {\n_ant()\n{\n	local cur prev buildfile i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-buildfile|-f)\n			_filedir ''xml''\n			return 0\n			;;\n		-logfile)\n			_filedir\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		# relevant options completion\n		COMPREPLY=( $( compgen -W ''-help -projecthelp -version -quiet \\\n			       -verbose -debug -emacs -logfile -logger \\\n			       -listener -buildfile -f -D -find'' -- $cur ) )\n	else\n		# available targets completion\n		# find which buildfile to use\n		buildfile=build.xml\n		for (( i=1; i < COMP_CWORD; i++ )); do\n			if [[ "${COMP_WORDS[i]}" == -buildfile ]]; then\n				buildfile=${COMP_WORDS[i+1]}\n				break\n			fi\n		done\n		[ ! -f $buildfile ] && return 0\n\n		# parse buildfile for targets\n		COMPREPLY=( $( awk -F''"'' ''/<target name="/ {print $2}'' \\\n				$buildfile | grep "^$cur" )\n			    $( awk -F"''" "/<target name=''/ "''{print $2}'' \\\n				$buildfile | grep "^$cur" )\n			    $( awk -F''"'' ''/<target [^n]/ {if ($1 ~ /name=/) { print $2 } else if ($3 ~ /name=/) {print $4} else if ($5 ~ /name=/) {print $6}}'' \\\n				$buildfile | grep "^$cur" ) )\n	fi\n}\nhave complete-ant-cmd.pl && \\\n     complete -C complete-ant-cmd.pl -F _ant $filenames ant || \\\n     complete -F _ant $filenames ant\n}\n\nhave nslookup &&\n_nslookup()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]#-}\n\n	COMPREPLY=( $( compgen -P ''-'' -W ''all class= debug d2 domain= \\\n			       srchlist= defname search port= querytype= \\\n			       type= recurse retry root timeout vc \\\n			       ignoretc'' -- $cur ) )\n} &&\ncomplete -F _nslookup nslookup\n\n# mysqladmin(1) completion\n#\nhave mysqladmin &&\n_mysqladmin()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]} \n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-u)\n		COMPREPLY=( $( compgen -u -- $cur ) )\n		return 0\n		;;\n	*)\n		;;\n	esac\n\n	COMPREPLY=( $( compgen -W ''-# -f -? -C -h -p -P -i -r -E -s -S -t -u \\\n					      -v -V -w'' -- $cur ) )\n\n	COMPREPLY=( ${COMPREPLY[@]} \\\n		    $( compgen -W ''create drop extended-status flush-hosts \\\n				   flush-logs flush-status flush-tables \\\n				   flush-threads flush-privileges kill \\\n				   password ping processlist reload refresh \\\n				   shutdown status variables version'' \\\n		       -- $cur ) )\n} &&\ncomplete -F _mysqladmin mysqladmin\n\n# gzip(1) completion\n#\nhave gzip &&\n_gzip()\n{\n	local cur prev xspec IFS=$''\\t\\n''\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-c -d -f \\\n			-h -l -L -n -N -q -r -S -t -v -V \\\n			-1 -2 -3 -4 -5 -6 -7 -8 -9 \\\n			--stdout --decompress --force --help --list \\\n			--license --no-name --name --quiet --recursive \\\n			--suffix --test --verbose --version --fast \\\n			--best'' -- $cur ) )\n		return 0\n	fi\n\n	xspec="*.?(t)gz"\n	if [[ "$prev" == --* ]]; then\n		[[ "$prev" == --decompress || \\\n			"$prev" == --list || \\\n			"$prev" == --test ]] && xspec="!"$xspec\n		[[ "$prev" == --force ]] && xspec=\n	elif [[ "$prev" == -* ]]; then\n		[[ "$prev" == -*[dlt]* ]] && xspec="!"$xspec\n		[[ "$prev" == -*f* ]] && xspec=\n	elif [ "$prev" = ''>'' ]; then\n		xspec=\n	fi\n\n	_expand || return 0\n\n	COMPREPLY=( $( compgen -f -X "$xspec" -- $cur ) \\\n		    $( compgen -d -- $cur ) )\n} &&\ncomplete -F _gzip $filenames gzip\n\n# bzip2(1) completion\n#\nhave bzip2 &&\n_bzip2()\n{\n	local cur prev xspec\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-c -d -f -h -k -L -q -s \\\n			-t -v -V -z -1 -2 -3 -4 -5 -6 -7 -8 -9 \\\n			--help --decompress --compress --keep --force \\\n			--test --stdout --quiet --verbose --license \\\n			--version --small --fast --best'' -- $cur ) )\n		return 0\n	fi\n\n	xspec="*.bz2"\n	if [[ "$prev" == --* ]]; then\n		[[ "$prev" == --decompress || \\\n			"$prev" == --list || \\\n			"$prev" == --test ]] && xspec="!"$xspec\n		[[ "$prev" == --compress ]] && xspec=\n	elif [[ "$prev" == -* ]]; then\n		[[ "$prev" == -*[dt]* ]] && xspec="!"$xspec\n		[[ "$prev" == -*z* ]] && xspec=\n	fi\n\n	_expand || return 0\n\n	COMPREPLY=( $( compgen -f -X "$xspec" -- $cur ) \\\n		    $( compgen -d -- $cur ) )\n} &&\ncomplete -F _bzip2 $filenames bzip2\n\n# openssl(1) completion\n#\nhave openssl && {\n_openssl_sections()\n{\n	local config\n\n	config=/etc/ssl/openssl.cnf\n	[ ! -f $config ] && config=/usr/share/ssl/openssl.cnf\n	for (( i=2; i < COMP_CWORD; i++ )); do\n		if [[ "${COMP_WORDS[i]}" == -config ]]; then\n			config=${COMP_WORDS[i+1]}\n			break\n		fi\n	done\n	[ ! -f $config ] && return 0\n\n	COMPREPLY=( $( awk ''/\\[.*\\]/ {print $2} '' $config | grep "^$cur" ) )\n}\n\n_openssl()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -W ''asn1parse ca ciphers crl crl2pkcs7 \\\n			dgst dh dhparam dsa dsaparam enc errstr gendh gendsa \\\n			genrsa nseq passwd pkcs12 pkcs7 pkcs8 rand req rsa \\\n			rsautl s_client s_server s_time sess_id smime speed \\\n			spkac verify version x509 md2 md4 md5 mdc2 rmd160 sha \\\n			sha1 base64 bf bf-cbc bf-cfb bf-ecb bf-ofb cast \\\n			cast-cbc cast5-cbc cast5-cfb cast5-ecb cast5-ofb des \\\n			des-cbc des-cfb des-ecb des-ede des-ede-cbc \\\n			des-ede-cfb des-ede-ofb des-ede3 des-ede3-cbc \\\n			des-ede3-cfb des-ede3-ofb des-ofb des3 desx rc2 \\\n			rc2-40-cbc rc2-64-cbc rc2-cbc rc2-cfb rc2-ecb rc2-ofb \\\n			rc4 rc4-40'' -- $cur ) )\n	else\n		prev=${COMP_WORDS[COMP_CWORD-1]}\n		case ${COMP_WORDS[1]} in\n			asn1parse)\n				case $prev in\n					-inform)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out|oid))\n						_filedir\n						return 0\n						;;\n					esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -in -out -noout -offset \\\n						-length -i -oid -strparse'' -- $cur ) )\n				fi\n				;;\n			ca)\n				case $prev in\n					-@(config|revoke|cert|in|out|spkac|ss_cert))\n						_filedir\n						return 0\n						;;\n					-outdir)\n						_filedir -d\n						return 0\n						;;\n					-@(name|crlexts|extensions))\n						_openssl_sections\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-verbose -config -name \\\n						-gencrl -revoke -crldays -crlhours -crlexts \\\n						-startdate -enddate -days -md -policy -keyfile \\\n						-key -passin -cert -in -out -notext -outdir \\\n						-infiles -spkac -ss_cert -preserveDN -batch \\\n						-msie_hack -extensions'' -- $cur ) )\n				fi\n				;;\n			ciphers)\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-v -ssl2 -ssl3 -tls1'' -- $cur ) )\n				fi\n				;;\n			crl)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out|CAfile))\n						_filedir\n						return 0\n						;;\n					-CAPath)\n						_filedir -d\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -text -in -out -noout \\\n						-hash -issuer -lastupdate -nextupdate -CAfile -CApath'' -- $cur ) )\n				fi\n				;;\n			crl2pkcs7)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in -out -print_certs'' -- $cur ) )\n				fi\n				;;\n			dgst)\n				case $prev in\n					-@(out|sign|verify|prvrify|signature))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-md5 -md4 -md2 -sha1 -sha -mdc2 -ripemd160 -dss1 \\\n						-c -d -hex -binary -out -sign -verify -prverify -signature'' -- $cur ) )\n				else\n						_filedir\n				fi\n			       ;;\n			dsa)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in -passin -out -passout -des -des3 -idea -text -noout \\\n						-modulus -pubin -pubout'' -- $cur ) )\n				fi\n				;;\n			dsaparam)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out|rand))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in -out -noout \\\n						-text -C -rand -genkey'' -- $cur ) )\n				fi\n				;;\n			enc)\n				case $prev in\n					-@(in|out|kfile))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-ciphername -in -out -pass \\\n						-e -d -a -A -k -kfile -S -K -iv -p -P -bufsize -debug'' -- $cur ) )\n				fi\n				;;\n			dhparam)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out|rand))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in -out -dsaparam -noout \\\n						-text -C -2 -5 -rand'' -- $cur ) )\n				fi\n				;;\n			gendsa)\n				case $prev in\n					-@(out|rand))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-out -des -des3 -idea -rand'' -- $cur ) )\n				else\n						_filedir\n				fi\n				;;\n			genrsa)\n				case $prev in\n					-@(out|rand))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-out -passout -des -des3 -idea -f4 -3 -rand'' -- $cur ) )\n				fi\n				;;\n			pkcs7)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in -out -print_certs -text -noout'' -- $cur ) )\n				fi\n				;;\n			rand)\n				case $prev in\n					-@(out|rand))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-out -rand -base64'' -- $cur ) )\n				fi\n				;;\n			req)\n				case "$prev" in\n					-@(in|out|key)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n\n					-@(in|out|rand|key|keyout|config))\n						_filedir\n						return 0\n						;;\n					-extensions)\n						_openssl_sections\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in \\\n						-passin -out -passout -text -noout -verify \\\n						-modulus -new -rand -newkey -newkey -nodes \\\n						-key -keyform -keyout -md5 -sha1 -md2 -mdc2 \\\n						-config -x509 -days -asn1-kludge -newhdr \\\n						-extensions -reqexts section'' -- $cur ) )\n				fi\n				;;\n			rsa)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER NET PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in -passin -out -passout \\\n						-sgckey -des -des3 -idea -text -noout -modulus -check -pubin \\\n						-pubout -engine'' -- $cur ) )\n				fi\n				;;\n			rsautl)\n				case $prev in\n					-@(in|out|inkey))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-in -out -inkey -pubin -certin -sign -verify \\\n						-encrypt -decrypt -pkcs -ssl -raw -hexdump -asn1parse'' -- $cur ) )\n				fi\n				;;\n			s_client)\n				case $prev in\n					-connect)\n						_known_hosts\n						return 0\n						;;\n					-@(cert|key|CAfile|rand))\n						_filedir\n						return 0\n						;;\n					-CApath)\n						_filedir -d\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-connect -verify -cert -key -CApath -CAfile \\\n						-reconnect -pause -showcerts -debug -msg -nbio_test -state -nbio \\\n						-crlf -ign_eof -quiet -ssl2 -ssl3 -tls1 -no_ssl2 -no_ssl3 -no_tls1 \\\n						-bugs -cipher -starttls -engine -rand'' -- $cur ) )\n				fi\n				;;\n			s_server)\n				case $prev in\n					-@(cert|key|dcert|dkey|dhparam|CAfile|rand))\n						_filedir\n						return 0\n						;;\n					-CApath)\n						_filedir -d\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-accept -context -verify -Verify -cert -key \\\n						 -dcert -dkey -dhparam -nbio -nbio_test -crlf -debug -msg -state -CApath \\\n						 -CAfile -nocert -cipher -quiet -no_tmp_rsa -ssl2 -ssl3 -tls1 -no_ssl2 \\\n						 -no_ssl3 -no_tls1 -no_dhe -bugs -hack -www -WWW -HTTP -engine -id_prefix \\\n						 -rand'' -- $cur ) )\n				 fi\n				 ;;\n			s_time)\n				case $prev in\n					-connect)\n						_known_hosts\n						return 0\n						;;\n					-@(cert|key|CAfile))\n						_filedir\n						return 0\n						;;\n					-CApath)\n						_filedir -d\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-connect -www -cert -key -CApath -CAfile -reuse \\\n						-new -verify -nbio -time -ssl2 -ssl3 -bugs -cipher'' -- $cur ) )\n				fi\n				;;\n\n			sess_id) \n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out))\n						_filedir\n						return 0\n						;;\n				esac\n\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform -in -out -text -noout \\\n						-context ID'' -- $cur ) )\n				fi\n				;;\n			smime)\n				case $prev in\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''SMIME DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-@(in|out|certfile|signer|recip|inkey|content|rand))\n						_filedir\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-encrypt -decrypt -sign -verify -pk7out -des -des3 \\\n						-rc2-40 -rc2-64 -rc2-128 -aes128 -aes192 -aes256 -in -certfile -signer \\\n						-recip -inform -passin -inkey -out -outform -content -to -from -subject \\\n						-text -rand'' -- $cur ) )\n				else\n						_filedir\n				fi\n				;;\n			speed)\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-engine'' -- $cur ) )\n				else\n					COMPREPLY=( $( compgen -W ''md2 mdc2 md5 hmac sha1 rmd160 idea-cbc \\\n						rc2-cbc rc5-cbc bf-cbc des-cbc des-ede3 rc4 rsa512 rsa1024 rsa2048 \\\n						rsa4096 dsa512 dsa1024 dsa2048 idea rc2 des rsa blowfish'' -- $cur ) )\n				fi\n				;;\n			verify)\n				case $prev in\n					-@(CAfile|untrusted))\n						_filedir\n						return 0\n						;;\n					-CApath)\n						_filedir -d\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-CApath -CAfile -purpose -untrusted -help -issuer_checks \\\n						-verbose -certificates'' -- $cur ) )\n				else\n						_filedir\n				fi\n				;;\n			x509)\n				case "$prev" in\n					-@(in|out|CA|CAkey|CAserial|extfile))\n						_filedir\n						return 0\n						;;\n					-@(in|out)form)\n						COMPREPLY=( $( compgen -W ''DER PEM NET'' -- $cur ) )\n						return 0\n						;;\n					-@(key|CA|CAkey)form)\n						COMPREPLY=( $( compgen -W ''DER PEM'' -- $cur ) )\n						return 0\n						;;\n					-extensions)\n						_openssl_sections\n						return 0\n						;;\n				esac\n\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-inform -outform \\\n						-keyform -CAform -CAkeyform -in -out \\\n						-serial -hash -subject -issuer -nameopt \\\n						-email -startdate -enddate -purpose \\\n						-dates -modulus -fingerprint -alias \\\n						-noout -trustout -clrtrust -clrreject \\\n						-addtrust -addreject -setalias -days \\\n						-set_serial -signkey -x509toreq -req \\\n						-CA -CAkey -CAcreateserial -CAserial \\\n						-text -C -md2 -md5 -sha1 -mdc2 -clrext \\\n						-extfile -extensions -engine'' -- $cur ) )\n				fi\n				;;\n			@(md5|md4|md2|sha1|sha|mdc2|ripemd160))\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-c -d'' -- $cur ) )\n				else\n						_filedir\n				fi\n				;;\n		esac\n	fi\n\n	return 0\n}\ncomplete -F _openssl $default openssl\n}\n\n# screen(1) completion\n#\nhave screen &&\n_screen()\n{\n	local cur prev preprev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	[ "$COMP_CWORD" -ge 2 ] && preprev=${COMP_WORDS[COMP_CWORD-2]}\n\n	if [ "$preprev" = "-d" -o "$preprev" = "-D" -a "$prev" = "-r" -o \\\n	     "$prev" = "-R" ]; then\n		# list all\n		COMPREPLY=( $( command screen -ls | \\\n				sed -ne ''s|^[''$''\\t'''']\\+\\(''$cur''[0-9]\\+\\.[^''$''\\t'''']\\+\\).*$|\\1|p'' ) )\n	else\n		case "$prev" in\n		-[rR])\n			# list detached\n			COMPREPLY=( $( command screen -ls | \\\n					sed -ne ''s|^[''$''\\t'''']\\+\\(''$cur''[0-9]\\+\\.[^''$''\\t'''']\\+\\).*Detached.*$|\\1|p'' ) )\n			;;\n		-[dDx])\n			# list attached\n			COMPREPLY=( $( command screen -ls | \\\n					sed -ne ''s|^[''$''\\t'''']\\+\\(''$cur''[0-9]\\+\\.[^''$''\\t'''']\\+\\).*Attached.*$|\\1|p'' ) )\n			;;\n		-s)\n			# shells\n			COMPREPLY=( $( grep ^${cur:-[^#]} /etc/shells ) )\n			;;\n		*)\n			;;\n		esac\n	fi\n\n	return 0\n} &&\ncomplete -F _screen $default screen\n\n# lftp(1) bookmark completion\n#\nhave lftp &&\n_lftp()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ] && [ -f ~/.lftp/bookmarks ]; then\n	    COMPREPLY=( $( compgen -W ''$( sed -ne "s/^\\(.*\\)''$''\\t''''.*$/\\1/p" \\\n			   ~/.lftp/bookmarks )'' -- $cur ) )\n	fi\n\n	return 0\n} &&\ncomplete -F _lftp $default lftp\n\n# ncftp(1) bookmark completion\n#\nhave ncftp &&\n_ncftp()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ] && [ -f ~/.ncftp/bookmarks ]; then\n	    COMPREPLY=( $( compgen -W ''$( sed -ne "s/^\\([^,]\\{1,\\}\\),.*$/\\1/p" \\\n			   ~/.ncftp/bookmarks )'' -- $cur ) )\n	fi\n\n	return 0\n} &&\ncomplete -F _ncftp $default ncftp\n\n# gdb(1) completion\n#\nhave gdb &&\n_gdb()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -c -- $cur ) )\n	elif [ $COMP_CWORD -eq 2 ]; then\n		prev=${prev##*/}\n		COMPREPLY=( $( compgen -fW "$( command ps axo comm,pid | \\\n				awk ''{if ($1 ~ /^''"$prev"''/) print $2}'' ) )" \\\n				-- "$cur" ) )\n	fi\n} &&\ncomplete -F _gdb $filenames gdb\n\n# Postgresql completion\n#\nhave psql && {\n_pg_databases() \n{\n	COMPREPLY=( $( psql -l 2>/dev/null | \\\n			sed -e ''1,/^-/d'' -e ''/^(/,$d'' | \\\n			awk ''{print $1}'' | grep "^$cur" ) )\n}\n\n_pg_users()\n{\n	COMPREPLY=( $( psql -qtc ''select usename from pg_user'' template1 2>/dev/null | \\\n			grep "^ $cur" ) )\n	[ ${#COMPREPLY[@]} -eq 0 ] && COMPREPLY=( $( compgen -u -- $cur ) )\n}\n\n# createdb(1) completion\n#\n_createdb() \n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-@(h|-host=)) \n		_known_hosts\n		return 0\n		;;\n	-@(U|-username=))\n		_pg_users\n		return 0\n		;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-D -T -E -h -p -U -W -e -q \\\n			--location= --template= --encoding= --host= --port= \\\n			--username= --password --echo --quiet --help'' -- $cur ))\n	else\n		_pg_databases\n	fi\n}\ncomplete -F _createdb $default createdb\n\n# dropdb(1) completion\n#\n_dropdb() \n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-@(h|-host=)) \n		_known_hosts\n		return 0\n		;;\n	-@(U|-username=))\n		_pg_users\n		return 0\n		;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-h -p -U -W -e -q \\\n				--host= --port= --username= --password \\\n				--interactive --echo --quiet --help'' -- $cur ) )\n	else\n		_pg_databases\n	fi\n}\ncomplete -F _dropdb $default dropdb\n\n# psql(1) completion\n#\n_psql() \n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-h|--host) \n		_known_hosts\n		return 0\n		;;\n	-U|--username)\n		_pg_users\n		return 0\n		;;\n	-d|--dbname)\n		_pg_databases\n		return 0\n		;;\n	-@(o|f)|--output|--file)\n		_filedir\n		return 0\n		;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		# return list of available options\n		COMPREPLY=( $( compgen -W ''-a --echo-all -A --no-align \\\n			-c --command -d --dbname -e --echo-queries \\\n			-E --echo-hidden -f --file -F --filed-separator \\\n			-h --host -H --html -l --list -n -o --output \\\n			-p --port -P --pset -q -R --record-separator \\\n			-s --single-step -S --single-line -t --tuples-only \\\n			-T --table-attr -U --username -v --variable \\\n			-V --version -W --password -x --expanded -X --nopsqlrc \\\n			-? --help '' -- $cur ) )\n	else\n		# return list of available databases\n		_pg_databases\n	fi\n}\ncomplete -F _psql $default psql\n}\n\n_longopt()\n{\n	local cur opt\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == --*=* ]]; then\n		opt=${cur%%=*}\n		# cut backslash that gets inserted before ''='' sign\n		opt=${opt%\\\\*}\n		cur=${cur#*=}\n		_filedir\n		COMPREPLY=( $( compgen -P "$opt=" -W ''${COMPREPLY[@]}'' -- $cur))\n		return 0\n	fi\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( $1 --help 2>&1 | sed -e ''/--/!d'' \\\n				-e ''s/.*\\(--[-A-Za-z0-9]\\+=\\?\\).*/\\1/'' | \\\n			       command grep "^$cur" | sort -u ) )\n	elif [[ "$1" == @(mk|rm)dir ]]; then\n		_filedir -d\n	else\n		_filedir\n	fi\n}\n# makeinfo and texi2dvi are defined elsewhere.\nfor i in a2ps autoconf automake bc gprof ld nm objcopy objdump readelf strip \\\n	 bison cpio diff patch enscript cp df dir du ln ls mkfifo mknod mv rm \\\n	 touch vdir awk gperf grep grub indent less m4 sed shar date \\\n	 tee who texindex cat csplit cut expand fmt fold head \\\n	 md5sum nl od paste pr ptx sha1sum sort split tac tail tr unexpand \\\n	 uniq wc ldd bash id irb mkdir rmdir; do\n  have $i && complete -F _longopt $filenames $i\ndone\n\n# These commands use filenames, so ''-o filenames'' is not needed.\nfor i in env netstat seq uname units wget; do\n  have $i && complete -F _longopt $default $i\ndone\nunset i\n\n# gcc(1) completion\n#\n# The only unusual feature is that we don''t parse "gcc --help -v" output\n# directly, because that would include the options of all the other backend\n# tools (linker, assembler, preprocessor, etc) without any indication that\n# you cannot feed such options to the gcc driver directly.  (For example, the\n# linker takes a -z option, but you must type -Wl,-z for gcc.)  Instead, we\n# ask the driver ("g++") for the name of the compiler ("cc1"), and parse the\n# --help output of the compiler.\n#\nhave gcc &&\n_gcc()\n{\n	local cur cc backend\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_expand || return 0\n\n	case "$1" in\n	gcj)\n		backend=jc1\n		;;\n	gpc)\n		backend=gpc1\n		;;\n	*77)\n		backend=f771\n		;;\n	*)\n		backend=cc1	# (near-)universal backend\n		;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		cc=$( $1 -print-prog-name=$backend )\n		# sink stderr:\n		# for C/C++/ObjectiveC it''s useless\n		# for FORTRAN/Java it''s an error\n		COMPREPLY=( $( $cc --help 2>/dev/null | tr ''\\t'' '' '' | \\\n			       sed -e ''/^  *-/!d'' -e ''s/ *-\\([^ ]*\\).*/-\\1/'' | \\\n			       command grep "^$cur" | sort -u ) )\n	else\n		_filedir\n	fi\n} &&\ncomplete $filenames -F _gcc gcc g++ c++ g77 gcj gpc\n[ $UNAME = GNU -o $UNAME = Linux -o $UNAME = Cygwin ] && \\\n[ -n "${have:-}" ] && complete $filenames -F _gcc cc\n\n# Linux cardctl(8) completion\n#\nhave cardctl &&\n_cardctl()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -W ''status config ident suspend \\\n					   resume reset eject insert scheme'' \\\n			       -- $cur ) )\n	fi\n} &&\ncomplete -F _cardctl cardctl\n\n# This function is required by _dpkg() and _dpkg-reconfigure()\n#\nhave dpkg && {\nhave grep-status && {\n_comp_dpkg_installed_packages()\n{\n	grep-status -P -e "^$1" -a -FStatus ''install ok installed'' -n -s Package\n}\n} || {\n_comp_dpkg_installed_packages()\n{\n	grep -A 2 "Package: $1" /var/lib/dpkg/status | \\\n		grep -B 2 ''ok installed'' | grep "Package: $1" | cut -d\\  -f2\n}\n}\n\n# Debian dpkg(8) completion\n#\n_dpkg()\n{\n	local cur prev i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	i=$COMP_CWORD\n\n	_expand || return 0\n\n	# find the last option flag\n	if [[ $cur != -* ]]; then\n		while [[ $prev != -* && $i != 1 ]]; do\n			i=$((i-1))\n			prev=${COMP_WORDS[i-1]}\n		done\n	fi\n\n	case "$prev" in \n	-@(c|i|A|I|f|e|x|X|-@(install|unpack|record-avail|contents|info| \\\n			  fsys-tarfile|field|control|extract)))\n		_filedir ''?(u)deb''\n		return 0\n		;;\n	-@(b|-build))\n		_filedir -d\n		return 0\n		;;\n   	-@(s|p|l|-@(status|print-avail|list)))\n		COMPREPLY=( $( apt-cache pkgnames $cur 2>/dev/null ) )\n		return 0\n		;;\n	-@(S|-search))\n		_filedir\n		return 0\n		;;\n	-@(r|L|P|-@(remove|purge|listfiles)))\n		COMPREPLY=( $( _comp_dpkg_installed_packages $cur ) )\n		return 0\n		;;\n	*)\n\n	COMPREPLY=( $( compgen -W ''-i --install --unpack -A --record-avail \\\n			--configure -r --remove -P --purge --get-selections \\\n			--set-selections --update-avail --merge-avail \\\n			--clear-avail  --command-fd --forget-old-unavail -s \\\n			--status -p --print-avail -L --listfiles -l --list \\\n			-S --search -C --audit --print-architecture \\\n			--print-gnu-build-architecture \\\n			--print-installation-architecture \\\n			--compare-versions --help --version --force-help \\\n			--force-all --force-auto-select --force-downgrade \\\n			--force-configure-any --force-hold --force-bad-path \\\n			--force-not-root --force-overwrite \\\n			--force-overwrite-diverted --force-bad-verify \\\n			--force-depends-version --force-depends \\\n			--force-confnew --force-confold --force-confdef \\\n			--force-confmiss --force-conflicts --force-architecture\\\n			--force-overwrite-dir --force-remove-reinstreq \\\n			--force-remove-essential -Dh \\\n			--debug=help --licence --admindir= --root= --instdir= \\\n			-O --selected-only -E --skip-same-version \\\n			-G --refuse-downgrade -B --auto-deconfigure \\\n			--no-debsig --no-act -D --debug= --status-fd \\\n			-b --build -I --info -f --field -c --contents \\\n			-x --extract -X --vextract --fsys-tarfile -e --control \\\n			--ignore-depends= --abort-after'' -- $cur ) )\n		;;\n	esac\n\n\n}\ncomplete -F _dpkg $filenames dpkg dpkg-deb\n}\n\n# Debian GNU dpkg-reconfigure(8) completion\n#\nhave dpkg-reconfigure &&\n_dpkg_reconfigure()\n{\n	local cur prev opt\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n\n	case "$prev" in\n	    -@(f|-frontend))\n		opt=( $( echo /usr/share/perl5/Debconf/FrontEnd/* ) )\n		opt=( ${opt[@]##*/} )\n		opt=( ${opt[@]%.pm} )\n		COMPREPLY=( $( compgen -W ''${opt[@]}'' -- $cur ) )\n		return 0\n		;;\n	    -@(p|-priority))\n  		COMPREPLY=( $( compgen -W ''low medium high critical'' -- $cur ) )\n		return 0\n		;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n	    COMPREPLY=( $( compgen -W ''-f --frontend -p --priority -a --all \\\n				       -u --unseen-only -h --help -s --showold \\\n				       --force --terse'' -- $cur ) )\n	else\n	    COMPREPLY=( $( _comp_dpkg_installed_packages $cur ) )\n	fi\n} &&\ncomplete -F _dpkg_reconfigure $default dpkg-reconfigure\n\n# Debian dpkg-source completion\n#\nhave dpkg-source &&\n_dpkg_source()\n{\n	local cur prev options work i action packopts unpackopts\n\n	packopts="-c -l -F -V -T -D -U -W -E -sa -i -I -sk -sp -su -sr -ss -sn -sA -sK -sP -sU -sR"\n	unpackopts="-sp -sn -su"\n	options=`echo "-x -b $packopts $unpackopts" | xargs echo | sort -u | xargs echo`\n\n	COMPREPLY=()\n	if [ "$1" != "dpkg-source" ]; then\n		exit 1\n	fi\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	action="options"\n	for (( i=0; i < ${#COMP_WORDS[@]}-1; i++ )); do\n		if [[ ${COMP_WORDS[$i]} == "-x" ]]; then\n			action=unpack\n		elif [[ ${COMP_WORDS[$i]} == "-b" ]]; then\n			action=pack\n		elif [[ ${COMP_WORDS[$i]} == "-h" ]]; then\n			action=help\n		fi\n	done\n	# if currently seeing a complete option, return just itself.\n	for i in $options; do\n		if [ "$cur" = "$i" ]; then\n			COMPREPLY=( "$cur" )\n			return 0\n		fi\n	done\n	case "$action" in\n		"unpack")\n			if [ "$cur" = "-" -o "$cur" = "-s" ]; then\n				COMPREPLY=( $unpackots )\n				return 0\n			fi\n			case "$prev" in\n				"-x")\n					COMPREPLY=( $( compgen -d -- "$cur" ) \\\n						    $( compgen -f -X ''!*.dsc'' -- "$cur" ) )\n					return 0\n					;;\n				*)\n					COMPREPLY=( $unpackopts $(compgen -d -f -- "$cur" ) )\n					return 0\n					;;\n			esac\n			return 0\n			;;\n		"pack")\n			if [ "$cur" = "-" ]; then\n				COMPREPLY=( $packopts )\n				return 0\n			fi\n			if [ "$cur" = "-s" ]; then\n				COMPREPLY=( "-sa" "-sk" "-sp" "-su" "-sr" "-ss" "-sn" \\\n			    		"-sA" "-sK" "-sP" "-sU" "-sR" )\n				return 0\n			fi\n			case "$prev" in\n				"-b")\n					COMPREPLY=( $( compgen -d -- "$cur" ) )\n					return 0\n					;;\n				"-c"|"-l"|"-T"|"-i"|"-I")\n					# -c: get controlfile\n					# -l: get per-version info from this file\n					# -T: read variables here, not debian/substvars\n					# -i: <regexp> filter out files to ignore diffs of.\n					# -I: filter out files when building tarballs.\n					# return directory names and file names\n					COMPREPLY=( $( compgen -d -f ) )\n					return 0\n					;;\n				"-F")\n					# -F: force change log format\n					COMPREPLY=( $( ( cd /usr/lib/dpkg/parsechangelog; compgen -f "$cur" ) ) )\n					return 0\n					;;\n				"-V"|"-D")\n					# -V: set a substitution variable\n					# we don''t know anything about possible variables or values\n					# so we don''t try to suggest any completion.\n					COMPREPLY=()\n					return 0\n					;;\n				"-D")\n					# -D: override or add a .dsc field and value\n					# if $cur doesn''t contain a = yet, suggest variable names\n					if echo -- "$cur" | grep -q "="; then\n						# $cur contains a "="\n						COMPREPLY=()\n						return 0\n					else\n						COMPREPLY=( Format Source Version Binary Maintainer Uploader Architecture Standards-Version Build-Depends Files )\n						return 0\n					fi\n					;;\n				"-U")\n					# -U: remove a field\n					# Suggest possible fieldnames\n					COMPREPLY=( Format Source Version Binary Maintainer Uploader Architecture Standards-Version Build-Depends Files )\n					return 0\n					;;\n				*)\n					COMPREPLY=( $packopts )\n					return 0\n					;;\n			esac\n			return 0\n			;;\n		*)\n			# if seeing a partial option, return possible completions.\n			if [ "$cur" = "-s" ]; then\n				COMPREPLY=( "-sa" "-sk" "-sp" "-su" "-sr" "-ss" "-sn" \\\n			    		"-sA" "-sK" "-sP" "-sU" "-sR" )\n				return 0\n			fi\n			# else return all possible options.\n			COMPREPLY=( $options )\n			return 0\n			;;\n	esac\n} &&\ncomplete -F _dpkg_source dpkg-source\n\n# Debian Linux dselect(8) completion.\n#\nhave dselect &&\n_dselect()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	     --admindir)\n		  _filedir -d\n		  return 0\n		  ;;\n\n	     -@(D|debug))\n		  _filedir\n		  return 0\n		  ;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n	    COMPREPLY=( $( compgen -W ''--admindir --help --version --licence \\\n				  --license --expert --debug'' -- $cur ) )\n	else\n	    COMPREPLY=( $( compgen -W ''access update select install config \\\n				  remove quit'' -- $cur ) )\n	fi\n\n\n	return 0\n} &&\ncomplete -F _dselect $filenames dselect\n\n# Java completion\n#\n\n# available path elements completion\nhave java && {\n_java_path()\n{\n	cur=${cur##*:}\n	_filedir ''@(jar|zip)''\n}\n\n# exact classpath determination\n_java_find_classpath()\n{\n	local i\n\n	# search first in current options\n	for (( i=1; i < COMP_CWORD; i++ )); do\n		if [[ "${COMP_WORDS[i]}" == -@(cp|classpath) ]]; then\n			classpath=${COMP_WORDS[i+1]}\n			break\n		fi\n	done\n\n	# default to environment\n	[ -z "$classpath" ] && classpath=$CLASSPATH\n\n	# default to current directory\n	[ -z "$classpath" ] && classpath=.\n}\n\n# exact sourcepath determination\n_java_find_sourcepath()\n{\n	local i\n\n	# search first in current options\n	for (( i=1; i < COMP_CWORD; i++ )); do\n		if [[ "${COMP_WORDS[i]}" == -sourcepath ]]; then\n			sourcepath=${COMP_WORDS[i+1]}\n			break\n		fi\n	done\n\n	# default to classpath\n	[ -z "$sourcepath" ] && _java_find_classpath\n	sourcepath=$classpath\n}\n\n# available classes completion\n_java_classes()\n{\n	local classpath i\n\n	# find which classpath to use\n	_java_find_classpath\n\n	# convert package syntax to path syntax\n	cur=${cur//.//}\n	# parse each classpath element for classes\n	for i in ${classpath//:/ }; do\n		if [ -r $i ] && [[ "$i" == *.@(jar|zip) ]]; then\n			if type zipinfo &> /dev/null; then\n				COMPREPLY=( ${COMPREPLY[@]} $( zipinfo -1 \\\n				"$i" | grep "^$cur" | grep ''\\.class$'' | \\\n				grep -v "\\\\$" ) )\n			else\n				COMPREPLY=( ${COMPREPLY[@]} $( jar tf "$i" \\\n				"$cur" | grep "\\.class$" | grep -v "\\\\$" ) )\n			fi\n\n		elif [ -d $i ]; then\n			i=${i%/}\n			COMPREPLY=( ${COMPREPLY[@]} $( find "$i" -type f \\\n			-path "$i/$cur*.class" 2>/dev/null | \\\n			grep -v "\\\\$" | sed -e "s|^$i/||" ) )\n		fi\n	done\n\n	# remove class extension\n	COMPREPLY=( ${COMPREPLY[@]%.class} )\n	# convert path syntax to package syntax\n	COMPREPLY=( ${COMPREPLY[@]//\\//.} )\n}\n\n# available packages completion\n_java_packages()\n{\n	local sourcepath i\n\n	# find wich sourcepath to use\n	_java_find_sourcepath\n\n	# convert package syntax to path syntax\n	cur=${cur//.//}\n	# parse each sourcepath element for packages\n	for i in ${sourcepath//:/ }; do\n		if [ -d $i ]; then\n			COMPREPLY=( ${COMPREPLY[@]} $( command ls -F -d \\\n				$i/$cur* 2>/dev/null | sed -e ''s|^''$i''/||'' ) )\n		fi\n	done\n	# keep only packages\n	COMPREPLY=( $( echo ${COMPREPLY[@]} | tr " " "\\n" | grep "/$" ) )\n	# remove packages extension\n	COMPREPLY=( ${COMPREPLY[@]%/} )\n	# convert path syntax to package syntax\n	cur=${COMPREPLY[@]//\\//.}\n}\n\n# java completion\n#\n_java()\n{\n	local cur prev i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	for ((i=1; i < $COMP_CWORD; i++)); do\n		case ${COMP_WORDS[$i]} in\n		    -cp|-classpath)\n			((i++))	# skip the classpath string.\n			;;\n		    -*)\n			# this is an option, not a class/jarfile name.\n			;;\n		    *)\n			# once we''ve seen a class, just do filename completion\n			_filedir\n			return 0\n			;;\n		esac\n	done\n\n	case $prev in\n		-@(cp|classpath))\n			_java_path\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		# relevant options completion\n		COMPREPLY=( $( compgen -W ''-client -hotspot -server -classic \\\n				-cp -classpath -D -verbose -verbose:class \\\n				-verbose:gc -version:jni -version \\\n				-showversion -? -help -X -jar \\\n				-ea -enableassertions -da -disableassertions \\\n				-esa -enablesystemassertions \\\n				-dsa -disablesystemassertions '' -- $cur ) )\n	else\n		if [[ "$prev" == -jar ]]; then\n			# jar file completion\n			_filedir jar\n		else\n			# classes completion\n			_java_classes\n		fi\n	fi\n}\ncomplete -F _java $filenames java\n}\n\n# javadoc completion\n#\nhave javadoc &&\n_javadoc()\n{\n	COMPREPLY=()\n	local cur prev\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		-@(overview|helpfile|stylesheetfile))\n			_filedir\n			return 0\n			;;\n		-d)\n			_filedir -d\n			return 0\n			;;\n		-@(classpath|bootclasspath|docletpath|sourcepath|extdirs))\n			_java_path\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		# relevant options completion\n		COMPREPLY=( $( compgen -W ''-overview -public -protected \\\n				-package -private -help -doclet -docletpath \\\n				-sourcepath -classpath -exclude -subpackages \\\n				-breakiterator -bootclasspath -source -extdirs \\\n				-verbose -locale -encoding -J -d -use -version \\\n				-author -docfilessubdirs -splitindex \\\n				-windowtitle -doctitle -header -footer -bottom \\\n				-link -linkoffline -excludedocfilessubdir \\\n				-group -nocomment -nodeprecated -noqualifier \\\n				-nosince -nodeprecatedlist -notree -noindex \\\n				-nohelp -nonavbar -quiet -serialwarn -tag \\\n				-taglet -tagletpath -charset -helpfile \\\n				-linksource -stylesheetfile -docencoding'' -- \\\n				$cur ) )\n	else\n		# source files completion\n		_filedir java\n		# packages completion\n		_java_packages\n	fi\n} &&\ncomplete -F _javadoc $filenames javadoc\n\n# javac completion\n#\nhave javac &&\n_javac()\n{\n	COMPREPLY=()\n	local cur prev\n\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		-d)\n			_filedir -d\n			return 0\n			;;\n		-@(classpath|bootclasspath|sourcepath|extdirs))\n			_java_path\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		# relevant options completion\n		COMPREPLY=( $( compgen -W ''-g -g:none -g:lines -g:vars\\\n		-g:source -O -nowarn -verbose -deprecation -classpath\\\n		-sourcepath -bootclasspath -extdirs -d -encoding -source\\\n		-target -help'' -- $cur ) )\n	else\n		# source files completion\n		_filedir java\n	fi\n} &&\ncomplete -F _javac $filenames javac\n\n# PINE address-book completion\n#\nhave pine &&\n_pineaddr()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( compgen -W ''$( awk "{print \\$1}" ~/.addressbook 2>/dev/null)'' \\\n			-- $cur ) )\n} &&\ncomplete -F _pineaddr $default pine\n\n# mutt completion\n#\n# Mutt doesn''t have an "addressbook" like Pine, but it has aliases and\n# a "query" function to retrieve addresses, so that''s what we use here.\nhave mutt || have muttng && {\n_muttaddr()\n{\n	_muttaliases\n	_muttquery\n	return 0\n}\n\n_muttconffiles()\n{\n	local file sofar\n	local -a newconffiles\n\n	sofar=" $1 "\n	shift\n	while [[ "$1" ]]; do\n	    newconffiles=( $(sed -rn ''s|^source[[:space:]]+([^[:space:]]+).*$|\\1|p'' $(eval echo $1) ) )\n	    for file in ${newconffiles[@]}; do\n		[[ ! "$file" ]] || [[ "${sofar/ ${file} / }" != "$sofar" ]] &&\n		    continue\n		sofar="$sofar $file"\n		sofar=" $(eval _muttconffiles \\"$sofar\\" $file) "\n	    done\n	    shift\n	done\n	echo $sofar\n}\n\n_muttaliases()\n{\n	local cur muttrc\n	local -a conffiles aliases\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	[ -f ~/.${muttcmd}/${muttcmd}rc ] && muttrc="~/.${muttcmd}/${muttcmd}rc"\n	[ -f ~/.${muttcmd}rc ] && muttrc="~/.${muttcmd}rc"\n	[ -z "$muttrc" ] && return 0\n\n	conffiles=( $(eval _muttconffiles $muttrc $muttrc) )\n	aliases=( $( sed -rn ''s|^alias[[:space:]]+([^[:space:]]+).*$|\\1|p'' \\\n			$(eval echo ${conffiles[@]}) ) )\n	COMPREPLY=( ${COMPREPLY[@]} $( compgen -W "${aliases[*]}" -- $cur ) )\n\n	return 0\n}\n\n_muttquery()\n{\n	local cur querycmd\n	local -a queryresults\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	querycmd="$( $muttcmd -Q query_command  | sed -r ''s|^query_command=\\"(.*)\\"$|\\1|; s|%s|''$cur''|'' )"\n	if [ -z "$cur" -o -z "$querycmd" ]; then\n	    queryresults=()\n	else \n	    queryresults=( $( $querycmd | \\\n	      sed -nr ''2,$s|^([^[:space:]]+).*|\\1|p'' ) )\n	fi\n\n	COMPREPLY=( ${COMPREPLY[@]} $( compgen -W "${queryresults[*]}" \\\n			-- $cur ) )\n\n	return 0\n}\n\n_muttfiledir()\n{\n	local cur folder spoolfile\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	# This is currently not working so well. Perhaps this function should\n	# just call _filedir() for the moment.\n	if [[ $cur == [=+]* ]]; then\n		folder="$( $muttcmd -Q folder | sed -r ''s|^folder=\\"(.*)\\"$|\\1|'' )"\n		: folder:=~/Mail\n\n		# Match any file in $folder beginning with $cur\n		# (minus the leading ''='' sign).\n		COMPREPLY=( $( compgen -f -- "$folder/${cur:1}" ) )\n		COMPREPLY=( ${COMPREPLY[@]#$folder/} )\n		return 0\n	elif [ "$cur" == !* ]; then\n		spoolfile="$( $muttcmd -Q spoolfile | sed -r ''s|^spoolfile=\\"(.*)\\"$|\\1|'' )"\n		[ ! -z "$spoolfile" ] && eval cur="${cur/^!/$spoolfile}";\n	fi\n	_filedir\n\n	return 0\n}\n\n_mutt()\n{\n	local cur prev\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	COMPREPLY=()\n	\n	[ ${COMP_WORDS[0]} == muttng ] && muttcmd="muttng" || muttcmd="mutt"\n\n	case "$cur" in\n	-*)\n		COMPREPLY=( $( compgen -W ''-A -a -b -c -e -f -F -H -i -m -n \\\n					    -p -Q -R -s -v -x -y -z -Z -h'' \\\n					    -- $cur ) )\n		return 0\n		;;\n	*)\n	    case "$prev" in\n	    -@(a|f|F|H|i))\n		    _muttfiledir\n		    return 0\n		    ;;\n	    -A)\n		    _muttaliases\n		    return 0\n		    ;;\n	    -@(e|m|Q|s|h|p|R|v|y|z|Z))\n		    return 0\n		    ;;\n	    *)\n		    _muttaddr\n		    return 0\n		    ;;\n	    esac\n	    ;;\n	esac\n	\n}\ncomplete -F _mutt $default $filenames mutt muttng\n}\n\n_configure_func()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	# if $COMP_CONFIGURE_HINTS is not null, then completions of the form\n	# --option=SETTING will include ''SETTING'' as a contextual hint\n	[[ "$cur" != -* ]] && return 0\n\n	if [ -n "$COMP_CONFIGURE_HINTS" ]; then\n		COMPREPLY=( $( $1 --help | awk ''/^  --[A-Za-z]/ { print $1; if ($2 ~ /--[A-Za-z]/) print $2 }'' | sed -e ''s/[[,].*//g'' | grep ^$cur ) )\n\n	else\n		COMPREPLY=( $( $1 --help | awk ''/^  --[A-Za-z]/ { print $1; if ($2 ~ /--[A-Za-z]/) print $2 }'' | sed -e ''s/[[,=].*//g'' | grep ^$cur ) )\n	fi\n}\ncomplete -F _configure_func $default configure\n\n# Debian reportbug(1) completion\n#\nhave reportbug &&\n_reportbug()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	    -f|--filename|-i|--include|--mta|-o|--output)\n		_filedir\n		return 0\n		;;\n	    -B|--bts)\n		COMPREPLY=( $( compgen -W "debian guug kde mandrake help" -- \\\n			       $cur ))\n		return 0\n		;;\n	    -e|--editor|--mua)\n		COMP_WORDS=(COMP_WORDS[0] $cur)\n		COMP_CWORD=1\n		_command\n		return 0\n		;;\n	    --mode)\n		COMPREPLY=( $( compgen -W "novice standard expert" -- $cur ) )\n		return 0\n		;;\n	    -S|--severity)\n		COMPREPLY=( $( compgen -W "grave serious important normal \\\n					   minor wishlist" -- $cur ) )\n		return 0\n		;;\n	    -u|--ui|--interface)\n		COMPREPLY=( $( compgen -W "newt text gnome" -- $cur ) )\n		return 0\n		;;\n	    -t|--type)\n		COMPREPLY=( $( compgen -W "gnats debbugs" -- $cur ) )\n		return 0\n		;;\n	    -T|--tags)\n		COMPREPLY=( $( compgen -W "none patch security upstream sid \\\n					   woody potato sarge fixed" -- $cur ))\n		return 0\n		;;\n	    *)\n		;;\n	esac\n	\n	COMPREPLY=($( compgen -W ''-h --help -v --version -a --af -b \\\n			--no-query-bts --query-bts -B --bts -c --configure \\\n			--no-config-files --check-available -d --debug \\\n			--no-check-available -e --editor --email -f \\\n			--filename -g --gnupg -H --header -i --include -j \\\n			--justification -l --ldap --no-ldap -L --list-cc -m \\\n			--maintonly --mode --mua --mta --mutt -n --mh --nmh \\\n			-o --output -p --print -P --pgp --proxy --http_proxy\\\n			-q --quiet -Q --query-only --realname --report-quiet \\\n			--reply-to --replyto -s --subject -S --severity \\\n			--smtphost -t --type -T --tags --template -V -x \\\n			--no-cc --package-version -z --no-compress \\\n			--ui --interface -u \\\n			wnpp boot-floppies kernel-image'' -- $cur ) \\\n	    		$( apt-cache pkgnames -- $cur ) )\n	_filedir\n	return 0\n} &&\ncomplete -F _reportbug $filenames reportbug\n\n# Debian querybts(1) completion\n#\nhave querybts &&\n_querybts()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	    -B|--bts)\n		COMPREPLY=( $( compgen -W "debian guug kde mandrake help" -- \\\n			       $cur ))\n		return 0\n		;;\n	    -u|--ui|--interface)\n		COMPREPLY=($( compgen -W "newt text gnome" -- $cur ))\n		return 0\n		;;\n	    *)\n		;;\n	esac\n\n	COMPREPLY=($( compgen -W ''-h --help -v --version -A --archive \\\n			-B --bts -l --ldap --no-ldap --proxy= --http_proxy= \\\n			-s --source -w --web -u --ui --interface \\\n			wnpp boot-floppies'' -- $cur ) \\\n	    		$( apt-cache pkgnames -- $cur ) )\n} &&\ncomplete -F _querybts $filenames querybts\n\n# update-alternatives completion\n#\nhave update-alternatives && {\ninstalled_alternatives()\n{\n	local admindir\n	# find the admin dir\n	for i in alternatives dpkg/alternatives rpm/alternatives; do\n		[ -d /var/lib/$i ] && admindir=/var/lib/$i && break\n	done\n	for (( i=1; i < COMP_CWORD; i++ )); do\n		if [[ "${COMP_WORDS[i]}" == --admindir ]]; then\n			admindir=${COMP_WORDS[i+1]}\n			break\n		fi\n	done\n	COMPREPLY=( $( command ls $admindir | grep "^$cur" ) )\n}\n\n_update_alternatives()\n{\n	local cur prev mode args i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	--@(altdir|admindir))\n		_filedir -d\n		return 0\n		;;\n	--@(help|version))\n		return 0\n		;;\n	esac\n\n	# find wich mode to use and how many real args used so far\n	for (( i=1; i < COMP_CWORD; i++ )); do\n		if [[ "${COMP_WORDS[i]}" == --@(install|remove|auto|display|config) ]]; then\n			mode=${COMP_WORDS[i]}\n			args=$(($COMP_CWORD - i))\n			break\n		fi\n	done\n\n	case $mode in\n	--install)\n		case $args in\n		1)\n			_filedir\n			;;\n		2)\n			installed_alternatives\n			;;\n		3)\n			_filedir\n			;;\n		esac\n		;;\n	--remove)\n		case $args in\n		1)\n			installed_alternatives\n			;;\n		2)\n			_filedir\n			;;\n		esac\n		;;\n	--auto)\n		installed_alternatives\n		;;\n	--display)\n		installed_alternatives\n		;;\n	--config)\n		installed_alternatives\n		;;\n	*)\n		COMPREPLY=( $( compgen -W ''--verbose --quiet --help --version \\\n			       --altdir --admindir'' -- $cur ) \\\n			    $( compgen -W ''--install --remove --auto --display \\\n			       --config'' -- $cur ) )\n	esac\n}\ncomplete -F _update_alternatives update-alternatives\n}\n\n# Python completion\n#\nhave python &&\n_python()\n{\n	local prev cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]##*/}\n\n	case "$prev" in\n	-Q)\n		COMPREPLY=( $( compgen -W "old new warn warnall" -- $cur ) )\n		return 0\n		;;\n	-W)\n		COMPREPLY=( $( compgen -W "ignore default all module once error" -- $cur ) )\n		return 0\n		;;\n	-c)\n		_filedir ''@(py|pyc|pyo)''\n		return 0\n		;;\n	!(python|-?))\n		[[ ${COMP_WORDS[COMP_CWORD-2]} != -@(Q|W) ]] && _filedir\n		;;\n	esac\n\n\n	# if ''-c'' is already given, complete all kind of files.\n	for (( i=0; i < ${#COMP_WORDS[@]}-1; i++ )); do\n		if [[ ${COMP_WORDS[i]} == -c ]]; then\n			_filedir\n		fi\n	done\n\n\n	if [[ "$cur" != -* ]]; then\n		_filedir ''@(py|pyc|pyo)''\n	else\n		COMPREPLY=( $( compgen -W "- -d -E -h -i -O -Q -S -t -u \\\n					   -U -v -V -W -x -c" -- $cur ) )\n	fi\n\n\n\n	return 0\n} &&\ncomplete -F _python $filenames python\n\n# Perl completion\n#\nhave perl &&\n{\n_perlmodules()\n{\n    COMPREPLY=( $( compgen -P "$prefix" -W "$( perl -e ''sub mods { my ($base,$dir)=@_; return if  $base !~ /^\\Q$ENV{cur}/; chdir($dir) or return; for (glob(q[*.pm])) {s/\\.pm$//; print qq[$base$_\\n]}; mods(/^(?:[.\\d]+|$Config{archname}-$Config{osname}|auto)$/ ? undef : qq[${base}${_}\\\\\\\\:\\\\\\\\:],qq[$dir/$_]) for grep {-d} glob(q[*]); } mods(undef,$_) for @INC;'' )" -- $cur ) )\n}\n\n_perl()\n{\n    local cur prev prefix temp\n\n    COMPREPLY=()\n    cur=${COMP_WORDS[COMP_CWORD]}\n    prev=${COMP_WORDS[COMP_CWORD-1]}\n    prefix=""\n\n    # completing an option (may or may not be separated by a space)\n    if [[ "$cur" == -?* ]]; then\n	temp=$cur\n	prev=${temp:0:2}\n	cur=${temp:2}\n	prefix=$prev\n    fi\n\n    # only handle module completion for now\n    case "$prev" in\n	-m|-M)\n	    _perlmodules\n	    return 0\n	    ;;\n    esac\n\n    # handle case where first parameter is not a dash option\n    if [ $COMP_CWORD -eq 1 ] && [[ "$cur" != -* ]]; then\n	_filedir\n	return 0\n    fi\n\n    # complete using basic options\n    COMPREPLY=( $( compgen -W ''-C -s -T -u -U -W -X -h -v -V -c -w -d -D -p \\\n			-n -a -F -l -0 -I -m -M -P -S -x -i -e '' -- $cur ) )\n    return 0\n}\ncomplete -F _perl $filenames perl\n\n_perldoc()\n{\n    local cur prev prefix temp\n\n    COMPREPLY=()\n    cur=${COMP_WORDS[COMP_CWORD]}\n    prev=${COMP_WORDS[COMP_CWORD-1]}\n    prefix=""\n\n    # completing an option (may or may not be separated by a space)\n    if [[ "$cur" == -?* ]]; then\n	temp=$cur\n	prev=${temp:0:2}\n	cur=${temp:2}\n	prefix=$prev\n    fi\n\n    # complete builtin perl functions\n    case $prev in\n	-f)\n	    COMPREPLY=( $( compgen -W ''chomp chop chr crypt hex index lc \\\n	    lcfirst length oct ord pack q qq reverse rindex sprintf \\\n	    substr tr uc ucfirst y m pos quotemeta s split study qr abs \\\n	    atan2 cos exp hex int log oct rand sin sqrt srand pop push \\\n	    shift splice unshift grep join map qw reverse sort unpack \\\n	    delete each exists keys values binmode close closedir \\\n	    dbmclose dbmopen die eof fileno flock format getc print \\\n	    printf read readdir rewinddir seek seekdir select syscall \\\n	    sysread sysseek syswrite tell telldir truncate warn write \\\n	    pack read syscall sysread syswrite unpack vec -X chdir chmod \\\n	    chown chroot fcntl glob ioctl link lstat mkdir open opendir \\\n	    readlink rename rmdir stat symlink umask unlink utime caller \\\n	    continue do dump eval exit goto last next redo return \\\n	    sub wantarray caller import local my our package use defined \\\n	    formline reset scalar undef \\\n	    alarm exec fork getpgrp getppid getpriority kill pipe qx \\\n	    setpgrp setpriority sleep system times wait waitpid \\\n	    import no package require use bless dbmclose dbmopen package \\\n	    ref tie tied untie use accept bind connect getpeername \\\n	    getsockname getsockopt listen recv send setsockopt shutdown \\\n	    socket socketpair msgctl msgget msgrcv msgsnd semctl semget \\\n	    semop shmctl shmget shmread shmwrite endgrent endhostent \\\n	    endnetent endpwent getgrent getgrgid getgrnam getlogin \\\n	    getpwent getpwnam getpwuid setgrent setpwent endprotoent \\\n	    endservent gethostbyaddr gethostbyname gethostent \\\n	    getnetbyaddr getnetbyname getnetent getprotobyname \\\n	    getprotobynumber getprotoent getservbyname getservbyport \\\n	    getservent sethostent setnetent setprotoent setservent \\\n	    gmtime localtime time times'' -- $cur ) )\n	    return 0\n	    ;;\n    esac\n\n    case $cur in\n	-*)\n	    COMPREPLY=( $( compgen -W ''-h -v -t -u -m -l -F -X -f -q'' -- $cur ))\n	    return 0\n	    ;;\n	*/*)\n	    return 0\n	    ;;\n	*)\n	    _perlmodules\n	    COMPREPLY=( ${COMPREPLY[@]} $( compgen -W ''$( PAGER=cat man perl 2>/dev/null | sed -ne "/perl.*Perl overview/,/perlwin32/s/^[^a-z0-9]*\\([a-z0-9]*\\).*$/\\1/p")'' -- $cur ) )\n\n	    return 0\n	    ;;\n    esac\n}\ncomplete -F _perldoc $default perldoc\n}\n\n# rcs(1) completion\n#\nhave rcs &&\n_rcs()\n{\n	local cur prev file dir i\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	file=${cur##*/}\n	dir=${cur%/*}\n\n	# deal with relative directory\n	[ "$file" = "$dir" ] && dir=.\n\n	COMPREPLY=( $( compgen -f "$dir/RCS/$file" ) )\n\n	for (( i=0; i < ${#COMPREPLY[@]}; i++ )); do\n		file=${COMPREPLY[$i]##*/}\n		dir=${COMPREPLY[$i]%RCS/*}\n		COMPREPLY[$i]=$dir$file\n	done\n	\n	COMPREPLY=( "${COMPREPLY[@]}" $( compgen -G "$dir/$file*,v" ) )\n\n	for (( i=0; i < ${#COMPREPLY[@]}; i++ )); do\n		COMPREPLY[$i]=${COMPREPLY[$i]%,v}\n	done\n\n	# default to files if nothing returned and we''re checking in.\n	# otherwise, default to directories\n	[ ${#COMPREPLY[@]} -eq 0 -a $1 = ci ] && _filedir || _filedir -d\n} &&\ncomplete -F _rcs $filenames ci co rlog rcs rcsdiff\n\n# lilo(8) completion\n#\nhave lilo && {\n_lilo_labels()\n{\n	COMPREPLY=( $( awk -F''='' ''/label/ {print $2}'' \\\n		/etc/lilo.conf | sed -e ''s/"//g'' | grep "^$cur" ) )\n}\n\n_lilo()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		-@(C|i|m|s|S))\n			_filedir\n			return 0\n			;;\n		-r)\n			_filedir -d\n			return 0\n			;;\n		-@(I|D|R))\n			# label completion\n			_lilo_labels\n			return 0\n			;;\n		-@(A|b|M|u|U))\n			# device completion\n			cur=${cur:=/dev/}\n			_filedir\n			return 0\n			;;\n		-T)\n			# topic completion\n			COMPREPLY=( $( compgen -W ''help ChRul EBDA geom geom= \\\n					table= video'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		# relevant options completion\n		COMPREPLY=( $( compgen -W ''-A -b -c -C -d -f -g -i -I -l -L -m \\\n			-M -p -P -q -r -R -s -S -t -T -u -U -v -V -w -x -z'' -- \\\n			$cur ) )\n	fi\n}\ncomplete -F _lilo lilo\n}\n\n# links completion\n#\nhave links &&\n_links()\n{\n	local cur\n  \n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n  \n	case "$cur" in\n	    --*)\n		COMPREPLY=( $( compgen -W ''--help'' -- $cur ) )\n		;;\n	    -*)\n		COMPREPLY=( $( compgen -W ''-async-dns -max-connections \\\n				-max-connections-to-host -retries \\\n				-receive-timeout -unrestartable-receive-timeout\\\n				-format-cache-size -memory-cache-size \\\n				-http-proxy -ftp-proxy -download-dir \\\n				-assume-codepage -anonymous -dump -no-connect \\\n				-source -version -help'' -- $cur ) )\n		;;\n	    *)\n		if [ -r ~/.links/links.his ]; then\n		    COMPREPLY=( $( compgen -W ''$( < ~/.links/links.his )'' \\\n				   -- $cur ) )\n		fi\n				_filedir ''@(htm|html)''\n				return 0\n		;;\n	esac\n  \n	return 0\n} &&\ncomplete -F _links $filenames links\n\n[ $UNAME = FreeBSD ] && {\n# FreeBSD package management tool completion\n#\n_pkg_delete()\n{\n	local cur pkgdir prev\n\n	pkgdir=${PKG_DBDIR:-/var/db/pkg}/\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	[ "$prev" = "-o" -o "$prev" = "-p" -o "$prev" = "-W" ] && return 0\n\n	COMPREPLY=( $( compgen -d $pkgdir$cur ) )\n	COMPREPLY=( ${COMPREPLY[@]#$pkgdir} )\n\n	return 0\n}\ncomplete -F _pkg_delete $dirnames pkg_delete pkg_info\nhave pkg_deinstall && complete -F _pkg_delete $dirnames pkg_deinstall\n\n# FreeBSD kernel module commands\n#\n_kldload()\n{\n	local cur moddir\n\n	moddir=/modules/\n	[ -d $moddir ] || moddir=/boot/kernel/\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( compgen -f $moddir$cur ) )\n	COMPREPLY=( ${COMPREPLY[@]#$moddir} )\n	COMPREPLY=( ${COMPREPLY[@]%.ko} )\n\n	return 0\n}\ncomplete -F _kldload $filenames kldload\n\n_kldunload()\n{\n	local cur\n	cur=${COMP_WORDS[COMP_CWORD]}\n	COMPREPLY=( $(kldstat | sed -ne "s/^.*[ \\t]\\+\\($cur[a-z_]\\+\\).ko$/\\1/p") )\n}\ncomplete -F _kldunload $filenames kldunload\n}\n\n# FreeBSD portupgrade completion\n#\nhave portupgrade &&\n_portupgrade()\n{\n	local cur pkgdir prev\n\n	pkgdir=${PKG_DBDIR:-/var/db/pkg}/\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	[ "$prev" = "-l" -o "$prev" = "-L" -o "$prev" = "-o" ] && return 0\n\n	COMPREPLY=( $( compgen -d $pkgdir$cur ) )\n	COMPREPLY=( ${COMPREPLY[@]#$pkgdir} )\n	COMPREPLY=( ${COMPREPLY[@]%-*} )\n\n	return 0\n} &&\ncomplete -F _portupgrade $dirnames portupgrade\n\n# FreeBSD portinstall completion\n#\nhave portinstall &&\n_portinstall()\n{\n	local cur portsdir prev indexfile\n	local -a COMPREPLY2\n\n	portsdir=${PORTSDIR:-/usr/ports}/\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	# First try INDEX-5\n	indexfile=$portsdir/INDEX-5\n	# Then INDEX if INDEX-5 does not exist or system is not FreeBSD 5.x\n	[ "${OSTYPE%.*}" = "freebsd5" -a -f $indexfile ] ||\n	  indexfile=$portsdir/INDEX\n\n	[ "$prev" = "-l" -o "$prev" = "-L" -o "$prev" = "-o" ] && return 0\n\n	COMPREPLY=( $( egrep "^$cur" < $indexfile | cut -d''|'' -f1 ) )\n	COMPREPLY2=( $( egrep "^[^\\|]+\\|$portsdir$cur" < $indexfile | \\\n			cut -d''|'' -f2 ) )\n	COMPREPLY2=( ${COMPREPLY2[@]#$portsdir} )\n	COMPREPLY=( ${COMPREPLY[@]} ${COMPREPLY2[@]} )\n\n	return 0\n} &&\ncomplete -F _portinstall $dirnames portinstall\n\n# Slackware Linux removepkg completion\n#\nhave removepkg && [ -f /etc/slackware-version ] &&\n_removepkg()\n{\n	local packages cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( (cd /var/log/packages; compgen -f -- "$cur") ) )\n} &&\ncomplete -F _removepkg $filenames removepkg &&\n	complete $dirnames -f -X ''!*.tgz'' installpkg upgradepkg explodepkg\n\n# look(1) completion\n#\nhave look && \n_look()\n{\n	local cur\n  \n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD = 1 ]; then\n		COMPREPLY=( $( compgen -W ''$(look $cur)'' ) )\n	fi\n} &&\ncomplete -F _look $default look\n\n# ypcat(1) and ypmatch(1) completion\n#\nhave ypmatch &&\n_ypmatch()\n{\n	local cur map\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	[ $1 = ypcat ] && [ $COMP_CWORD -gt 1 ] && return 0\n	[ $1 = ypmatch ] && [ $COMP_CWORD -gt 2 ] && return 0\n\n	if [ $1 = ypmatch ] && [ $COMP_CWORD -eq 1 ] && \\\n	   [ ${#COMP_WORDS[@]} -eq 3 ]; then\n		map=${COMP_WORDS[2]}\n		COMPREPLY=( $( compgen -W ''$( ypcat $map | \\\n						cut -d'':'' -f 1 )'' -- $cur) )\n	else\n		[ $1 = ypmatch ] && [ $COMP_CWORD -ne 2 ] && return 0\n		COMPREPLY=( $( compgen -W \\\n			      ''$( echo $(ypcat -x | cut -d"\\"" -f 2))'' -- $cur))\n	fi\n\n	return 0\n} &&\ncomplete -F _ypmatch ypmatch ypcat\n\n# mplayer(1) completion\n#\nhave mplayer && {\n_mplayer_options_list()\n{\n	cur=${cur%\\\\}\n	COMPREPLY=( $( $1 $2 help 2> /dev/null | \\\n		sed -e ''1,/^Available/d'' | awk ''{print $1}'' | \\\n		sed -e ''s/:$//'' -e ''s/^''${2#-}''$//'' -e ''s/<.*//'' | \\\n		grep "^$cur" ) )\n}\n\n_mplayer()\n{\n	local cmd cur prev skinsdir IFS=$'' \\t\\n'' i j k=0\n\n	COMPREPLY=()\n	cmd=${COMP_WORDS[0]}\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(ac|afm|vc|vfm|ao|vo|vop|fstype))\n			_mplayer_options_list mplayer $prev\n			return 0\n			;;\n		-@(oac|ovc|of))\n			_mplayer_options_list mencoder $prev\n			return 0\n			;;\n		-audiofile)\n			_filedir ''@(mp3|MP3|mpg|MPG|ogg|OGG|wav|WAV|mid|MID)''\n			return 0\n			;;\n		-font)\n			_filedir ''@(desc|ttf)''\n			return 0\n			;;\n		-sub)\n			_filedir ''@(srt|SRT|sub|SUB|txt|TXT|utf|UTF|rar|RAR|mpsub|smi|js)''\n			return 0\n			;;\n		-vobsub)\n			_filedir ''@(idx|IDX|ifo|IFO|sub|SUB)''\n			IFS=$''\\t\\n'' \n			COMPREPLY=( $( for i in ${COMPREPLY[@]}; do\n						if [ -f $i -a -r $i ]; then\n							echo ${i%.*}\n						else\n							echo $i\n						fi\n				       done ) )\n			IFS=$'' \\t\\n'' \n			return 0\n			;;\n		-ifo)\n			_filedir ''@(ifo|IFO)''\n			return 0\n			;;\n		-cuefile)\n			_filedir ''@(bin|BIN|cue|CUE)''\n			return 0\n			;;\n		-skin)\n			# if you don''t have installed mplayer in /usr/local you\n			# may want to set the MPLAYER_SKINS_DIR global variable\n			if [ -n "$MPLAYER_SKINS_DIR" ]; then\n				skinsdir=$MPLAYER_SKINS_DIR\n			else\n				skinsdir=/usr/local/share/mplayer/Skin\n			fi\n\n			IFS=$''\\t\\n'' \n			for i in ~/.mplayer/Skin $skinsdir; do\n				if [ -d $i -a -r $i ]; then\n					for j in $( compgen -d $i/$cur ); do\n						COMPREPLY[$k]=${j#$i/}\n						k=$((++k))\n					done\n				fi\n			done\n			IFS=$'' \\t\\n'' \n			return 0\n			;;\n		-@(mixer|@(cdrom|dvd)-device|dvdauth|fb|zrdev))\n			cur=${cur:=/dev/}\n			_filedir\n			return 0\n			;;\n		-@(edl?(out)|lircconf|menu-cfg|playlist|csslib|dumpfile)| \\\n		-@(subfile|vobsub|aofile|fbmodeconfig|include|o|dvdkey)| \\\n		-passlogfile)\n			_filedir\n			return 0\n			;;\n		-@(auto@(q|sync)|loop|menu-root|speed|sstep|aid|alang)| \\\n		-@(?(@(audio|sub)-)demuxer|bandwidth|cache|chapter)| \\\n		-@(dvd?(angle)|fps|frames|mc|passwd|user|sb|srate|ss|vcd)| \\\n		-@(vi?(d|vo)|ffactor|sid|slang|spu@(align|aa|gauss))| \\\n		-@(vobsubid|delay|bpp|brightness|contrast|dfbopts|display)| \\\n		-@(fbmode|geometry|guiwid|hue|icelayer|screen[wh]|wid)| \\\n		-@(monitor@(aspect|-@(dotclock|[hv]freq))|panscan|saturation)| \\\n		-@(xineramascreen|zr@(crop|norm|quality|[xy]doff|[vh]dec))| \\\n		-@(aspect|pp|x|y|xy|z|stereo|audio-@(density|delay|preload))| \\\n		-@(endpos|osdlevel|ffourcc|sws|channels|skiplimit|format)| \\\n		-@(ofps|aa@(driver|@(osd|sub)color)|vobsubout?(i@(ndex|d)))| \\\n		-sub@(-bg-@(alpha|color)|cp|delay|fps|pos|align|width)| \\\n		-sub@(font-@(blur|outline|autoscale|encoding|@(osd|text)-scale)))\n			return 0\n			;;\n		-lavdopts)\n			COMPREPLY=( $( compgen -W ''ec er= bug= idct= gray'' \\\n					-- $cur ) )\n			return 0\n			;;\n		-lavcopts)\n			COMPREPLY=( $( compgen -W ''vcodec= vqmin= vqscale= \\\n					vqmax= mbqmin= mbqmax= vqdiff= \\\n					vmax_b_frames= vme= vhq v4mv \\\n					keyint= vb_strategy= vpass= \\\n					aspect= vbitrate= vratetol= \\\n					vrc_maxrate= vrc_minrate= \\\n					vrc_buf_size= vb_qfactor= vi_qfactor= \\\n					vb_qoffset= vi_qoffset= vqblur= \\\n					vqcomp= vrc_eq= vrc_override= \\\n					vrc_init_cplx= vqsquish= vlelim= \\\n					vcelim= vstrict= vdpart vpsize= gray \\\n					vfdct= idct= lumi_mask= dark_mask= \\\n					tcplx_mask= scplx_mask= naq ildct \\\n					format= pred qpel precmp= cmp= \\\n					subcmp= predia= dia= trell last_pred= \\\n					preme= subq= psnr mpeg_quant aic umv'' \\\n					-- $cur ) )\n			return 0\n			;;\n		-ssf)\n			COMPREPLY=( $( compgen -W ''lgb= cgb= ls= cs= chs= \\\n					cvs='' -- $cur ) )\n			return 0\n			;;\n		-jpeg)\n			COMPREPLY=( $( compgen -W ''noprogressive progressive \\\n					nobaseline baseline optimize= \\\n					smooth= quality= outdir='' -- $cur ) )\n			return 0\n			;;\n		-xvidopts)\n			COMPREPLY=( $( compgen -W ''dr2 nodr2'' -- $cur ) )\n			return 0\n			;;\n		-xvidencopts)\n			COMPREPLY=( $( compgen -W ''pass= bitrate= \\\n					fixed_quant= me_quality= 4mv \\\n					rc_reaction_delay_factor= \\\n					rc_averaging_period= rc_buffer= \\\n					quant_range= min_key_interval= \\\n					max_key_interval= mpeg_quant \\\n					mod_quant lumi_mask hintedme \\\n					hintfile debug keyframe_boost= \\\n					kfthreshold= kfreduction='' -- $cur ) )\n			return 0\n			;;\n		-divx4opts)\n			COMPREPLY=( $( compgen -W ''br= key= deinterlace q= \\\n					min_quant= max_quant= rc_period= \\\n					rc_reaction_period= crispness= \\\n					rc_reaction_ratio= pass= vbrpass= \\\n					help'' -- $cur ) )\n			return 0\n			;;\n		-info)\n			COMPREPLY=( $( compgen -W ''name= artist= genre= \\\n					subject= copyright= srcform= \\\n					comment= help'' -- $cur ) )\n			return 0\n			;;\n		-lameopts)\n			COMPREPLY=( $( compgen -W ''vbr= abr cbr br= q= aq= \\\n					ratio= vol= mode= padding= fast \\\n					preset= help'' -- $cur ) )\n			return 0\n			;;\n		-rawaudio)\n			COMPREPLY=( $( compgen -W ''on channels= rate= \\\n					samplesize= format='' -- $cur ) )\n			return 0\n			;;\n		-rawvideo)\n			COMPREPLY=( $( compgen -W ''on fps= sqcif qcif cif \\\n					4cif pal ntsc w= h= y420 yv12 yuy2 \\\n					y8 format= size='' -- $cur ) )\n			return 0\n			;;\n		-aop)\n			COMPREPLY=( $( compgen -W ''list= delay= format= fout= \\\n					volume= mul= softclip'' -- $cur ) )\n			return 0\n			;;\n		-dxr2)\n			COMPREPLY=( $( compgen -W ''ar-mode= iec958-encoded \\\n					iec958-decoded mute ucode= 75ire bw \\\n					color interlaced macrovision= norm= \\\n					square-pixel ccir601-pixel cr-left= \\\n					cr-right= cr-top= cr-bot= ck-rmin= \\\n					ck-gmin= ck-bmin= ck-rmax= ck-gmax= \\\n					ck-bmax= ck-r= ck-g= ck-b= \\\n					ignore-cache= ol-osd= olh-cor= \\\n					olw-cor= olx-cor= oly-cor= overlay \\\n					overlay-ratio= update-cache'' -- $cur ))\n			return 0\n			;;\n		-tv)\n			COMPREPLY=( $( compgen -W ''on noaudio driver= device= \\\n					input= freq= outfmt= width= height= \\\n					buffersize= norm= channel= chanlist= \\\n					audiorate= forceaudio alsa amode= \\\n					forcechan= adevice= audioid= volume= \\\n					bass= treble= balance= fps= \\\n					channels= immediatemode='' -- $cur ) )\n			return 0\n			;;\n		-mf)\n			COMPREPLY=( $( compgen -W ''on w= h= fps= type='' \\\n					-- $cur ) )\n			return 0\n			;;\n		-cdda)\n			COMPREPLY=( $( compgen -W ''speed= paranoia= \\\n					generic-dev= sector-size= overlap= \\\n					toc-bias toc-offset= skip noskip'' \\\n					-- $cur ) )\n			return 0\n			;;\n		-input)\n			COMPREPLY=( $( compgen -W ''conf= ar-delay ar-rate \\\n					keylist cmdlist js-dev file'' -- $cur ) )\n			return 0\n			;;\n		-af)\n			COMPREPLY=( $( compgen -W ''resample resample= \\\n					channels channels= format format= \\\n					volume volume= delay delay= pan \\\n					pan= sub sub= surround surround='' \\\n					-- $cur ) )\n			return 0\n			;;\n		-af-adv)\n			COMPREPLY=( $( compgen -W ''force= list='' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	case "$cur" in\n		-*)\n			COMPREPLY=( $( compgen -W ''-aid -alang -audio-demuxer \\\n					-audiofile -cdrom-device -cache -cdda \\\n					-channels -chapter -csslib -demuxer \\\n					-dvd -dvd-device -dvdangle -dvdauth \\\n					-dvdkey -dvdnav -forceidx -fps -frames \\\n					-hr-mp3-seek -idx -mc -mf -ni -nobps \\\n					-passwd -rawaudio -rtsp-stream-over-tcp\\\n					-skipopening -sb -srate -ss -tv -user \\\n					-vcd -vid -vivo -ifo -ffactor -font \\\n					-noautosub -nooverlapsub -sid -slang \\\n					-sub -subcc -subcp -sub-demuxer \\\n					-subdelay -subfont-autoscale \\\n					-subfont-blur -subfont-encoding \\\n					-subfont-osd-scale -subfont-outline \\\n					-subfont-text-scale -subfps -subfile \\\n					-subpos -unicode -utf8 -vobsub \\\n					-vobsubid -ac -afm -aspect -flip \\\n					-lavdopts -noaspect -nosound -pp -ssf \\\n					-stereo -sws -vc -vfm -vop -xvidopts\\\n					-xy -zoom -bandwidth -cuefile \\\n					-noextbased -rawvideo -overlapsub \\\n					-sub-bg-alpha -sub-bg-color -subalign \\\n					-subwidth -sub-no-text-pp -spualign \\\n					-spuaa -spugauss -pphelp -verbose -v \\\n					-noni -noidx -nohr-mp3-seek -extbased \\\n					-bps -oldpp -nozoom -noflip -nounicode \\\n					-noutf8'' -- $cur ) )\n			# add mplayer specific options\n			[[ "$cmd" == @(?(g)mplayer) ]] && COMPREPLY=( ${COMPREPLY[@]} \\\n				$(compgen -W ''-autoq -autosync -benchmark \\\n					-framedrop -h -help -hardframedrop \\\n					-identify -input -lircconf -loop \\\n					-nojoystick -nolirc -nortc -playlist \\\n					-quiet -really-quiet -rnd -sdp -skin \\\n					-slave -softsleep -speed -sstep \\\n					-use-stdin -dumpaudio -dumpfile \\\n					-dumpstream -dumpvideo -dumpmicrodvdsub\\\n					-dumpmpsub -dumpsrtsub -dumpjacosub \\\n					-dumpsami -dumpsub -osdlevel -af \\\n					-af-adv -ao -aofile -aop -delay -mixer \\\n					-nowaveheader -bpp -brightness \\\n					-contrast -display -double -dr -dxr2 \\\n					-fb -fbmode -fbmodeconfig -forcexv -fs \\\n					-geometry -hue -icelayer -jpeg \\\n					-monitor-dotclock -monitor-hfreq \\\n					-monitor-vfreq -monitoraspect \\\n					-nograbpointer -noslices -panscan \\\n					-rootwin -saturation -screenw -screenh \\\n					-stop-xscreensaver -vm -vo -vsync -wid \\\n					-xineramascreen -z -zrbw -zrcrop \\\n					-zrdev -zrfd -zrhelp -zrnorm -zrquality \\\n					-zrvdec -zrhdec -zrxdoff -zrydoff -y \\\n					-edl -edlout -enqueue -fixed-vo \\\n					-menu -menu-root -menu-cfg -shuffle \\\n					-format -aahelp -dfbopts -fstype \\\n					-guiwid -nokeepaspect -x --help \\\n					-aaosdcolor -aasubcolor -aadriver \\\n					-aaextended -aaeight'' -- $cur) )\n			# add mencoder specific options\n			[[ "$cmd" = mencoder ]] && COMPREPLY=( ${COMPREPLY[@]} \\\n				$(compgen -W ''-audio-density -audio-delay \\\n					-audio-preload -divx4opts -endpos \\\n					-ffourcc -include -info -lameopts \\\n					-lavcopts -noskip -o -oac -ofps -ovc \\\n					-passlogfile -skiplimit -vobsubout \\\n					-vobsuboutindex -vobsuboutid \\\n					-xvidencopts -of --verbose'' -- $cur) )\n			;;\n		*)\n			_filedir ''@(mp?(e)g|MP?(E)G|wm[av]|WM[AV]|avi|AVI|asf|ASF|vob|VOB|bin|BIN|dat|DAT|vcd|VCD|ps|PS|pes|PES|fli|FLI|viv|VIV|rm?(j)|RM?(J)|ra?(m)|RA?(M)|yuv|YUV|mov|MOV|qt|QT|mp[34]|MP[34]|og[gm]|OG[GM]|wav|WAV|dump|DUMP|mkv|MKV|m4a|M4A|aac|AAC|m2v|M2V|dv|DV|rmvb|RMVB|mid|MID|ts|TS|3gp|mpc|MPC|flac|FLAC)''\n			;;\n	esac\n\n	return 0\n}\ncomplete $filenames -F _mplayer mplayer mencoder gmplayer kplayer\n}\n\n# KDE dcop completion\n#\nhave dcop &&\n_dcop()\n{\n	local cur compstr\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	if [ -z $cur ]; then\n	    compstr=${COMP_WORDS[*]}\n	else\n	    compstr=$( command echo ${COMP_WORDS[*]} | sed "s/ $cur$//" )\n	fi\n	COMPREPLY=( $( compgen -W ''$( command $compstr | sed s/\\(.*\\)// )''  -- $cur ) )\n} &&\ncomplete -F _dcop dcop\n\n# wvdial(1) completion\n#\nhave wvdial &&\n_wvdial()\n{\n	local cur prev config i IFS=$''\\t\\n''\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		--config)\n			_filedir\n			return 0\n			;;\n	esac\n\n	case $cur in\n		-*)\n			COMPREPLY=( $( compgen -W ''--config --chat \\\n				--remotename --help --version --no-syslog'' \\\n				-- $cur ) )\n			;;\n		*)\n			# start with global and personal config files\n		       	config="/etc/wvdial.conf"$''\\t''"$HOME/.wvdialrc"\n			# replace with command line config file if present\n			for (( i=1; i < COMP_CWORD; i++ )); do\n				if [[ "${COMP_WORDS[i]}" == "--config" ]]; then\n					config=${COMP_WORDS[i+1]}\n					break\n				fi\n			done\n			# parse config files for sections and\n			# remove default section\n			COMPREPLY=( $( sed -ne \\\n				    "s|^\\[Dialer \\($cur.*\\)\\]$|\\1|p" \\\n				    $config 2>/dev/null |grep -v ''^Defaults$''))\n			# escape spaces\n			COMPREPLY=${COMPREPLY// /\\\\ }\n			;;\n	esac\n\n} &&\ncomplete -F _wvdial wvdial\n\n# gpg(1) completion\n#\nhave gpg &&\n_gpg() \n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-@(s|-sign|-clearsign|-decrypt-files|-load-extension)) \n		_filedir\n		return 0\n		;;\n	--@(export|@(?(l|nr|nrl)sign|edit)-key)) \n		# return list of public keys\n		COMPREPLY=( $( compgen -W "$( gpg --list-keys 2>/dev/null | sed -ne ''s@^pub.*/\\([^ ]*\\).*\\(<\\([^>]*\\)>\\).*$@\\1 \\3@p'')" -- "$cur" ))\n		return 0\n		;;\n	-@(r|-recipient))\n		COMPREPLY=( $( compgen -W "$( gpg --list-keys 2>/dev/null | sed -ne ''s@^pub.*<\\([^>]*\\)>.*$@\\1@p'')" -- "$cur" ))\n		if [ -e ~/.gnupg/gpg.conf ]; then\n			COMPREPLY=( ${COMPREPLY[@]} $( compgen -W "$( sed -ne ''s@^[ \\t]*group[ \\t][ \\t]*\\([^=]*\\).*$@\\1@p'' ~/.gnupg/gpg.conf  )" -- "$cur") )\n		fi\n		return 0\n		;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-s -b -e -f -c -d -a -r -u -Z -o -v\\\n				-q -n -N $(gpg --dump-options)'' -- $cur ) )\n	 fi\n\n} &&\ncomplete -F _gpg $default gpg\n\n# iconv(1) completion\n#\nhave iconv &&\n_iconv()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(f|t|-@(from|to)-code))\n			COMPREPLY=( $( compgen -W \\\n			    ''$( iconv --list | sed -e "s@//@@;" )'' -- "$cur" ) )\n			return 0\n			;;\n	esac\n\n\n	if [[ "$cur" = -* ]]; then\n		COMPREPLY=( $( compgen -W ''--from-code -f --to-code -t --list\n		--output -o --verbose'' -- "$cur" ) )\n		return 0\n	fi\n} &&\ncomplete -F _iconv $default iconv\n\n# dict(1) completion\n#\n{ have dict || have rdict; } && {\n_dictdata()\n{\n	dict $host $port $1 2>/dev/null | sed -ne \\\n	    ''s/^[''$''\\t ''''][''$''\\t '''']*\\([^''$''\\t '''']*\\).*$/\\1/p''\n}\n\n_dict()\n{\n	local cur prev host port db dictfile\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n	dictfile=/usr/share/dict/words\n\n	for (( i=1; i < COMP_CWORD; i++ )); do\n		case "${COMP_WORDS[i]}" in\n		-@(h|--host))\n			host=${COMP_WORDS[i+1]}\n			[ -n "$host" ] && host="-h $host"\n			i=$((++i))\n			;;\n		-@(p|-port))\n			port=${COMP_WORDS[i+1]}\n			[ -n "$port" ] && port="-p $port"\n			i=$((++i))\n			;;\n		-@(d|-database))\n			db=${COMP_WORDS[i+1]}\n			[ -n "$db" ] && host="-d $db"\n			i=$((++i))\n			;;\n		*)\n			;;\n		esac\n	done\n\n	if [[ "$cur" = -* ]]; then\n		COMPREPLY=( $( compgen -W ''-h --host -p --port -d --database \\\n			       -m --match -s --strategy -c --config -C \\\n			       --nocorrect -D --dbs -S --strats -H \\\n			       --serverhelp -i --info -I --serverinfo \\\n			       -a --noauth -u --user -k --key -V --version \\\n			       -L --license --help -v --verbose -r --raw \\\n			       -P --pager --debug --html --pipesize --client'' \\\n			       -- "$cur" ) )\n		return 0\n	fi\n\n	case "$prev" in\n	-@(d|-database|i|info))\n		COMPREPLY=( $( compgen -W ''$( _dictdata -D )'' -- "$cur" ) )\n		return 0\n		;;\n	-@(s|-strategy))\n		COMPREPLY=( $( compgen -W ''$( _dictdata -S )'' -- "$cur" ) )\n		return 0\n		;;\n	*)\n		;;\n	esac\n\n	[ -r $dictfile ] && \\\n		COMPREPLY=( $( compgen -W ''$( cat $dictfile )'' -- "$cur" ) )\n}\ncomplete -F _dict $default dict rdict\n}\n\n# cdrecord(1) completion\n#\nhave cdrecord &&\n_cdrecord()\n{\n	local cur prev i generic_options track_options track_mode\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# foo=bar style option\n	if [[ "$cur" == *=* ]]; then\n		prev=${cur/=*/}\n		cur=${cur/*=/}\n		case "$prev" in\n			@(text|cue)file)\n				_filedir\n				return 0\n				;;\n			blank)\n				COMPREPLY=( $( compgen -W ''help all fast \\\n				track unreserve trtail unclose session'' \\\n				-- $cur ) )\n				return 0\n				;;\n			driveropts)\n				COMPREPLY=( $( compgen -W ''burnfree noburnfree\\\n				  varirec= audiomaster forcespeed noforcespeed\\\n				  speedread nospeedread singlesession \\\n				  nosinglesession hidecdr nohidecdr tattooinfo\\\n				  tattoofile='' -- $cur ) )\n				return 0\n				;;\n		esac\n	fi\n\n	generic_options=(-version -v -V -d -silent -s -force -immed -dummy \\\n			 -dao -raw -raw96r -raw96p -raw16 -multi -msinfo -toc \\\n			 -atip -fix -nofix -waiti -load -lock -eject -format \\\n			 -setdropts -checkdrive -prcap -inq -scanbus -reset \\\n			 -abort -overburn -ignsize -useinfo -packet -noclose \\\n			 -text debug= kdebug= kd= minbuf= speed= blank= fs= \\\n			 dev= gracetime= timeout= driver= driveropts= \\\n			 defpregap= pktsize= mcn= textfile= cuefile=)\n	track_options=(-audio -swab -data -mode2 -xa -xa1 -xa2 -xamix -cdi \\\n		       -isosize -pad padsize= -nopad -shorttrack -noshorttrack\\\n		       pregap= -preemp -nopreemp -copy -nocopy -scms tcsize= \\\n		       isrc= index=)\n	# look if previous was either a file or a track option\n	track_mode=0\n	if [ $COMP_CWORD -gt 1 ]; then\n		if [ -f "$prev" ]; then\n			track_mode=1\n		else\n			for (( i=0; i < ${#track_options[@]}; i++ )); do\n				if [[ "${track_options[i]}" == "$prev" ]]; then\n					track_mode=1\n					break\n				fi\n			done\n		fi\n	fi\n\n	# files are always eligible completion\n	_filedir\n	# track options are always available\n	COMPREPLY=( ${COMPREPLY[@]} $( compgen -W ''${track_options[@]}'' -- $cur ) )\n	# general options are no more available after file or track option\n	if [ $track_mode -eq 0 ]; then\n		COMPREPLY=( ${COMPREPLY[@]} \\\n			    $( compgen -W ''${generic_options[@]}'' -- $cur ) )\n	fi\n\n} &&\ncomplete -F _cdrecord $filenames cdrecord\n\n# mkisofs(8) completion\n#\nhave mkisofs &&\n_mkisofs()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(o|abstract|biblio|check-session|copyright|log-file|root-info|prep-boot|*-list))\n			_filedir\n			return 0\n			;;\n		-*-charset)\n			COMPREPLY=( $( mkisofs -input-charset help 2>&1 | \\\n					tail +3 | grep "^$cur") )\n			return 0\n			;;\n		-uid)\n			_uids\n			return 0\n			;;\n		-gid)\n			_gids\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-abstract -A -allow-lowercase \\\n				-allow-multidot -biblio -cache-inodes \\\n				-no-cache-inodes -b -eltorito-alt-boot -B -G \\\n				-hard-disk-boot -no-emul-boot -no-boot \\\n				-boot-load-seg -boot-load-size \\\n				-boot-info-table -C -c -check-oldname \\\n				-check-session -copyright -d -D -dir-mode \\\n				-dvd-video -f -file-mode -gid -gui \\\n				-graft-points -hide -hide-list -hidden \\\n				-hidden-list -hide-joliet -hide-joliet-list \\\n				-hide-joliet-trans-tbl -hide-rr-moved \\\n				-input-charset -output-charset -iso-level -J \\\n				-joliet-long -jcharset -l -L -log-file -m \\\n				-exclude-list -max-iso9660-filenames -M -N \\\n				-new-dir-mode -nobak -no-bak -force-rr -no-rr \\\n				-no-split-symlink-components \\\n				-no-split-symlink-fields -o -pad -no-pad \\\n				-path-list -P -p -print-size -quiet -R -r \\\n				-relaxed-filenames -sort -split-output \\\n				-stream-media-size -stream-file-name -sysid -T\\\n				-table-name -ucs-level -udf -uid \\\n				-use-fileversion -U -no-iso-translate -V \\\n				-volset -volset-size -volset-seqno -v -x -z \\\n				-hfs -apple -map -magic -hfs-creator \\\n				-hfs-type -probe -no-desktop -mac-name \\\n				-boot-hfs-file -part -auto -cluster-size \\\n				-hide-hfs -hide-hfs-list -hfs-volid \\\n				-icon-position -root-info -prep-boot \\\n				-input-hfs-charset -output-hfs-charset \\\n				-hfs-unlock -hfs-bless -hfs-parms --cap \\\n				--netatalk --double --ethershare --ushare \\\n				--exchange --sgi --xinet --macbin --single \\\n				--dave --sfm --osx-double --osx-hfs'' -- $cur ))\n	else\n		_filedir\n	fi\n\n} &&\ncomplete -F _mkisofs $filenames mkisofs\n\n# mc(1) completion\n#\nhave mc &&\n_mc()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# -name value style option\n	case "$prev" in\n		-@(e|v|l|P))\n			_filedir\n			return 0\n			;;\n	esac\n\n	# --name=value style option\n	if [[ "$cur" == *=* ]]; then\n		prev=${cur/=*/}\n		cur=${cur/*=/}\n		case "$prev" in\n			--@(edit|view|ftplog|printwd))\n				_filedir\n				return 0\n				;;\n		esac\n	fi\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-a --stickchars -b --nocolor -c \\\n			--color -C --colors= -d --nomouse -e --edit= -f \\\n			--datadir -k --resetsoft -l --ftplog= -P --printwd= \\\n			-s --slow -t --termcap -u --nosubshell -U --subshell \\\n			-v --view= -V --version -x --xterm -h --help'' -- $cur ) )\n	else\n		_filedir -d\n	fi\n} &&\ncomplete -F _mc $filenames mc\n\n# yum(8) completion\n#\nhave yum && {\n_yum()\n{\n	local cur prev special\n	\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	for (( i=0; i < ${#COMP_WORDS[@]}-1; i++ )); do\n		if [[ ${COMP_WORDS[i]} == @(install|update|upgrade|remove|erase|deplist) ]]; then\n			special=${COMP_WORDS[i]}\n		fi\n	done\n\n	if [ -n "$special" ]; then\n	    case $special in\n		install|deplist)\n		    COMPREPLY=( $( compgen -W ''$( yum -C list | cut -d" " -f1 )'' -- $cur ) )\n		    return 0\n		    ;;\n		*)\n		    _rpm_installed_packages\n		    return 0\n		    ;;\n		esac\n	fi\n\n	case $cur in\n	    --*)\n		COMPREPLY=( $( compgen -W ''--installroot --version --help --enablerepo --disablerepo --exclude --obsoletes --noplugins'' -- $cur ) )\n		return 0\n		;;\n	    -*)\n		COMPREPLY=( $( compgen -W ''-c -e -d -y -t -R -C -h'' -- $cur ) )\n		return 0\n		;;\n	esac\n\n	case $prev in\n	    list)\n		COMPREPLY=( $( compgen -W ''all available updates installed extras obsoletes recent'' -- $cur ) )\n		;;\n	    clean)\n		COMPREPLY=( $( compgen -W ''packages headers metadata cache dbcache all'' -- $cur ) )\n		;;\n	    localinstall)\n		_filedir rpm\n		;;\n	    -c)\n		_filedir\n		;;\n	    --installroot)\n		_filedir -d\n		;;\n	    *)\n		COMPREPLY=( $( compgen -W ''install update check-update upgrade remove list \\\n						search info provides clean groupinstall groupupdate \\\n						grouplist deplist erase groupinfo groupremove \\\n						localinstall localupdate makecache resolvedep \\\n						shell whatprovides'' -- $cur ) )\n		;;\n	esac\n}\ncomplete -F _yum $filenames yum\n\n# yum-arch(8) completion\n#\n_yum_arch()\n{\n    local cur\n    COMPREPLY=()\n    cur=${COMP_WORDS[COMP_CWORD]}\n\n    case "$cur" in\n	-*)\n	    COMPREPLY=( $( compgen -W ''-d -v -vv -n -c -z -s -l -q'' -- $cur ) )\n	    ;;\n	*)\n	    _filedir -d\n	    ;;\n    esac\n\n    return 0\n\n}\ncomplete -F _yum_arch $filenames yum-arch\n}\n\n# ImageMagick completion\n#\nhave convert && {\n_ImageMagick()\n{\n	local prev\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-channel)\n			COMPREPLY=( $( compgen -W ''Red Green Blue Opacity \\\n				Matte Cyan Magenta Yellow Black'' -- $cur ) )\n			return 0\n			;;\n		-colormap)\n			COMPREPLY=( $( compgen -W ''shared private'' -- $cur ) )\n			return 0\n			;;\n		-colorspace)\n			COMPREPLY=( $( compgen -W ''GRAY OHTA RGB Transparent \\\n				XYZ YCbCr YIQ YPbPr YUV CMYK'' -- $cur ) )\n			return 0\n			;;\n		-compose)\n			COMPREPLY=( $( compgen -W ''Over In Out Atop Xor Plus \\\n				Minus Add Subtract Difference Multiply Bumpmap\\\n				Copy CopyRed CopyGreen CopyBlue CopyOpacity'' \\\n				-- $cur ) )\n			return 0\n			;;\n		-compress)\n			COMPREPLY=( $( compgen -W ''None BZip Fax Group4 JPEG \\\n				Lossless LZW RLE Zip'' -- $cur ) )\n			return 0\n			;;\n		-dispose)\n			COMPREPLY=( $( compgen -W ''Undefined None Background \\\n						    Previous'' -- $cur ) )\n			return 0\n			;;\n		-encoding)\n			COMPREPLY=( $( compgen -W ''AdobeCustom AdobeExpert \\\n				AdobeStandard AppleRoman BIG5 GB2312 Latin2 \\\n				None SJIScode Symbol Unicode Wansung'' -- $cur))\n			return 0\n			;;\n		-endian)\n			COMPREPLY=( $( compgen -W ''MSB LSB'' -- $cur ) )\n			return 0\n			;;\n		-filter)\n			COMPREPLY=( $( compgen -W ''Point Box Triangle Hermite \\\n				Hanning Hamming Blackman Gaussian Quadratic \\\n				Cubic Catrom Mitchell Lanczos Bessel Sinc'' \\\n				-- $cur ) )\n			return 0\n			;;\n		-format)\n			COMPREPLY=( $( convert -list format | \\\n				    awk ''/ [r-][w-][+-] / {print $1}'' | \\\n				    tr -d ''*'' | tr [:upper:] [:lower:] | \\\n				    grep "^$cur" ) )\n			return 0\n			;;\n		-gravity)\n			COMPREPLY=( $( compgen -W ''Northwest North NorthEast \\\n				West Center East SouthWest South SouthEast'' \\\n				-- $cur ) )\n			return 0\n			;;\n		-intent)\n			COMPREPLY=( $( compgen -W ''Absolute Perceptual \\\n					Relative Saturation'' -- $cur ) )\n			return 0\n			;;\n		-interlace)\n			COMPREPLY=( $( compgen -W ''None Line Plane Partition'' \\\n					-- $cur ) )\n			return 0\n			;;\n		-limit)\n			COMPREPLY=( $( compgen -W ''Disk File Map Memory'' \\\n					-- $cur ) )\n			return 0\n			;;\n		-list)\n			COMPREPLY=( $( compgen -W ''Delegate Format Magic \\\n					Module Resource Type'' -- $cur ) )\n			return 0\n			;;\n		-map)\n			COMPREPLY=( $( compgen -W ''best default gray red \\\n					green blue'' -- $cur ) )\n			_filedir\n			return 0\n			;;\n		-noise)\n			COMPREPLY=( $( compgen -W ''Uniform Gaussian \\\n					Multiplicative \\\n				Impulse Laplacian Poisson'' -- $cur ) )\n			return 0\n			;;\n		-preview)\n			COMPREPLY=( $( compgen -W ''Rotate Shear Roll Hue \\\n					Saturation Brightness Gamma Spiff \\\n					Dull Grayscale Quantize Despeckle \\\n					ReduceNoise AddNoise Sharpen Blur \\\n					Treshold EdgeDetect Spread Shade \\\n					Raise Segment Solarize Swirl Implode \\\n					Wave OilPaint CharcoalDrawing JPEG'' \\\n					-- $cur ) )\n			return 0\n			;;\n		-@(mask|profile|texture|tile|write))\n			_filedir\n			return 0\n			;;\n		-type)\n			COMPREPLY=( $( compgen -W ''Bilevel Grayscale Palette \\\n					PaletteMatte TrueColor TrueColorMatte \\\n					ColorSeparation ColorSeparationlMatte \\\n					Optimize'' -- $cur ) )\n			return 0\n			;;\n		-units)\n			COMPREPLY=( $( compgen -W ''Undefined PixelsPerInch \\\n					PixelsPerCentimeter'' -- $cur ) )\n			return 0\n			;;\n		-virtual-pixel)\n			COMPREPLY=( $( compgen -W ''Constant Edge mirror tile'' \\\n					-- $cur ) )\n			return 0\n			;;\n		-visual)\n			COMPREPLY=( $( compgen -W ''StaticGray GrayScale \\\n					StaticColor PseudoColor TrueColor \\\n					DirectColor defaut visualid'' -- $cur ))\n			return 0\n			;;\n	esac\n}\n\n_convert()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_ImageMagick\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-adjoin -affine -antialias -append \\\n			-authenticate -average -background -black-threshold \\\n			-blue-primary -blur -border -bordercolor -channel \\\n			-charcoal -chop -clip -coalesce -colorize -colors \\\n			-colorspace -comment -compress -contrast -convolve \\\n			-crop -cycle -debug -deconstruct -delay -density \\\n			-depth -despeckle -display -dispose -dither -draw \\\n			-edge -emboss -encoding -endian -enhance -equalize \\\n			-extract -fill -filter -flatten -flip -flop -font \\\n			-frame -fuzz -gamma -gaussian -geometry \\\n			-green-primary -gravity -help -implode -intent \\\n			-interlace -label -lat -level -limit -list -log -loop \\\n			-map -mask -matte -median -modulate -monochrome \\\n			-morph -mosaic -negate -noop -noise -normalize \\\n			-opaque -ordered-dither -page -paint -ping -pointsize \\\n			-preview -profile -quality -raise -random-threshold \\\n			-region -raise -red-primary -render -resize -resample \\\n			-roll -rotate -sample -sampling-factor -scale -scene \\\n			-seed -segment -shade -sharpen -shave -shear -size \\\n			-solarize -spread -stroke -strokewidth -swirl \\\n			-texture -threshold -thumbnail -tile -transform \\\n			-transparent -treedepth -trim -type -undercolor \\\n			-units -unsharp -verbose -version -view \\\n			-virtual-pixel -wave -white-point -white-threshold \\\n			-write'' -- $cur ) )\n	elif [[ "$cur" == +* ]]; then\n		COMPREPLY=( $( compgen -W ''+adjoin +append +compress \\\n			+contrast +debug +dither +endian +gamma +label +map \\\n			+mask +matte +negate +noise +page +raise +render \\\n			+write'' -- $cur ) ) \n	else\n		_filedir\n	fi\n}\ncomplete -F _convert $filenames convert\n\n_mogrify()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_ImageMagick\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-affine -antialias -authenticate \\\n			-background -black-threshold -blue-primary -blur \\\n			-border -bordercolor -channel -charcoal -chop \\\n			-colorize -colors -colorspace -comment -compress \\\n			-contrast -convolve -crop -cycle -debug -delay \\\n			-density -depth -despeckle -display -dispose -dither \\\n			-draw -edge -emboss -encoding -endian -enhance \\\n			-equalize -extract -fill -filter -flip -flop -font \\\n			-format -frame -fuzz -gamma -gaussian -geometry \\\n			-green-primary -implode -interlace -help -label -lat \\\n			-level -limit -list -log -loop -map -mask -matte \\\n			-median -modulate -monochrome -negate -noop \\\n			-normalize -opaque -page -paint -fill -ordered-dither \\\n			-pointsize -profile -quality -raise -random-threshold \\\n			-red-primary -region -resample -resize -roll -rotate \\\n			-sample -sampling-factor -scale -scene -seed -segment \\\n			-shade -sharpen -shear -size -solarize -spread \\\n			-stroke -strokewidth -swirl -texture -threshold \\\n			-thumbnail -tile -transform -transparent -treedepth \\\n			-trim -type -undercolor -units -unsharp -verbose \\\n			-version -view -virtual-pixel -wave -white-point \\\n			-white-threshold'' -- $cur ) )\n	elif [[ "$cur" == +* ]]; then\n		COMPREPLY=( $( compgen -W ''+compress +contrast +debug +dither \\\n			+endian +gamma +label +map +mask +matte +negate +page \\\n			+raise'' -- $cur ) ) \n	else\n		_filedir\n	fi\n}\ncomplete -F _mogrify $filenames mogrify\n\n_display()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_ImageMagick\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-authenticate -backdrop -border \\\n			-colormap -colors -colorspace -comment -compress \\\n			-contrast -crop -debug -delay -density -depth \\\n			-despeckle -display -dispose -dither -edge -endian \\\n			-enhance -extract -filter -flip -flop -frame -gamma \\\n			-geometry -help -immutable -interlace -label -limit \\\n			-log -map -matte -monochrome -negate -noop -page \\\n			-quality -raise -remote -roll -rotate -sample \\\n			-sampling-factor -scene -segment -sharpen -size \\\n			-texture -treedepth -trim -update -verbose -version \\\n			-virtual-pixel -window -window_group -write'' -- $cur))\n	elif [[ "$cur" == +* ]]; then\n		COMPREPLY=( $( compgen -W ''+compress +contrast +debug +dither \\\n			+endian +gamma +label +map +matte +negate +page \\\n			+raise +write'' -- $cur ) ) \n	else\n		_filedir\n	fi\n}\ncomplete -F _display $filenames display\n\n_animate()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_ImageMagick\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-authenticate -backdrop -colormap \\\n			-colors -colorspace -crop -debug -delay -density \\\n			-depth -display -dither -extract -gamma -geometry \\\n			-help -interlace -limit -log -matte -map -monochrome \\\n			-noop -pause -remote -rotate -sampling-factor -scene \\\n			-size -treedepth -trim -verbose -version -visual \\\n			-virtual-pixel -window'' -- $cur ) )\n	elif [[ "$cur" == +* ]]; then\n		COMPREPLY=( $( compgen -W ''+debug +dither +gamma +map +matte'' -- $cur ) ) \n	else\n		_filedir\n	fi\n}\ncomplete -F _animate $filenames animate\n\n_identify()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_ImageMagick\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-authenticate -debug -density \\\n			-depth -extract -format -help -interlace -limit -list \\\n			-log -size -sampling-factor -verbose -version \\\n			-virtual-pixel'' -- $cur ) )\n	elif [[ "$cur" == +* ]]; then\n		COMPREPLY=( $( compgen -W ''+debug '' -- $cur ) ) \n	else\n		_filedir\n	fi\n}\ncomplete -F _identify $filenames identify\n\n_montage()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_ImageMagick\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-adjoin -affine -authenticate \\\n			-blue-primary -blur -colors -colorspace -comment \\\n			-compose -compress -crop -debug -density -depth \\\n			-display -dispose -dither -draw -encoding -endian \\\n			-extract -fill -filter -flip -flop -frame -gamma \\\n			-geometry -gravity -green-primary -interlace -help \\\n			-label -limit -log -matte -mode -monochrome -noop \\\n			-page -pointsize -quality -red-primary -resize \\\n			-rotate -sampling-factor -scene -shadow -size \\\n			-stroke -texture -thumbnail -tile -transform \\\n			-transparent -treedepth -trim -type -verbose \\\n			-version -virtual-pixel -white-point'' -- $cur ) )\n	elif [[ "$cur" == +* ]]; then\n		COMPREPLY=( $( compgen -W ''+adjoin +compress +debug +dither \\\n			+endian +gamma +label +matte +page'' -- $cur ) ) \n	else\n		_filedir\n	fi\n}\ncomplete -F _montage $filenames montage\n\n_composite()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_ImageMagick\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-affine -authenticate \\\n			-blue-primary -colors -colorspace -comment -compose \\\n			-compress -debug -density -depth -displace -display \\\n			-dispose -dissolve -dither -encoding -endian -extract \\\n			-filter -font -geometry -gravity -green-primary -help \\\n			-interlace -label -limit -log -matte -monochrome \\\n			-negate -page -profile -quality -red-primary -rotate \\\n			-resize -sampling-factor -scene -sharpen -size \\\n			-stegano -stereo -thumbnail -tile -transform \\\n			-treedepth -type -units -unsharp -verbose -version \\\n			-virtual-pixel -watermark -white-point -write'' \\\n			-- $cur ) )\n	elif [[ "$cur" == +* ]]; then\n		COMPREPLY=( $( compgen -W ''+compress +debug +dither +endian +label \\\n			+matte +negate +page +write'' -- $cur ) ) \n	else\n		_filedir\n	fi\n}\ncomplete -F _composite $filenames composite\n}\n\n# dd(1) completion\n#\nhave dd &&\n_dd()\n{\n	 local cur\n\n	 COMPREPLY=()\n	 cur=${COMP_WORDS[COMP_CWORD]}\n\n	 case "$cur" in\n	 if=*|of=*)\n		 cur=${cur#*=}\n		 _filedir\n		 return 0\n		 ;;\n	 conv=*)\n		 cur=${cur#*=}\n		 COMPREPLY=( $( compgen -W ''ascii ebcdic ibm block unblock \\\n				lcase notrunc ucase swab noerror sync'' \\\n				-- $cur ) )\n		 return 0\n		 ;;\n	 esac\n\n	 _expand || return 0\n\n	 COMPREPLY=( $( compgen -W ''--help --version'' -- $cur ) \\\n		     $( compgen -W ''bs cbs conv count ibs if obs of seek skip''\\\n				-S ''='' -- $cur ) )\n} &&\ncomplete -F _dd $nospace $filenames dd\n\n# CUPS cancel(1) completion\n#\nhave cancel &&\n_cancel()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( lpstat | cut -d'' '' -f1 | grep "^$cur" ) )\n} &&\ncomplete -F _cancel $filenames cancel\n\n# aspell(1) completion\n#\nhave aspell && {\n_aspell_dictionary()\n{\n	local datadir\n	datadir=/usr/lib/aspell\n	COMPREPLY=( $( command ls $datadir/*.@(multi|alias) ) )\n	COMPREPLY=( ${COMPREPLY[@]%.@(multi|alias)} )\n	COMPREPLY=( $( compgen -W ''${COMPREPLY[@]#$datadir/}'' -- $cur ) )\n}\n\n_aspell()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# --name value style option\n	case "$prev" in\n		@(-c|-p|check))\n			_filedir\n			return 0\n			;;\n		@(dump|create|merge))\n			COMPREPLY=( $( compgen -W ''master personal repl'' -- $cur ) )\n			return 0\n			;;\n		-d)\n			_aspell_dictionary\n			return 0\n			;;\n	esac\n\n	# --name=value style option\n	if [[ "$cur" == *=* ]]; then\n		prev=${cur/=*/}\n		cur=${cur/*=/}\n		case "$prev" in\n			--@(conf|personal|repl|per-conf))\n				_filedir\n				return 0\n				;;\n			--@(conf-dir|data-dir|dict-dir|home-dir|local-data-dir|prefix))\n				_filedir -d\n				return 0\n				;;\n			--master)\n				_aspell_dictionary\n				return 0\n				;;\n			--mode)\n				COMPREPLY=( $( compgen -W ''none url email sgml tex'' -- $cur ) )\n				return 0\n				;; \n			--sug-mode)\n				COMPREPLY=( $( compgen -W ''ultra fast normal bad-speller'' -- $cur ) )\n				return 0\n				;;\n			--keymapping)\n				COMPREPLY=( $( compgen -W ''aspell ispell'' -- $cur ) )\n				return 0\n				;;\n		esac\n	fi\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--conf= --conf-dir= --data-dir= --dict-dir= \\\n			--encoding= --add-filter= --rem-filter= --mode= -e \\\n			-H -t --add-extra-dicts= --rem-extra-dicts= \\\n			--home-dir= -W --ignore= --ignore-accents \\\n			--dont-ignore-accents --ignore-case --dont-ignore-case \\\n			--ignore-repl --dont-ignore-repl --jargon= --keyboard= \\\n			--lang= --language-tag= --local-data-dir= -d --master= \\\n			--module= --add-module-search-order= \\\n			--rem-module-search-order= --per-conf= -p --personal= \\\n			--prefix= --repl= -C -B --run-together --dont-run-together \\\n			--run-together-limit= --run-together-min= --save-repl \\\n			--dont-save-repl --set-prefix --dont-set-prefix --size= \\\n			--spelling= --strip-accents --dont-strip-accents \\\n			--sug-mode= --add-word-list-path= --rem-word-list-path= \\\n			-b -x --backup -b|-x --dont-backup --reverse --dont-reverse \\\n			--time --dont-time --keymapping= --add-email-quote= \\\n			--rem-email-quote= --email-margin= --add-tex-command= \\\n			--rem-tex-command= --tex-check-comments \\\n			--dont-tex-check-comments --add-tex-extension= \\\n			--rem-tex-extension= --add-sgml-check= --rem-sgml-check= \\\n			--add-sgml-extension= --rem-sgml-extension='' -- $cur ) )\n	else\n		COMPREPLY=( $( compgen -W ''-? help -c check -a pipe -l list \\\n			config config soundslike filter -v version dump \\\n			create merge'' -- $cur ) )\n	fi\n\n}\ncomplete -F _aspell $default aspell\n}\n\n# xmms(1) completion\n#\nhave xmms &&\n_xmms()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-h --help -r --rew -p --play \\\n			-u --pause -s --stop -t --play-pause -f --fwd -e \\\n			--enqueue -m --show-main-window -i --sm-client-id \\\n			-v --version'' -- $cur ) )\n	else\n		_filedir ''@(mp[23]|MP[23]|ogg|OGG|wav|WAV|pls|m3u|xm|mod|s[3t]m|it|mtm|ult|flac)''\n\n	fi\n\n} &&\ncomplete -F _xmms $filenames xmms\n\n# info(1) completion\n#\nhave info &&\n_info()\n{\n	local cur infopath UNAME\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_expand || return 0\n\n	# default completion if parameter contains /\n	if [[ "$cur" == */* ]]; then\n		_filedir\n		return 0\n	fi\n\n	infopath=''/usr/share/info''\n\n	if [ "${INFOPATH: -1:1}" == '':'' ]; then\n		infopath=${INFOPATH}${infopath}\n	elif [ ${INFOPATH:+set} ]; then\n		infopath=$INFOPATH\n	fi\n\n	infopath=$infopath:\n	if [ -n "$cur" ]; then\n		infopath="${infopath//://$cur* }"\n	else\n		infopath="${infopath//:// }"\n	fi\n\n	# redirect stderr for when path doesn''t exist\n	COMPREPLY=( $( eval command ls "$infopath" 2>/dev/null ) )\n	# weed out directory path names and paths to info pages\n	COMPREPLY=( ${COMPREPLY[@]##*/?(:)} )\n	# weed out info dir file\n	for (( i=0 ; i < ${#COMPREPLY[@]} ; ++i )); do\n		if [ "${COMPREPLY[$i]}" == ''dir'' ]; then\n			unset COMPREPLY[$i];\n		fi;\n	done  \n	# strip suffix from info pages\n	COMPREPLY=( ${COMPREPLY[@]%.@(gz|bz2)} )\n	COMPREPLY=( $( compgen -W ''${COMPREPLY[@]%.*}'' -- "${cur//\\\\\\\\/}" ) )\n\n	return 0\n} &&\ncomplete -F _info $filenames info\n\n# dhclient(1) completion\n#\nhave dhclient && _dhclient()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(cf|lf|pf|sf))\n			_filedir\n			return 0\n			;;\n		-s)\n			_known_hosts\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-p -d -q -1 -r -lf -pf \\\n			-cf -sf -s -g -n -nw -w'' -- $cur ) )\n	else\n		_available_interfaces\n	fi\n} &&\ncomplete -F _dhclient dhclient\n\n# lvm(8) completion\n#\nhave lvm && {\n_volumegroups()\n{\n	COMPREPLY=( $(compgen -W "$( vgscan 2>/dev/null | \\\n	    sed -n -e ''s|.*Found.*"\\(.*\\)".*$|\\1|p'' )" -- $cur ) )\n}\n\n_physicalvolumes()\n{\n	COMPREPLY=( $(compgen -W "$( pvscan 2>/dev/null | \\\n	    sed -n -e ''s|^.*PV \\(.*\\) VG.*$|\\1|p'' )" -- $cur ) )\n}\n\n_logicalvolumes()\n{\n	COMPREPLY=( $(compgen -W "$( lvscan 2>/dev/null | \\\n	    sed -n -e "s|^.*''\\(.*\\)''.*$|\\1|p" )" -- $cur ) )\n}\n\n_units()\n{\n	COMPREPLY=( $( compgen -W ''h s b k m g t H K M G T'' -- $cur ) )\n}\n\n_sizes()\n{\n	COMPREPLY=( $( compgen -W ''k K m M g G t T'' -- $cur ) )\n}\n\n_args()\n{\n	args=0\n	if [[ "${COMP_WORDS[0]}" == lvm ]]; then\n		offset=2\n	else\n		offset=1\n	fi\n	for (( i=$offset; i < COMP_CWORD; i++ )); do\n		if [[ "${COMP_WORDS[i]}" != -* ]]; then\n			args=$(($args + 1))\n		fi\n	done\n}\n\n_lvmdiskscan()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -h -? --help -l \\\n			--lvmpartition -v --verbose --version'' -- $cur ) )\n	fi\n}\ncomplete -F _lvmdiskscan lvmdiskscan\n\n_pvscan()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -e \\\n			--exported -n --novolumegroup -h -? \\\n			--help --ignorelockingfailure -P \\\n			--partial -s --short -u --uuid -v \\\n			--verbose --version'' -- $cur ) )\n	fi\n}\ncomplete -F _pvscan pvscan\n\n_pvs()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(o|O|-options|-sort))\n			COMPREPLY=( $( compgen -W ''pv_fmt pv_uuid \\\n				pv_size pv_free pv_used pv_name \\\n				pv_attr pv_pe_count \\\n				pv_pe_alloc_count'' -- $cur ) )\n			return 0\n			;;\n		--units)\n			_units\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--aligned -a --all -d --debug \\\n			-h -? --help --ignorelockingfailure --noheadings \\\n			--nosuffix -o --options -O --sort \\\n			--separator --unbuffered --units \\\n			-v --verbose --version'' -- $cur ) )\n	else\n		_physicalvolumes\n	fi\n}\ncomplete -F _pvs pvs\n\n_pvdisplay()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		--units)\n			_units\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-c --colon -C --columns --units \\\n			-v --verbose -d --debug -h --help --version'' -- $cur ) )\n	else\n		_physicalvolumes\n	fi\n}\ncomplete -F _pvdisplay pvdisplay\n\n_pvchange()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|x|-autobackup|--allocatable))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-a --all -A --autobackup \\\n			-d --debug -h --help -t --test -u --uuid -x \\\n			--allocatable -v --verbose --addtag --deltag \\\n			--version'' -- $cur ) )\n	else\n		_physicalvolumes\n	fi\n}\ncomplete -F _pvchange pvchange\n\n_pvcreate()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		--restorefile)\n			_filedir\n			return 0\n			;;\n		-@(M|-metadatatype))\n			COMPREPLY=( $( compgen -W ''1 2'' -- $cur ) )\n			return 0\n			;;\n		--metadatacopies)\n			COMPREPLY=( $( compgen -W ''0 1 2'' -- $cur ) )\n			return 0\n			;;\n		--@(metadatasize|setphysicalvolumesize))\n			_sizes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--restorefile -d --debug -f \\\n			--force -h -? --help --labelsector -M --metadatatype \\\n			--metadatacopies --metadatasize \\\n			--setphysicalvolumesize -t --test -u --uuid uuid -v \\\n			--verbose -y --yes --version'' -- $cur ) )\n	else\n		_physicalvolumes\n	fi\n}\ncomplete -F _pvcreate pvcreate\n\n_pvmove()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(n|-name))\n			_logicalvolumes\n			return 0\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--abort -A --autobackup \\\n			-b --background -d --debug -f --force -h -? \\\n			--help -i --interval -t --test -v --verbose \\\n			--version -n --name'' -- $cur ) )\n	else\n		_physicalvolumes\n	fi\n}\ncomplete -F _pvmove pvmove\n\n_pvremove()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -f --force -h -? \\\n			--help -y --yes -t --test -v --verbose \\\n			--version'' -- $cur ) )\n	else\n		_physicalvolumes\n	fi\n}\ncomplete -F _pvremove pvremove\n\n_vgscan()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -h --help \\\n			--ignorelockingfailure --mknodes -P \\\n			--partial -v --verbose --version'' -- $cur ) )\n	fi\n}\ncomplete -F _vgscan vgscan\n\n_vgs()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(o|O|-options|-sort))\n			COMPREPLY=( $( compgen -W ''vg_fmt vg_uuid vg_name \\\n				vg_attr vg_size vg_free vg_sysid \\\n				vg_extent_size vg_extent_count vg_free_count \\\n				max_lv max_pv pv_count lv_count snap_count \\\n				vg_seqno'' -- $cur ) )\n			return 0\n			;;\n		--units)\n			_units\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--aligned -d --debug \\\n			-h --help --ignorelockingfailure --noheadings \\\n			--nosuffix -o --options -O --sort -P --partial \\\n			--separator --unbuffered --units \\\n			-v --verbose --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgs vgs\n\n_vgdisplay()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		--units)\n			_units\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-c --colon -C --columns --units \\\n			-P --partial -A --activevolumegroups -v --verbose \\\n			-d --debug -h --help --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgdisplay vgdisplay\n\n_vgchange()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(a|A|x|-available|-autobackup|-resizeable))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup --alloc -P \\\n			--partial -d --debug -h --help --ignorelockingfailure \\\n			-t --test -u --uuid -v --verbose --version -a \\\n			--available -x --resizeable -l --logicalvolume \\\n			--addtag --deltag'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgchange vgchange\n\n_vgcreate()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(M|-metadatatype))\n			COMPREPLY=( $( compgen -W ''1 2'' -- $cur ) )\n			return 0\n			;;\n		-@(s|-physicalextentsize))\n			_sizes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup --addtag \\\n			--alloc -d --debug -h --help -l --maxlogicalvolumes \\\n			-M --metadatatype -p --maxphysicalvolumes -s \\\n			--physicalextentsize -t --test -v --verbose \\\n			--version'' -- $cur ) )\n	else\n		_args\n		if [ $args -eq 0 ]; then\n			_volumegroups\n		else\n			_physicalvolumes\n		fi\n	fi\n}\ncomplete -F _vgcreate vgcreate\n\n_vgremove()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -h --help -t --test \\\n		-v --verbose --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgremove vgremove\n\n_vgrename()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -d --debug -h \\\n			-? --help -t --test -v --verbose --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgrename vgrename\n\n_vgreduce()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-a --all -A --autobackup -d \\\n			--debug -h --help --removemissing -t --test -v \\\n			--verbose --version'' -- $cur ) )\n\n	else\n		_args\n		if [ $args -eq 0 ]; then\n			_volumegroups\n		else\n			_physicalvolumes\n		fi\n	fi\n}\ncomplete -F _vgreduce vgreduce\n\n_vgextend()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(L|-size))\n			_sizes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -d --debug -h \\\n			-? --help -t --test -v --verbose --version'' -- $cur ) )\n	else\n		_args\n		if [ $args -eq 0 ]; then\n			_volumegroups\n		else\n			_physicalvolumes\n		fi\n	fi\n}\ncomplete -F _vgextend vgextend\n\n_vgport()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-a --all -d --debug -h \\\n			-? --help -v --verbose --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgport vgimport vgexport\n\n_vgck()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -h \\\n			-? --help -v --verbose --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgck vgck\n\n_vgconvert()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(M|-metadatatype))\n			COMPREPLY=( $( compgen -W ''1 2'' -- $cur ) )\n			return 0\n			;;\n		--metadatacopies)\n			COMPREPLY=( $( compgen -W ''0 1 2'' -- $cur ) )\n			return 0\n			;;\n		--metadatasize)\n			_sizes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -h --help --labelsector \\ \n			-M --metadatatype --metadatacopies --metadatasize \\\n			-t --test -v --verbose --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgconvert vgconvert\n\n_vgcfgbackup()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(f|-file))\n			_filedir\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -f --file -h --help \\\n			--ignorelockingfailure -P --partial -v --verbose \\\n			--version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgcfgbackup vgcfgbackup\n\n_vgcfgrestore()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(f|-file))\n			_filedir\n			return 0\n			;;\n		-@(M|-metadatatype))\n			COMPREPLY=( $( compgen -W ''1 2'' -- $cur ) )\n			return 0\n			;;\n		-@(n|-name))\n			_volumegroups\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -f --file -l --list \\\n			-h --help -M --Metadatatype -n --name -t --test \\\n			-v --verbose --version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgcfgrestore vgcfgrestore\n\n_vgmerge()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -d --debug \\\n			-h --help -l --list -t --test -v --verbose \\\n			--version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgmerge vgmerge\n\n_vgsplit()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(M|-metadatatype))\n			COMPREPLY=( $( compgen -W ''1 2'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -d --debug \\\n			-h --help -l --list -M --metadatatype -t --test \\\n			-v --verbose --version'' -- $cur ) )\n	else\n		_args\n		if [ $args -eq 0 -o $args -eq 1 ]; then\n			_volumegroups\n		else\n			_physicalvolumes\n		fi\n	fi\n}\ncomplete -F _vgsplit vgsplit\n\n_vgmknodes()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-d --debug -h --help -v --verbose \\\n			--version'' -- $cur ) )\n	else\n		_volumegroups\n	fi\n}\ncomplete -F _vgmknodes vgmknodes\n\n_lvscan()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-b --blockdevice -d --debug \\\n			-h -? --help --ignorelockingfailure -P \\\n			--partial -v --verbose --version'' -- $cur ) )\n	fi\n}\ncomplete -F _lvscan lvscan\n\n_lvs()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(o|O|-options|-sort))\n			COMPREPLY=( $( compgen -W ''lv_uuid lv_name \\\n				lv_attr lv_minor lv_size seg_count \\\n				origin snap_percent segtype stripes \\\n				stripesize chunksize seg_start \\\n				seg_size'' -- $cur ) )\n			return 0\n			;;\n		--units)\n			_units\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--aligned -d --debug \\\n			-h --help --ignorelockingfailure --noheadings \\\n			--nosuffix -o --options -O --sort -P --partial \\\n			--segments --separator --unbuffered --units \\\n			-v --verbose --version'' -- $cur ) )\n	else\n		_logicalvolumes\n	fi\n}\ncomplete -F _lvs lvs\n\n_lvdisplay()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		--units)\n			_units\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-c --colon -C --columns --units \\\n			-P --partial -m --maps -v --verbose -d --debug -h \\\n			--help --version'' -- $cur ) )\n	else\n		_logicalvolumes\n	fi\n}\ncomplete -F _lvdisplay lvdisplay\n\n_lvchange()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(a|A|C|M|-available|-autobackup|-continguous|-persistent))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(p|-permission))\n			COMPREPLY=( $( compgen -W ''r rw'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -a --available \\\n			--addtag --alloc -C --contiguous -d --debug --deltag \\\n			-f --force -h --help --ignorelockingfailure -M \\\n			--persistent --major major --minor minor -P --partial \\\n			-p --permission -r --readahead --refresh -t --test \\\n			-v --verbose --version'' -- $cur ) )\n	else\n		_logicalvolumes\n	fi\n}\ncomplete -F _lvchange lvchange\n\n_lvcreate()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|C|M|Z|-autobackup|-continguous|-persistent|-zero))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(L|-size))\n			_sizes\n			return 0\n			;;\n		-@(p|-permission))\n			COMPREPLY=( $( compgen -W ''r rw'' -- $cur ) )\n			return 0\n			;;\n		-@(n|-name))\n			_logicalvolumes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup --addtag --alloc \\\n			-C --contiguous -d --debug -h -? --help -i --stripes \\\n			-I --stripesize -l --extents -L --size -M --persistent \\\n			--major --minor -n --name -p --permission -r \\\n			--readahead -t --test --type -v --verbose -Z --zero \\\n			--version'' -- $cur ) )\n	else\n		_args\n		if [ $args -eq 0 ]; then\n			_volumegroups\n		else\n			_physicalvolumes\n		fi\n	fi\n}\ncomplete -F _lvcreate lvcreate\n\n_lvremove()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -d --debug -f \\\n			--force -h -?  --help -t --test -v --verbose \\\n			--version'' -- $cur ) )\n	else\n		_logicalvolumes\n	fi\n}\ncomplete -F _lvremove lvremove\n\n_lvrename()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -d --debug -h \\\n			-? --help -t --test -v --verbose --version'' -- $cur ) )\n	else\n		_logicalvolumes\n	fi\n}\ncomplete -F _lvrename lvrename\n\n_lvreduce()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(L|-size))\n			_sizes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup -d \\\n			--debug -f --force -h --help -l --extents \\\n			-L --size -n --nofsck -r --resizefs -t --test \\\n			-v --verbose --version'' -- $cur ) )\n	else\n		_logicalvolumes\n	fi\n}\ncomplete -F _lvreduce lvreduce\n\n_lvresize()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(L|-size))\n			_sizes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup --alloc -d \\\n			--debug -h --help -i --stripes -I --stripesize \\\n			-l --extents -L --size -n --nofsck -r --resizefs \\\n			-t --test --type -v --verbose --version'' -- $cur ) )\n	else\n		_args\n		if [ $args -eq 0 ]; then\n			_logicalvolumes\n		else\n			_physicalvolumes\n		fi\n	fi\n}\ncomplete -F _lvresize lvresize\n\n_lvextend()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n		-@(A|-autobackup))\n			COMPREPLY=( $( compgen -W ''y n'' -- $cur ) )\n			return 0\n			;;\n		-@(L|-size))\n			_sizes\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-A --autobackup --alloc -d \\\n			--debug -h --help -i --stripes -I --stripesize \\\n			-l --extents -L --size -n --nofsck -r --resizefs \\\n			-t --test --type -v --verbose --version'' -- $cur ) )\n	else\n		_args\n		if [ $args -eq 0 ]; then\n			_logicalvolumes\n		else\n			_physicalvolumes\n		fi\n	fi\n}\ncomplete -F _lvextend lvextend\n\n_lvm()\n{\n	local prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -W ''dumpconfig help lvchange \\\n			lvcreate lvdisplay lvextend lvmchange \\\n			lvmdiskscan lvmsadc lvmsar lvreduce \\\n			lvremove lvrename lvresize lvs lvscan \\\n			pvchange pvcreate pvdata pvdisplay pvmove \\\n			pvremove pvresize pvs pvscan vgcfgbackup \\\n			vgcfgrestore vgchange vgck vgconvert \\\n			vgcreate vgdisplay vgexport vgextend \\\n			vgimport vgmerge vgmknodes vgreduce \\\n			vgremove vgrename vgs vgscan vgsplit \\\n			version'' -- $cur ) )\n	else\n		case ${COMP_WORDS[1]} in\n			pvchange)\n				_pvchange\n				;;\n			pvcreate)\n				_pvcreate\n				;;\n			pvdisplay)\n				_pvdisplay\n				;;\n			pvmove)\n				_pvmove\n				;;\n			pvremove)\n				_pvremove\n				;;\n			pvresize)\n				_pvresize\n				;;\n			pvs)\n				_pvs\n				;;\n			pvscan)\n				_pvscan\n				;;\n			vgcfgbackup)\n				_vgcfgbackup\n				;;\n			vgcfgrestore)\n				_vgcfgrestore\n				;;\n			vgchange)\n				_vgchange\n				;;\n			vgck)\n				_vgck\n				;;\n			vgconvert)\n				_vgconvert\n				;;\n			vgcreate)\n				_vgcreate\n				;;\n			vgdisplay)\n				_vgdisplay\n				;;\n			vgexport)\n				_vgexport\n				;;\n			vgextend)\n				_vgextend\n				;;\n			vgimport)\n				_vgimport\n				;;\n			vgmerge)\n				_vgmerge\n				;;\n			vgmknodes)\n				_vgmknodes\n				;;\n			vgreduce)\n				_vgreduce\n				;;\n			vgremove)\n				_vgremove\n				;;\n			vgrename)\n				_vgrename\n				;;\n			vgs)\n				_vgs\n				;;\n			vgscan)\n				_vgscan\n				;;\n			vgsplit)\n				_vgsplit\n				;;\n			lvchange)\n				_lvchange\n				;;\n			lvcreate)\n				_lvcreate\n				;;\n			lvdisplay)\n				_lvdisplay\n				;;\n			lvextend)\n				_lvextend\n				;;\n			lvreduce)\n				_lvreduce\n				;;\n			lvremove)\n				_lvremove\n				;;\n			lvrename)\n				_lvrename\n				;;\n			lvresize)\n				_lvresize\n				;;\n			lvs)\n				_lvs\n				;;\n			lvscan)\n				_lvscan\n				;;\n		esac\n	fi\n}\ncomplete -F _lvm lvm\n}\n\n# mkinitrd(8) completion\n#\nhave mkinitrd &&\n_mkinitrd()\n{\n	local cur args\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# --name value style option\n	case "$prev" in\n		--preload)\n			_modules\n			return 0\n			;;\n	esac\n\n	# --name=value style option\n	if [[ "$cur" == *=* ]]; then\n		prev=${cur/=*/}\n		cur=${cur/*=/}\n		case "$prev" in\n			--@(with|builtin))\n				_modules\n				return 0\n				;;\n			--@(fstab|dsdt))\n				_filedir\n				return 0\n				;;\n			--tmpdir)\n				_filedir -d\n				return 0\n				;;\n		esac\n	fi\n\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''--version -v -f --preload \\\n			--with= --omit-scsi-modules --omit-raid-modules \\\n			--images-version --fstab= --nocompress --builtin= \\\n			--nopivot --noudev --allow-missing --tmpdir= \\\n			--initrdfs= --dsdt= --lvm-version= --froce-usb'' \\\n			-- $cur ) )\n	else\n		_count_args\n\n		case $args in\n			1)\n				_filedir\n				;;\n			2)\n				COMPREPLY=( $( command ls /lib/modules | grep "^$cur" ) )\n				;;\n		esac\n	fi\n\n} &&\ncomplete -F _mkinitrd mkinitrd\n\n# pkgconfig(1) completion\n#\nhave pkg-config &&\n_pkg_config()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		# return list of available options\n		COMPREPLY=( $( compgen -W ''-version --modversion \\\n		      --atleast-pkgconfig-version= --libs --libs-only-l \\\n		      --libs-only-other --libs-only-L --cflags \\\n		      --cflags-only-I --cflags-only-othee --variable= \\\n		      --define-variable= --exists --uninstalled \\\n		      --atleast-version= --exact-version= --max-version= \\\n		      --list-all --debug --print-errors --silence-errors \\\n		      --errors-to-stdout -? --help --usage'' -- $cur))\n	else\n		COMPREPLY=( $( pkg-config --list-all 2>/dev/null | \\\n				    awk ''{print $1}'' | grep "^$cur" ) )\n	fi\n} &&\ncomplete -F _pkg_config pkg-config\n\n\n# cpio(1) completion\n#\nhave cpio && {\n_cpio_format()\n{\n	COMPREPLY=( $( compgen -W ''bin odc newc crc tar ustar hpbin hpodc'' -- $cur ) )\n}\n\n_cpio()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# --name value style option\n	case $prev in\n		-H)\n			_cpio_format\n			return 0\n			;;\n		-@(E|F|I))\n			_filedir\n			return 0\n			;;\n		-R)\n			_usergroup\n			return 0\n			;;\n	esac\n\n	# --name=value style option\n	if [[ "$cur" == *=* ]]; then\n		prev=${cur/=*/}\n		cur=${cur/*=/}\n		case $prev in\n			--format)\n				_cpio_format\n				return 0\n				;;\n			--@(file|pattern-file))\n				_filedir\n				return 0\n				;;\n			--owner)\n				_usergroup\n				return 0\n				;;\n			--rsh-command)\n				COMPREPLY=( $( compgen -c -- $cur ) )\n				return 0\n				;;\n		esac\n	fi\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -W ''-o --create -i --extract -p --pass-through'' -- $cur) ) \n	else\n		case ${COMP_WORDS[1]} in\n			-@(o|-create))\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-0 -a -c -v -A -B\\\n						-L -V -C -H -M -O -F --file= --format=\\\n						--message= --null --reset-access-time\\\n						--verbose --dot --append --block-size=\\\n						--dereference --io-size= --quiet\\\n						--force-local --rsh-command= --help\\\n						--version'' -- $cur ) )\n				fi\n				;;\n			-@(i|-extract))\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-b -c -d -f -m -n -r\\\n						-t -s -u -v -B -S -V -C -E -H -M -R -I\\\n						-F --file= --make-directories\\\n						--nonmatching\\\n						--preserve-modification-time\\\n						--numeric-uid-gid --rename -t --list\\\n						--swap-bytes --swap --dot\\\n						--unconditional --verbose --block-size=\\\n						--swap-halfwords --io-size=\\\n						--pattern-file= --format= --owner=\\\n						--no-preserve-owner --message=\\\n						--force-local --no-absolute-filenames\\\n						--sparse --only-verify-crc --quiet\\\n						--rsh-command= --help\\\n						--version'' -- $cur ) )\n				fi\n				;;\n			-@(p|-pass-through))\n				if [[ "$cur" == -* ]]; then\n					COMPREPLY=( $( compgen -W ''-0 -a -d -l -m -u -v\\\n						-L -V -R --null --reset-access-time\\\n						--make-directories --link --quiet\\\n						--preserve-modification-time\\\n						--unconditional --verbose --dot\\\n						--dereference --owner=\\\n						--no-preserve-owner --sparse --help\\\n						--version'' -- $cur ) )\n				else\n					_filedir -d\n				fi\n				;;\n		esac\n	fi\n}\ncomplete -F _cpio cpio\n}\n\n# id(1) completion\n#\nhave id &&\n_id()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-a -g --group -G --groups -n --name\\\n			-r --real -u --user --help --version'' -- $cur ) )\n	else\n		COMPREPLY=( $( compgen -u $cur  ) )\n	fi\n} &&\ncomplete -F _id id\n\n# getent(1) completion\n#\nhave getent &&\n_getent()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		passwd)\n			COMPREPLY=( $( compgen -u $cur  ) )\n			return 0\n			;;\n		group)\n			COMPREPLY=( $( compgen -g $cur  ) )\n			return 0\n			;;\n		services)\n			COMPREPLY=( $( compgen -s $cur  ) )\n			return 0\n			;;\n		hosts)\n			COMPREPLY=( $( compgen -A hostname $cur  ) )\n			return 0\n			;;\n		protocols)\n			COMPREPLY=( $( getent protocols | awk ''{print $1}'' | grep "^$cur" ) )\n			return 0\n			;;\n		networks)\n			COMPREPLY=( $( getent networks | awk ''{print $1}'' | grep "^$cur" ) )\n			return 0\n			;;\n	esac\n\n\n	if [ $COMP_CWORD -eq 1 ]; then\n		COMPREPLY=( $( compgen -W ''passwd group hosts services protocols networks'' -- $cur ) )\n	fi\n} &&\ncomplete -F _getent getent\n\n# ntpdate(1) completion\n#\nhave ntpdate &&\n_ntpdate()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		-k)\n			_filedir\n			return 0\n			;;\n		-U)\n			COMPREPLY=( $( compgen -u $cur  ) )\n			return 0\n			;;\n	esac\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-4 -6 -b -B -d -Q -q -s -u -v -a\\\n			-e -k -p -o -r -t'' -- $cur ) )\n	else\n		_known_hosts\n	fi\n} &&\ncomplete -F _ntpdate ntpdate\n\n# smartctl(8) completion\n#\nhave smartctl && {\n_smartctl_quietmode()\n{\n	COMPREPLY=( $( compgen -W ''errorsonly silent'' -- $cur ) )\n}\n_smartctl_device()\n{\n	COMPREPLY=( $( compgen -W ''ata scsi 3ware'' -- $cur ) )\n}\n_smartctl_tolerance()\n{\n	COMPREPLY=( $( compgen -W ''warn exit ignore'' -- $cur ) )\n}\n_smartctl_badsum()\n{\n	COMPREPLY=( $( compgen -W ''normal conservative permissive verypermissive'' -- $cur ) )\n}\n_smartctl_report()\n{\n	COMPREPLY=( $( compgen -W ''ioctl ataioctl scsiioctl'' -- $cur ) )\n}\n_smartctl_feature()\n{\n	COMPREPLY=( $( compgen -W ''on off'' -- $cur ) )\n}\n_smartctl_log()\n{\n	COMPREPLY=( $( compgen -W ''error selftest selective directory'' -- $cur ) )\n}\n_smartctl_vendorattribute()\n{\n	COMPREPLY=( $( compgen -W ''help 9,minutes 9,seconds 9,halfminutes \\\n		9,temp 192,emergencyretractcyclect 193,loadunload \\\n		194,10xCelsius 194,unknown 198,offlinescanuncsectorct \\\n		200,writeerrorcount 201,detectedtacount 220,temp'' -- $cur ) )\n}\n_smartctl_firmwarebug()\n{\n	COMPREPLY=( $( compgen -W ''none samsung samsung2'' -- $cur ) )\n}\n_smartctl_presets()\n{\n	COMPREPLY=( $( compgen -W ''use ignore show showall'' -- $cur ) )\n}\n_smartctl_test()\n{\n	COMPREPLY=( $( compgen -W ''offline short long conveyance select afterselect,on afterselect,off pending'' -- $cur ) )\n}\n\n_smartctl()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	# --name value style option\n	case "$prev" in\n		-q)\n			_smartctl_quietmode\n			;;\n		-d)\n			_smartctl_device\n			return 0\n			;;\n		-t)\n			_smartctl_tolerance\n			return 0\n			;;\n		-b)\n			_smartctl_badsum\n			return 0\n			;;\n		-r)\n			_smartctl_report\n			return 0\n			;;\n		-s)\n			_smartctl_feature\n			return 0\n			;;\n		-o)\n			_smartctl_feature\n			return 0\n			;;\n		-S)\n			_smartctl_feature\n			return 0\n			;;\n		-l)\n			_smartctl_log\n			return 0\n			;;\n		-v)\n			_smartctl_vendorattribute\n			return 0\n			;;\n		-F)\n			_smartctl_firmwarebug\n			return 0\n			;;\n		-P)\n			_smartctl_presets\n			return 0\n			;;\n		-t)\n			_smartctl_test\n			return 0\n			;;\n	esac\n\n	# --name=value style option\n	if [[ "$cur" == *=* ]]; then\n		prev=${cur/=*/}\n		cur=${cur/*=/}\n		case "$prev" in\n			--quietmode)\n				_smartctl_quietmode\n				return 0\n				;;\n			--device)\n				_smartctl_device\n				return 0\n				;;\n			--tolerance)\n				_smartctl_tolerance\n				return 0\n				;;\n			--badsum)\n				_smartctl_badsum\n				return 0\n				;;\n			--report)\n				_smartctl_report\n				return 0\n				;;\n			--smart)\n				_smartctl_feature\n				return 0\n				;;\n			--offlineauto)\n				_smartctl_feature\n				return 0\n				;;\n			--saveauto)\n				_smartctl_feature\n				return 0\n				;;\n			--log)\n				_smartctl_log\n				return 0\n				;;\n			--vendorattribute)\n				_smartctl_vendorattribute\n				return 0\n				;;\n			--firmwarebug)\n				_smartctl_firmwarebug\n				return 0\n				;;\n			--presets)\n				_smartctl_presets\n				return 0\n				;;\n			--test)\n				_smartctl_test\n				return 0\n				;;\n		esac\n	fi\n\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-h --help --usage -V --version \\\n			--copyright --license-i --info -a --all -q \\\n			--quietmode= -d --device= -T --tolerance= -b --badsum= \\\n			-r --report= -s --smart= -o --offlineauto= -S \\\n			--saveauto= -H --health -c --capabilities -A \\\n			--attributes -l --log= -v --vendorattribute= -F \\\n			--firmwarebug= -P --presets= -t --test= -C \\\n			--captive -X --abort'' -- $cur ) )\n	else\n		cur=${cur:=/dev/}\n		_filedir\n	fi\n}\ncomplete -F _smartctl smartctl\n}\n\n# vncviewer(1) completion\n#\nhave vncviewer &&\n_vncviewer()\n{\n	local cur prev\n	local -a config\n    \n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case "$prev" in\n	-via)\n	   _known_hosts -a\n	   ;;\n	*)\n	   # ssh into the the server, find and ping the broadcast address, then\n	   # sort and show the results.\n	   COMPREPLY=( $( ssh -o ''Batchmode yes'' $prev \\\n			  "ping -bnc 4 255.255.255.255" 2>/dev/null | \\\n			  awk -F '' '' ''{print $4}'' | \\\n			  sort -n | uniq | egrep ''[0-9]+\\.[0-9]+\\.'' 2>/dev/null ) )\n	esac\n								   \n	return 0\n} &&\ncomplete -F _vncviewer vncviewer\n\n# sysctl(8) completion\n#\nhave sysctl &&\n_sysctl()\n{\n	local cur\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	COMPREPLY=( $( compgen -W "$(sysctl -N -a 2>/dev/null)" -- $cur ) )\n\n	return 0\n} &&\ncomplete -F _sysctl sysctl\n\n# update-rc.d(8) completion\n#\n# Copyright (C) 2004 Servilio Afre Puentes <servilio@gmail.com>\n#\nhave update-rc.d &&\n_update_rc_d()\n{\n    local cur prev sysvdir services options valid_options\n\n    cur=${COMP_WORDS[COMP_CWORD]}\n    prev=${COMP_WORDS[COMP_CWORD-1]}\n\n    [ -d /etc/rc.d/init.d ] && sysvdir=/etc/rc.d/init.d \\\n	|| sysvdir=/etc/init.d\n\n    services=( $(echo $sysvdir/!(README*|*.sh|*.dpkg*|*.rpm*)) )\n    services=( ${services[@]#$sysvdir/} )\n    options=( -f -n )\n\n    if [[ $COMP_CWORD -eq 1 || "$prev" == -* ]]; then\n	valid_options=( $( \\\n	    echo "${COMP_WORDS[@]} ${options[@]}" \\\n	    | tr " " "\\n" \\\n	    | sed -ne "/$( echo "${options[@]}" | sed "s/ /\\\\|/g" )/p" \\\n	    | sort | uniq -u \\\n	    ) )\n	COMPREPLY=( $( compgen -W ''${options[@]} ${services[@]}'' \\\n	    -X ''$( echo ${COMP_WORDS[@]} | tr " " "|" )'' -- $cur ) )\n    elif [[ "$prev" == ?($( echo ${services[@]} | tr " " "|" )) ]]; then\n	COMPREPLY=( $( compgen -W ''remove defaults start stop'' -- $cur ) )\n    elif [[ "$prev" == defaults && "$cur" == [0-9] ]]; then\n	COMPREPLY=( 0 1 2 3 4 5 6 7 8 9 )\n    elif [[ "$prev" == defaults && "$cur" == [sk]?([0-9]) ]]; then\n	COMPREPLY=( 0 1 2 3 4 5 6 7 8 9 )\n    elif [[ "$prev" == defaults && -z "$cur" ]]; then\n	COMPREPLY=( 0 1 2 3 4 5 6 7 8 9 s k )\n    elif [[ "$prev" == ?(start|stop) ]]; then\n	if [[ "$cur" == [0-9] || -z "$cur" ]]; then \n	    COMPREPLY=( 0 1 2 3 4 5 6 7 8 9 )\n	elif [[ "$cur" == [0-9][0-9] ]]; then \n	    COMPREPLY=( $cur )\n	else\n	    COMPREPLY=()\n	fi\n    elif [[ "$prev" == ?([0-9][0-9]|[0-6S]) ]]; then\n	if [[ -z "$cur" ]]; then\n	    if [[ $prev == [0-9][0-9] ]]; then\n		COMPREPLY=( 0 1 2 3 4 5 6 S )\n	    else\n		COMPREPLY=( 0 1 2 3 4 5 6 S . )\n	    fi\n	elif [[ "$cur" == [0-6S.] ]]; then \n	    COMPREPLY=( $cur )\n	else\n	    COMPREPLY=()\n	fi\n    elif [[ "$prev" == "." ]]; then\n	COMPREPLY=( $(compgen -W "start stop" -- $cur) )\n    else\n	COMPREPLY=()\n    fi\n\n    return 0\n} &&\ncomplete -F _update_rc_d update-rc.d\n\n# invoke-rc.d(8) completion\n#\n# Copyright (C) 2004 Servilio Afre Puentes <servilio@gmail.com>\n#\nhave invoke-rc.d &&\n_invoke_rc_d()\n{\n    local cur prev sysvdir services options valid_options\n\n    cur=${COMP_WORDS[COMP_CWORD]}\n    prev=${COMP_WORDS[COMP_CWORD-1]}\n\n    [ -d /etc/rc.d/init.d ] && sysvdir=/etc/rc.d/init.d \\\n	|| sysvdir=/etc/init.d\n\n    services=( $(echo $sysvdir/!(README*|*.sh|*.dpkg*|*.rpm*)) )\n    services=( ${services[@]#$sysvdir/} )\n    options=( --help --quiet --force --try-anyway --disclose-deny --query --no-fallback )\n\n    if [[ ($COMP_CWORD -eq 1) || ("$prev" == --* ) ]]; then\n	valid_options=( $( \\\n	    echo ${COMP_WORDS[@]} ${options[@]} \\\n	    | tr " " "\\n" \\\n	    | sed -ne "/$( echo ${options[@]} | sed "s/ /\\\\\\\\|/g" )/p" \\\n	    | sort | uniq -u \\\n	    ) )\n	COMPREPLY=( $( compgen -W ''${valid_options[@]} ${services[@]}'' -- \\\n	    $cur ) )\n    elif [ -x $sysvdir/$prev ]; then\n	COMPREPLY=( $( compgen -W ''`sed -ne "y/|/ /; \\\n					    s/^.*Usage:[ ]*[^ ]*[ ]*{*\\([^}\\"]*\\).*$/\\1/p" \\\n					    $sysvdir/$prev`'' -- \\\n	    $cur ) )\n    else\n	COMPREPLY=()\n    fi\n\n    return 0\n} &&\ncomplete -F _invoke_rc_d invoke-rc.d\n\n# minicom(1) completion\n#\nhave minicom &&\n_minicom()\n{\n	local cur prev\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n	prev=${COMP_WORDS[COMP_CWORD-1]}\n\n	case $prev in\n		-@(a|c))\n			COMPREPLY=( $( compgen -W ''on off'' -- $cur ) )\n			return 0\n			;;\n		-@(S|C))\n			_filedir\n			return 0\n			;;\n		-P)\n			COMPREPLY=( $( command ls /dev/tty* ) )\n			COMPREPLY=( $( compgen -W ''${COMPREPLY[@]} ${COMPREPLY[@]#/dev/}'' -- $cur ) )\n			return 0\n			;;\n	esac\n\n\n	if [[ "$cur" == -* ]]; then\n		COMPREPLY=( $( compgen -W ''-s -o -m -M -z -l -L -w -a -t \\\n			-c -S -d -p -C -T -8'' -- $cur ) )\n	else\n		COMPREPLY=( $( command ls /etc/minirc.* | sed -e ''s|/etc/minirc.||'' | grep "^$cur" ) )\n	fi\n} &&\ncomplete -F _minicom minicom\n\n# svn completion\n#\nhave svn &&\n{\n_svn()\n{\n	local cur prev commands options command\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	commands=''add blame praise annotate ann cat checkout co cleanup commit \\\n		ci copy cp delete del remove rm diff di export help ? h import \\\n		info list ls lock log merge mkdir move mv rename ren \\\n		propdel pdel pd propedit pedit pe propget pget pg \\\n		proplist plist pl propset pset ps resolved revert \\\n		status stat st switch sw unlock update up''\n\n	if [[ $COMP_CWORD -eq 1 ]] ; then\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--version'' -- $cur ) )\n		else\n			COMPREPLY=( $( compgen -W "$commands" -- $cur ) )\n		fi\n	else\n\n		prev=${COMP_WORDS[COMP_CWORD-1]}\n		case $prev in\n			--config-dir)\n				_filedir -d\n				return 0;\n				;;\n			-@(F|-file|-targets))\n				_filedir\n				return 0;\n				;;\n			--encoding)\n				COMPREPLY=( $( compgen -W \\\n					''$( iconv --list | sed -e "s@//@@;" )'' \\\n					-- "$cur" ) )\n				return 0;\n				;;\n			--@(editor|diff|diff3)-cmd)\n				COMP_WORDS=(COMP_WORDS[0] $cur)\n				COMP_CWORD=1\n				_command\n				return 0;\n				;;\n		esac\n\n		command=${COMP_WORDS[1]}\n\n		if [[ "$cur" == -* ]]; then\n			# possible options for the command\n			case $command in\n				add)\n					options=''--auto-props --no-auto-props \\\n						--force --targets --no-ignore \\\n						--non-recursive -N -q --quiet''\n					;;\n				@(blame|annotate|ann|praise))\n					options=''-r --revisions --username \\\n						--password --no-auth-cache \\\n						--non-interactive -v \\\n						--verbose --incremental --xml''\n					;;\n				cat)\n					options=''-r --revision --username \\\n						--password --no-auth-cache \\\n						--non-interactive''\n					;;\n				@(checkout|co))\n					options=''-r --revision -q --quiet -N \\\n						--non-recursive --username \\\n						--password --no-auth-cache \\\n						--non-interactive \\\n						--ignore-externals''\n					;;\n				cleanup)\n					options=''--diff3-cmd''\n					;;\n				@(commit|ci))\n					options=''-m --message -F --file \\\n						--encoding --force-log -q \\\n						--quiet --non-recursive -N \\\n						--targets --editor-cmd \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive --no-unlock''\n					;;\n				@(copy|cp))\n					options=''-m --message -F --file \\\n						--encoding --force-log -r \\\n						--revision -q --quiet \\\n						--editor-cmd -username \\\n						--password --no-auth-cache \\\n						--non-interactive''\n					;;\n				@(delete|del|remove|rm))\n					options=''--force -m --message -F \\\n						--file --encoding --force-log \\\n						-q --quiet --targets \\\n						--editor-cmd -username \\\n						--password --no-auth-cache \\\n						--non-interactive''\n					;;\n				@(diff|di))\n					options=''-r --revision -x --extensions \\\n						--diff-cmd --no-diff-deleted \\\n						-N --non-recursive --username \\\n						--password --no-auth-cache \\\n						--non-interactive --force \\\n						--old --new --notice-ancestry''\n					;;\n				export)\n					options=''-r --revision -q --quiet \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive -N \\\n						--non-recursive --force \\\n						--native-eol --ignore-externals''\n					;;\n				import)\n					options=''--auto-props --no-auto-props \\\n						-m --message -F --file \\\n						--encoding --force-log -q \\\n						--quiet --non-recursive \\\n						--no-ignore --editor-cmd \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive''\n					;; \n				info)\n					options=''--username --password \\\n						--no-auth-cache \\\n						--non-interactive -r \\\n						--revision --xml --targets \\\n						-R --recursive --incremental''\n					;;\n				@(list|ls))\n					options=''-r --revision -v --verbose -R \\\n						--recursive --username \\\n						--password --no-auth-cache \\\n						--non-interactive \\\n						--incremental --xml''\n					;;\n				lock)\n					options=''-m --message -F --file \\\n						--encoding --force-log \\\n						--targets --force --username \\\n						--password --no-auth-cache \\\n						--non-interactive''\n					;;\n				log)\n					options=''-r --revision -v --verbose \\\n						--targets --username \\\n						--password --no-auth-cache \\\n						--non-interactive \\\n						--stop-on-copy --incremental \\\n						--xml -q --quiet --limit''\n					;;\n				merge)\n					options=''-r --revision -N \\\n						--non-recursive -q --quiet \\\n						--force --dry-run --diff3-cmd \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive \\\n						--ignore-ancestry''\n					;;\n				mkdir)\n					options=''-m --message -F --file \\\n						--encoding --force-log -q \\\n						--quiet --editor-cmd \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive''\n					;;\n				@(move|mv|rename|ren))\n					options=''-m --message -F --file \\\n						--encoding --force-log -r \\\n						--revision -q --quiet \\\n						--force --editor-cmd \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive''\n					;;\n				@(propdel|pdel|pd))\n					options=''-q --quiet -R --recursive -r \\\n						--revision --revprop \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive''\n					;;\n				@(propedit|pedit|pe))\n					options=''-r --revision --revprop \\\n						--encoding --editor-cmd \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive --force''\n					;;\n				@(propget|pget|pg))\n					options=''-R --recursive -r --revision \\\n						--revprop --strict --username \\\n						--password --no-auth-cache \\\n						--non-interactive''\n					;;\n				@(proplist|plist|pl))\n					options=''-v --verbose -R --recursive \\\n						-r --revision --revprop -q \\\n						--quiet --username --password \\\n						--no-auth-cache \\\n						--non-interactive''\n					;;\n				@(propset|pset|ps))\n					options=''-F --file -q --quiet \\\n						--targets -R --recursive \\\n						--revprop --encoding \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive -r \\\n						--revision --force''\n					;;\n				resolved)\n					options=''--targets -R --recursive -q \\\n						--quiet''\n					;;\n				revert)\n					options=''--targets -R --recursive -q \\\n						--quiet''\n					;;\n				@(status|stat|st))\n					options=''-u --show-updates -v \\\n						--verbose -N --non-recursive \\\n						-q --quiet --username \\\n						--password --no-auth-cache \\\n						--non-interactive --no-ignore \\\n						--ignore-externals \\\n						--incremental --xml''\n					;;\n				@(switch|sw))\n					options=''--relocate -r --revision -N \\\n						--non-recursive -q --quiet \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive --diff3-cmd''\n					;;\n				unlock)\n					options=''--targets --force --username \\\n						--password --no-auth-cache \\\n						--non-interactive''\n					;;\n				@(update|up))\n					options=''-r --revision -N \\\n						--non-recursive -q --quiet \\\n						--username --password \\\n						--no-auth-cache \\\n						--non-interactive \\\n						--diff3-cmd --ignore-externals''\n					;;\n			esac\n			options="$options --help -h --config-dir"\n\n			COMPREPLY=( $( compgen -W "$options" -- $cur ) )\n		else\n			if [[ "$command" == @(help|h|\\?) ]]; then\n				COMPREPLY=( $( compgen -W "$commands" -- $cur ) )\n			else\n				_filedir\n			fi\n		fi\n	fi\n\n	return 0\n}\ncomplete -F _svn $default svn\n\n_svnadmin()\n{\n	local cur prev commands options mode\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	commands=''create deltify dump help ? hotcopy list-dblogs \\\n		list-unused-dblogs load lslocks lstxns recover rmlocks \\\n		rmtxns setlog verify''\n\n	if [[ $COMP_CWORD -eq 1 ]] ; then\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--version'' -- $cur ) )\n		else\n			COMPREPLY=( $( compgen -W "$commands" -- $cur ) )\n		fi\n	else\n		prev=${COMP_WORDS[COMP_CWORD-1]}\n		case $prev in\n			--config-dir)\n				_filedir -d\n				return 0;\n				;;\n			--fs-type)\n				COMPREPLY=( $( compgen -W ''fsfs bdb'' -- $cur ) )\n				return 0;\n				;;\n		esac\n\n		command=${COMP_WORDS[1]}\n\n		if [[ "$cur" == -* ]]; then\n			# possible options for the command\n			case $command in\n				create)\n					options=''--bdb-txn-nosync \\\n						--bdb-log-keep --config-dir \\\n						--fs-type''\n					;;\n				deltify)\n					options=''-r --revision -q --quiet''\n					;;\n				dump)\n					options=''-r --revision --incremental \\\n						-q --quiet --deltas''\n					;;\n				hotcopy)\n					options=''--clean-logs''\n					;;\n				load)\n					options=''--ignore-uuid --force-uuid \\\n						--parent-dir -q --quiet \\\n						--use-pre-commit-hook \\\n						--use-post-commit-hook''\n					;;\n				rmtxns)\n					options=''-q --quiet''\n					;;\n				setlog)\n					options=''-r --revision --bypass-hooks''\n					;;\n			esac\n\n			options="$options --help -h"\n			COMPREPLY=( $( compgen -W "$options" -- $cur ) )\n		else\n			if [[ "$command" == @(help|h|\\?) ]]; then\n				COMPREPLY=( $( compgen -W "$commands" -- $cur ) )\n			else\n				_filedir\n			fi\n		fi\n	fi\n\n	return 0\n}\ncomplete -F _svnadmin $default svnadmin\n\n_svnlook()\n{\n	local cur prev commands options mode\n\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	commands=''author cat changed date diff dirs-changed help ? h history \\\n		info lock log propget pget pg proplist plist pl tree uuid \\\n		youngest''\n\n	if [[ $COMP_CWORD -eq 1 ]] ; then\n		if [[ "$cur" == -* ]]; then\n			COMPREPLY=( $( compgen -W ''--version'' -- $cur ) )\n		else\n			COMPREPLY=( $( compgen -W "$commands" -- $cur ) )\n		fi\n	else\n		command=${COMP_WORDS[1]}\n\n		if [[ "$cur" == -* ]]; then\n			# possible options for the command\n			case $command in\n				@(author|cat|date|dirs-changed|info|log))\n					options=''-r --revision -t \\\n						--transaction''\n					;;\n				changed)\n					options=''-r --revision -t \\\n						--transaction --copy-info''\n					;;\n				diff)\n					options=''-r --revision -t \\\n						--transaction \\\n						--no-diff-deleted \\\n						--no-diff-added \\\n						--diff-copy-from''\n					;;\n				history)\n					options=''-r --revision --show-ids''\n					;;\n				prop@(get|list))\n					options=''-r --revision -t \\\n						--transaction --revprop''\n					;;\n				tree)\n					options=''-r --revision -t \\\n						--transaction --show-ids \\\n						--full-paths''\n					;;\n			esac\n\n			options="$options --help -h"\n			COMPREPLY=( $( compgen -W "$options" -- $cur ) )\n		else\n			if [[ "$command" == @(help|h|\\?) ]]; then\n				COMPREPLY=( $( compgen -W "$commands" -- $cur ) )\n			else\n				_filedir\n			fi\n		fi\n	fi\n\n	return 0\n}\ncomplete -F _svnlook $default svnlook\n}\n\n_filedir_xspec()\n{\n	local IFS cur xspec\n\n	IFS=$''\\t\\n''\n	COMPREPLY=()\n	cur=${COMP_WORDS[COMP_CWORD]}\n\n	_expand || return 0\n\n	# get first exclusion compspec that matches this command\n	xspec=$( sed -ne $''/^complete .*[ \\t]''${1##*/}$''\\([ \\t]\\|$\\)/{p;q;}'' \\\n		  $BASH_COMPLETION )\n	# prune to leave nothing but the -X spec\n	xspec=${xspec#*-X }\n	xspec=${xspec%% *}\n\n	COMPREPLY=( $( eval compgen -f -X "$xspec" -- \\\n		    \\"${cur#[\\`\\"\\'']}\\" 2>/dev/null ) \\\n		    $( compgen -d -- $cur ) )\n}\nlist=( $( sed -ne ''/^# START exclude/,/^# FINISH exclude/p'' \\\n	  $BASH_COMPLETION | \\\n	# read exclusion compspecs\n	(\n	while read line\n	do\n		# ignore compspecs that are commented out\n		if [ "${line#\\#}" != "$line" ]; then continue; fi\n		line=${line%# START exclude*}\n		line=${line%# FINISH exclude*}\n		line=${line##*\\''}\n		list=( ${list[@]:-} $line )\n	done\n	echo ${list[@]}\n	)\n     ) )\n# remove previous compspecs\nif [ ${#list[@]} -gt 0 ]; then\n    eval complete -r ${list[@]}\n    # install new compspecs\n    eval complete -F _filedir_xspec $filenames ${list[@]}\nfi\nunset list\n\n# source completion directory definitions\nif [ -d $BASH_COMPLETION_DIR -a -r $BASH_COMPLETION_DIR -a \\\n     -x $BASH_COMPLETION_DIR ]; then\n	for i in $BASH_COMPLETION_DIR/*; do\n		[[ ${i##*/} != @(*~|*.bak|*.swp|\\#*\\#|*.dpkg*|.rpm*) ]] &&\n			[ \\( -f $i -o -h $i \\) -a -r $i ] && . $i\n	done\nfi\nunset i\n\n# source user completion file\n[ $BASH_COMPLETION != ~/.bash_completion -a -r ~/.bash_completion ] \\\n	&& . ~/.bash_completion\nunset -f have\nunset UNAME RELEASE default dirnames filenames have nospace bashdefault \\\n      plusdirs\n\n###  Local Variables:\n###  mode: shell-script\n###  End:\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(128, 'bash_tab_sh', '# $Id: bash_completion.sh,v 1.2 2006/02/25 01:21:33 ianmacd Exp $\n\n# Check for bash (and that we haven''t already been sourced).\n[ -z "$BASH_VERSION" -o -n "$BASH_COMPLETION" ] && return\n\n# Check for recent enough version of bash.\nbash=${BASH_VERSION%.*}; bmajor=${bash%.*}; bminor=${bash#*.}\n\n# Check for interactive shell.\nif [ -n "$PS1" ]; then\n  if [ $bmajor -eq 2 -a $bminor ''>'' 04 ] || [ $bmajor -gt 2 ]; then\n    if [ -r /etc/bash_completion ]; then\n      # Source completion code.\n      . /etc/bash_completion\n    fi\n  fi\nfi\nunset bash bminor bmajor\n', ''),
(131, 'install_jumpserver_client', '#!/bin/bash\n# Author: LaoGuang\n# Date: 2014-04-28\n\ngetSysVersion(){\n    cat /etc/redhat-release  | awk ''{ print $3 }'' | awk -F. ''{ print $1 }''\n}\n\nsys_version=`getSysVersion`\nread -p "输入LDAP Server地址: " server\n\nif [ "$sys_version" == "5" ];then\n    yum -y install openldap openldap-clients nss_ldap &> /dev/null && echo "安装 LDAP Client 成功"\n    grep "pam_mkhomedir.so" /etc/pam.d/system-auth &> /dev/null || echo "session required pam_mkhomedir.so skel=/etc/skel umask=0077" >> /etc/pam.d/system-auth\n    authconfig --enableldap --enableldapauth --enablemkhomedir --ldapserver=$server --ldapbasedn="dc=jumpserver,dc=org" --update\n    grep "Sudoers" /etc/ldap.conf &> /dev/null || echo "Sudoers_base ou=Sudoers,dc=jumpserver,dc=org" >> /etc/ldap.conf\n    grep "Sudoers" /etc/nsswitch.conf || echo "Sudoers_base ou=Sudoers,dc=jumpserver,dc=org" >> /etc/ldap.conf\n\nelif [ "$sys_version" == "6" ];then\n    yum -y install openldap openldap-clients nss-pam-ldapd pam_ldap &> /dev/null && echo "安装 LDAP Client 成功"\n    grep "pam_mkhomedir.so" /etc/pam.d/system-auth &> /dev/null || echo "session required pam_mkhomedir.so skel=/etc/skel umask=0077" >> /etc/pam.d/system-auth\n    authconfig --savebackup=auth.bak\n    authconfig --enableldap --enableldapauth --enablemkhomedir --enableforcelegacy --disablesssd --disablesssdauth --ldapserver=$server --ldapbasedn="dc=jumpserver,dc=org" --update\n    grep "Sudoers" /etc/sudo-ldap.conf &> /dev/null || echo -e "uri ldap://$server\\nSudoers_base ou=Sudoers,dc=jumpserver,dc=org" > /etc/sudo-ldap.conf\n    grep "Sudoders" /etc/nsswitch.conf || echo "Sudoers: files ldap" >>  /etc/nsswitch.conf\nelse\n    echo "脚本不支持该系统版本，请手工测试"\n    exit 2\nfi\n', ''),
(132, 'install_jumpserver_server', '#!/bin/bash\n# Version: 2.0.0\n# Author: LaoGuang\n# Date: 2015-04-28\n\nldap_conf=/etc/openldap/slapd.conf\n\ngetSysVersion(){\n    cat /etc/redhat-release  | awk ''{ print $3 }''\n}\n\necho\necho -e "\\033[32m 开始安装Jumpserver v2.0.0 版，期间需要下载软件包，根据网络情况会持续一段时间，并不是卡死. \\033[0m"\n\nyum install -y wget\n\nwget https://github.com/sjqzhang/software/raw/master/jumpserver.tar.bz2 -O jumpserver.tar.bz2\n\n\ntar xjvf jumpserver.tar.bz2\n\ncd jumpserver\n\n\necho\nrpm -q automake &> /dev/null\nmini=$?\nversion=`getSysVersion`\nif [ "$mini" != "0" -a "$version" != "6.5" ];then\n    echo -n "你确定你的CentOS 6.5 且是最小化安装吗?"\n    read confirm\nfi\nservice iptables stop &> /dev/null && setenforce 0\n# Install epel and dependency package\nrpm -ivh epel-release-6-8.noarch.rpm &> setup.log && echo "1. 安装epel源 成功" || echo "1. epel已经安装"\nyum clean all &> /dev/null \nyum install -y vim automake autoconf gcc xz ncurses-devel patch python-devel git python-pip gcc-c++  &>> setup.log && echo "2. 安装依赖包 成功" || exit 2\n\n# Install openldap server\nyum install -y openldap openldap-servers openldap-clients openldap-devel &>> setup.log && echo "3. 安装ldapserver 成功" || exit 3\n\n# Set ldap config\nrm -rf /var/lib/ldap/* && cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG \ncp /usr/share/doc/sudo-1.8.6p3/schema.OpenLDAP /etc/openldap/schema/sudo.schema\ncp slapd.conf /etc/openldap/\n\n# Start service \nservice slapd restart &> /dev/null\nrm -rf /etc/openldap/slapd.d/*\nslaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d &> /dev/null && echo "4. LDAP Server 配置 成功"\nchown -R ldap:ldap /etc/openldap/slapd.d/\nservice slapd restart\necho \n\n# Import ldif\necho "5. 导入基本schema到LDAP Server"\nldapadd -x -w secret234 -D "cn=admin,dc=jumpserver,dc=org" -f base.ldif &>> setup.log && echo "	base.ldif OK"\nldapadd -x -w secret234 -D "cn=admin,dc=jumpserver,dc=org" -f group.ldif &>> setup.log  && echo "	group.ldif OK"\nldapadd -x -w secret234 -D "cn=admin,dc=jumpserver,dc=org" -f passwd.ldif &>> setup.log && echo "	passwd.ldif OK"\nldapadd -x -w secret234 -D "cn=admin,dc=jumpserver,dc=org" -f sudo.ldif &>> setup.log && echo "	sudo.ldif OK"\necho \n\necho -n "6. 在客户端(另一台测试机)上执行 client_setup.sh ，完成后 回车继续"\nread confirm\n\necho -n "7. 另开一个session执行 ssh testuser@客户端地址 , 密码是 testuser123, 并测试 sudo su(不应该提示输密码), 如果没有问题,回车继续"\nread confirm \nldapdelete -x -D "cn=admin,dc=jumpserver,dc=org" -w secret234 "uid=testuser,ou=People,dc=jumpserver,dc=org"\nldapdelete -x -D "cn=admin,dc=jumpserver,dc=org" -w secret234 "cn=testuser,ou=Sudoers,dc=jumpserver,dc=org"\n\n# Install mysql\nyum -y install mysql mysql-server mysql-devel &> /dev/null\nservice mysqld start &> /dev/null\nmysql -e "drop database if exists jumpserver;create database jumpserver charset=''utf8'';" || echo "MySQL 密码不对 退出"\nmysql -e "grant all on jumpserver.* to ''jumpserver''@''127.0.0.1'' identified by ''mysql234'';" || exit 2\necho "8. 安装MySQL 成功"\n\n# Clone jumpserver project\ntar xf jumpserver.tar.bz2 -C /opt\ntar xf node_modules.tar.bz2 -C /opt/jumpserver/websocket/\ntar xf pip-build-root.tar.bz2 -C /tmp/\ncd /opt/jumpserver\ngit pull origin master:master && echo "9. 更新代码 成功"\ncd /opt/jumpserver/docs\nrm -rf /usr/lib64/python2.6/site-packages/Crypto && echo y | pip uninstall pycrypto\npip install -r requirements.txt -i http://pypi.douban.com/simple &>> setup.log && echo "10. 安装pypi依赖库 成功"\n\n# Config jumpserver conf\ncd /opt/jumpserver\nread -p "输入本机IP地址：" host\nread -p "输入smtp server地址: （如 smtp.qq.com）" smtp_server\nread -p "输入smtp server端口: （如 25）" smtp_port\nread -p "输入邮件地址: （如 446465001@qq.com) " email\nread -p "输入邮箱密码: （如 dfkelfasdf) " password\n\ncf="jumpserver.conf" \nsed -i "s@ip =.*@ip = $host@g" $cf\nsed -i "s@web_socket.*@web_socket_host = $host:3000@g" $cf\nsed -i "s@email_host = .*@email_host = $smtp_server@g" $cf\nsed -i "s@email_port.*@email_port = $smtp_port@g" $cf\nsed -i "s/email_host_user.*/email_host_user = $email/g" $cf\nsed -i "s@email_host_password.*@email_host_password = $password@g" $cf\n\necho "11. 修改jumpserver.conf 配置文件 成功"\n\nmkdir -p logs/{connect,exec_cmds} && chmod -R 777 logs\nchmod +x *.py *.sh\necho no | python manage.py syncdb\necho\n\n# config websocket\nyum -y install nodejs npm &>> setup.log\ncd /opt/jumpserver/websocket\nnpm install &>> setup.log\necho "12. Nodejs 安装并设置完成"\necho "13. 启动服务"\ncd /opt/jumpserver\nsh service.sh start\n\ncd docs\ncp zzjumpserver.sh /etc/profile.d/ \necho "14. 设置登录运行 成功"\necho "15. 浏览器访问 http://$host/install 初始化 然后登陆，默认账号密码 admin admin 访问http://laoguang.blog.51cto.com/获得帮助"\n\n', ''),
(133, 'jumpserver_error', ' 1. 添加用户时SMTPAuthenticationError\r\n\r\n	SMTP服务器账号信息有误，需修改jumpserver.conf中的email部分，建议先用qq邮箱测试，确保你的qq邮箱开通了SMTP功能(新开通qq邮箱需要15天后才能开通该功能),修改完成后要重启django运行的web 或者 直接 sh service.sh restart, Email的格式如下配置：\r\n	[mail]\r\n	email_host = smtp.qq.com\r\n	email_port = 25\r\n	email_host_user = 446465001@qq.com\r\n	email_host_password = myqqpasswd\r\n	email_use_tls = False\r\n\r\n2. 添加用户时报错 generate_c() takes这是由于系统python自带的 pycrypto版本较低导致的，需要先卸载旧版本，然后安装新版本\r\n\r\n	pip uninstall pycrypto\r\n	rm -rf /usr/lib64/python2.6/site-packages/Crypto\r\n	pip install pycrypto\r\n\r\n3. 执行connect.py时报 compress错\r\n\r\n	TypeError: connect() got an unexpected keyword argument ''compress''\r\n	这是由于paramiko版本过低导致的，升级paramiko版本\r\n	pip install --upgrade paramiko\r\n\r\n4. sudo命令授权后需要输入密码\r\n\r\n	sudo命令请写全路径如:\r\n	/bin/su\r\n	/sbin/ifconfig\r\n	所有就是ALL\r\n	授权后用户通常 sudo ifconfig执行命令了，但是修改用户组，主机组，或者命令组后，记得手动点击右上方的刷新按钮，确保ldap server更改。如果还是不行，安装ldapbrowser ，使用方法：\r\n	File -- New Profile -- 名称随意输入 -- 下一步 -- host填写 ldapserver地址 Base DN可以手写dc=jumpserver,dc=org，可以fetch一下 -- 下一步 -- user填写  cn=admin,dc=jumpserver,dc=org 密码填写 设置的密码 链接成功以后，查看其中sudoers ou，查看其中设置的和授权的是否一致！\r\n\r\n5. logs目录权限\r\n\r\n	logs目录是各个用户写日志的目录，里面会有 connect和 exec_cmds目录，权限都需要777\r\n\r\n6. service.sh启动失败\r\n\r\n	ps axu | grep "runserver | log_handler | node" 查看哪个进程没有启动起来，手动启动测试\r\n	cd /opt/jumpserver;\r\n	python manage.py runserver 0.0.0.0:80\r\n	python log_handler.py\r\n	cd websocket;\r\n	node index.js\r\n	手动排查问题所在，然后处理报错\r\n\r\n7. 点击监控没有反应\r\n\r\n	点击监控没有反应，通常可能是node index.js这个进程没有运行， 或者没有正常运行，如果确定这里没问题后，查看jumpserver.conf配置文件中，websocket中写的地址和端口，客户端是否能正常访问，iptables是是否给禁止了？\r\n\r\n8. 点击统计没有反应\r\n\r\n	统计内容是log_handler.py这个进程生成，查看该进程是否启动，或者logs/connect里面日志是不是没有正常记录\r\n\r\n9. 申请授权，管理员审批后发现没有主机权限\r\n\r\n	目前权限申请，和审批只是个流程，管理收到权限申请后需要手动为该用户授权，授权完成后，点击确认按钮，或者链接\r\n\r\n10. 部门授权\r\n\r\n	部门授权的意义在于 把机器授权给部门，部门管理员可以把该部门的主机授权给本部门的成员！ 而不是 将主机授权给部门后，部门下的成员就有权限了\r\n\r\n\r\n11. 执行connect.py时，按p报UnicodeEncodeError错\r\n\r\n	/etc/profile.d/ 中lang.sh是初始化语言，jumpserver.sh脚本要晚于它执行，所以后来把jumpserver.sh 改名为zzjumpserver.sh了，拷贝到 /etc/profile.d/中是 zzjumpserver.sh就没问题了，当然 zzzzzzzzzzjumpserver.sh也没问题，估计读取的时候是按照字母排序来读取的。	', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(134, 'linux_perf', '\r\n1.0 性能监控介绍  \r\n\r\n	性能优化就是找到系统处理中的瓶颈以及去除这些的过程,多数管理员相信看一些相关的"cook book"就 \r\n	可以实现性能优化,通常通过对内核的一些配置是可以简单的解决问题,但并不适合每个环境,性能优化其实 \r\n	是对 OS 各子系统达到一种平衡的定义,这些子系统包括了: \r\n\r\n	    CPU \r\n	    Memory \r\n	    IO \r\n	    Network \r\n\r\n	这些子系统之间关系是相互彼此依赖的,任何一个高负载都会导致其他子系统出现问题.比如: \r\n\r\n	大量的页调入请求导致内存队列的拥塞  \r\n\r\n	网卡的大吞吐量可能导致更多的 CPU 开销  \r\n	大量的 CPU 开销又会尝试更多的内存使用请求  \r\n	大量来自内存的磁盘写请求可能导致更多的 CPU 以及 IO 问题  \r\n\r\n	所以要对一个系统进行优化,查找瓶颈来自哪个方面是关键,虽然看似是某一个子系统出现问题,其实有可能 \r\n	是别的子系统导致的. \r\n\r\n1.1 确定应用类型  \r\n\r\n	基于需要理解该从什么地方来入手优化瓶颈,首先重要的一点,就是理解并分析当前系统的特点,多数系统所 \r\n	跑的应用类型,主要为 2 种: \r\n\r\n	IO Bound(IO 范畴): 在这个范畴中的应用,一般都是高负荷的内存使用以及存储系统,这实际上表示 IO 范 \r\n	畴的应用,就是一个大量数据处理的过程.IO 范畴的应用不对 CPU 以及网络发起更多请求(除非类似 NAS \r\n	这样的网络存储硬件).IO 范畴的应用通常使用 CPU 资源都是为了产生 IO 请求以及进入到内核调度的 \r\n	sleep 状态.通常数据库软件(例如 mysql,oracle 等)被认为是 IO 范畴的应用类型. \r\n\r\n	CPU Bound(CPU 范畴): 在这个范畴中的应用,一般都是高负荷的 CPU 占用. CPU 范畴的应用,就是一个 \r\n	批量处理 CPU 请求以及数学计算的过程.通常 web server,mail server,以及其他类型服务被认为是 CPU \r\n	范畴的应用类型. \r\n\r\n1.2 确定基准线统计  \r\n\r\n	系统利用率情况,一般随管理员经验以及系统本身用途来决定.唯一要清楚的就是,系统优化希望达成什么效 \r\n	果,以及哪些方面是需要优化,还有参考值是什么?因此就建立一个基准线,这个统计数据必须是系统可用性 \r\n	能状态值,用来比较不可用性能状态值. \r\n\r\n	在以下例子中,1 个系统性能的基准线快照,用来比较当高负荷时的系统性能快照. \r\n\r\n	# vmstat 1 \r\n	procs memory swap io system cpu \r\n\r\n\r\n	r b swpd free buff cache si so bi bo in cs us sy wa id \r\n	1 0 138592 17932 126272 214244 0 0 1 18 109 19 2 1 1 96 \r\n	0 0 138592 17932 126272 214244 0 0 0 0 105 46 0 1 0 99 \r\n	0 0 138592 17932 126272 214244 0 0 0 0 198 62 40 14 0 45 \r\n	0 0 138592 17932 126272 214244 0 0 0 0 117 49 0 0 0 100 \r\n	0 0 138592 17924 126272 214244 0 0 0 176 220 938 3 4 13 80 \r\n	0 0 138592 17924 126272 214244 0 0 0 0 358 1522 8 17 0 75 \r\n	1 0 138592 17924 126272 214244 0 0 0 0 368 1447 4 24 0 72 \r\n	0 0 138592 17924 126272 214244 0 0 0 0 352 1277 9 12 0 79 \r\n\r\n	# vmstat 1 \r\n	procs memory swap io system cpu \r\n	r b swpd free buff cache si so bi bo in cs us sy wa id \r\n	2 0 145940 17752 118600 215592 0 1 1 18 109 19 2 1 1 96 \r\n	2 0 145940 15856 118604 215652 0 0 0 468 789 108 86 14 0 0 \r\n	3 0 146208 13884 118600 214640 0 360 0 360 498 71 91 9 0 0 \r\n	2 0 146388 13764 118600 213788 0 340 0 340 672 41 87 13 0 0 \r\n	2 0 147092 13788 118600 212452 0 740 0 1324 620 61 92 8 0 0 \r\n	2 0 147360 13848 118600 211580 0 720 0 720 690 41 96 4 0 0 \r\n	2 0 147912 13744 118192 210592 0 720 0 720 605 44 95 5 0 0 \r\n	2 0 148452 13900 118192 209260 0 372 0 372 639 45 81 19 0 0 \r\n	2 0 149132 13692 117824 208412 0 372 0 372 457 47 90 10 0 0 \r\n\r\n	从上面第一个结果可看到,最后一列(id) 表示的是空闲时间,我们可以看到,在基准线统计时,CPU 的空闲时 \r\n	间在 79% ­ 100%.在第二个结果可看到,系统处于 100%的占用率以及没有空闲时间.从这个比较中,我们就 \r\n	可以确定是否是 CPU 使用率应该被优化. \r\n\r\n2.0 安装监控工具  \r\n\r\n	多数 *nix 系统都有一堆标准的监控命令.这些命令从一开始就是*nix 的一部分.Linux 则通过基本安装包 \r\n	以及额外包提供了其他监控工具,这些安装包多数都存在各个 Linux 发布版本中.尽管还有其他更多的开源 \r\n	以及第三方监控软件,但本文档只讨论基于 Linux 发布版本的监控工具. \r\n\r\n	本章将讨论哪些工具怎样来监控系统性能. \r\n\r\n	3.0 CPU 介绍  \r\n\r\n	CPU 利用率主要依赖于是什么资源在试图存取.内核调度器将负责调度 2 种资源种类:线程(单一或者多路) \r\n	和中断.调度器去定义不同资源的不同优先权.以下列表从优先级高到低排列: \r\n\r\n	Interrupts(中断) ­ 设备通知内核,他们完成一次数据处理的过程.例子,当一块网卡设备递送网络数据包或 \r\n	者一块硬件提供了一次IO 请求. \r\n\r\n	Kernel(System) Processes(内核处理过程) ­ 所有内核处理过程就是控制优先级别. \r\n\r\n	User Processes(用户进程) ­ 这块涉及"userland".所有软件程序都运行在这个 user space.这块在内核调度 \r\n\r\n\r\n	机制中处于     优先级. \r\n\r\n	从上面,我们可以看出内核是怎样管理不同资源的.还有几个关键内容需要介绍,以下部分就将介绍 \r\n	context(上下文切换),run queues(运行队列)以及 utilization(利用率). \r\n\r\n3.1 上下文切换  \r\n\r\n	多数现代处理器都能够运行一个进程(单一线程)或者线程.多路超线程处理器有能力运行多个线程.然 \r\n	而,Linux 内核还是把每个处理器核心的双核心芯片作为独立的处理器.比如,以 Linux 内核的系统在一个 \r\n	双核心处理器上,是报告显示为两个独立的处理器. \r\n\r\n	一个标准的 Linux 内核可以运行 50 至 50,000 的处理线程.在只有一个 CPU 时,内核将调度并均衡每个进 \r\n	程线程.每个线程都分配一个在处理器中被开销的时间额度.一个线程要么就是获得时间额度或已抢先获得 \r\n	一些具有较高优先级(比如硬件中断),其中较高优先级的线程将从区域重新放置回处理器的队列中.这种线 \r\n	程的转换关系就是我们提到的上下文切换. \r\n\r\n	每次内核的上下文切换,资源被用于关闭在 CPU 寄存器中的线程和放置在队列中.系统中越多的上下文切 \r\n	换,在处理器的调度管理下,内核将得到更多的工作. \r\n\r\n3.2 运行队列  \r\n\r\n	每个 CPU 都维护一个线程的运行队列.理论上,调度器应该不断的运行和执行线程.进程线程不是在 sleep \r\n	状态中(阻塞中和等待IO 中)或就是在可运行状态中.如果 CPU 子系统处于高负荷下,那就意味着内核调度 \r\n	将无法及时响应系统请求.导致结果,可运行状态进程拥塞在运行队列里.当运行队列越来越巨大,进程线程 \r\n	将花费更多的时间获取被执行. \r\n\r\n	比较流行的术语就是"load",它提供当前运行队列的详细状态.系统 load 就是指在 CPU 队列中有多少数目 \r\n	的线程,以及其中当前有多少进程线程数目被执行的组合.如果一个双核系统执行了 2 个线程,还有 4 个在运 \r\n	行队列中,则 load 应该为 6. top 这个程序里显示的 load averages 是指1,5,15分钟以内的 load 情况. \r\n\r\n	3.3 CPU 利用率  \r\n\r\n	CPU 利用率就是定义 CPU 使用的百分比.评估系统最重要的一个度量方式就是 CPU 的利用率.多数性能 \r\n	监控工具关于 CPU 利用率的分类有以下几种: \r\n\r\n	User Time(用户进程时间) ­ 关于在 user space 中被执行进程在 CPU 开销时间百分比. \r\n\r\n	System Time(内核线程以及中断时间) ­ 关于在 kernel space 中线程和中断在 CPU 开销时间百分比. \r\n\r\n	Wait IO(IO 请求等待时间) ­ 所有进程线程被阻塞等待完成一次IO 请求所占 CPU 开销 idle 的时间百分 \r\n	比. \r\n\r\n	Idle(空闲) ­ 一个完整空闲状态的进程在 CPU 处理器中开销的时间百分比. \r\n\r\n4.0 CPU 性能监控  \r\n\r\n\r\n  \r\n\r\n	理解运行队列,利用率,上下文切换对怎样 CPU 性能最优化之间的关系.早期提及到,性能是相对于基准线数 \r\n	据的.在一些系统中,通常预期所达到的性能包括: \r\n\r\n	Run Queues ­ 每个处理器应该运行队列不超过 1­3 个线程.例子,一个双核处理器应该运行队列不要超过 \r\n	6 个线程. \r\n\r\n	CPU Utiliation ­ 如果一个 CPU 被充分使用,利用率分类之间均衡的比例应该是  \r\n	65% ­ 70% User Time \r\n	30% ­ 35% System Time \r\n	0% ­ 5% Idle Time \r\n\r\n	Context Switches ­ 上下文切换的数目直接关系到 CPU 的使用率,如果 CPU 利用率保持在上述均衡状态 \r\n	时,大量的上下文切换是正常的. \r\n\r\n	很多 Linux 上的工具可以得到这些状态值,首先就是 vmstat 和 top 这 2 个工具. \r\n\r\n4.1 vmstat 工具的使用  \r\n\r\n	vmstat 工具提供了一种          开销的系统性能观察方式.因为 vmstat 本身就是                    开销工具,在非常高负荷的服 \r\n	务器上,你需要查看并监控系统的健康情况,在控制窗口还是能够使用 vmstat 输出结果.这个工具运行在 2 \r\n	种模式下:average 和 sample 模式.sample 模式通过指定间隔时间测量状态值.这个模式对于理解在持续 \r\n	负荷下的性能表现,很有帮助.下面就是  \r\n\r\n	vmstat 运行 1秒间隔的示例: \r\n\r\n	# vmstat 1 \r\n	procs ­­­­­­­­­­­memory­­­­­­­­­­ ­­­swap­­ ­­­­­io­­­­ ­­system­­ ­­­­cpu­­­­ \r\n	r b swpd free buff cache si so bi bo in cs us sy id wa \r\n	0 0 104300 16800 95328 72200 0 0 5 26 7 14 4 1 95 0 \r\n	0 0 104300 16800 95328 72200 0 0 0 24 1021 64 1 1 98 0 \r\n	0 0 104300 16800 95328 72200 0 0 0 0 1009 59 1 1 98 0 \r\n\r\n	    The vmstat CPU statistics \r\n	    Field Description \r\n	    r The amount of threads in the run queue. These are threads that are runnable, but the CPU is not \r\n	available to execute them. \r\n	    当前运行队列中线程的数目.代表线程处于可运行状态,但 CPU 还未能执行. \r\n	    b This is the number of processes blocked and waiting on IO requests to finish. \r\n	    当前进程阻塞并等待IO 请求完成的数目  \r\n	    in This is the number of interrupts being processed. \r\n\r\n	    当前中断被处理的数目  \r\n\r\n	    cs This is the number of context switches currently happening on the system. \r\n	    当前 kernel system 中,发生上下文切换的数目  \r\n	    us This is the percentage of user CPU utilization. \r\n\r\n\r\n	    CPU 利用率的百分比  \r\n	    sys This is the percentage of kernel and interrupts utilization. \r\n\r\n	    内核和中断利用率的百分比  \r\n\r\n	    wa This is the percentage of idle processor time due to the fact that ALL runnable threads are \r\n	blocked waiting on IO. \r\n	    所有可运行状态线程被阻塞在等待IO 请求的百分比  \r\n	    id This is the percentage of time that the CPU is completely idle. \r\n	    CPU 空闲时间的百分比  \r\n\r\n4.2 案例学习:持续的 CPU 利用率  \r\n\r\n	在这个例子中,这个系统被充分利用  \r\n\r\n	# vmstat 1 \r\n	procs memory swap io system cpu \r\n	r b swpd free buff cache si so bi bo in cs us sy wa id \r\n	3 0 206564 15092 80336 176080 0 0 0 0 718 26 81 19 0 0 \r\n	2 0 206564 14772 80336 176120 0 0 0 0 758 23 96 4 0 0 \r\n	1 0 206564 14208 80336 176136 0 0 0 0 820 20 96 4 0 0 \r\n	1 0 206956 13884 79180 175964 0 412 0 2680 1008 80 93 7 0 0 \r\n	2 0 207348 14448 78800 175576 0 412 0 412 763 70 84 16 0 0 \r\n	2 0 207348 15756 78800 175424 0 0 0 0 874 25 89 11 0 0 \r\n	1 0 207348 16368 78800 175596 0 0 0 0 940 24 86 14 0 0 \r\n	1 0 207348 16600 78800 175604 0 0 0 0 929 27 95 3 0 2 \r\n	3 0 207348 16976 78548 175876 0 0 0 2508 969 35 93 7 0 0 \r\n	4 0 207348 16216 78548 175704 0 0 0 0 874 36 93 6 0 1 \r\n	4 0 207348 16424 78548 175776 0 0 0 0 850 26 77 23 0 0 \r\n	2 0 207348 17496 78556 175840 0 0 0 0 736 23 83 17 0 0 \r\n	0 0 207348 17680 78556 175868 0 0 0 0 861 21 91 8 0 1 \r\n\r\n	根据观察值,我们可以得到以下结论: \r\n\r\n	1,有大量的中断(in) 和较少的上下文切换(cs).这意味着一个单一的进程在产生对硬件设备的请求. \r\n\r\n	2,进一步显示某单个应用,user time(us) 经常在 85%或者更多.考虑到较少的上下文切换,这个应用应该还 \r\n	在处理器中被处理. \r\n\r\n	3,运行队列还在可接受的性能范围内,其中有 2 个地方,是超出了允许限制. \r\n\r\n4.3 案例学习:超负荷调度  \r\n\r\n	在这个例子中,内核调度中的上下文切换处于饱和  \r\n\r\n	# vmstat 1 \r\n	procs memory swap io system cpu \r\n	r b swpd free buff cache si so bi bo in cs us sy wa id \r\n	2 1 207740 98476 81344 180972 0 0 2496 0 900 2883 4 12 57 27 \r\n\r\n\r\n	0 1 207740 96448 83304 180984 0 0 1968 328 810 2559 8 9 83 0 \r\n	0 1 207740 94404 85348 180984 0 0 2044 0 829 2879 9 6 78 7 \r\n	0 1 207740 92576 87176 180984 0 0 1828 0 689 2088 3 9 78 10 \r\n	2 0 207740 91300 88452 180984 0 0 1276 0 565 2182 7 6 83 4 \r\n	3 1 207740 90124 89628 180984 0 0 1176 0 551 2219 2 7 91 0 \r\n	4 2 207740 89240 90512 180984 0 0 880 520 443 907 22 10 67 0 \r\n	5 3 207740 88056 91680 180984 0 0 1168 0 628 1248 12 11 77 0 \r\n	4 2 207740 86852 92880 180984 0 0 1200 0 654 1505 6 7 87 0 \r\n	6 1 207740 85736 93996 180984 0 0 1116 0 526 1512 5 10 85 0 \r\n	0 1 207740 84844 94888 180984 0 0 892 0 438 1556 6 4 90 0 \r\n\r\n	根据观察值,我们可以得到以下结论: \r\n\r\n	1,上下文切换数目高于中断数目,说明kernel 中相当数量的时间都开销在上下文切换线程. \r\n\r\n	2,大量的上下文切换将导致 CPU 利用率分类不均衡.很明显实际上等待io 请求的百分比(wa)非常高,以及 \r\n	user time 百分比非常       (us). \r\n\r\n	3,因为 CPU 都阻塞在 IO 请求上,所以运行队列里也有相当数目的可运行状态线程在等待执行. \r\n\r\n4.4 mpstat 工具的使用  \r\n\r\n	如果你的系统运行在多处理器芯片上,你可以使用 mpstat 命令来监控每个独立的芯片.Linux 内核视双核 \r\n	处理器为 2 CPU''s,因此一个双核处理器的双内核就报告有 4 CPU''s 可用. \r\n\r\n	mpstat 命令给出的 CPU 利用率统计值大致和 vmstat 一致,但是 mpstat 可以给出基于单个处理器的统计 \r\n	值. \r\n\r\n	# mpstat –P ALL 1 \r\n	Linux 2.4.21­20.ELsmp (localhost.localdomain) 05/23/2006 \r\n\r\n	05:17:31 PM CPU %user %nice %system %idle intr/s \r\n	05:17:32 PM all 0.00 0.00 3.19 96.53 13.27 \r\n	05:17:32 PM 0 0.00 0.00 0.00 100.00 0.00 \r\n	05:17:32 PM 1 1.12 0.00 12.73 86.15 13.27 \r\n	05:17:32 PM 2 0.00 0.00 0.00 100.00 0.00 \r\n	05:17:32 PM 3 0.00 0.00 0.00 100.00 0.00 \r\n\r\n4.5 案例学习: 未充分使用的处理量  \r\n\r\n	在这个例子中,为 4 CPU 核心可用.其中 2 个 CPU 主要处理进程运行(CPU 0 和1).第 3 个核心处理所有 \r\n	内核和其他系统功能(CPU 3).第 4 个核心处于 idle(CPU 2). \r\n\r\n	使用 top 命令可以看到有 3 个进程差不多完全占用了整个 CPU 核心. \r\n\r\n	# top ­d 1 \r\n	top ­ 23:08:53 up 8:34, 3 users, load average: 0.91, 0.37, 0.13 \r\n	Tasks: 190 total, 4 running, 186 sleeping, 0 stopped, 0 zombie \r\n\r\n\r\n	Cpu(s): 75.2% us, 0.2% sy, 0.0% ni, 24.5% id, 0.0% wa, 0.0% hi, 0.0% \r\n	si \r\n	Mem: 2074736k total, 448684k used, 1626052k free, 73756k buffers \r\n	Swap: 4192956k total, 0k used, 4192956k free, 259044k cached \r\n\r\n	PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND \r\n	15957 nobody 25 0 2776 280 224 R 100 20.5 0:25.48 php \r\n	15959 mysql 25 0 2256 280 224 R 100 38.2 0:17.78 mysqld \r\n	15960 apache 25 0 2416 280 224 R 100 15.7 0:11.20 httpd \r\n	15901 root 16 0 2780 1092 800 R 1 0.1 0:01.59 top \r\n	1 root 16 0 1780 660 572 S 0 0.0 0:00.64 init \r\n\r\n	# mpstat –P ALL 1 \r\n	Linux 2.4.21­20.ELsmp (localhost.localdomain) 05/23/2006 \r\n\r\n	05:17:31 PM CPU %user %nice %system %idle intr/s \r\n	05:17:32 PM all 81.52 0.00 18.48 21.17 130.58 \r\n	05:17:32 PM 0 83.67 0.00 17.35 0.00 115.31 \r\n	05:17:32 PM 1 80.61 0.00 19.39 0.00 13.27 \r\n	05:17:32 PM 2 0.00 0.00 16.33 84.66 2.01 \r\n	05:17:32 PM 3 79.59 0.00 21.43 0.00 0.00 \r\n\r\n	05:17:32 PM CPU %user %nice %system %idle intr/s \r\n	05:17:33 PM all 85.86 0.00 14.14 25.00 116.49 \r\n	05:17:33 PM 0 88.66 0.00 12.37 0.00 116.49 \r\n	05:17:33 PM 1 80.41 0.00 19.59 0.00 0.00 \r\n	05:17:33 PM 2 0.00 0.00 0.00 100.00 0.00 \r\n	05:17:33 PM 3 83.51 0.00 16.49 0.00 0.00 \r\n\r\n	05:17:33 PM CPU %user %nice %system %idle intr/s \r\n	05:17:34 PM all 82.74 0.00 17.26 25.00 115.31 \r\n	05:17:34 PM 0 85.71 0.00 13.27 0.00 115.31 \r\n	05:17:34 PM 1 78.57 0.00 21.43 0.00 0.00 \r\n	05:17:34 PM 2 0.00 0.00 0.00 100.00 0.00 \r\n	05:17:34 PM 3 92.86 0.00 9.18 0.00 0.00 \r\n\r\n	05:17:34 PM CPU %user %nice %system %idle intr/s \r\n	05:17:35 PM all 87.50 0.00 12.50 25.00 115.31 \r\n	05:17:35 PM 0 91.84 0.00 8.16 0.00 114.29 \r\n	05:17:35 PM 1 90.82 0.00 10.20 0.00 1.02 \r\n	05:17:35 PM 2 0.00 0.00 0.00 100.00 0.00 \r\n	05:17:35 PM 3 81.63 0.00 15.31 0.00 0.00 \r\n\r\n	你也可以使用 ps 命令通过查看 PSR 这列,检查哪个进程在占用了哪个 CPU. \r\n\r\n	# while :; do ps ­eo pid,ni,pri,pcpu,psr,comm | grep ''mysqld''; sleep 1; \r\n	done \r\n	PID NI PRI %CPU PSR COMMAND \r\n	15775 0 15 86.0 3 mysqld \r\n	PID NI PRI %CPU PSR COMMAND \r\n\r\n\r\n	15775 0 14 94.0 3 mysqld \r\n	PID NI PRI %CPU PSR COMMAND \r\n	15775 0 14 96.6 3 mysqld \r\n	PID NI PRI %CPU PSR COMMAND \r\n	15775 0 14 98.0 3 mysqld \r\n	PID NI PRI %CPU PSR COMMAND \r\n	15775 0 14 98.8 3 mysqld \r\n	PID NI PRI %CPU PSR COMMAND \r\n	15775 0 14 99.3 3 mysqld \r\n\r\n4.6 结论  \r\n\r\n	监控 CPU 性能由以下几个部分组成: \r\n\r\n	1,检查 system 的运行队列,以及确定不要超出每个处理器3 个可运行状态线程的限制. \r\n\r\n	2,确定 CPU 利用率中 user/system 比例维持在 70/30 \r\n\r\n	3,当 CPU 开销更多的时间在 system mode,那就说明已经超负荷并且应该尝试重新调度优先级  \r\n\r\n	4,当I/O 处理得到增长,CPU 范畴的应用处理将受到影响  \r\n\r\n	5.0 Virtual Memory 介绍  \r\n\r\n	虚拟内存就是采用硬盘对物理内存进行扩展,所以对可用内存的增加是要相对在一个有效范围内的.内核会 \r\n	写当前未使用内存块的内容到硬盘上,此时这部分内存被用于其它用途.当再一次需要原始内容时,此时再读 \r\n	回到内存中.这对于用户来说,是完全透明的;在 Linux 下运行的程序能够看到,也仅仅是大量的可用内存,同 \r\n	时也不会留意到,偶尔还有部分是驻留在磁盘上的.当然,在硬盘上进行读和写,都是很慢的(大约会慢上千 \r\n	倍),相对于使用真实内存的话,因此程序无法运行的更快.用硬盘的一部分作为 Virtual Memory,这就被称 \r\n	为"swap space"(交换空间). \r\n\r\n5.1 Virtual Memory Pages \r\n\r\n	虚拟内存被分为很多 pages(页),在 X86 架构中,每个虚拟内存页为 4KB.当内核写内存到磁盘或者读磁盘 \r\n	到内存,这就是一次写内存到页的过程.内核通常是在 swap 分区和文件系统之间进行这样的操作. \r\n\r\n5.2 Kernel Memory Paging \r\n\r\n	内存分页在正常情况下总是活跃的,与memory swapping(内存交换)之间不要搞错了.内存分页是指内核 \r\n	会定期将内存中的数据同步到硬盘,这个过程就是 Memory Paging. 日复一 日,应用最终将会消耗掉所有的 \r\n	内存空间.考虑到这点,内核就必须经常扫描内存空间并且收回其中未被使用的内存页,然后再重新分配内存 \r\n	空间给其他应用使用. \r\n\r\n5.3 The Page Frame Reclaim Algorithm(PFRA)(页框回收算法) \r\n\r\n	PFRA 就是 OS 内核用来回收并释放内存空间的算法.PFRA 选择哪个内存页被释放是基于内存页类型的. \r\n\r\n\r\n	页类型有以下几种: \r\n\r\n	  \r\n\r\n	Unreclaimable –锁定的 ，内核保留的页面  \r\n	Swappable –匿名的内存页  \r\n	Syncable –通过硬盘文件备份的内存页  \r\n	Discardable –静态页和被丢弃的页  \r\n\r\n	除了第一种      （Unreclaimable）之外其余的都可以被 PFRA 进行回收. \r\n\r\n	与PFRA 相关的,还包括 kswapd 内核线程以及Low On Memory Reclaiming(LMR 算法) 这 2 种进程 \r\n	和实现. \r\n\r\n5.4 kswapd \r\n\r\n	kswapd 进程负责确保内存空间总是在被释放中.它监控内核中的 pages_high 和pages_low 阀值.如果空 \r\n	闲内存的数值       于 pages_low,则每次 kswapd 进程启动扫描并尝试释放32 个 free pages.并一直重复这 \r\n	个过程,直到空闲内存的数值高于 pages_high. \r\n\r\n	kswapd 进程完成以下几个操作: \r\n\r\n	1,如果该页处于未修改状态,则将该页放置回空闲列表中. \r\n	2,如果该页处于已修改状态并可备份回文件系统,则将页内容写入到磁盘. \r\n	3,如果该页处于已修改状态但没有任何磁盘备份,则将页内容写入到 swap device. \r\n\r\n	# ps ­ef | grep kswapd \r\n	root 30 1 0 23:01 ? 00:00:00 [kswapd0] \r\n\r\n5.5 Kernel Paging with pdflush \r\n\r\n	pdflush 进程负责将内存中的内容和文件系统进行同步操作.也就是说,当一个文件在内存中进行修改后, \r\n	pdflush 将负责写回到磁盘上. \r\n\r\n	# ps ­ef | grep pdflush \r\n	root 28 3 0 23:01 ? 00:00:00 [pdflush] \r\n	root 29 3 0 23:01 ? 00:00:00 [pdflush] \r\n\r\n	当内存中存在 10% 的脏页,pdflush 将被启动同步脏页回文件系统里.这个参数值可以通过  \r\n	vm.dirty_background_ratio 来进行调整. \r\n\r\n	(Q:什么是脏页? \r\n	A:由于内存中页缓存的缓存作用,写操作实际上都是延迟的.当页缓存中的数据比磁盘存储的数据还要更新 \r\n	时,那么该数据就被称做脏页.) \r\n\r\n	# sysctl ­n vm.dirty_background_ratio \r\n	10 \r\n\r\n\r\n	在多数环境下,Pdflush 与PFRA 是独立运行的,当内核调用LMR 时,LMR 就触发 pdflush 将脏页写入到 \r\n	磁盘里. \r\n\r\n	++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \r\n	在 2.4 内核下,一个高负荷的内存环境中,系统将遇到交换过程中不断的崩溃.这是因为 PFRA 从一个运行 \r\n	进程中,偷取其中一个内存页并尝试使用.导致结果就是,这个进程如果要回收那个页时,要是没有就会尝试 \r\n	再去偷取这个页,这样一来,就越来越糟糕了.在 2.6 内核下,使用"Swap token"修复了这个 BUG,用来防止 \r\n	PFRA 不断从一个进程获取同一个页. \r\n	++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \r\n\r\n5.6 案例学习:大量的入口I/O \r\n\r\n	vmstat 工具报告里除了 CPU 使用情况,还包括了虚拟内存.以下就是 vmstat 输出中关于虚拟内存的部分: \r\n\r\n	Table 2: The vmstat Memory Statistics \r\n	Field Description \r\n	Swapd The amount of virtual memory in KB currently in use. As free memory reaches low \r\n	thresholds, more data is paged to the swap device. \r\n	当前虚拟内存使用的总额(单位:KB).空闲内存达到最                      的阀值时,更多的数据被转换成页到交换设备中. \r\n	Free The amount of physical RAM in kilobytes currently available to running applications. \r\n	当前内存中可用空间字节数. \r\n	Buff The amount of physical memory in kilobytes in the buffer cache as a result of read() and \r\n	write() operations. \r\n	当前内存中用于read()和write()操作的缓冲区中缓存字节数  \r\n	Cache The amount of physical memory in kilobytes mapped into process address space. \r\n\r\n	当前内存中映射到进程地址空间字节数  \r\n	So The amount of data in kilobytes written to the swap disk. \r\n\r\n	写入交换空间的字节数总额  \r\n	Si The amount of data in kilobytes written from the swap disk back into RAM. \r\n\r\n	从交换空间写回内存的字节数总额  \r\n	Bo The amount of disk blocks paged out from the RAM to the filesystem or swap device. \r\n\r\n	磁盘块页面从内存到文件或交换设备的总额  \r\n	Bi The amount of disk blocks paged into RAM from the filesystem or swap device. \r\n\r\n	磁盘块页面从文件或交换设备到内存的总额  \r\n\r\n	以下 vmstat 的输出结果,就是演示一个在 I/O 应用中,虚拟内存在高负荷情况下的环境  \r\n\r\n	# vmstat 3 \r\n	procs memory swap io system cpu \r\n	r b swpd free buff cache si so bi bo in cs us sy id wa \r\n	3 2 809192 261556 79760 886880 416 0 8244 751 426 863 17 3 6 75 \r\n	0 3 809188 194916 79820 952900 307 0 21745 1005 1189 2590 34 6 12 48 \r\n	0 3 809188 162212 79840 988920 95 0 12107 0 1801 2633 2 2 3 94 \r\n	1 3 809268 88756 79924 1061424 260 28 18377 113 1142 1694 3 5 3 88 \r\n	1 2 826284 17608 71240 1144180 100 6140 25839 16380 1528 1179 19 9 12 61 \r\n	2 1 854780 17688 34140 1208980 1 9535 25557 30967 1764 2238 43 13 16 28 \r\n	0 8 867528 17588 32332 1226392 31 4384 16524 27808 1490 1634 41 10 7 43 \r\n\r\n\r\n	4 2 877372 17596 32372 1227532 213 3281 10912 3337 678 932 33 7 3 57 \r\n	1 2 885980 17800 32408 1239160 204 2892 12347 12681 1033 982 40 12 2 46 \r\n	5 2 900472 17980 32440 1253884 24 4851 17521 4856 934 1730 48 12 13 26 \r\n	1 1 904404 17620 32492 1258928 15 1316 7647 15804 919 978 49 9 17 25 \r\n	4 1 911192 17944 32540 1266724 37 2263 12907 3547 834 1421 47 14 20 20 \r\n	1 1 919292 17876 31824 1275832 1 2745 16327 2747 617 1421 52 11 23 14 \r\n	5 0 925216 17812 25008 1289320 12 1975 12760 3181 772 1254 50 10 21 19 \r\n	0 5 932860 17736 21760 1300280 8 2556 15469 3873 825 1258 49 13 24 15 \r\n\r\n	根据观察值,我们可以得到以下结论: \r\n\r\n	1,大量的磁盘块页面来自文件系统(bi),很明显在进程地址空间里,数据缓存在不断的增长. \r\n\r\n	2,在这个时间点上,空闲内存(free) 始终保持在 17MB,即使数据是从磁盘到分页而在消耗空闲 RAM. \r\n\r\n	3,为了维护空闲列表, kswapd 从读/写缓存区(buff)中获取内存并分配到空闲列表里.很明显可以看到 \r\n	buffer cache(buff) 在逐渐的减少中. \r\n\r\n	4, kswapd 进程当写脏页到交换设备(so)时,很明显虚拟内存的利用率是逐渐的增加中(swpd). \r\n\r\n5.7 结论  \r\n\r\n	监控虚拟内存性能由以下几个部分组成: \r\n\r\n	1,当系统中出现较重大的页错误,要获得最好的响应时间,就要使得memory caches(内存高速缓存)超过 \r\n	disk caches(磁盘高速缓存). \r\n\r\n	2,较少的空闲内存,是件好事情,那意味着缓存的使用更有效率.除非在不断的写入 swap device(交换设备) \r\n	和disk(硬盘). \r\n\r\n	3,如果系统不断报告,swap device 总是繁忙中,那就意味着内存已经不足,需要升级了. \r\n\r\n6.0 I/O 监控介绍  \r\n\r\n	磁盘 I/O 子系统是 Linux 系统中最慢的部分.这个主要是归于 CPU 到物理操作磁盘之间距离(盘片旋转以 \r\n	及寻道).如果拿读取磁盘和内存的时间作比较就是分钟级到秒级,这就像 7 天和7 分钟的区别.因此本质 \r\n	上,Linux 内核就是要最       程度的降 I/O 数.本章将诉述内核在磁盘和内存之间处理数据的这个过程中,哪 \r\n	些地方会产生 I/O. \r\n\r\n6.1 读和写数据 ­ 内存页  \r\n\r\n	Linux 内核将硬盘 I/O 进行分页,多数 Linux 系统的默认页大小为 4K.读和写磁盘块进出到内存都为 4K \r\n	页大小.你可以使用 time 这个命令加­v 参数,来检查你系统中设置的页大小: \r\n\r\n	# /usr/bin/time ­v date \r\n	2009 年 08 月 13 日 星期四 23:07:59 CST \r\n\r\n\r\n		Command being timed: "date" \r\n		User time (seconds): 0.00 \r\n		System time (seconds): 0.00 \r\n		Percent of CPU this job got: 200% \r\n		Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.00 \r\n		Average shared text size (kbytes): 0 \r\n		Average unshared data size (kbytes): 0 \r\n		Average stack size (kbytes): 0 \r\n		Average total size (kbytes): 0 \r\n		Maximum resident set size (kbytes): 0 \r\n		Average resident set size (kbytes): 0 \r\n		Major (requiring I/O) page faults: 0 \r\n		Minor (reclaiming a frame) page faults: 264 \r\n		Voluntary context switches: 1 \r\n		Involuntary context switches: 1 \r\n		Swaps: 0 \r\n		File system inputs: 0 \r\n		File system outputs: 0 \r\n		Socket messages sent: 0 \r\n		Socket messages received: 0 \r\n		Signals delivered: 0 \r\n		Page size (bytes): 4096 \r\n		Exit status: 0 \r\n\r\n	<snip> \r\n	Page size (bytes): 4096 \r\n	<snip> \r\n\r\n6.2 Major and Minor Page Faults(主要页错误和次要页错误) \r\n\r\n	Linux,类似多数的 UNIX 系统,使用一个虚拟内存层来映射硬件地址空间.当一个进程被启动,内核先扫描 \r\n	CPU caches 和物理内存.如果进程需要的数据在这 2 个地方都没找到,就需要从磁盘上读取,此时内核过程 \r\n	就是 major page fault(MPF).MPF 要求磁盘子系统检索页并缓存进 RAM. \r\n\r\n	一旦内存页被映射进内存的 buffer cache(buff)中,内核将尝试从内存中读取或写入,此时内核过程就是 \r\n	minor page fault(MnPF).与在磁盘上操作相比,MnPF 通过反复使用内存中的内存页就大大的缩短了内核 \r\n	时间. \r\n\r\n	以下的例子,使用 time 命令验               了,当进程启动后,MPF 和 MnPF 的变化情况.第一次运行进程,MPF 会更 \r\n	多: \r\n\r\n	# /usr/bin/time ­v evolution \r\n	<snip> \r\n	Major (requiring I/O) page faults: 163 \r\n	Minor (reclaiming a frame) page faults: 5918 \r\n	<snip> \r\n\r\n\r\n	第二次再运行时,内核已经不需要进行 MPF 了,因为进程所需的数据已经在内存中: \r\n\r\n	  \r\n	# /usr/bin/time ­v evolution \r\n	<snip> \r\n	Major (requiring I/O) page faults: 0 \r\n	Minor (reclaiming a frame) page faults: 5581 \r\n	<snip> \r\n\r\n6.3 The File Buffer Cache(文件缓存区) \r\n\r\n	文件缓存区就是指,内核将MPF 过程最小化,MnPF 过程最大化.随着系统不断的产生 I/O,buffer cache 也 \r\n	将不断的增加.直到内存不够,以及系统需要释放老的内存页去给其他用户进程使用时,系统就会丢弃这些内 \r\n	存页.结果是,很多 SA(系统管理员)对系统中过少的 free memory(空闲内存)表示担心,实际上这是系统更 \r\n	高效的在使用 caches. \r\n\r\n	以下例子,是查看/proc/meminfo 文件: \r\n\r\n	# cat /proc/meminfo \r\n	MemTotal: 2075672 kB \r\n	MemFree: 52528 kB \r\n	Buffers: 24596 kB \r\n	Cached: 1766844 kB \r\n	<snip> \r\n\r\n	可以看出,这个系统总计有 2GB (Memtotal)的可用内存.当前的空闲内存为 52MB (MemFree),有 24 MB \r\n	内存被分配磁盘写操作(Buffers),还有 1.7 GB页用于读磁盘(Cached). \r\n\r\n	内核这样是通过MnPF 机制,而不代表所有的页都是来自磁盘.通过以上部分,我们不可能确认系统是否处 \r\n	于瓶颈中. \r\n\r\n6.4 Type of Memory Pages \r\n\r\n	在 Linux 内核中,memory pages 有 3 种,分别是: \r\n\r\n	1,Read Pages ­ 这些页通过 MPF 从磁盘中读入,而且是只读.这些页存在于 Buffer Cache 中以及包括不能 \r\n	够修改的静态文件,二进制文件,还有库文件.当内核需要它们时,将读取到内存中.如果内存不足,内核将释放 \r\n	它们回空闲列表中.程序再次请求时,则通过 MPF 再次读回内存. \r\n\r\n	2,Dirty Pages ­ 这些页是内核在内存中已经被修改过的数据页.当这些页需要同步回磁盘上,由pdflush 负 \r\n	责写回磁盘.如果内存不足,kswapd (与pdflush 一起)将这些页写回到磁盘上并释放更多的内存. \r\n\r\n	3,Anonymous Pages ­ 这些页属于某个进程,但是没有任何磁盘文件和它们有关.他们不能和同步回磁盘. \r\n	如果内存不足,kswapd 将他们写入 swap 分区上并释放更多的内存("swapping" pages). \r\n\r\n6.5 Writing Data Pages Back to Disk \r\n\r\n\r\n	应用程序有很多选择可以写脏页回磁盘上,可通过 I/O 调度器使用 fsync() 或 sync() 这样的系统函数来实 \r\n	现立即写回.如果应用程序没有调用以上函数,pdflush 进程会定期与磁盘进行同步. \r\n\r\n	  \r\n	# ps ­ef | grep pdflush \r\n	root 186 6 0 18:04 ? 00:00:00 [pdflush] \r\n\r\n7.0 监控 I/O \r\n\r\n	当觉得系统中出现了 I/O 瓶颈时,可以使用标准的监控软件来查找原因.这些工具包括了 \r\n	top,vmstat,iostat,sar.它们的输出结果一小部分是很相似,不过每个也都提供了各自对于性能不同方面的解 \r\n	释.以下章节就将讨论哪些情况会导致 I/O 瓶颈的出现. \r\n\r\n7.1 Calculating IO''s Per Second(IOPS 的计算) \r\n\r\n	每个 I/O 请求到磁盘都需要若干时间.主要是因为磁盘的盘边必须旋转,机头必须寻道.磁盘的旋转常常被称 \r\n	为"rotational delay"(RD),机头的移动称为"disk seek"(DS).一个 I/O 请求所需的时间计算就是 DS 加上 \r\n	RD.磁盘的 RD 基于设备自身RPM 单位值(RPM 是 Revolutions Perminute 的缩写,是转/每分钟,代表了 \r\n	硬盘的转速).一个 RD 就是一个盘片旋转的半圆.如何计算一个 10K RPM设备的 RD 值呢: \r\n\r\n	1, 10000 RPM / 60 seconds (10000/60 = 166 RPS) \r\n	2, 转换为 166分之 1 的值(1/166 = 0.006 seconds/Rotation) \r\n	3, 单位转换为毫秒(6 MS/Rotation) \r\n	4, 旋转半圆的时间(6/2 = 3MS) 也就是 RD \r\n	5, 加上平均3 MS 的寻道时间 (3MS + 3MS = 6MS) \r\n	6, 加上 2MS 的延迟(6MS + 2MS = 8MS) \r\n	7, 1000 MS / 8 MS (1000/8 = 125 IOPS) \r\n\r\n	每次应用程序产生一个 I/O,在 10K RPM磁盘上都要花费平均 8MS.在这个固定时间里,磁盘将尽可能且 \r\n	有效率在进行读写磁盘.IOPS 可以计算出大致的 I/O 请求数,10K RPM 磁盘有能力提供120­150 次 \r\n	IOPS.评估IOPS 的效能,可用每秒读写 I/O 字节数除以每秒读写 IOPS 数得出. \r\n\r\n7.2 Random vs Sequential I/O(随机/顺序 I/O) \r\n\r\n	per I/O 产生的 KB 字节数是与系统本身 workload 相关的,有 2 种不同workload 的类型,它们是 \r\n	sequential 和random. \r\n\r\n	7.2.1 Sequential I/O(顺序IO) \r\n\r\n	iostat 命令提供信息包括 IOPS 和每个 I/O 数据处理的总额.可使用 iostat ­x 查看.顺序的 workload 是同 \r\n	时读顺序请求大量的数据.这包括的应用,比如有商业数据库(database)在执行大量的查询和流媒体服务.在 \r\n	这个 workload 中,KB per I/O 的比率应该是很高的.Sequential workload 是可以同时很快的移动大量数 \r\n	据.如果每个 I/O 都节省了时间,那就意味了能带来更多的数据处理. \r\n\r\n	# iostat ­x 1 \r\n\r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	0.00 0.00 57.1 4 42.86 \r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 0.00 12891.43 0.00 105.71 0.00 1 06080.00 0.00 53040.00 1003.46 1099.43 3442.43 26.49 \r\n	280.00 \r\n	/dev/sda1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n	/dev/sda2 0.00 12857.14 0.00 5.71 0.00 105782.86 0.00 52891.43 18512.00 559.14 780.00 490.00 \r\n	280.00 \r\n	/dev/sda3 0.00 34.29 0.00 100.00 0.00 297.14 0.00 148.57 2.97 540.29 594.57 24.00 240.00 \r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	0.00 0.00 23.53 76.47 \r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 0.00 17320.59 0.00 102.94 0.00 142305.88 0.00 71152.94 1382.40 6975.29 952.29 28.57 \r\n	294.12 \r\n	/dev/sda1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n	/dev/sda2 0.00 16844.12 0.00 102.94 0.00 138352.94 0.00 69176.47 1344.00 6809.71 952.29 28.57 \r\n	294.12 \r\n	/dev/sda3 0.00 476.47 0.00 0.00 0.00 952.94 0.00 1976.47 0.00 165.59 0.00 0.00 276.47 \r\n\r\n	评估IOPS 的效能,可用每秒读写 I/O 字节数除以每秒读写 IOPS 数得出,比如  \r\n	rkB/s 除以 r/s \r\n	wkB/s 除以 w/s \r\n\r\n	53040/105 = 505KB per I/O \r\n	71152/102 = 697KB per I/O \r\n	在上面例子可看出,每次循环下,/dev/sda 的 per I/O 都在增加. \r\n\r\n7.2.2 Random I/O(随机IO) \r\n\r\n	Random 的 worklaod 环境下,不依赖于数据大小的多少,更多依赖的是磁盘的 IOPS 数.Web和Mail 服务 \r\n	就是典型的 Random workload.I/O 请求内容都很小.Random workload 是同时每秒会有更多的请求数产 \r\n	生.所以,磁盘的 IOPS 数是关键. \r\n\r\n	# iostat ­x 1 \r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	2.04 0.00 97.96 0.00 \r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 0.00 633.67 3.06 102.31 24.49 5281.63 12.24 2640.82 288.89 73.67 113.89 27.22 50.00 \r\n	/dev/sda1 0.00 5.10 0.00 2.04 0.00 57.14 0.00 28.57 28.00 1.12 55.00 55.00 11.22 \r\n	/dev/sda2 0.00 628.57 3.06 100.27 24.49 5224.49 12.24 2612.24 321.50 72.55 121.25 30.63 50.00 \r\n	/dev/sda3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	2.15 0.00 97.85 0.00 \r\n\r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 0.00 41.94 6.45 130.98 51.61 352.69 25.81 3176.34 19.79 2.90 286.32 7.37 15.05 \r\n	/dev/sda1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n	/dev/sda2 0.00 41.94 4.30 130.98 34.41 352.69 17.20 3176.34 21.18 2.90 320.00 8.24 15.05 \r\n	/dev/sda3 0.00 0.00 2.15 0.00 17.20 0.00 8.60 0.00 8.00 0.00 0.00 0.00 0.00 \r\n\r\n	计算方式和之前的公式一致: \r\n\r\n	2640/102 = 23KB per I/O \r\n	3176/130 = 24KB per I/O \r\n\r\n	(对于顺序I/O 来说,主要是考虑读取大量数据的能力即KB per request.对于随机I/O 系统,更需要考虑的 \r\n	是 IOPS 值) \r\n\r\n7.3 When Virtual Memory Kills I/O \r\n\r\n	如果系统没有足够的 RAM 响应所有的请求,就会使用到 SWAP device.就像使用文件系统 I/O,使用 \r\n	SWAP device 代价也很大.如果系统已经没有物理内存可用,那就都在 SWAP disk 上创建很多很多的内存 \r\n	分页,如果同一文件系统的数据都在尝试访问 SWAP device,那系统将遇到 I/O 瓶颈.最终导致系统性能的 \r\n	全面崩溃.如果内存页不能够及时读或写磁盘,它们就一直保留在 RAM 中.如果保留时间太久,内核又必须 \r\n	释放内存空间.问题来了,I/O 操作都被阻塞住了,什么都没做就被结束了,不可避免地就出现 kernel panic \r\n	和system crash. \r\n\r\n	下面的 vmstat 示范了一个内存不足情况下的系统: \r\n\r\n	procs ­­­­­­­­­­­memory­­­­­­­­­­ ­­­swap­­ ­­­­­io­­­­ ­­system­­ ­­­­cpu­­­­ \r\n	r b swpd free buff cache si so bi bo in cs us sy id wa \r\n	17 0 1250 3248 45820 1488472 30 132 992 0 2437 7657 23 50 0 23 \r\n	11 0 1376 3256 45820 1488888 57 245 416 0 2391 7173 10 90 0 0 \r\n	12 0 1582 1688 45828 1490228 63 131 1348 76 2432 7315 10 90 0 10 \r\n	12 2 3981 1848 45468 1489824 185 56 2300 68 2478 9149 15 12 0 73 \r\n	14 2 10385 2400 44484 1489732 0 87 1112 20 2515 11620 0 12 0 88 \r\n	14 2 12671 2280 43644 1488816 76 51 1812 204 2546 11407 20 45 0 35 \r\n\r\n	这个结果可看出,大量的读请求回内存(bi),导致了空闲内存在不断的减少(free).这就使得系统写入 swap \r\n	device 的块数目(so)和swap 空间(swpd)在不断增加.同时看到 CPU WIO time(wa)百分比很大.这表明I/ \r\n	O 请求已经导致 CPU 开始效率               下. \r\n\r\n	要看 swaping 对磁盘的影响,可使用 iostat 检查 swap 分区  \r\n\r\n	# iostat ­x 1 \r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	0.00 0.00 100.00 0.00 \r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 0.00 1766.67 4866.67 1700.00 38933.33 31200.00 19466.67 15600.00 10.68 6526.67 \r\n\r\n\r\n	100.56 5.08 3333.33 \r\n	/dev/sda1 0.00 933.33 0.00 0.00 0.00 7733.33 0.00 3866.67 0.00 20.00 2145.07 7.37 200.00 \r\n	/dev/sda2 0.00 0.00 4833.33 0.00 38666.67 533.33 19333.33 266.67 8.11 373.33 8.07 6.90 87.00 \r\n	/dev/sda3 0.00 833.33 33.33 1700.00 266.67 22933.33 133.33 11466.67 13.38 6133.33 358.46 11.35 \r\n	1966.67 \r\n\r\n	在这个例子中,swap device(/dev/sda1) 和 file system device(/dev/sda3)在互相作用于 I/O. 其中任一个 \r\n	会有很高写请求(w/s),也会有很高 wait time(await),或者较              的服务时间比率(svctm).这表明2 个分区之 \r\n	间互有联系,互有影响. \r\n\r\n7.4 结论  \r\n\r\n	I/O 性能监控包含了以下几点: \r\n\r\n	    1,当 CPU 有等待I/O 情况时,那说明磁盘处于超负荷状态. \r\n	    2,计算你的磁盘能够承受多大的 IOPS 数. \r\n	    3,确定你的应用是属于随机或者顺序读取磁盘. \r\n	    4,监控磁盘慢需要比较 wait time(await) 和 service time(svctm). \r\n	    5,监控 swap 和系统分区,要确保virtual memory 不是文件系统 I/O 的瓶颈. \r\n\r\n8.0 Network 监控介绍  \r\n\r\n	在所有的子系统监控中,网络是最困难的.这主要是由于网络概念很抽象.当监控系统上的网络性能,这有太 \r\n	多因素.这些因素包括了延迟,冲突,拥挤和数据包丢失. \r\n\r\n	这个章节讨论怎么样检查 Ethernet(网卡),IP,TCP 的性能. \r\n\r\n8.1 Ethernet Configuration Settings(网卡配置的设置) \r\n\r\n	除非很明确的指定,几乎所有的网卡都是自适应网络速度.当一个网络中有很多不同的网络设备时,会各自采 \r\n	用不同的速率和工作模式. \r\n\r\n	多数商业网络都运行在 100 或 1000BaseTX.使用 ethtool 可以确定这个系统是处于那种速率. \r\n\r\n	以下的例子中,是一个有 100BaseTX 网卡的系统,自动协商适应至10BaseTX 的情况. \r\n\r\n	# ethtool eth0 \r\n	Settings for eth0: \r\n	Supported ports: [ TP MII ] \r\n	Supported link modes: 10baseT/Half 10baseT/Full \r\n	100baseT/Half 100baseT/Full \r\n	Supports auto­negotiation: Yes \r\n	Advertised link modes: 10baseT/Half 10baseT/Full \r\n	100baseT/Half 100baseT/Full \r\n	Advertised auto­negotiation: Yes \r\n	Speed: 10Mb/s \r\n\r\n\r\n	Duplex: Half \r\n	Port: MII \r\n	PHYAD: 32 \r\n	Transceiver: internal \r\n	Auto­negotiation: on \r\n	Supports Wake­on: pumbg \r\n	Wake­on: d \r\n	Current message level: 0x00000007 (7) \r\n	Link detected: yes \r\n\r\n	以下示范例子中,如何强制网卡速率调整至100BaseTX: \r\n\r\n	# ethtool ­s eth0 speed 100 duplex full autoneg off \r\n\r\n	# ethtool eth0 \r\n	Settings for eth0: \r\n	Supported ports: [ TP MII ] \r\n	Supported link modes: 10baseT/Half 10baseT/Full \r\n	100baseT/Half 100baseT/Full \r\n	Supports auto­negotiation: Yes \r\n	Advertised link modes: 10baseT/Half 10baseT/Full \r\n	100baseT/Half 100baseT/Full \r\n	Advertised auto­negotiation: No \r\n	Speed: 100Mb/s \r\n	Duplex: Full \r\n	Port: MII \r\n	PHYAD: 32 \r\n	Transceiver: internal \r\n	Auto­negotiation: off \r\n	Supports Wake­on: pumbg \r\n	Wake­on: d \r\n	Current message level: 0x00000007 (7) \r\n	Link detected: yes \r\n\r\n8.2 Monitoring Network Throughput(网络吞吐量监控) \r\n\r\n	接口之间的同步并不意味着仅仅有带宽问题.重要的是,如何管理并优化,这 2 台主机之间的交换机,网线,或 \r\n	者路由器.测试网络吞吐量最好的方式就是,在这 2 个系统之间互相发送数据传输并统计下来,比如延迟和速 \r\n	度. \r\n\r\n8.2.0 使用 iptraf 查看本地吞吐量  \r\n\r\n	iptraf 工具(http://iptraf.seul.org),提供了每个网卡吞吐量的仪表盘. \r\n\r\n	#iptraf ­d eth0 \r\n\r\n	从输出中可看到,该系统发送传输率(Outgoing rates)为 61 mbps,这对于 100 mbps 网络来说,有点慢. \r\n\r\n\r\n8.2.1 使用 netperf 查看终端吞吐量  \r\n\r\n  \r\n\r\n	不同于 iptraf 被动的在本地监控流量,netperf 工具可以让管理员,执行更加可控的吞吐量监控.对于确定从 \r\n	客户端工作站到一个高负荷的服务器端(比如 file 或web server),它们之间有多少吞吐量是非常有帮助 \r\n	的.netperf 工具运行的是 client/server 模式. \r\n\r\n	完成一个基本可控吞吐量测试,首先 netperf server 必须运行在服务器端系统上: \r\n\r\n	server# netserver \r\n	Starting netserver at port 12865 \r\n	Starting netserver at hostname 0.0.0.0 port 12865 and family AF_UNSPEC \r\n\r\n	netperf 工具可能需要进行多重采样.多数基本测试就是一次标准的吞吐量测试.以下例子就是,一个 \r\n	LAN(局域网) 环境下,从 client 上执行一次30 秒的 TCP 吞吐量采样: \r\n\r\n	从输出可看出,该网络的吞吐量大致在 89 mbps 左右.server(192.168.1.215) 与client 在同一 LAN 中.这 \r\n	对于 100 mbps 网络来说,性能非常好. \r\n\r\n	client# netperf ­H 192.168.1.215 ­l 30 \r\n	TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to \r\n	192.168.1.230 (192.168.1.230) port 0 AF_INET \r\n	Recv Send Send \r\n	Socket Socket Message Elapsed \r\n	Size Size Size Time Throughput \r\n	bytes bytes bytes secs. 10^6bits/sec \r\n\r\n	87380 16384 16384 30.02 89.46 \r\n\r\n	从 LAN 切换到具备54G(Wireless­G 是未来 54Mbps 无线网联网标准)无线网络路由器中,并在 10 英尺 \r\n	范围内测试时.该吞吐量就急剧的下降.在最大就为 54 MBits 的可能下,笔记本电脑可实现总吞吐量就为 14 \r\n	MBits. \r\n\r\n	client# netperf ­H 192.168.1.215 ­l 30 \r\n	TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to \r\n	192.168.1.215 (192.168.1.215) port 0 AF_INET \r\n	Recv Send Send \r\n	Socket Socket Message Elapsed \r\n	Size Size Size Time Throughput \r\n	bytes bytes bytes secs. 10^6bits/sec \r\n\r\n	87380 16384 16384 30.10 14.09 \r\n\r\n	如果在 50 英尺范围内呢,则进一步会下降至5 MBits. \r\n\r\n	# netperf ­H 192.168.1.215 ­l 30 \r\n	TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to \r\n	192.168.1.215 (192.168.1.215) port 0 AF_INET \r\n\r\n\r\n	Recv Send Send \r\n	Socket Socket Message Elapsed \r\n	Size Size Size Time Throughput \r\n	bytes bytes bytes secs. 10^6bits/sec \r\n\r\n	87380 16384 16384 30.64 5.05 \r\n\r\n	如果从 LAN 切换到互联网上,则吞吐量跌至1 Mbits下了. \r\n\r\n	# netperf ­H litemail.org ­p 1500 ­l 30 \r\n	TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to \r\n	litemail.org (72.249.104.148) port 0 AF_INET \r\n	Recv Send Send \r\n	Socket Socket Message Elapsed \r\n	Size Size Size Time Throughput \r\n	bytes bytes bytes secs. 10^6bits/sec \r\n\r\n	87380 16384 16384 31.58 0.93 \r\n\r\n	最后是一个 VPN 连接环境,这是所有网络环境中最槽糕的吞吐量了. \r\n\r\n	# netperf ­H 10.0.1.129 ­l 30 \r\n	TCP STREAM TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to \r\n	10.0.1.129 (10.0.1.129) port 0 AF_INET \r\n	Recv Send Send \r\n	Socket Socket Message Elapsed \r\n	Size Size Size Time Throughput \r\n	bytes bytes bytes secs. 10^6bits/sec \r\n\r\n	87380 16384 16384 31.99 0.51 \r\n\r\n	另外,netperf 可以帮助测试每秒总计有多少的 TCP 请求和响应数.通过建立单一 TCP 连接并顺序地发送 \r\n	多个请求/响应(ack 包来回在 1个 byte 大小).有点类似于 RDBMS 程序在执行多个交易或者邮件服务器 \r\n	在同一个连接 道中发送邮件. \r\n\r\n	以下例子在 30 秒的持续时间内,模拟TCP 请求/响应: \r\n\r\n	client# netperf ­t TCP_RR ­H 192.168.1.230 ­l 30 \r\n	TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET \r\n	to 192.168.1.230 (192.168.1.230) port 0 AF_INET \r\n	Local /Remote \r\n	Socket Size Request Resp. Elapsed Trans. \r\n	Send Recv Size Size Time Rate \r\n	bytes Bytes bytes bytes secs. per sec \r\n\r\n	16384 87380 1 1 30.00 4453.80 \r\n	16384 87380 \r\n\r\n	在输出中看出,这个网络支持的处理速率为每秒4453 psh/ack(包大小为 1 byte).这其实是理想状态下,因为 \r\n\r\n\r\n	实际情况时,多数 requests(请求),特别是 responses(响应),都大于 1 byte. \r\n\r\n	现实情况下,netperf 一般 requests 默认使用 2K 大小,responses 默认使用 32K 大小: \r\n\r\n	client# netperf ­t TCP_RR ­H 192.168.1.230 ­l 30 ­­ ­r 2048,32768 \r\n	TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to \r\n	192.168.1.230 (192.168.1.230) port 0 AF_INET \r\n	Local /Remote \r\n	Socket Size Request Resp. Elapsed Trans. \r\n	Send Recv Size Size Time Rate \r\n	bytes Bytes bytes bytes secs. per sec \r\n\r\n	16384 87380 2048 32768 30.00 222.37 \r\n	16384 87380 \r\n\r\n	这个处理速率减少到了每秒222. \r\n\r\n8.2.2 使用 iperf 评估网络效率  \r\n\r\n	基于都是需要在 2 端检查连接情况下,iperf 和netperf 很相似.不同的是,iperf 更深入的通过 windows size \r\n	和QOS 设备来检查 TCP/UDP 的效率情况.这个工具,是给需要优化 TCP/IP stacks 以及测试这些 stacks \r\n	效率的管理员们量身定做的. \r\n\r\n	iperf 作为一个二进制程序,可运行在 server 或者client 任一模式下.默认使用 50001 端口. \r\n\r\n	首先启动server 端(192.168.1.215): \r\n\r\n	server# iperf ­s ­D \r\n	Running Iperf Server as a daemon \r\n	The Iperf daemon process ID : 3655 \r\n	­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n	Server listening on TCP port 5001 \r\n	TCP window size: 85.3 KByte (default) \r\n	­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n\r\n	在以下例子里,一个无线网络环境下,其中 client 端重复运行 iperf,用于测试网络的吞吐量情况.这个环境假 \r\n	定处于被充分利用状态,很多主机都在下载 ISO images 文件. \r\n\r\n	首先 client 端连接到 server 端(192.168.1.215),并在总计 60 秒时间内,每 5 秒进行一次带宽测试的采样. \r\n\r\n	client# iperf ­c 192.168.1.215 ­t 60 ­i 5 \r\n	­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n	Client connecting to 192.168.1.215, TCP port 5001 \r\n	TCP window size: 25.6 KByte (default) \r\n	­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n	[ 3] local 192.168.224.150 port 51978 connected with \r\n	192.168.1.215 port 5001 \r\n	[ ID] Interval Transfer Bandwidth \r\n\r\n\r\n	[ 3] 0.0­ 5.0 sec 6.22 MBytes 10.4 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 5.0­10.0 sec 6.05 MBytes 10.1 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 10.0­15.0 sec 5.55 MBytes 9.32 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 15.0­20.0 sec 5.19 MBytes 8.70 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 20.0­25.0 sec 4.95 MBytes 8.30 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 25.0­30.0 sec 5.21 MBytes 8.74 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 30.0­35.0 sec 2.55 MBytes 4.29 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 35.0­40.0 sec 5.87 MBytes 9.84 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 40.0­45.0 sec 5.69 MBytes 9.54 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 45.0­50.0 sec 5.64 MBytes 9.46 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 50.0­55.0 sec 4.55 MBytes 7.64 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 55.0­60.0 sec 4.47 MBytes 7.50 Mbits/sec \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 0.0­60.0 sec 61.9 MBytes 8.66 Mbits/sec \r\n\r\n	这台主机的其他网络传输,也会影响到这部分的带宽采样.所以可以看到总计 60 秒时间内,都在 4 ­ 10 \r\n	MBits 上下起伏. \r\n\r\n	除了 TCP 测试之外,iperf 的 UDP 测试主要是评估包丢失和抖动. \r\n\r\n	接下来的 iperf 测试,是在同样的 54Mbit G 标准无线网络中.在早期的示范例子中,目前的吞吐量只有 9 \r\n	Mbits. \r\n\r\n	# iperf ­c 192.168.1.215 ­b 10M \r\n	WARNING: option ­b implies udp testing \r\n	­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n	Client connecting to 192.168.1.215, UDP port 5001 \r\n	Sending 1470 byte datagrams \r\n	UDP buffer size: 107 KByte (default) \r\n	­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n	[ 3] local 192.168.224.150 port 33589 connected with 192.168.1.215 port 5001 \r\n	[ ID] Interval Transfer Bandwidth \r\n	[ 3] 0.0­10.0 sec 11.8 MBytes 9.90 Mbits/sec \r\n	[ 3] Sent 8420 datagrams \r\n	[ 3] Server Report: \r\n	[ ID] Interval Transfer Bandwidth Jitter Lost/Total Datagrams \r\n	[ 3] 0.0­10.0 sec 6.50 MBytes 5.45 Mbits/sec 0.480 ms 3784/ 8419 (45%) \r\n	[ 3] 0.0­10.0 sec 1 datagrams received out­of­order \r\n\r\n\r\n	从输出中可看出,在尝试传输10M 的数据时,实际上只产生了 5.45M.却有 45% 的包丢失. \r\n\r\n  \r\n8.3 Individual Connections with tcptrace \r\n\r\n	tcptrace 工具提供了对于某一具体连接里,详细的 TCP 相关信息.该工具使用 libcap 来分析某一具体TCP \r\n	sessions.该工具汇报的信息,有时很难在某一 TCP stream 被发现.这些信息  \r\n\r\n	包括了有: \r\n\r\n	    1,TCP Retransmissions(IP 转播) ­ 所有数据大小被发送所需的包总额  \r\n	    2,TCP Windows Sizes ­ 连接速度慢与小的 windows sizes 有关  \r\n	    3,Total throughput of the connection ­ 连接的吞吐量  \r\n	    4,Connection duration ­ 连接的持续时间  \r\n\r\n8.3.1 案例学习 ­ 使用 tcptrace \r\n\r\n	tcptrace 工具可能已经在部分 Linux 发布版中有安装包了,该文作者通过网站,下载的是源码安装包:http:// \r\n	dag.wieers.com/rpm/packages /tcptrace.tcptrace 需要 libcap 基于文件输入方式使用.在 tcptrace 没有选 \r\n	项的情况下,默认每个唯一的连接过程都将被捕获. \r\n\r\n	以下例子是,使用 libcap 基于输入文件为 bigstuff: \r\n\r\n	# tcptrace bigstuff \r\n	1 arg remaining, starting with ''bigstuff'' \r\n	Ostermann''s tcptrace ­­ version 6.6.7 ­­ Thu Nov 4, 2004 \r\n\r\n	146108 packets seen, 145992 TCP packets traced \r\n	elapsed wallclock time: 0:00:01.634065, 89413 pkts/sec analyzed \r\n	trace file elapsed time: 0:09:20.358860 \r\n	TCP connection info: \r\n	1: 192.168.1.60:pcanywherestat ­ 192.168.1.102:2571 (a2b) 404> 450< \r\n	2: 192.168.1.60:3356 ­ ftp.strongmail.net:21 (c2d) 35> 21< \r\n	3: 192.168.1.60:3825 ­ ftp.strongmail.net:65023 (e2f) 5> 4< \r\n	(complete) \r\n	4: 192.168.1.102:1339 ­ 205.188.8.194:5190 (g2h) 6> 6< \r\n	5: 192.168.1.102:1490 ­ cs127.msg.mud.yahoo.com:5050 (i2j) 5> 5< \r\n	6: py­in­f111.google.com:993 ­ 192.168.1.102:3785 (k2l) 13> 14< \r\n\r\n	上面的输出中,每个连接都有对应的源主机和目的主机.tcptrace 使用­l 和­o 选项可查看某一连接更详细的 \r\n	数据. \r\n\r\n	以下的结果,就是在 bigstuff 文件中,#16 连接的相关统计数据: \r\n\r\n	# tcptrace ­l ­o1 bigstuff \r\n	1 arg remaining, starting with ''bigstuff'' \r\n	Ostermann''s tcptrace ­­ version 6.6.7 ­­ Thu Nov 4, 2004 \r\n\r\n\r\n	146108 packets seen, 145992 TCP packets traced \r\n	elapsed wallclock time: 0:00:00.529361, 276008 pkts/sec analyzed \r\n	trace file elapsed time: 0:09:20.358860 \r\n	TCP connection info: \r\n	32 TCP connections traced: \r\n	TCP connection 1: \r\n	host a: 192.168.1.60:pcanywherestat \r\n	host b: 192.168.1.102:2571 \r\n	complete conn: no (SYNs: 0) (FINs: 0) \r\n	first packet: Sun Jul 20 15:58:05.472983 2008 \r\n	last packet: Sun Jul 20 16:00:04.564716 2008 \r\n	elapsed time: 0:01:59.091733 \r\n	total packets: 854 \r\n	filename: bigstuff \r\n	a­>b: b­>a: \r\n	total packets: 404 total packets: 450 \r\n	ack pkts sent: 404 ack pkts sent: 450 \r\n	pure acks sent: 13 pure acks sent: 320 \r\n	sack pkts sent: 0 sack pkts sent: 0 \r\n	dsack pkts sent: 0 dsack pkts sent: 0 \r\n	max sack blks/ack: 0 max sack blks/ack: 0 \r\n	unique bytes sent: 52608 unique bytes sent: 10624 \r\n	actual data pkts: 391 actual data pkts: 130 \r\n	actual data bytes: 52608 actual data bytes: 10624 \r\n	rexmt data pkts: 0 rexmt data pkts: 0 \r\n	rexmt data bytes: 0 rexmt data bytes: 0 \r\n	zwnd probe pkts: 0 zwnd probe pkts: 0 \r\n	zwnd probe bytes: 0 zwnd probe bytes: 0 \r\n	outoforder pkts: 0 outoforder pkts: 0 \r\n	pushed data pkts: 391 pushed data pkts: 130 \r\n	SYN/FIN pkts sent: 0/0 SYN/FIN pkts sent: 0/0 \r\n	urgent data pkts: 0 pkts urgent data pkts: 0 pkts \r\n	urgent data bytes: 0 bytes urgent data bytes: 0 bytes \r\n	mss requested: 0 bytes mss requested: 0 bytes \r\n	max segm size: 560 bytes max segm size: 176 bytes \r\n	min segm size: 48 bytes min segm size: 80 bytes \r\n	avg segm size: 134 bytes avg segm size: 81 bytes \r\n	max win adv: 19584 bytes max win adv: 65535 bytes \r\n	min win adv: 19584 bytes min win adv: 64287 bytes \r\n	zero win adv: 0 times zero win adv: 0 times \r\n	avg win adv: 19584 bytes avg win adv: 64949 bytes \r\n	initial window: 160 bytes initial window: 0 bytes \r\n	initial window: 2 pkts initial window: 0 pkts \r\n	ttl stream length: NA ttl stream length: NA \r\n	missed data: NA missed data: NA \r\n	truncated data: 36186 bytes truncated data: 5164 bytes \r\n	truncated packets: 391 pkts truncated packets: 130 pkts \r\n	data xmit time: 119.092 secs data xmit time: 116.954 secs \r\n	idletime max: 441267.1 ms idletime max: 441506.3 ms \r\n\r\n\r\n	throughput: 442 Bps throughput: 89 Bps \r\n\r\n8.3.2 案例学习 ­ 计算转播率  \r\n\r\n	几乎不可能确定说哪个连接会有严重不足的转播问题,只是需要分析,使用 tcptrace 工具可以通过过滤机制 \r\n	和布尔表达式来找出出问题的连接.一个很繁忙的网络中,会有很多的连接,几乎所有的连接都会有转播.找 \r\n	出其中最多的一个,这就是问题的关键. \r\n\r\n	下面的例子里,tcptrace 将找出那些转播大于 100 segments(分段数)的连接: \r\n\r\n	# tcptrace ­f''rexmit_segs>100'' bigstuff \r\n	Output filter: ((c_rexmit_segs>100)OR(s_rexmit_segs>100)) \r\n	1 arg remaining, starting with ''bigstuff'' \r\n	Ostermann''s tcptrace ­­ version 6.6.7 ­­ Thu Nov 4, 2004 \r\n\r\n	146108 packets seen, 145992 TCP packets traced \r\n	elapsed wallclock time: 0:00:00.687788, 212431 pkts/sec analyzed \r\n	trace file elapsed time: 0:09:20.358860 \r\n	TCP connection info: \r\n	16: ftp.strongmail.net:65014 ­ 192.168.1.60:2158 (ae2af) 18695> 9817< \r\n\r\n	在这个输出中,是#16 这个连接里,超过了 100 转播.现在,使用以下命令查看关于这个连接的其他信息: \r\n\r\n	# tcptrace ­l ­o16 bigstuff \r\n	arg remaining, starting with ''bigstuff'' \r\n	Ostermann''s tcptrace ­­ version 6.6.7 ­­ Thu Nov 4, 2004 \r\n\r\n	146108 packets seen, 145992 TCP packets traced \r\n	elapsed wallclock time: 0:00:01.355964, 107752 pkts/sec analyzed \r\n	trace file elapsed time: 0:09:20.358860 \r\n	TCP connection info: \r\n	32 TCP connections traced: \r\n	================================ \r\n	TCP connection 16: \r\n	host ae: ftp.strongmail.net:65014 \r\n	host af: 192.168.1.60:2158 \r\n	complete conn: no (SYNs: 0) (FINs: 1) \r\n	first packet: Sun Jul 20 16:04:33.257606 2008 \r\n	last packet: Sun Jul 20 16:07:22.317987 2008 \r\n	elapsed time: 0:02:49.060381 \r\n	total packets: 28512 \r\n	filename: bigstuff \r\n	ae­>af: af­>ae: \r\n\r\n	unique bytes sent: 25534744 unique bytes sent: 0 \r\n	actual data pkts: 18695 actual data pkts: 0 \r\n	actual data bytes: 25556632 actual data bytes: 0 \r\n	rexmt data pkts: 1605 rexmt data pkts: 0 \r\n	rexmt data bytes: 2188780 rexmt data bytes: 0 \r\n\r\n\r\n	计算转播率: \r\n	rexmt/actual * 100 = Retransmission rate \r\n\r\n	1605/18695* 100 = 8.5% \r\n\r\n	这个慢连接的原因,就是因为它有 8.5% 的转播率. \r\n\r\n8.3.3 案例学习 ­ 计算转播时间  \r\n\r\n	tcptrace 工具有一系列的模块展示不同的数据,按照属性,其中就有 protocol(协议),port(端口),time 等 \r\n	等.Slice module使得你可观察在一段时间内的 TCP 性能.你可以在一系列的转发过程中,查看其他性能数 \r\n	据,以确定找出瓶颈. \r\n\r\n	以下例子示范了,tcptrace 是怎样使用 slice 模式的: \r\n\r\n	# tcptrace –xslice bigfile \r\n\r\n	以上命令会创建一个 slice.dat 文件在现在的工作目录中.这个文件内容,包含是每 15秒间隔内转播的相关 \r\n	信息: \r\n\r\n	# ls ­l slice.dat \r\n	­rw­r­­r­­ 1 root root 3430 Jul 10 22:50 slice.dat \r\n	# more slice.dat \r\n	date segs bytes rexsegs rexbytes new active \r\n	­­­­­­­­­­­­­­­ ­­­­­­­­ ­­­­­­­­ ­­­­­­­­ ­­­­­­­­ ­­­­­­­­ ­­­­­­­­ \r\n	22:19:41.913288 46 5672 0 0 1 1 \r\n	22:19:56.913288 131 25688 0 0 0 1 \r\n	22:20:11.913288 0 0 0 0 0 0 \r\n	22:20:26.913288 5975 4871128 0 0 0 1 \r\n	22:20:41.913288 31049 25307256 0 0 0 1 \r\n	22:20:56.913288 23077 19123956 40 59452 0 1 \r\n	22:21:11.913288 26357 21624373 5 7500 0 1 \r\n	22:21:26.913288 20975 17248491 3 4500 12 13 \r\n	22:21:41.913288 24234 19849503 10 15000 3 5 \r\n	22:21:56.913288 27090 22269230 36 53999 0 2 \r\n	22:22:11.913288 22295 18315923 9 12856 0 2 \r\n	22:22:26.913288 8858 7304603 3 4500 0 1 \r\n\r\n8.4 结论  \r\n\r\n	监控网络性能由以下几个部分组成: \r\n\r\n	    1,检查并确定所有网卡都工作在正确的速率. \r\n	    2,检查每块网卡的吞吐量,并确认其处于服务时的网络速度. \r\n	    3,监控网络流量的类型,并确定适当的流量优先级策略. \r\n	结束语: 这是该译文的最后一篇,在这篇中,作者提供了一个案例环境,用之前几篇所阐述的理论以及涉及到 \r\n\r\n\r\n	的工具,对其进行一个整体的系统性能检查.对大家更好理解系统性能监控,进行一次实战演习. \r\n	BTW:在中文技术网站上,类似内容的文章,大体是来自该作者06­07 年所著论文,此译文是建立在作者为 \r\n	OSCON 2009 重写基础上的.所以部分内容可能会存在重复雷同,特此说明下. \r\n\r\n	附录 A: 案例学习 ­ 性能监控之循序渐进  \r\n\r\n	某一天,一个客户打电话来需要技术帮助,并抱怨平常 15秒就可以打开的网页现在需要 20 分钟才可以打开. \r\n\r\n	具体系统配置如下: \r\n\r\n	RedHat Enterprise Linux 3 update 7 \r\n	Dell 1850 Dual Core Xenon Processors, 2 GB RAM, 75GB 15K Drives \r\n	Custom LAMP software stack(Llinux+apache+mysql+php 环境) \r\n\r\n	性能分析之步骤  \r\n\r\n	1. 首先使用 vmstat 查看大致的系统性能情况: \r\n\r\n	# vmstat 1 10 \r\n	procs memory swap io system cpu \r\n	r b swpd free buff cache si so bi bo in cs us sy id wa \r\n	1 0 249844 19144 18532 1221212 0 0 7 3 22 17 25 8 17 18 \r\n	0 1 249844 17828 18528 1222696 0 0 40448 8 1384 1138 13 7 65 14 \r\n	0 1 249844 18004 18528 1222756 0 0 13568 4 623 534 3 4 56 37 \r\n	2 0 249844 17840 18528 1223200 0 0 35200 0 1285 1017 17 7 56 20 \r\n	1 0 249844 22488 18528 1218608 0 0 38656 0 1294 1034 17 7 58 18 \r\n	0 1 249844 21228 18544 1219908 0 0 13696 484 609 559 5 3 54 38 \r\n	0 1 249844 17752 18544 1223376 0 0 36224 4 1469 1035 10 6 67 17 \r\n	1 1 249844 17856 18544 1208520 0 0 28724 0 950 941 33 12 49 7 \r\n	1 0 249844 17748 18544 1222468 0 0 40968 8 1266 1164 17 9 59 16 \r\n	1 0 249844 17912 18544 1222572 0 0 41344 12 1237 1080 13 8 65 13 \r\n\r\n	分析: \r\n	1,不会是内存不足导致,因为 swapping 始终没变化(si 和 so).尽管空闲内存不多(free),但 swpd 也没有变 \r\n	化. \r\n	2,CPU 方面也没有太大问题,尽管有一些运行队列(procs r),但处理器还始终有 50% 多的 idle(CPU id). \r\n	3,有太多的上下文切换(cs)以及 disk block 从 RAM 中被读入(bo). \r\n	4,CPU 还有平均20% 的 I/O 等待情况. \r\n\r\n	结论: \r\n	从以上总结出,这是一个 I/O 瓶颈. \r\n\r\n	2. 然后使用 iostat 检查是谁在发出 IO 请求: \r\n\r\n	# iostat ­x 1 \r\n	Linux 2.4.21­40.ELsmp (mail.example.com) 03/26/2007 \r\n\r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	30.00 0.00 9.33 60.67 \r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 7929.01 30.34 1180.91 14.23 7929.01 357.84 3964.50 178.92 6.93 0.39 0.03 0.06 6.69 \r\n	/dev/sda1 2.67 5.46 0.40 1.76 24.62 57.77 12.31 28.88 38.11 0.06 2.78 1.77 0.38 \r\n	/dev/sda2 0.00 0.30 0.07 0.02 0.57 2.57 0.29 1.28 32.86 0.00 3.81 2.64 0.03 \r\n	/dev/sda3 7929.01 24.58 1180.44 12.45 7929.01 297.50 3964.50 148.75 6.90 0.32 0.03 0.06 6.68 \r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	9.50 0.00 10.68 79.82 \r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 0.00 0.00 1195.24 0.00 0.00 0.00 0.00 0.00 0.00 43.69 3.60 0.99 117.86 \r\n	/dev/sda1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n	/dev/sda2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n	/dev/sda3 0.00 0.00 1195.24 0.00 0.00 0.00 0.00 0.00 0.00 43.69 3.60 0.99 117.86 \r\n\r\n	avg­cpu: %user %nice %sys %idle \r\n	9.23 0.00 10.55 79.22 \r\n\r\n	Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq­sz avgqu­sz await svctm %util \r\n	/dev/sda 0.00 0.00 1200.37 0.00 0.00 0.00 0.00 0.00 0.00 41.65 2.12 0.99 112.51 \r\n	/dev/sda1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n	/dev/sda2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \r\n	/dev/sda3 0.00 0.00 1200.37 0.00 0.00 0.00 0.00 0.00 0.00 41.65 2.12 0.99 112.51 \r\n\r\n	分析: \r\n	1,看上去只有/dev/sda3 分区很活跃,其他分区都很空闲. \r\n	2,差不多有 1200 读IOPS,磁盘本身是支持200 IOPS 左右(参考之前的 IOPS 计算公式). \r\n	3,有超过 2 秒,实际上没有一个读磁盘(rkb/s).这和在 vmstat 看到有大量 I/O wait 是有关系的. \r\n	4,大量的 read IOPS(r/s)和在 vmstat 中大量的上下文是匹配的.这说明很多读操作都是失败的. \r\n\r\n	结论: \r\n	从以上总结出,部分应用程序带来的读请求,已经超出了 I/O 子系统可处理的范围. \r\n\r\n	3. 使用 top 来查找系统最活跃的应用程序  \r\n\r\n	# top ­d 1 \r\n	11:46:11 up 3 days, 19:13, 1 user, load average: 1.72, 1.87, 1.80 \r\n	176 processes: 174 sleeping, 2 running, 0 zombie, 0 stopped \r\n	CPU states: cpu user nice system irq softirq iowait idle \r\n	total 12.8% 0.0% 4.6% 0.2% 0.2% 18.7% 63.2% \r\n	cpu00 23.3% 0.0% 7.7% 0.0% 0.0% 36.8% 32.0% \r\n	cpu01 28.4% 0.0% 10.7% 0.0% 0.0% 38.2% 22.5% \r\n	cpu02 0.0% 0.0% 0.0% 0.9% 0.9% 0.0% 98.0% \r\n	cpu03 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% \r\n	Mem: 2055244k av, 2032692k used, 22552k free, 0k shrd, 18256k buff \r\n\r\n\r\n	1216212k actv, 513216k in_d, 25520k in_c \r\n	Swap: 4192956k av, 249844k used, 3943112k free 1218304k cached \r\n\r\n	  \r\n	PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND \r\n	14939 mysql 25 0 379M 224M 1117 R 38.2 25.7% 15:17.78 mysqld \r\n	4023 root 15 0 2120 972 784 R 2.0 0.3 0:00.06 top \r\n	1 root 15 0 2008 688 592 S 0.0 0.2 0:01.30 init \r\n	2 root 34 19 0 0 0 S 0.0 0.0 0:22.59 ksoftirqd/0 \r\n	3 root RT 0 0 0 0 S 0.0 0.0 0:00.00 watchdog/0 \r\n	4 root 10 ­5 0 0 0 S 0.0 0.0 0:00.05 events/0 \r\n\r\n	分析: \r\n	1,占用资源最多的好像就是 mysql 进程,其他都处于完全idle 状态. \r\n	2,在 top(wa) 看到的数值,和在 vmstat 看到的 wio 数值是有关联的. \r\n\r\n	结论: \r\n	从以上总结出,似乎就只有 mysql 进程在请求资源,因此可以推论它就是导致问题的关键. \r\n\r\n	4. 现在已经确定是 mysql 在发出读请求,使用 strace 来检查它在读请求什么. \r\n\r\n	# strace ­p 14939 \r\n\r\n	Process 14939 attached ­ interrupt to quit \r\n	read(29, "\\3\\1\\237\\1\\366\\337\\1\\222%\\4\\2\\0\\0\\0\\0\\0012P/d", 20) = 20 \r\n	read(29, "ata1/strongmail/log/strongmail­d"..., 399) = 399 \r\n	_llseek(29, 2877621036, [2877621036], SEEK_SET) = 0 \r\n	read(29, "\\1\\1\\241\\366\\337\\1\\223%\\4\\2\\0\\0\\0\\0\\0012P/da", 20) = 20 \r\n	read(29, "ta1/strongmail/log/strongmail­de"..., 400) = 400 \r\n	_llseek(29, 2877621456, [2877621456], SEEK_SET) = 0 \r\n	read(29, "\\1\\1\\235\\366\\337\\1\\224%\\4\\2\\0\\0\\0\\0\\0012P/da", 20) = 20 \r\n	read(29, "ta1/strongmail/log/strongmail­de"..., 396) = 396 \r\n	_llseek(29, 2877621872, [2877621872], SEEK_SET) = 0 \r\n	read(29, "\\1\\1\\245\\366\\337\\1\\225%\\4\\2\\0\\0\\0\\0\\0012P/da", 20) = 20 \r\n	read(29, "ta1/strongmail/log/strongmail­de"..., 404) = 404 \r\n	_llseek(29, 2877622296, [2877622296], SEEK_SET) = 0 \r\n	read(29, "\\3\\1\\236\\2\\366\\337\\1\\226%\\4\\2\\0\\0\\0\\0\\0012P/d", 20) = 20 \r\n\r\n	分析: \r\n	1,大量的读操作都在不断寻道中,说明mysql 进程产生的是随机IO. \r\n	2,看上去似乎是,某一 sql 查询导致读操作. \r\n\r\n	结论: \r\n	从以上总结出,所有的读IOPS 都是 mysql 进程在执行某些读查询时产生的. \r\n\r\n	5. 使用 mysqladmin 命令,来查找是哪个慢查询导致的. \r\n\r\n	# ./mysqladmin ­pstrongmail processlist \r\n\r\n\r\n	+­­­­+­­­­­­+­­­­­­­­­­­+­­­­­­­­­­­­+­­­­­­­­­+­­­­­­+­­­­­­­­­­+­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n	| Id | User | Host | db | Command | Time | State | Info \r\n	+­­­­+­­­­­­+­­­­­­­­­­­+­­­­­­­­­­­­+­­­­­­­­­+­­­­­­+­­­­­­­­­­+­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­ \r\n	| 1 | root | localhost | strongmail | Sleep | 10 | | \r\n	| 2 | root | localhost | strongmail | Sleep | 8 | | \r\n	| 3 | root | localhost | root | Query | 94 | Updating | update `failures` set \r\n	`update_datasource`=''Y'' where database_id=''32'' and update_datasource=''N'' and | \r\n	| 14 | root | localhost | | Query | 0 | | show processlist \r\n\r\n	分析: \r\n	1,MySQL 数据库里,似乎在不断的运行 table update 查询. \r\n	2,基于这个 update 查询,数据库是对所有的 table 进行索引. \r\n\r\n	结论: \r\n	从以上总结出,MySQL 里这些 update 查询问题,都是在尝试对所有 table 进行索引.这些产生的读请求正 \r\n	是导致系统性能下降的原因. \r\n\r\n	后续  \r\n\r\n	把以上这些性能信息移交给了相关开发人员,用于分析他们的 PHP 代码.一个开发人员对代码进行了临时 \r\n	性优化.某个查询如果出错了,也最多到 100K记录.数据库本身考虑最多存在 4 百万记录.最后,这个查询不 \r\n	会再给数据库带来负担了. \r\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(135, 'python_man', '    python实例手册\n\n#encoding:utf8\n# 设定编码-支持中文\n\n0 说明\n\n    手册制作: 雪松 littlepy www.51reboot.com\n    更新日期: 2015-06-07\n\n    欢迎系统运维加入Q群: 198173206  # 加群请回答问题\n    欢迎运维开发加入Q群: 365534424  # 不定期技术分享\n\n    请使用"notepad++"或其它编辑器打开此文档, "alt+0"将函数折叠后方便查阅    \n    请勿删除信息, 转载请说明出处, 抵制不道德行为    \n    错误在所难免, 还望指正！    \n        \n    [python实例手册] [shell实例手册] [LazyManage运维批量管理(shell/python两个版本)]\n    网盘更新下载地址:    http://pan.baidu.com/s/1sjsFrmX\n    github更新下载地址:  https://github.com/liquanzhou/ops_doc\n\n1 基础\n\n    安装python2.7\n\n        wget https://www.python.org/ftp/python/2.7.8/Python-2.7.8.tgz\n\n        tar xvf Python-2.7.8.tgz\n        cd Python-2.7.8\n        ./configure --prefix=/usr/local/python27\n        make\n        make install\n        mv /usr/bin/python /usr/bin/python_old\n        ln -s /usr/local/python27/bin/python /usr/bin/python\n        python          # 查看版本\n\n        解决YUM无法使用的问题\n\n           vim /usr/bin/yum \n           首行#!/usr/bin/python 替换为老版本python  #!/usr/bin/python2.4  注意可能为2.6\n\n    pip模块安装\n\n        yum install python-pip            # centos安装pip\n        sudo apt-get install python-pip   # ubuntu安装pip\n        pip官方安装脚本\n            wget https://raw.github.com/pypa/pip/master/contrib/get-pip.py\n            python get-pip.py\n        pip编译安装\n            wget http://pypi.python.org/packages/source/s/setuptools/setuptools-0.6c11.tar.gz\n            tar zxvf setuptools-0.6c11.tar.gz\n            cd setuptools-0.6c11\n            python setup.py build\n            python setup.py install\n            wget https://pypi.python.org/packages/source/p/pip/pip-1.5.6.tar.gz#md5=01026f87978932060cc86c1dc527903e\n            tar zxvf pip-1.5.6.tar.gz\n            cd pip-1.5.6\n            python setup.py build\n            python setup.py install\n        加载环境变量\n            vim /etc/profile\n            export PATH=/usr/local/python27/bin:$PATH\n            . /etc/profile\n\n        pip install Package             # 安装包 pip install requests\n        pip show --files Package        # 查看安装包时安装了哪些文件\n        pip show --files Package        # 查看哪些包有更新\n        pip install --upgrade Package   # 更新一个软件包\n        pip uninstall Package           # 卸载软件包\n\n    查看帮助\n\n        python -c "help(''modules'')"     # 查看python所有模块\n        import os\n        for i in dir(os):\n            print i         # 模块的方法\n        help(os.path)       # 方法的帮助\n\n    python中关键字\n\n        import keyword\n        keyword.iskeyword(str)       # 字符串是否为python关键字\n        keyword.kwlist               # 返回pytho所有关键字\n        [''and'', ''as'', ''assert'', ''break'', ''class'', ''continue'', ''def'', ''del'', ''elif'', ''else'', ''except'', ''exec'', ''finally'', ''for'', ''from'', ''global'', ''if'', ''import'', ''in'', ''is'', ''lambda'', ''not'', ''or'', ''pass'', ''print'', ''raise'', ''return'', ''try'', ''while'', ''with'', ''yield'']\n\n    调试\n\n        python -m trace -t aaaaaa.py\n\n    变量\n\n        r=r''\\n''          # 输出时原型打印\n        u=u''中文''        # 定义为unicode编码\n        global x         # 全局变量\n        a = 0 or 2 or 1  # 布尔运算赋值,a值为True既不处理后面,a值为2.  None、字符串''''、空元组()、空列表[],空字典{}、0、空字符串都是false\n        name = raw_input("input:").strip()        # 输入字符串变量\n        num = int(raw_input("input:").strip())    # 输入字符串str转为int型\n        locals()                                  # 所有局部变量组成的字典\n        locals().values()                         # 所有局部变量值的列表\n        os.popen("date -d @{0} +''%Y-%m-%d %H:%M:%S''".format(12)).read()    # 特殊情况引用变量 {0} 代表第一个参数\n\n        基于字典的字符串格式化\n            params = {"server":"mpilgrim", "database":"master", "uid":"sa", "pwd":"secret"}\n            "%(pwd)s" % params                                         # ''secret''\n            "%(pwd)s is not a good password for %(uid)s" % params      # ''secret is not a good password for sa''\n            "%(database)s of mind, %(database)s of body" % params      # ''master of mind, master of body''\n\n    打印\n\n        # 字符串 %s  整数 %d  浮点 %f  原样打印 %r\n        print ''字符串: %s 整数: %d 浮点: %f 原样打印: %r'' % (''aa'',2,1.0,''r'')\n        print ''abc'',      # 有逗号,代表不换行打印,在次打印会接着本行打印\n		print ''%-10s %s'' % (''aaa'',''bbb'')    # 左对齐 占10个字符\n		print ''%10s %s'' % (''aaa'',''bbb'')     # 右对齐 占10个字符\n\n    列表\n\n        # 列表元素的个数最多 536870912\n        shoplist = [''apple'', ''mango'', ''carrot'', ''banana'']\n        shoplist[2] = ''aa''\n        del shoplist[0]\n        shoplist.insert(4,''www'')\n        shoplist.append(''aaa'')\n        shoplist[::-1]    # 倒着打印 对字符翻转串有效\n        shoplist[2::3]    # 从第二个开始每隔三个打印\n        shoplist[:-1]     # 排除最后一个\n        ''\\t''.join(li)     # 将列表转换成字符串 用字表符分割\n        sys.path[1:1]=[5] # 在位置1前面插入列表中一个值\n        list(set([''qwe'', ''as'', ''123'', ''123'']))   # 将列表通过集合去重复\n        eval("[''1'',''a'']")                        # 将字符串当表达式求值,得到列表\n\n    元组\n\n        # 不可变\n        zoo = (''wolf'', ''elephant'', ''penguin'')\n\n    字典\n\n        ab = {       ''Swaroop''   : ''swaroopch@byteofpython.info'',\n                     ''Larry''     : ''larry@wall.org'',\n             }\n        ab[''c''] = 80      # 添加字典元素\n        del ab[''Larry'']   # 删除字典元素\n        ab.keys()         # 查看所有键值\n        ab.values()       # 打印所有值\n        ab.has_key(''a'')   # 查看键值是否存在\n        ab.items()        # 返回整个字典列表\n        \n        复制字典\n            a = {1: {1: 2, 3: 4}}\n            b = a             \n            b[1][1] = 8888                # a和b都为 {1: {1: 8888, 3: 4}}\n            import copy\n            c = copy.deepcopy(a)          # 再次赋值 b[1][1] = 9999 拷贝字典为新的字典,互不干扰\n\n            a[2] = copy.deepcopy(a[1])    # 复制出第二个key，互不影响  {1: {1: 2, 3: 4},2: {1: 2, 3: 4}}\n\n    流程结构\n\n        if判断\n\n            # 布尔值操作符 and or not 实现多重判断\n            if a == b:\n                print ''==''\n            elif a < b:\n                print b\n            else:\n                print a\n\n        while循环\n\n            while True:\n                if a == b:\n                    print "=="\n                    break\n                print "!="\n            else:\n                print ''over''\n            \n            count=0\n            while(count<9):\n                print count\n                count += 1\n\n        for循环\n\n            sorted()           # 返回一个序列(列表)\n            zip()              # 返回一个序列(列表)\n            enumerate()        # 返回循环列表序列 for i,v in enumerate([''a'',''b'']):\n            reversed()         # 反序迭代器对象\n            dict.iterkeys()    # 通过键迭代\n            dict.itervalues()  # 通过值迭代\n            dict.iteritems()   # 通过键-值对迭代\n            readline()         # 文件迭代\n            iter(obj)          # 得到obj迭代器 检查obj是不是一个序列\n            iter(a,b)          # 重复调用a,直到迭代器的下一个值等于b\n            for i in range(1, 5):\n                print i\n            else:\n                print ''over''\n\n            list = [''a'',''b'',''c'',''b'']\n            for i in range(len(list)):\n                print list[i]\n            for x, Lee in enumerate(list):\n                print "%d %s Lee" % (x+1,Lee)\n            \n            # enumerate 使用函数得到索引值和对应值\n            for i, v in enumerate([''tic'', ''tac'', ''toe'']):\n                print(i, v)\n\n        流程结构简写\n\n            [ i * 2 for i in [8,-2,5]]\n            [16,-4,10]\n            [ i for i in range(8) if i %2 == 0 ]\n            [0,2,4,6]\n\n    tab补全\n\n        # vim /usr/lib/python2.7/dist-packages/tab.py\n        # python startup file\n        import sys\n        import readline\n        import rlcompleter\n        import atexit\n        import os\n        # tab completion\n        readline.parse_and_bind(''tab: complete'')\n        # history file\n        histfile = os.path.join(os.environ[''HOME''], ''.pythonhistory'')\n\n    函数\n\n        def printMax(a, b = 1):\n            if a > b:\n                print a\n                return a\n            else:\n                print b\n                return b\n        x = 5\n        y = 7\n        printMax(x, y)\n\n        def update(*args,**kwargs):\n            p=''''\n            for i,t in kwargs.items():\n                    p = p+ ''%s=%s,'' %(i,str(t))\n            sql = "update  ''user'' set (%s) where (%s)" %(args[0],p)\n            print sql\n\n        update(''aaa'',uu=''uu'',id=3)\n\n    模块\n\n        # Filename: mymodule.py\n        def sayhi():\n            print ''mymodule''\n        version = ''0.1''\n        \n        # 使用模块中方法\n        import mymodule\n        from mymodule import sayhi, version\n        mymodule.sayhi()   # 使用模块中函数方法\n\n    装饰器\n\n        # 为已存在的功能添加额外的功能,只在初始化脚本的时候执行一次\n        \n        #!/usr/bin/env python\n\n        def deco(func):\n            def wrapper(*args, **kwargs):\n                print "Wrap start"\n                func(*args, **kwargs)\n                func(*args, **kwargs)\n                print "Wrap end\\n"\n            return wrapper\n\n        @deco\n        def foo(x):\n            print "In foo():"\n            print "I have a para: %s" % x\n        @deco\n        def foo_dict(x,z=''dict_para''):\n            print "In foo_dict:"\n            print "I have two para, %s and %s" % (x, z)\n\n        if __name__ == "__main__":\n            # 装饰器 @deco  等价于 foo = deco(foo)  \n            foo(''x'')\n            foo_dict(''x'', z=''dict_para'')\n            \n        结果\n\n            Wrap start\n            In foo():\n            I have a para: x\n            In foo():\n            I have a para: x\n            Wrap end\n\n            Wrap start\n            In foo_dict:\n            I have two para, x and dict_para\n            In foo_dict:\n            I have two para, x and dict_para\n            Wrap end\n\n    类对象的方法\n\n        __xxx__               # 系统定义名字\n        __init__              # 实例化初始化类的方法\n        __all__ = [''xs'']      # __all__ 用于模块import导入时限制,定义了只有all内指定的属性、方法、类可被导入,没定义则模块内的所有将被导入\n        _xxx                  # _开头的为私有类,只有类对象和子类对象自己能访问到这些变量  不能用 from module import * 导入  class _status:\n        __xxx                 # __开头的为类中的私有变量名,只有类对象自己能访问,连子类对象也不能访问到这个数据\n\n        class Person:\n            # 实例化初始化的方法\n            def __init__(self, name ,age):\n                self.name = name\n                self.age = age\n                print self.name\n            # 有self此函数为方法\n            def sayHi(self):\n                print ''Hello, my name is'', self.name\n            # 对象消逝的时候被调用\n            def __del__(self):\n                print ''over''\n        # 实例化对象\n        p = Person(''Swaroop'',23)\n        # 使用对象方法\n        p.sayHi()\n        # 继承\n        class Teacher(Person):\n            def __init__(self, name, age, salary):\n                Person.__init__(self, name, age)\n                self.salary = salary\n                print ''(Initialized Teacher: %s)'' % self.name\n            def tell(self):\n                Person.tell(self)\n                print ''Salary: "%d"'' % self.salary\n        t = Teacher(''Mrs. Shrividya'', 40, 30000)\n\n        getattr(object,name,default)\n\n            # 返回object的名称为name的属性的属性值,如果属性name存在,则直接返回其属性值.如果属性name不存在,则触发AttribetError异常或当可选参数default定义时返回default值\n            \n            class A:   \n                def __init__(self):   \n                    self.name = ''zhangjing''  \n                def method(self):   \n                    print"method print"  \n              \n            Instance = A()   \n            print getattr(Instance , ''name'', ''not find'')           # 如果Instance 对象中有属性name则打印self.name的值，否则打印''not find''\n            print getattr(Instance , ''age'', ''not find'')            # 如果Instance 对象中有属性age则打印self.age的值，否则打印''not find''\n            print getattr(Instance, ''method'', ''default'')           # 如果有方法method，否则打印其地址，否则打印default   \n            print getattr(Instance, ''method'', ''default'')()         # 如果有方法method，运行函数并打印None否则打印default  \n\n        setattr(object,name,value)      \n\n            # 设置object的名称为name(type：string)的属性的属性值为value，属性name可以是已存在属性也可以是新属性。\n\n            #等同多次 self.name = name 赋值 在外部可以直接把变量和值对应关系传进去\n            #class Person:\n            #    def __init__(self, name ,age):\n            #        self.name = name\n            #        self.age = age\n            \n            config = {''name'':''name'',''age'',''age''}\n            class Configure(object):\n                def __init__(self, config):\n                    self.register(config)\n\n                def register(self, config):\n                    for key, value in config.items():\n                        if key.upper() == key:\n                            setattr(self, key, value)\n\n    模块包\n\n        # 文件 ops/fileserver/__init__.py\n        import readers\n        import writers\n\n        # 每个模块的包中，都有一个 __init__.py 文件，有了这个文件，才能导入这个目录下的module，在导入一个包时 import ops.fileserver ，实际上是导入了它的 __init__.py 文件，可以再 __init__.py 文件中再导入其他的包，或者模块。就不需要将所有的import语句写在一个文件里了，也可以减少代码量，不需要一个个去导入module了。\n        # __init__.py 有一个重要的变量 __all__ 。有时会需要全部导入，from PackageName import *   ，这时 import 就会把注册在包 __init__.py 文件中 __all__ 列表中的子模块和子包导入到当前作用域中来。如：\n        __all__ = ["Module1", "Module2", "subPackage1", "subPackage2"]\n\n    执行模块类中的所有方法\n\n        # moniItems.py\n        import sys, time\n        import inspect\n\n        class mon:\n            def __init__(self):\n                self.data = dict()\n            def run(self):\n                return self.runAllGet()\n            def getDisk(self):\n                return 222\n            def getCpu(self):\n                return 111\n            def runAllGet(self):\n                for fun in inspect.getmembers(self, predicate=inspect.ismethod):\n                    print fun[0], fun[1]\n                    if fun[0][:3] == ''get'':\n                        self.data[fun[0][3:]] = fun[1]()\n                print self.data\n                return self.data\n        \n        # 模块导入使用\n        from moniItems import mon\n        m = mon()\n        m.runAllGet()\n\n    文件处理\n\n        # 模式: 读''r''  写[清空整个文件]''w'' 追加[文件需要存在]''a'' 读写''r+'' 二进制文件''b''  ''rb'',''wb'',''rb+''\n\n        写文件\n            i={''ddd'':''ccc''}\n            f = file(''poem.txt'', ''a'') \n            f.write("string")\n            f.write(str(i))\n            f.flush()\n            f.close()\n\n        读文件\n            f = file(''/etc/passwd'',''r'')\n            c = f.read().strip()        # 读取为一个大字符串，并去掉最后一个换行符\n            for i in c.spilt(''\\n''):     # 用换行符切割字符串得到列表循环每行\n                print i\n            f.close()\n\n        读文件1\n            f = file(''/etc/passwd'',''r'')\n            while True:\n                line = f.readline()    # 返回一行\n                if len(line) == 0:\n                    break\n                x = line.split(":")                  # 冒号分割定义序列\n                #x = [ x for x in line.split(":") ]  # 冒号分割定义序列\n                #x = [ x.split("/") for x in line.split(":") ]  # 先冒号分割,在/分割 打印x[6][1]\n                print x[6],"\\n",\n            f.close() \n\n        读文件2\n            f = file(''/etc/passwd'')\n            c = f.readlines()       # 读入所有文件内容,可反复读取,大文件时占用内存较大\n            for line in c:\n                print line.rstrip(),\n            f.close()\n\n        读文件3\n            for i in open(''b.txt''):   # 直接读取也可迭代,并有利于大文件读取,但不可反复读取\n                print i,\n\n        追加日志\n            log = open(''/home/peterli/xuesong'',''a'')\n            print >> log,''faaa''\n            log.close()\n        \n        with读文件\n\n            # 自动关闭文件、线程锁的自动获取和释放等\n            with open(''a.txt'') as f:\n                for i in f:\n                    print i\n                print f.read()        # 打印所有内容为字符串\n                print f.readlines()   # 打印所有内容按行分割的列表\n\n        文件高级随机读写\n\n            # 文件本没有换行,一切都是字符,文件也没有插入功能\n            f.tell()       # 当前读写位置\n            f.read(5)      # 读取5个字符并改变指针\n            f.seek(5)      # 改变用户态读写指针偏移位置,可做随机写\n            f.seek(p,0)    # 移动当文件第p个字节处，绝对位置\n            f.seek(p,1)    # 移动到相对于当前位置之后的p个字节\n            f.seek(p,2)    # 移动到相对文件尾之后的p个字节\n            f.seek(0,2)    # 指针指到尾部\n            # 改变指针超出文件尾部,会造成文件洞,ll看占用较大，但du -sh却非常小\n            f.read(65535)  # 读取64K字节\n            f.write("str") # 写会覆盖当前指针后的响应字符,无插入功能\n\n    内建函数\n\n        dir(sys)            # 显示对象的属性\n        help(sys)           # 交互式帮助\n        int(obj)            # 转型为整形\n        str(obj)            # 转为字符串\n        len(obj)            # 返回对象或序列长度\n        open(file,mode)     # 打开文件 #mode (r 读,w 写, a追加)\n        range(0,3)          # 返回一个整形列表\n        raw_input("str:")   # 等待用户输入\n        type(obj)           # 返回对象类型\n        abs(-22)            # 绝对值\n        random              # 随机数\n        choice()            # 随机返回给定序列的一个元素\n        divmod(x,y)         # 函数完成除法运算，返回商和余数。\n        round(x[,n])        # 函数返回浮点数x的四舍五入值，如给出n值，则代表舍入到小数点后的位数\n        strip()             # 是去掉字符串两端多于空格,该句是去除序列中的所有字串两端多余的空格\n        del                 # 删除列表里面的数据\n        cmp(x,y)            # 比较两个对象    #根据比较结果返回一个整数，如果x<y，则返回-1；如果x>y，则返回1,如果x==y则返回0\n        max()               # 字符串中最大的字符\n        min()               # 字符串中最小的字符\n        sorted()            # 对序列排序\n        reversed()          # 对序列倒序\n        enumerate()         # 返回索引位置和对应的值\n        sum()               # 总和\n        list()              # 变成列表可用于迭代\n        eval(''3+4'')         # 将字符串当表达式求值 得到7\n        exec ''a=100''        # 将字符串按python语句执行\n        exec(a+''=new'')      # 将变量a的值作为新的变量\n        tuple()             # 变成元组可用于迭代   #一旦初始化便不能更改的数据结构,速度比list快\n        zip(s,t)            # 返回一个合并后的列表  s = [''11'',''22'']  t = [''aa'',''bb'']  [(''11'', ''aa''), (''22'', ''bb'')]\n        isinstance(object,int)    # 测试对象类型 int \n        xrange([lower,]stop[,step])            # 函数与range()类似，但xrnage()并不创建列表，而是返回一个xrange对象\n\n    列表类型内建函数\n\n        list.append(obj)                 # 向列表中添加一个对象obj\n        list.count(obj)                  # 返回一个对象obj在列表中出现的次数\n        list.extend(seq)                 # 把序列seq的内容添加到列表中\n        list.index(obj,i=0,j=len(list))  # 返回list[k] == obj 的k值,并且k的范围在i<=k<j;否则异常\n        list.insert(index.obj)           # 在索引量为index的位置插入对象obj\n        list.pop(index=-1)               # 删除并返回指定位置的对象,默认是最后一个对象\n        list.remove(obj)                 # 从列表中删除对象obj\n        list.reverse()                   # 原地翻转列表\n        list.sort(func=None,key=None,reverse=False)  # 以指定的方式排序列表中成员,如果func和key参数指定,则按照指定的方式比较各个元素,如果reverse标志被置为True,则列表以反序排列\n\n    序列类型操作符\n\n        seq[ind]              # 获取下标为ind的元素\n        seq[ind1:ind2]        # 获得下标从ind1到ind2的元素集合\n        seq * expr            # 序列重复expr次\n        seq1 + seq2           # 连接seq1和seq2\n        obj in seq            # 判断obj元素是否包含在seq中\n        obj not in seq        # 判断obj元素是否不包含在seq中\n\n    字符串类型内建方法\n\n        string.expandtabs(tabsize=8)                  # tab符号转为空格 #默认8个空格\n        string.endswith(obj,beg=0,end=len(staring))   # 检测字符串是否已obj结束,如果是返回True #如果beg或end指定检测范围是否已obj结束\n        string.count(str,beg=0,end=len(string))       # 检测str在string里出现次数  f.count(''\\n'',0,len(f)) 判断文件行数\n        string.find(str,beg=0,end=len(string))        # 检测str是否包含在string中\n        string.index(str,beg=0,end=len(string))       # 检测str不在string中,会报异常\n        string.isalnum()                              # 如果string至少有一个字符并且所有字符都是字母或数字则返回True\n        string.isalpha()                              # 如果string至少有一个字符并且所有字符都是字母则返回True\n        string.isnumeric()                            # 如果string只包含数字字符,则返回True\n        string.isspace()                              # 如果string包含空格则返回True\n        string.isupper()                              # 字符串都是大写返回True\n        string.islower()                              # 字符串都是小写返回True\n        string.lower()                                # 转换字符串中所有大写为小写\n        string.upper()                                # 转换字符串中所有小写为大写\n        string.lstrip()                               # 去掉string左边的空格\n        string.rstrip()                               # 去掉string字符末尾的空格\n        string.replace(str1,str2,num=string.count(str1))  # 把string中的str1替换成str2,如果num指定,则替换不超过num次\n        string.startswith(obj,beg=0,end=len(string))  # 检测字符串是否以obj开头\n        string.zfill(width)                           # 返回字符长度为width的字符,原字符串右对齐,前面填充0\n        string.isdigit()                              # 只包含数字返回True\n        string.split("分隔符")                        # 把string切片成一个列表\n        ":".join(string.split())                      # 以:作为分隔符,将所有元素合并为一个新的字符串\n\n    字典内建方法\n\n        dict.clear()                            # 删除字典中所有元素\n        dict copy()                             # 返回字典(浅复制)的一个副本\n        dict.fromkeys(seq,val=None)             # 创建并返回一个新字典,以seq中的元素做该字典的键,val做该字典中所有键对的初始值\n        dict.get(key,default=None)              # 对字典dict中的键key,返回它对应的值value,如果字典中不存在此键,则返回default值\n        dict.has_key(key)                       # 如果键在字典中存在,则返回True 用in和not in代替\n        dict.items()                            # 返回一个包含字典中键、值对元组的列表\n        dict.keys()                             # 返回一个包含字典中键的列表\n        dict.iter()                             # 方法iteritems()、iterkeys()、itervalues()与它们对应的非迭代方法一样,不同的是它们返回一个迭代子,而不是一个列表\n        dict.pop(key[,default])                 # 和方法get()相似.如果字典中key键存在,删除并返回dict[key]\n        dict.setdefault(key,default=None)       # 和set()相似,但如果字典中不存在key键,由dict[key]=default为它赋值\n        dict.update(dict2)                      # 将字典dict2的键值对添加到字典dict\n        dict.values()                           # 返回一个包含字典中所有值得列表\n\n        dict([container])     # 创建字典的工厂函数。提供容器类(container),就用其中的条目填充字典\n        len(mapping)          # 返回映射的长度(键-值对的个数)\n        hash(obj)             # 返回obj哈希值,判断某个对象是否可做一个字典的键值        \n        \n    集合方法\n\n        s.update(t)                         # 用t中的元素修改s,s现在包含s或t的成员   s |= t\n        s.intersection_update(t)            # s中的成员是共用属于s和t的元素          s &= t\n        s.difference_update(t)              # s中的成员是属于s但不包含在t中的元素    s -= t\n        s.symmetric_difference_update(t)    # s中的成员更新为那些包含在s或t中,但不是s和t共有的元素  s ^= t\n        s.add(obj)                          # 在集合s中添加对象obj\n        s.remove(obj)                       # 从集合s中删除对象obj;如果obj不是集合s中的元素(obj not in s),将引发KeyError错误\n        s.discard(obj)                      # 如果obj是集合s中的元素,从集合s中删除对象obj\n        s.pop()                             # 删除集合s中的任意一个对象,并返回它\n        s.clear()                           # 删除集合s中的所有元素\n        s.issubset(t)                       # 如果s是t的子集,则返回True   s <= t\n        s.issuperset(t)                     # 如果t是s的超集,则返回True   s >= t\n        s.union(t)                          # 合并操作;返回一个新集合,该集合是s和t的并集   s | t\n        s.intersection(t)                   # 交集操作;返回一个新集合,该集合是s和t的交集   s & t\n        s.difference(t)                     # 返回一个新集合,改集合是s的成员,但不是t的成员  s - t\n        s.symmetric_difference(t)           # 返回一个新集合,该集合是s或t的成员,但不是s和t共有的成员   s ^ t\n        s.copy()                            # 返回一个新集合,它是集合s的浅复制\n        obj in s                            # 成员测试;obj是s中的元素 返回True\n        obj not in s                        # 非成员测试:obj不是s中元素 返回True\n        s == t                              # 等价测试 是否具有相同元素\n        s != t                              # 不等价测试 \n        s < t                               # 子集测试;s!=t且s中所有元素都是t的成员\n        s > t                               # 超集测试;s!=t且t中所有元素都是s的成员\n\n    序列化\n\n        #!/usr/bin/python\n        import cPickle\n        obj = {''1'':[''4124'',''1241'',''124''],''2'':[''12412'',''142'',''1241'']}\n\n        pkl_file = open(''account.pkl'',''wb'')\n        cPickle.dump(obj,pkl_file)\n        pkl_file.close()\n\n        pkl_file = open(''account.pkl'',''rb'')\n        account_list = cPickle.load(pkl_file)\n        pkl_file.close()\n\n    文件对象方法\n        \n        file.close()                     # 关闭文件\n        file.fileno()                    # 返回文件的描述符\n        file.flush()                     # 刷新文件的内部缓冲区\n        file.isatty()                    # 判断file是否是一个类tty设备\n        file.next()                      # 返回文件的下一行,或在没有其他行时引发StopIteration异常\n        file.read(size=-1)               # 从文件读取size个字节,当未给定size或给定负值的时候,读取剩余的所有字节,然后作为字符串返回\n        file.readline(size=-1)           # 从文件中读取并返回一行(包括行结束符),或返回最大size个字符\n        file.readlines(sizhint=0)        # 读取文件的所有行作为一个列表返回\n        file.xreadlines()                # 用于迭代,可替换readlines()的一个更高效的方法\n        file.seek(off, whence=0)         # 在文件中移动文件指针,从whence(0代表文件起始,1代表当前位置,2代表文件末尾)偏移off字节\n        file.tell()                      # 返回当前在文件中的位置\n        file.truncate(size=file.tell())  # 截取文件到最大size字节,默认为当前文件位置\n        file.write(str)                  # 向文件写入字符串\n        file.writelines(seq)             # 向文件写入字符串序列seq;seq应该是一个返回字符串的可迭代对象\n\n    文件对象的属性\n        \n        file.closed          # 表示文件已被关闭,否则为False\n        file.encoding        # 文件所使用的编码  当unicode字符串被写入数据时,它将自动使用file.encoding转换为字节字符串;若file.encoding为None时使用系统默认编码\n        file.mode            # Access文件打开时使用的访问模式\n        file.name            # 文件名\n        file.newlines        # 未读取到行分隔符时为None,只有一种行分隔符时为一个字符串,当文件有多种类型的行结束符时,则为一个包含所有当前所遇到的行结束符的列表\n        file.softspace       # 为0表示在输出一数据后,要加上一个空格符,1表示不加\n\n    异常处理\n    \n        # try 中使用 sys.exit(2) 会被捕获,无法退出脚本,可使用 os._exit(2) 退出脚本\n        \n        class ShortInputException(Exception):  # 继承Exception异常的类,定义自己的异常\n            def __init__(self, length, atleast):\n                Exception.__init__(self)\n                self.length = length\n                self.atleast = atleast\n        try:\n            s = raw_input(''Enter something --> '')\n            if len(s) < 3:\n                raise ShortInputException(len(s), 3)    # 触发异常\n        except EOFError:\n            print ''\\nWhy did you do an EOF on me?''\n        except ShortInputException, x:      # 捕捉指定错误信息\n            print ''ShortInputException:  %d | %d'' % (x.length, x.atleast)\n        except Exception as err:            # 捕捉所有其它错误信息内容\n            print str(err)\n        #except urllib2.HTTPError as err:   # 捕捉外部导入模块的错误\n        #except:                            # 捕捉所有其它错误 不会看到错误内容\n        #        print ''except''\n        finally:                            # 无论什么情况都会执行 关闭文件或断开连接等\n               print ''finally'' \n        else:                               # 无任何异常 无法和finally同用\n            print ''No exception was raised.'' \n\n        不可捕获的异常\n\n            NameError:              # 尝试访问一个未申明的变量\n            ZeroDivisionError:      # 除数为零\n            SyntaxErrot:            # 解释器语法错误\n            IndexError:             # 请求的索引元素超出序列范围\n            KeyError:               # 请求一个不存在的字典关键字\n            IOError:                # 输入/输出错误\n            AttributeError:         # 尝试访问未知的对象属性\n            ImportError             # 没有模块\n            IndentationError        # 语法缩进错误\n            KeyboardInterrupt       # ctrl+C\n            SyntaxError             # 代码语法错误\n            ValueError              # 值错误\n            TypeError               # 传入对象类型与要求不符合\n\n        内建异常\n            \n            BaseException                # 所有异常的基类\n            SystemExit                   # python解释器请求退出\n            KeyboardInterrupt            # 用户中断执行\n            Exception                    # 常规错误的基类\n            StopIteration                # 迭代器没有更多的值\n            GeneratorExit                # 生成器发生异常来通知退出\n            StandardError                # 所有的内建标准异常的基类\n            ArithmeticError              # 所有数值计算错误的基类\n            FloatingPointError           # 浮点计算错误\n            OverflowError                # 数值运算超出最大限制\n            AssertionError               # 断言语句失败\n            AttributeError               # 对象没有这个属性\n            EOFError                     # 没有内建输入,到达EOF标记\n            EnvironmentError             # 操作系统错误的基类\n            IOError                      # 输入/输出操作失败\n            OSError                      # 操作系统错误\n            WindowsError                 # windows系统调用失败\n            ImportError                  # 导入模块/对象失败\n            KeyboardInterrupt            # 用户中断执行(通常是ctrl+c)\n            LookupError                  # 无效数据查询的基类\n            IndexError                   # 序列中没有此索引(index)\n            KeyError                     # 映射中没有这个键\n            MemoryError                  # 内存溢出错误(对于python解释器不是致命的)\n            NameError                    # 未声明/初始化对象(没有属性)\n            UnboundLocalError            # 访问未初始化的本地变量\n            ReferenceError               # 若引用试图访问已经垃圾回收了的对象\n            RuntimeError                 # 一般的运行时错误\n            NotImplementedError          # 尚未实现的方法\n            SyntaxError                  # python语法错误\n            IndentationError             # 缩进错误\n            TabError                     # tab和空格混用\n            SystemError                  # 一般的解释器系统错误\n            TypeError                    # 对类型无效的操作\n            ValueError                   # 传入无效的参数\n            UnicodeError                 # Unicode相关的错误\n            UnicodeDecodeError           # Unicode解码时的错误\n            UnicodeEncodeError           # Unicode编码时的错误\n            UnicodeTranslateError        # Unicode转换时错误\n            Warning                      # 警告的基类\n            DeprecationWarning           # 关于被弃用的特征的警告\n            FutureWarning                # 关于构造将来语义会有改变的警告\n            OverflowWarning              # 旧的关于自动提升为长整形的警告\n            PendingDeprecationWarning    # 关于特性将会被废弃的警告\n            RuntimeWarning               # 可疑的运行时行为的警告\n            SyntaxWarning                # 可疑的语法的警告\n            UserWarning                  # 用户代码生成的警告\n\n        触发异常\n\n            raise exclass            # 触发异常,从exclass生成一个实例(不含任何异常参数)\n            raise exclass()          # 触发异常,但现在不是类;通过函数调用操作符(function calloperator:"()")作用于类名生成一个新的exclass实例,同样也没有异常参数\n            raise exclass, args      # 触发异常,但同时提供的异常参数args,可以是一个参数也可以是元组\n            raise exclass(args)      # 触发异常,同上\n            raise exclass, args, tb  # 触发异常,但提供一个跟踪记录(traceback)对象tb供使用\n            raise exclass,instance   # 通过实例触发异常(通常是exclass的实例)\n            raise instance           # 通过实例触发异常;异常类型是实例的类型:等价于raise instance.__class__, instance\n            raise string             # 触发字符串异常\n            raise string, srgs       # 触发字符串异常,但触发伴随着args\n            raise string,args,tb     # 触发字符串异常,但提供一个跟踪记录(traceback)对象tb供使用\n            raise                    # 重新触发前一个异常,如果之前没有异常,触发TypeError\n\n        跟踪异常栈\n\n            # traceback 获取异常相关数据都是通过sys.exc_info()函数得到的\n            import traceback\n            import sys\n            try:\n                s = raw_input()\n                print int(s)\n            except ValueError:\n                # sys.exc_info() 返回值是元组，第一个exc_type是异常的对象类型，exc_value是异常的值，exc_tb是一个traceback对象，对象中包含出错的行数、位置等数据\n                exc_type, exc_value, exc_tb = sys.exc_info()\n                print "\\n%s \\n %s \\n %s\\n" %(exc_type, exc_value, exc_tb )\n                traceback.print_exc()        # 打印栈跟踪信息\n                \n        抓取全部错误信息存如字典\n\n            import sys, traceback\n\n            try:\n                s = raw_input()\n                int(s)\n            except:\n                exc_type, exc_value, exc_traceback = sys.exc_info() \n                traceback_details = {\n                                     ''filename'': exc_traceback.tb_frame.f_code.co_filename,\n                                     ''lineno''  : exc_traceback.tb_lineno,\n                                     ''name''    : exc_traceback.tb_frame.f_code.co_name,\n                                     ''type''    : exc_type.__name__,\n                                     ''message'' : exc_value.message, \n                                    }\n             \n                del(exc_type, exc_value, exc_traceback) \n                print traceback_details\n                f = file(''test1.txt'', ''a'')\n                f.write("%s %s %s %s %s\\n" %(traceback_details[''filename''],traceback_details[''lineno''],traceback_details[''name''],traceback_details[''type''],traceback_details[''message''], ))\n                f.flush()\n                f.close()\n\n    调试log\n\n        # cgitb覆盖了默认sys.excepthook全局异常拦截器\n        def func(a, b):\n            return a / b\n        if __name__ == ''__main__'':\n            import cgitb\n            cgitb.enable(format=''text'')\n            func(1, 0)\n\n    函数式编程的内建函数\n\n        apply(func[,nkw][,kw])          # 用可选的参数来调用func,nkw为非关键字参数,kw为关键字参数;返回值是函数调用的返回值\n        filter(func,seq)                # 调用一个布尔函数func来迭代遍历每个seq中的元素;返回一个使func返回值为true的元素的序列\n        map(func,seq1[,seq2])           # 将函数func作用于给定序列(s)的每个元素,并用一个列表来提供返回值;如果func为None,func表现为一个身份函数,返回一个含有每个序列中元素集合的n个元组的列表\n        reduce(func,seq[,init])         # 将二元函数作用于seq序列的元素,每次携带一堆(先前的结果以及下一个序列元素),连续地将现有的结果和下一个值作用在获得的随后的结果上,最后减少我们的序列为一个单一的返回值;如果初始值init给定,第一个比较会是init和第一个序列元素而不是序列的头两个元素\n        lambda x,y:x+y                  # 创建一个匿名函数 可用于上面几种方法中直接创建匿名函数式\n\n        # filter 即通过函数方法只保留结果为真的值组成列表\n        def f(x): return x % 2 != 0 and x % 3 != 0\n        f(3)     # 函数结果是False  3被filter抛弃\n        f(5)     # 函数结果是True   5被加入filter最后的列表结果\n        filter(f, range(2, 25))\n        [5, 7, 11, 13, 17, 19, 23]\n        \n        # map 通过函数对列表进行处理得到新的列表\n        def cube(x): return x*x*x\n        map(cube, range(1, 11))\n        [1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]\n        \n        # reduce 通过函数会先接收初始值和序列的第一个元素，然后是返回值和下一个元素，依此类推\n        def add(x,y): return x+y\n        reduce(add, range(1, 11))              # 结果55  是1到10的和  x的值是上一次函数返回的结果，y是列表中循环的值\n        reduce(lambda x,y:x+y, range(1,11))    # 等同上面两条  lambda来创建匿名函数[ lambda x,y:x+y ] ,后面跟可迭代的对象\n\n    编码转换\n\n        a=''中文''                    # 编码未定义按输入终端utf8或gbk\n        u=u''中文''                   # 定义为unicode编码  u值为 u''\\u4e2d\\u6587''\n        u.encode(''utf8'')            # 转为utf8格式 u值为 ''\\xe4\\xb8\\xad\\xe6\\x96\\x87''\n        print u                     # 结果显示 中文\n        print u.encode(''utf8'')      # 转为utf8格式,当显示终端编码为utf8  结果显示 中文  编码不一致则乱码\n        print u.encode(''gbk'')       # 当前终端为utf8 故乱码\n        ord(''4'')                    # 字符转ASCII码\n        chr(52)                     # ASCII码转字符\n\n    遍历递归\n\n        [os.path.join(x[0],y) for x in os.walk(''/root/python/5'') for y in x[2]]\n\n        for i in os.walk(''/root/python/5/work/server''):\n            print i\n\n2 常用模块\n\n    sys             [系统操作模块]\n\n        sys.argv              # 取参数列表\n        sys.exit(2)           # 退出脚本返回状态 会被try截取\n        sys.exc_info()        # 获取当前正在处理的异常类\n        sys.version           # 获取Python解释程序的版本信息\n        sys.maxint            # 最大的Int值  9223372036854775807\n        sys.maxunicode        # 最大的Unicode值\n        sys.modules           # 返回系统导入的模块字段，key是模块名，value是模块\n        sys.path              # 返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值\n        sys.platform          # 返回操作系统平台名称\n        sys.stdout            # 标准输出\n        sys.stdin             # 标准输入\n        sys.stderr            # 错误输出\n        sys.exec_prefix       # 返回平台独立的python文件安装的位置\n        sys.stdin.readline()  # 从标准输入读一行\n        sys.stdout.write("a") # 屏幕输出a \n        sys.path.insert(1, os.path.join(sys.path[0], ''/opt/script/''))     # 将/opt/script/目录加入环境变量，可导入相应模块\n\n    os              [系统模块]\n\n        # 相对sys模块 os模块更为底层 os._exit() try无法抓取\n        os.popen(''id'').read()      # 执行系统命令得到返回结果\n        os.system()                # 得到返回状态 返回无法截取\n        os.name                    # 返回系统平台 Linux/Unix用户是''posix''\n        os.getenv()                # 读取环境变量\n        os.putenv()                # 设置环境变量\n        os.getcwd()                # 当前工作路径\n        os.chdir()                 # 改变当前工作目录\n        os.walk(''/root/'')          # 递归路径\n        os.environ[''HOME'']         # 查看系统环境变量\n\n        文件处理\n            mkfifo()/mknod()       # 创建命名管道/创建文件系统节点\n            remove()/unlink()      # 删除文件\n            rename()/renames()     # 重命名文件\n            stat()                 # 返回文件信息\n            symlink()              # 创建符号链接\n            utime()                # 更新时间戳\n            tmpfile()              # 创建并打开(''w+b'')一个新的临时文件\n            walk()                 # 遍历目录树下的所有文件名\n\n            oct(os.stat(''th1.py'').st_mode)[-3:]      # 查看目录权限\n\n        目录/文件夹\n            chdir()/fchdir()       # 改变当前工作目录/通过一个文件描述符改变当前工作目录\n            chroot()               # 改变当前进程的根目录\n            listdir()              # 列出指定目录的文件\n            getcwd()/getcwdu()     # 返回当前工作目录/功能相同,但返回一个unicode对象\n            mkdir()/makedirs()     # 创建目录/创建多层目录\n            rmdir()/removedirs()   # 删除目录/删除多层目录\n\n        访问/权限\n            saccess()                    # 检验权限模式\n            chmod(''txt'',eval("0777"))    # 改变权限模式\n            chown()/lchown()             # 改变owner和groupID功能相同,但不会跟踪链接\n            umask()                      # 设置默认权限模式\n\n        文件描述符操作\n            open()                 # 底层的操作系统open(对于稳健,使用标准的内建open()函数)\n            read()/write()         # 根据文件描述符读取/写入数据 按大小读取文件部分内容\n            dup()/dup2()           # 复制文件描述符号/功能相同,但是复制到另一个文件描述符\n\n        设备号\n            makedev()              # 从major和minor设备号创建一个原始设备号\n            major()/minor()        # 从原始设备号获得major/minor设备号\n\n        os.path模块\n\n            os.path.expanduser(''~/.ssh/key'')   # 家目录下文件的全路径\n\n            分隔\n                os.path.basename()         # 去掉目录路径,返回文件名\n                os.path.dirname()          # 去掉文件名,返回目录路径\n                os.path.join()             # 将分离的各部分组合成一个路径名\n                os.path.spllt()            # 返回(dirname(),basename())元组\n                os.path.splitdrive()       # 返回(drivename,pathname)元组\n                os.path.splitext()         # 返回(filename,extension)元组\n            \n            信息\n                os.path.getatime()         # 返回最近访问时间\n                os.path.getctime()         # 返回文件创建时间\n                os.path.getmtime()         # 返回最近文件修改时间\n                os.path.getsize()          # 返回文件大小(字节)\n            \n            查询\n                os.path.exists()           # 指定路径(文件或目录)是否存在\n                os.path.isabs()            # 指定路径是否为绝对路径\n                os.path.isdir()            # 指定路径是否存在且为一个目录\n                os.path.isfile()           # 指定路径是否存在且为一个文件\n                os.path.islink()           # 指定路径是否存在且为一个符号链接\n                os.path.ismount()          # 指定路径是否存在且为一个挂载点\n                os.path.samefile()         # 两个路径名是否指向同一个文件\n\n        子进程\n            os.fork()    # 创建子进程,并复制父进程所有操作  通过判断pid = os.fork() 的pid值,分别执行父进程与子进程操作，0为子进程\n            os.wait()    # 等待子进程结束\n\n        跨平台os模块属性\n\n            linesep         # 用于在文件中分隔行的字符串\n            sep             # 用来分隔文件路径名字的字符串\n            pathsep         # 用于分割文件路径的字符串\n            curdir          # 当前工作目录的字符串名称\n            pardir          # 父目录字符串名称\n\n    commands        [执行系统命令]\n    \n        commands.getstatusoutput(''id'')       # 返回元组(状态,标准输出)\n        commands.getoutput(''id'')             # 只返回执行的结果, 忽略返回值\n        commands.getstatus(''file'')           # 返回ls -ld file执行的结果\n\n    re              [perl风格正则]\n\n        compile(pattern,flags=0)          # 对正则表达式模式pattern进行编译,flags是可选标识符,并返回一个regex对象\n        match(pattern,string,flags=0)     # 尝试用正则表达式模式pattern匹配字符串string,flags是可选标识符,如果匹配成功,则返回一个匹配对象;否则返回None\n        search(pattern,string,flags=0)    # 在字符串string中搜索正则表达式模式pattern的第一次出现,flags是可选标识符,如果匹配成功,则返回一个匹配对象;否则返回None\n        findall(pattern,string[,flags])   # 在字符串string中搜索正则表达式模式pattern的所有(非重复)出现:返回一个匹配对象的列表  # pattern=u''\\u4e2d\\u6587'' 代表UNICODE\n        finditer(pattern,string[,flags])  # 和findall()相同,但返回的不是列表而是迭代器;对于每个匹配,该迭代器返回一个匹配对象\n        split(pattern,string,max=0)       # 根据正则表达式pattern中的分隔符把字符string分割为一个列表,返回成功匹配的列表,最多分割max次(默认所有)\n        sub(pattern,repl,string,max=0)    # 把字符串string中所有匹配正则表达式pattern的地方替换成字符串repl,如果max的值没有给出,则对所有匹配的地方进行替换(subn()会返回一个表示替换次数的数值)\n        group(num=0)                      # 返回全部匹配对象(或指定编号是num的子组)\n        groups()                          # 返回一个包含全部匹配的子组的元组(如果没匹配成功,返回一个空元组)\n        \n        零宽断言\n            str = ''aaa111aaa , bbb222&, 333ccc''\n            re.compile(''\\d+(?=[a-z]+)'').findall(str)          # 前向界定 (?=exp) 找出连续的数字并且最后一个数字跟着至少一个a-z [''111'', ''333'']\n            re.compile(r"\\d+(?![a-z]+)").findall(str)         # 前向否定界定 (?!exp)  找出连续数字，且最后一个数字后不能跟a-z  [''11'', ''222'', ''33'']\n            re.compile(r"(?<=[a-z])\\d+").findall(str)         # 反向界定 (?<=exp) 逆序环视 找出连续的数字，且第一个数字前面是a-z  [''111'', ''222'']\n            re.compile(r"(?<![a-z])\\d+").findall(str)         # 反向否定界定 (?<!exp) 否定逆序环视  找出连续的数字，且第一个数字前不能是a-z  [''11'', ''22'', ''333'']\n            re.compile(r"(?:\\d+)").findall(str)               # 无捕获的匹配 (?:exp)\n            s= ''Tom:9527 , Sharry:0003 ''\n            re.match( r''(?P<name>\\w+):(?P<num>\\d+)'' , s).group(0)   # 捕获组 <num>第二个标签变量[9527] 获取 group("num") 等同 group(2)[9527], group(0)全部[Tom:9527]   \n\n        例子\n            re.findall(r''a[be]c'',''123abc456eaec789'')         # 返回匹配对象列表 [''abc'', ''aec'']\n            re.findall("(.)12[34](..)",a)                    # 取出匹配括号中内容   a=''qedqwe123dsf''\n            re.search("(.)123",a ).group(1)                  # 搜索匹配的取第1个标签\n            re.match("^(1|2) *(.*) *abc$", str).group(2)     # 取第二个标签\n            re.match("^(1|2) *(.*) *abc$", str).groups()     # 取所有标签\n            re.sub(''[abc]'',''A'',''alex'')                       # 替换\n            for i in re.finditer(r''\\d+'',s):                  # 迭代\n                print i.group(),i.span()                     #\n        \n        搜索网页中UNICODE格式的中文\n            QueryAdd=''http://www.anti-spam.org.cn/Rbl/Query/Result''\n            Ip=''222.129.184.52''\n            s = requests.post(url=QueryAdd, data={''IP'':Ip})\n            re.findall(u''\\u4e2d\\u56fd'', s.text, re.S)\n\n    csv             [访问csv逗号分隔的文件]\n\n        csv读配置文件  \n\n            192.168.1.5,web # 配置文件按逗号分割\n            list = csv.reader(file(''a.csv''))\n            for line in list:\n                print line              #  [''192.168.1.5'', ''web'']\n\n        csv配合with读文件\n\n            import csv\n            with open(''some.csv'', ''rb'') as f:\n                reader = csv.reader(f)\n                for row in reader:\n                    print row\n\n        csv配合with写文件\n\n            import csv\n            with open(''some.csv'', ''wb'') as f:\n                writer = csv.writer(f)\n                writer.writerow([''Column1'', ''Column2'', ''Column3''])    # 写单行 列表\n                writer.writerows([range(3) for i in range(5)])        # 写多行 列表套列表\n\n    shutil          [提供高级文件访问功能]\n    \n        import shutil\n        shutil.copyfile(''data.db'', ''archive.db'')             # 拷贝文件\n        shutil.move(''/build/executables'', ''installdir'')      # 移动文件或目录\n\n    dircache        [目录文件列表缓存]\n\n        import dircache\n        a = dircache.listdir(''/data/xuesong'')        # 列出目录下所有的文件和目录\n        dircache.annotate(''/data/xuesong'', a)        # 判断指定目录下的是文件还是目录,目录则后面加/ 文件或不存在则不改变\n\n    glob            [文件通配符]\n\n        import glob\n        glob.glob(''*.py'')    # 查找当前目录下py结尾的文件\n\n    random          [随机模块]\n    \n        import random\n        random.choice([''apple'', ''pear'', ''banana''])   # 随机取列表一个参数\n        random.sample(xrange(100), 10)  # 不重复抽取10个\n        random.random()                 # 随机浮点数\n        random.randrange(6)             # 随机整数范围\n\n    tempfile        [创建临时文件]\n\n        import os\n        import tempfile\n         \n        temp = tempfile.TemporaryFile()                # 定义一个临时文件对象\n        try:\n            temp.write(''Some data'')                    # 写入数据\n            temp.writelines([''first\\n'', ''second\\n''])   # 写入多行\n            temp.seek(0)                               # 写入\n             \n            print temp.read()                          # 读取\n\n            for line in temp:                          # 循环读取每一行\n                print line.rstrip()\n        finally:\n            temp.close()                               # 关闭后删除临时文件\n\n\n\n        # 创建临时目录\n        import os\n        import tempfile\n         \n        directory_name = tempfile.mkdtemp()\n        print directory_name                            # 打印临时目录地址 /var/folders...\n        # Clean up the directory yourself\n        os.removedirs(directory_name)                   # 创建临时目录需要手动删除\n\n\n        # 控制临时文件名\n        import tempfile\n         \n        temp = tempfile.NamedTemporaryFile(suffix=''_suffix'',  prefix=''prefix_'',  dir=''/tmp'')\n        try:\n            print ''temp:'', temp\n            print ''temp.name:'', temp.name\n        finally:\n            temp.close()\n\n    email           [发送邮件]\n\n        发送邮件内容\n\n            #!/usr/bin/python\n            #encoding:utf8\n            # 导入 smtplib 和 MIMEText \n            import smtplib\n            from email.mime.text import MIMEText\n\n            # 定义发送列表 \n            mailto_list=["272121935@qq.com","272121935@163.com"]\n\n            # 设置服务器名称、用户名、密码以及邮件后缀 \n            mail_host = "smtp.163.com"\n            mail_user = "mailuser"\n            mail_pass = "password"\n            mail_postfix="163.com"\n\n            # 发送邮件函数\n            def send_mail(to_list, sub):\n                me = mail_user + "<"+mail_user+"@"+mail_postfix+">"\n                fp = open(''context.txt'')\n                msg = MIMEText(fp.read(),_charset="utf-8")\n                fp.close()\n                msg[''Subject''] = sub\n                msg[''From''] = me\n                msg[''To''] = ";".join(to_list)\n                try:\n                    send_smtp = smtplib.SMTP()\n                    send_smtp.connect(mail_host)\n                    send_smtp.login(mail_user, mail_pass)\n                    send_smtp.sendmail(me, to_list, msg.as_string())\n                    send_smtp.close()\n                    return True\n                except Exception, e:\n                    print str(e)\n                    return False\n\n            if send_mail(mailto_list,"标题"):\n                print "测试成功"\n            else:\n                print "测试失败"\n\n        发送附件\n\n            #!/usr/bin/python\n            #encoding:utf8\n            import smtplib\n            from email.mime.multipart import MIMEMultipart\n            from email.mime.base import MIMEBase\n            from email import encoders\n\n            def send_mail(to_list, sub, filename):\n                me = mail_user + "<"+mail_user+"@"+mail_postfix+">"\n                msg = MIMEMultipart()\n                msg[''Subject''] = sub\n                msg[''From''] = me\n                msg[''To''] = ";".join(to_list)\n                submsg = MIMEBase(''application'', ''x-xz'')\n                submsg.set_payload(open(filename,''rb'').read())\n                encoders.encode_base64(submsg)\n                submsg.add_header(''Content-Disposition'', ''attachment'', filename=filename)\n                msg.attach(submsg)\n                try:\n                    send_smtp = smtplib.SMTP()\n                    send_smtp.connect(mail_host)\n                    send_smtp.login(mail_user, mail_pass)\n                    send_smtp.sendmail(me, to_list, msg.as_string())\n                    send_smtp.close()\n                    return True\n                except Exception, e:\n                    print str(e)[1]\n                    return False\n\n            # 设置服务器名称、用户名、密码以及邮件后缀 \n            mail_host = "smtp.163.com"\n            mail_user = "xuesong"\n            mail_pass = "mailpasswd"\n            mail_postfix = "163.com"\n            mailto_list = ["272121935@qq.com","quanzhou722@163.com"]\n            title = ''check''\n            filename = ''file_check.html''\n            if send_mail(mailto_list,title,filename):\n                print "发送成功"\n            else:\n                print "发送失败"\n\n    gzip            [解压缩gzip 删除原文件]\n\n        #压缩gzip\n        import gzip\n        f_in = open(''file.log'', ''rb'')\n        f_out = gzip.open(''file.log.gz'', ''wb'')\n        f_out.writelines(f_in)\n        f_out.close()\n        f_in.close()\n\n        #压缩gzip\n        File = ''xuesong_18.log''\n        g = gzip.GzipFile(filename="", mode=''wb'', compresslevel=9, fileobj=open((r''%s.gz'' %File),''wb''))\n        g.write(open(r''%s'' %File).read())\n        g.close()\n\n        #解压gzip\n        g = gzip.GzipFile(mode=''rb'', fileobj=open((r''xuesong_18.log.gz''),''rb''))\n        open((r''xuesong_18.log''),''wb'').write(g.read())\n\n    tarfile         [归档压缩tar.gz 保留原文件]\n\n        # 压缩tar.gz\n        import os\n        import tarfile\n        tar = tarfile.open("/tmp/tartest.tar.gz","w:gz")   # 创建压缩包名\n        for path,dir,files in os.walk("/tmp/tartest"):     # 递归文件目录\n            for file in files:\n                fullpath = os.path.join(path,file)\n                tar.add(fullpath)                          # 创建压缩包\n        tar.close()\n\n        # 解压tar.gz\n        import tarfile\n        tar = tarfile.open("/tmp/tartest.tar.gz")\n        #tar.extract("/tmp")                               # 全部解压到指定路径\n        names = tar.getnames()                             # 包内文件名\n        for name in names:\n            tar.extract(name,path="./")                    # 解压指定文件\n        tar.close()\n\n    zipfile         [解压缩zip 最大2G]\n\n        # 压缩zip\n        import zipfile,os\n        f = zipfile.ZipFile(''filename.zip'', ''w'' ,zipfile.ZIP_DEFLATED)    # ZIP_STORE 为默认表不压缩. ZIP_DEFLATED 表压缩\n        #f.write(''file1.txt'')                              # 将文件写入压缩包\n        for path,dir,files in os.walk("tartest"):          # 递归压缩目录\n            for file in files:\n                f.write(os.path.join(path,file))           # 将文件逐个写入压缩包         \n        f.close()\n\n        # 解压zip\n        if zipfile.is_zipfile(''filename.zip''):             # 判断一个文件是不是zip文件\n            f = zipfile.ZipFile(''filename.zip'')\n            for file in f.namelist():                      # 返回文件列表\n                f.extract(file, r''/tmp/'')                  # 解压指定文件\n            #f.extractall()                                # 解压全部\n            f.close()\n\n    time/datetime   [时间]\n\n        import time\n        time.strftime(''%Y%m%d_%H%M'')         # 格式化时间\n        time.time()                          # 时间戳[浮点]\n        int(time.time())                     # 时间戳[整s]\n        time.localtime()[1] - 1              # 上个月\n        time.strftime(''%Y-%m-%d_%X'',time.localtime( time.time() ) )              # 时间戳转日期\n        time.mktime(time.strptime(''2012-03-28 06:53:40'', ''%Y-%m-%d %H:%M:%S''))   # 日期转时间戳\n\n        判断输入时间格式是否正确\n        \n            #encoding:utf8\n            import time\n            while 1:\n                atime=raw_input(''输入格式如[14.05.13 13:00]:'')\n                try:\n                    btime=time.mktime(time.strptime(''%s:00'' %atime, ''%y.%m.%d %H:%M:%S''))\n                    break\n                except:\n                    print ''时间输入错误,请重新输入，格式如[14.05.13 13:00]''\n\n        上一个月最后一天\n            import datetime\n            lastMonth=datetime.date(datetime.date.today().year,datetime.date.today().month,1)-datetime.timedelta(1)\n            lastMonth.strftime("%Y/%m")\n\n        前一天\n            (datetime.datetime.now() + datetime.timedelta(days=-1) ).strftime(''%Y%m%d'')\n\n        两日期相差天数\n\n            import datetime\n            d1 = datetime.datetime(2005, 2, 16)\n            d2 = datetime.datetime(2004, 12, 31)\n            (d1 - d2).days\n\n        向后加10个小时\n\n            import datetime\n            d1 = datetime.datetime.now()\n            d3 = d1 + datetime.timedelta(hours=10)\n            d3.ctime()\n\n    optparse        [解析参数及标准提示]\n\n        import os, sys\n        import time\n        import optparse\n        # python aaa.py -t file -p /etc/opt -o aaaaa\n\n        def do_fiotest( type, path, output,):\n            print type, path, output,\n\n        def main():\n            parser = optparse.OptionParser()\n            parser.add_option(''-t'', ''--type'', dest = ''type'', default = None, help = ''test type[file, device]'')\n            parser.add_option(''-p'', ''--path'', dest = ''path'', default = None, help = ''test file path or device path'')\n            parser.add_option(''-o'', ''--output'', dest = ''output'', default = None, help = ''result dir path'')\n\n            (o, a) = parser.parse_args()\n\n            if None == o.type or None == o.path or None == o.output:\n                print "No device or file or output dir"\n                return -1\n\n            if ''file'' != o.type and ''device'' != o.type:\n                print "You need specify test type [''file'' or ''device'']"\n                return -1\n\n            do_fiotest(o.type, o.path, o.output)\n            print "Test done!"\n            \n\n        if __name__ == ''__main__'':\n            main()\n\n    getopt          [解析参数]\n    \n        import sys,os\n        import getopt\n\n        try:\n            options,argsErr = getopt.getopt(sys.argv[1:],"hu:c:",["help","user=","cmd="])    # 中间短参数，后面长参数对应. 不带:或=代表不带参数\n        except getopt.GetoptError:\n            print "Unknown parameters,More info with: %s -h" %(sys.argv[0])\n            sys.exit(2)\n        if argsErr != []:\n            print "Unknown parameters,More info with: %s -h" %(sys.argv[0])\n            sys.exit(2)\n\n        for o,a in  options:\n            if o in ("-h","--help"):\n                print ''''''Usage: python te.py -u user -c "cmd -options" ''''''\n                sys.exit(2)\n            if o in ("-u","--user"):\n                user = a\n            if o in ("-c","--cmd"):\n                cmd = a\n        print user,cmd\n\n    argparse        [命令行选项和参数解析库]\n\n        import argparse\n        parser = argparse.ArgumentParser( prog=''usage_name'', description=''开头打印'', epilog="结束打印")\n        parser.add_argument(''-f'', ''--foo'', help=''foo help'', action=''append'')      # 可选参数,如使用此参数必须传值 action=''store_true'' 不加参数为True  action=''append'' 多个参数可叠加为列表\n        parser.add_argument(''--aa'', type=int, default=42, help=''aa!'')             # type规定参数类型,default设置默认值\n        parser.add_argument(''bar'', nargs=''*'', default=[1, 2, 3], help=''BAR!'')     # 位置参数 必须传递  nargs=2 需要传递2个参数\n        parser.add_argument(''args'', nargs=argparse.REMAINDER)                     # 剩余参数收集到列表\n        parser.print_help()                                                       # 打印使用帮助\n        #parser.parse_args(''BAR --foo FOO''.split())                               # 设置位置参数\n        args = parser.parse_args()                                                # 全部的值\n        parser.get_default(''foo'')                                                 # 获取\n\n        python a.py --foo ww  --aa 40 xuesong 27                                  # 执行此脚本\n\n    base64          [编码]\n\n        # 简单但容易被直接破解\n        import base64\n        s1 = base64.encodestring(''hello world'')\n        s2 = base64.decodestring(s1)\n\n    uu              [对文件uu编码]\n\n        import uu\n        uu.encode(''in_file'',''out_file'')       # 编码\n        uu.decode(''in_file'',''out_file'')       # 解码\n\n    binascii        [ascii和二进制编码转换]\n\n    md5             [单向MD5加密]\n\n        import md5\n        m = md5.new(''123456'').hexdigest()\n\n    hashlib         [hash算法库]\n\n        import hashlib\n        m = hashlib.md5()\n        m.update("Nobody inspects")    # 使用update方法对字符串md5加密\n        m.digest()                     # 加密后二进制结果\n        m.hexdigest()                  # 加密后十进制结果\n        hashlib.new("md5", "string").hexdigest()               # 对字符串加密\n        hashlib.new("md5", open("file").read()).hexdigest()    # 查看文件MD5值\n\n        hashlib.sha224("Nobody inspects the spammish repetition").hexdigest()       # 几种hash算法 sha1  sha224  sha256  sha384  ha512\n\n    crypt           [单向加密]\n\n        import crypt\n        import random,string\n\n        def getsalt(chars = string.letters+string.digits):\n            return random.choice(chars)+random.choice(chars)\n        salt = getsalt()\n        print salt\n        print crypt.crypt(''bananas'',salt)\n\n    pycrypto        [加密]\n\n        # https://github.com/dlitz/pycrypto\n        SHA256  # 不可逆散列算法加密\n            from Crypto.Hash import SHA256\n            hash = SHA256.new()\n            hash.update(''message'')\n            hash.digest()\n            \n        AES     # 可逆加密,需要密钥\n            from Crypto.Cipher import AES\n            obj = AES.new(''This is a key123'', AES.MODE_CBC, ''This is an IV456'')\n            message = "The answer is no"\n            ciphertext = obj.encrypt(message)\n            ciphertext\n            ''\\xd6\\x83\\x8dd!VT\\x92\\xaa`A\\x05\\xe0\\x9b\\x8b\\xf1''\n            obj2 = AES.new(''This is a key123'', AES.MODE_CBC, ''This is an IV456'')\n            obj2.decrypt(ciphertext)\n            ''The answer is no''\n\n    rsa             [公钥加密算法]\n    \n        http://www.heikkitoivonen.net/m2crypto/api/M2Crypto.RSA.RSA-class.html\n\n        pip install M2Crypto\n        \n        from M2Crypto import RSA,BIO                         # help(RSA)\n        rsa = RSA.gen_key(2048, ''sha1'')                      # 设置生成密钥为2048位,1024较不安全,默认算法sha1\n        rsa.save_key(''rsa.priv.pem'', None )                  # 生成私钥pem文件\n        rsa.save_pub_key(''rsa.pub.pem'')                      # 生成公钥pem文件\n        rsa.save_key_bio()                                   # 私钥保存到pem格式的M2Crypto.BIO.BIO对象\n        rsa.save_pub_key_bio()                               # 公钥保存到pem格式的M2Crypto.BIO.BIO对象\n        priv=RSA.load_key(''rsa.priv.pem'')                    # 加载私钥文件\n        pub=RSA.load_pub_key(''rsa.pub.pem'')                  # 加载公钥文件\n        rsa.check_key()                                      # 检查key是否初始化\n        pub_key.public_encrypt(''data'',RSA.pkcs1_padding)     # 公钥加密\n        priv_key.private_decrypt(''密文'',RSA.pkcs1_padding)   # 私钥解密\n\n        from M2Crypto import RSA,BIO\n\n        rsa = RSA.gen_key(2048, 3, lambda *agr:None)\n        pub_bio = BIO.MemoryBuffer()\n        priv_bio = BIO.MemoryBuffer()\n\n        rsa.save_pub_key_bio(pub_bio)\n        rsa.save_key_bio(priv_bio, None)\n\n        # print pub_bio.read_all()\n        pub_key = RSA.load_pub_key_bio(pub_bio)\n        priv_key = RSA.load_key_bio(priv_bio)\n\n        message = ''i am luchanghong''\n\n        encrypted = pub_key.public_encrypt(message, RSA.pkcs1_padding)        # 加密\n        decrypted = priv_key.private_decrypt(encrypted, RSA.pkcs1_padding)    # 解密\n\n        print decrypted\n\n    getpass         [隐藏输入密码]\n\n        import getpass\n        passwd=getpass.getpass()\n\n    string          [字符串类]\n\n        import string\n        string.ascii_letters   # a-zA-Z  ascii的不受语言系统环境变化\n        string.ascii_lowercase # a-z\n        string.letters         # a-zA-Z  受系统语言环境变化影响\n        string.lowercase       # a-z \n        string.uppercase       # A-Z大小\n        string.digits          # 0-9\n        string.printable       # 所有字符\n        string.whitespace      # 空白字符\n\n    paramiko        [ssh客户端]\n\n        安装\n            sudo apt-get install python-setuptools \n            easy_install\n            sudo apt-get install python-all-dev\n            sudo apt-get install build-essential\n\n        paramiko实例(账号密码登录执行命令)\n\n            #!/usr/bin/python\n            #ssh\n            import paramiko\n            import sys,os\n\n            host = ''10.152.15.200''\n            user = ''peterli''\n            password = ''123456''\n\n            s = paramiko.SSHClient()                                 # 绑定实例\n            s.load_system_host_keys()                                # 加载本地HOST主机文件\n            s.set_missing_host_key_policy(paramiko.AutoAddPolicy())  # 允许连接不在know_hosts文件中的主机\n            s.connect(host,22,user,password,timeout=5)               # 连接远程主机\n            while True:\n                    cmd=raw_input(''cmd:'')\n                    stdin,stdout,stderr = s.exec_command(cmd)        # 执行命令\n                    cmd_result = stdout.read(),stderr.read()         # 读取命令结果\n                    for line in cmd_result:\n                            print line,\n            s.close()\n\n        paramiko实例(传送文件)\n\n            #!/usr/bin/evn python\n            import os\n            import paramiko\n            host=''127.0.0.1''\n            port=22\n            username = ''peterli''\n            password = ''123456''\n            ssh=paramiko.Transport((host,port))\n            privatekeyfile = os.path.expanduser(''~/.ssh/id_rsa'') \n            mykey = paramiko.RSAKey.from_private_key_file( os.path.expanduser(''~/.ssh/id_rsa''))   # 加载key 不使用key可不加\n            ssh.connect(username=username,password=password)           # 连接远程主机\n            # 使用key把 password=password 换成 pkey=mykey\n            sftp=paramiko.SFTPClient.from_transport(ssh)               # SFTP使用Transport通道\n            sftp.get(''/etc/passwd'',''pwd1'')                             # 下载 两端都要指定文件名\n            sftp.put(''pwd'',''/tmp/pwd'')                                 # 上传\n            sftp.close()\n            ssh.close()\n\n        paramiko实例(密钥执行命令)\n\n            #!/usr/bin/python\n            #ssh\n            import paramiko\n            import sys,os\n            host = ''10.152.15.123''\n            user = ''peterli''\n            s = paramiko.SSHClient()\n            s.load_system_host_keys()\n            s.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n            privatekeyfile = os.path.expanduser(''~/.ssh/id_rsa'')             # 定义key路径\n            mykey = paramiko.RSAKey.from_private_key_file(privatekeyfile)\n            # mykey=paramiko.DSSKey.from_private_key_file(privatekeyfile,password=''061128'')   # DSSKey方式 password是key的密码\n            s.connect(host,22,user,pkey=mykey,timeout=5)\n            cmd=raw_input(''cmd:'')\n            stdin,stdout,stderr = s.exec_command(cmd)\n            cmd_result = stdout.read(),stderr.read()\n            for line in cmd_result:\n                    print line,\n            s.close()\n\n        ssh并发(Pool控制最大并发)\n\n            #!/usr/bin/env python\n            #encoding:utf8\n            #ssh_concurrent.py\n\n            import multiprocessing\n            import sys,os,time\n            import paramiko\n\n            def ssh_cmd(host,port,user,passwd,cmd):\n                msg = "-----------Result:%s----------" % host\n\n                s = paramiko.SSHClient()\n                s.load_system_host_keys()\n                s.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n                try:\n                    s.connect(host,22,user,passwd,timeout=5) \n                    stdin,stdout,stderr = s.exec_command(cmd)\n\n                    cmd_result = stdout.read(),stderr.read()\n                    print msg\n                    for line in cmd_result:\n                            print line,\n\n                    s.close()\n                except paramiko.AuthenticationException:\n                    print msg\n                    print ''AuthenticationException Failed''\n                except paramiko.BadHostKeyException:\n                    print msg\n                    print "Bad host key"    \n\n            result = []\n            p = multiprocessing.Pool(processes=20)\n            cmd=raw_input(''CMD:'')\n            f=open(''serverlist.conf'')\n            list = f.readlines()\n            f.close()\n            for IP in list:\n                print IP\n                host=IP.split()[0]\n                port=int(IP.split()[1])\n                user=IP.split()[2]\n                passwd=IP.split()[3]\n                result.append(p.apply_async(ssh_cmd,(host,port,user,passwd,cmd)))\n\n            p.close()\n\n            for res in result:\n                res.get(timeout=35)\n\n        ssh并发(取文件状态并发送邮件)\n\n            #!/usr/bin/python\n            #encoding:utf8\n            #config file: ip.list\n\n            import paramiko\n            import multiprocessing\n            import smtplib\n            import sys,os,time,datetime,socket,re\n            from email.mime.text import MIMEText\n\n            # 配置文件(IP列表)\n            Conf = ''ip.list''\n            user_name = ''peterli''\n            user_pwd = ''passwd''\n            port = 22\n            PATH = ''/home/peterli/''\n\n            # 设置服务器名称、用户名、密码以及邮件后缀 \n            mail_host = "smtp.163.com"\n            mail_user = "xuesong"\n            mail_pass = "mailpasswd"\n            mail_postfix = "163.com"\n            mailto_list = ["272121935@qq.com","quanzhou722@163.com"]\n            title = ''file check''\n\n            DATE1=(datetime.datetime.now() + datetime.timedelta(days=-1) ).strftime(''%Y%m%d'')\n            file_path = ''%s%s'' %(PATH,DATE1)\n\n            def Ssh_Cmd(file_path,host_ip,user_name,user_pwd,port=22):\n\n                s = paramiko.SSHClient()\n                s.load_system_host_keys()\n                s.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n                \n                try:\n                    s.connect(hostname=host_ip,port=port,username=user_name,password=user_pwd)\n                    stdin,stdout,stderr = s.exec_command(''stat %s'' %file_path)\n                    stat_result = ''%s%s'' %(stdout.read(),stderr.read())\n                    if stat_result.find(''No such file or directory'') == -1:\n                        file_status = ''OK\\t''\n                        stdin,stdout,stderr = s.exec_command(''du -sh %s'' %file_path)\n                        cmd1_result = ''%s_%s'' %(stat_result.split()[32],stat_result.split()[33].split(''.'')[0])\n                        cmd2_result = (''%s%s'' %(stdout.read(),stderr.read())).split()[0] \n                    else:\n                        file_status = ''未生成\\t''\n                        cmd1_result = ''null''\n                        cmd2_result = ''null''\n                    q.put([''Login successful''])\n                    s.close()\n                except socket.error:\n                    file_status = ''主机或端口错误''\n                    cmd1_result = ''-''\n                    cmd2_result = ''-''\n                except paramiko.AuthenticationException:\n                    file_status = ''用户或密码错误''\n                    cmd1_result = ''-''\n                    cmd2_result = ''-''\n                except paramiko.BadHostKeyException:\n                    file_status = ''Bad host key''\n                    cmd1_result = ''-''\n                    cmd2_result = ''-''\n                except:\n                    file_status = ''ssh异常''\n                    cmd1_result = ''-''\n                    cmd2_result = ''-''\n                r.put(''%s\\t-\\t%s\\t%s\\t%s\\t%s\\n'' %(time.strftime(''%Y-%m-%d_%H:%M''),host_ip,file_status,cmd2_result,cmd1_result))\n\n            def Concurrent(Conf,file_path,user_name,user_pwd,port):\n                # 执行总计\n                total = 0\n                # 读取配置文件\n                f=open(Conf)\n                list = f.readlines()\n                f.close()\n                # 并发执行\n                process_list = []\n                log_file = file(''file_check.log'', ''w'')\n                log_file.write(''检查时间\\t\\t业务\\tIP\\t\\t文件状态\\t大小\\t生成时间\\n'') \n                for host_info in list:\n                    # 判断配置文件中注释行跳过\n                    if host_info.startswith(''#''):\n                        continue\n                    # 取变量,其中任意变量未取到就跳过执行\n                    try:\n                        host_ip=host_info.split()[0].strip()\n                        #user_name=host_info.split()[1]\n                        #user_pwd=host_info.split()[2]\n                    except:\n                        log_file.write(''Profile error: %s\\n'' %(host_info))\n                        continue\n                    #try:\n                    #    port=int(host_info.split()[3])\n                    #except:\n                    #    port=22\n                    total +=1\n                    p = multiprocessing.Process(target=Ssh_Cmd,args=(file_path,host_ip,user_name,user_pwd,port))\n                    p.start()\n                    process_list.append(p)\n                for j in process_list:\n                    j.join()\n                for j in process_list:\n                    log_file.write(r.get())\n\n                successful = q.qsize()\n                log_file.write(''执行完毕。 总执行:%s 登录成功:%s 登录失败:%s\\n'' %(total,successful,total - successful))\n                log_file.flush()\n                log_file.close()\n\n            def send_mail(to_list, sub):\n                me = mail_user + "<"+mail_user+"@"+mail_postfix+">"\n                fp = open(''file_check.log'')\n                msg = MIMEText(fp.read(),_charset="utf-8")\n                fp.close()\n                msg[''Subject''] = sub\n                msg[''From''] = me\n                msg[''To''] = ";".join(to_list)\n                try:\n                    send_smtp = smtplib.SMTP()\n                    send_smtp.connect(mail_host)\n                    send_smtp.login(mail_user, mail_pass)\n                    send_smtp.sendmail(me, to_list, msg.as_string())\n                    send_smtp.close()\n                    return True\n                except Exception, e:\n                    print str(e)[1]\n                    return False\n\n            if __name__ == ''__main__'':\n                q = multiprocessing.Queue()\n                r = multiprocessing.Queue()\n                Concurrent(Conf,file_path,user_name,user_pwd,port)\n                if send_mail(mailto_list,title):\n                    print "发送成功"\n                else:\n                    print "发送失败"\n\n    pysnmp          [snmp客户端]\n    \n        #!/usr/bin/python\n        from pysnmp.entity.rfc3413.oneliner import cmdgen\n\n        cg = cmdgen.CommandGenerator()\n\n        # 注意IP 端口 组默认public  oid值\n        varBinds = cg.getCmd( cmdgen.CommunityData(''any-agent'', ''public'',0 ), cmdgen.UdpTransportTarget((''10.10.76.42'', 161)),    (1,3,6,1,4,1,2021,10,1,3,1), )\n\n        print varBinds[3][0][1]\n\n    PDB             [单步调试]\n\n        # http://docs.python.org/2/library/pdb.html\n\n        (Pdb) h              # 帮助\n        # 断点设置 \n        (Pdb)b 10            # 断点设置在本py的第10行\n        (Pdb)b ots.py:20     # 断点设置到 ots.py第20行\n        (Pdb)b               # 查看断点编号\n        (Pdb)cl 2            # 删除第2个断点\n\n        # 运行\n        (Pdb)n               # 单步运行\n        (Pdb)s               # 细点运行 也就是会下到，方法\n        (Pdb)c               # 跳到下个断点\n        # 查看\n        (Pdb)p param         # 查看当前 变量值\n        (Pdb)l               # 查看运行到某处代码\n        (Pdb)a               # 查看全部栈内变量\n\n        python -m pdb myscript.py   # 直接对脚本单步调试\n\n        # 在程序里面加单步调试\n        import pdb\n        def tt():\n            pdb.set_trace()\n            for i in range(1, 5):\n                print i\n        >>> tt()\n        > <stdin>(3)tt()\n        (Pdb) n              #这里支持 n p c 而已\n\n    pstats          [源码性能分析测试]\n\n        import profile\n        import pstats\n\n        profile.run("run()", "prof.txt")\n        p = pstats.Stats("prof.txt")\n        p.sort_stats("time").print_stats()\n\n    apscheduler     [任务调度]\n\n        # 安装   pip install apscheduler    \n        # 例子   https://bitbucket.org/agronholm/apscheduler/src/e6298f953a68/tests/?at=master\n\n        scheduler.start()                                                   # 启动任务\n        job = scheduler.add_job(myfunc, ''interval'', minutes=2)              # 添加任务\n        job.remove()                                                        # 删除任务\n        scheduler.add_job(myfunc, ''interval'', minutes=2, id=''my_job_id'')    # 添加任务\n        scheduler.remove_job(''my_job_id'')                                   # 删除任务\n        job.modify(max_instances=6, name=''Alternate name'')                  # 修改工作\n        scheduler.shutdown()                                                # 关闭调度\n        scheduler.shutdown(wait=False)                                      # 关闭调度  不等待\n        # 暂停\n        apscheduler.job.Job.pause()\n        apscheduler.schedulers.base.BaseScheduler.pause_job()\n        # 恢复\n        apscheduler.job.Job.resume()\n        apscheduler.schedulers.base.BaseScheduler.resume_job()\n\n        定时任务\n            from pytz import utc\n            from apscheduler.schedulers.background import BackgroundScheduler\n            from apscheduler.executors.pool import ThreadPoolExecutor, ProcessPoolExecutor\n            import time\n\n            executors = {\n                ''default'': ThreadPoolExecutor(20),\n                ''processpool'': ProcessPoolExecutor(5)\n            }\n            job_defaults = {\n                ''coalesce'': False,\n                ''max_instances'': 3\n            }\n            scheduler = BackgroundScheduler( executors=executors, job_defaults=job_defaults, timezone=utc)\n\n            def myfunc():\n                print ''test''\n\n            scheduler.add_job(myfunc, ''interval'', minutes=1, id=''myworkid'')\n            scheduler.start()\n\n            try:\n                while True:\n                    time.sleep(2)\n                    # add_job\n            except (KeyboardInterrupt, SystemExit):\n                scheduler.shutdown()\n\n    logging         [日志记录]\n\n        # 日志级别大小关系为: critical > error > warning > info > debug > notset  也可自定义日志级别\n        import logging\n        logging.debug(''debug'')                 # 默认日志级别为 warning ,故debug日志不做打印\n        logging.warning(''warning'')             # 达到默认日志级别为WARNING,打印到屏幕 warning\n        logging.basicConfig                    # 通过logging.basicConfig函数对日志的输出格式及方式做相关配置\n            # basicConfig 相关参数帮助\n            filename               # 指定日志文件名\n            filemode               # 和file函数意义相同，指定日志文件的打开模式，''w''或''a''\n            datefmt                # 指定时间格式，同time.strftime()\n            level                  # 设置日志级别，默认为logging.WARNING\n            stream                 # 指定将日志的输出流，可以指定输出到sys.stderr,sys.stdout或者文件，默认输出到sys.stderr，当stream和filename同时指定时，stream被忽略\n            format                 # 指定输出的格式和内容，format可以输出很多有用信息，如上例所示:\n                %(levelno)s        # 打印日志级别的数值\n                %(levelname)s      # 打印日志级别名称\n                %(pathname)s       # 打印当前执行程序的路径，其实就是sys.argv[0]\n                %(filename)s       # 打印当前执行程序名\n                %(funcName)s       # 打印日志的当前函数\n                %(lineno)d         # 打印日志的当前行号\n                %(asctime)s        # 打印日志的时间\n                %(thread)d         # 打印线程ID\n                %(threadName)s     # 打印线程名称\n                %(process)d        # 打印进程ID\n                %(message)s        # 打印日志信息\n\n        logging.basicConfig(level=logging.DEBUG,\n                        format=''%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s'',\n                        datefmt=''%a, %d %b %Y %H:%M:%S'',\n                        filename=''myapp.log'',\n                        filemode=''w'')\n        # 日志级别warning或高于warning的会写入文件 myapp.log 中\n\n        logging.config.fileConfig("logger.conf")        # 加载配置文件\n        logger = logging.getLogger("example02")         # 使用已定义的日志记录器\n        logger.conf                                     # 配置文件\n            ###############################################\n            [loggers]\n            keys=root,example01,example02    # 设置三种日志记录器\n            [logger_root]                    # 针对单一种设置\n            level=DEBUG\n            handlers=hand01,hand02\n            [logger_example01]\n            handlers=hand01,hand02           # 使用2中处理方式 应该是根据不同级别区分的\n            qualname=example01\n            propagate=0\n            [logger_example02]\n            handlers=hand01,hand03\n            qualname=example02\n            propagate=0\n            ###############################################\n            [handlers]                      # 不同的处理方式\n            keys=hand01,hand02,hand03       # 三种方式的名字\n            [handler_hand01]                # 第一种方式配置\n            class=StreamHandler             # 发送错误信息到流\n            level=INFO                      # 日志级别\n            formatter=form02                # 日志的格式方式\n            args=(sys.stderr,)\n            [handler_hand02]\n            class=FileHandler               # FileHandler写入磁盘文件\n            level=DEBUG\n            formatter=form01\n            args=(''myapp.log'', ''a'')         # 追加到日志文件\n            [handler_hand03]\n            class=handlers.RotatingFileHandler\n            level=INFO\n            formatter=form02\n            args=(''myapp.log'', ''a'', 10*1024*1024, 5)    # 追加日志并切割日志\n            ###############################################\n            [formatters]                                # 针对不同处理日志方式设置具体的日志格式\n            keys=form01,form02\n            [formatter_form01]\n            format=%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s    # 日志列\n            datefmt=%a, %d %b %Y %H:%M:%S               # 时间格式\n            [formatter_form02]\n            format=%(name)-12s: %(levelname)-8s %(message)s\n            datefmt=\n\n    ConfigParser    [配置解析]\n    \n        写入配置文件\n    \n            import ConfigParser\n            config = ConfigParser.RawConfigParser()\n            config.add_section(''Section1'')                          # 添加配置文件的块 [name]\n            config.set(''Section1'', ''an_int'', ''15'')                  # 针对块设置配置参数和值\n            config.set(''Section1'', ''a_bool'', ''true'')\n            config.set(''Section1'', ''a_float'', ''3.1415'')\n            config.set(''Section1'', ''baz'', ''fun'')\n            config.set(''Section1'', ''bar'', ''Python'')\n            config.set(''Section1'', ''foo'', ''%(bar)s is %(baz)s!'')\n            with open(''example.cfg'', ''wb'') as configfile:           # 指定配置文件路径\n                config.write(configfile)                            # 写入配置文件\n\n        读取配置文件\n\n            import ConfigParser\n            config = ConfigParser.RawConfigParser()\n            config.read(''example.cfg'')                              # 读取配置文件\n            a_float = config.getfloat(''Section1'', ''a_float'')        # 获取配置文件参数对应的浮点值,如参数值类型不对则报ValueError\n            an_int = config.getint(''Section1'', ''an_int'')            # 获取配置文件参数对应的整数值,可直接进行计算\n            print a_float + an_int\n            if config.getboolean(''Section1'', ''a_bool''):             # 根据配置文件参数值是否为真\n                print config.get(''Section1'', ''foo'')                 # 再获取依赖的配置参数 get获取后值为字符串\n            print config.get(''Section1'', ''foo'', 0)                  # 获取配置文件参数的同时加载变量[配置文件中的参数]\n            print config.get(''Section1'', ''foo'', 1)                  # 获取配置文件参数 原始值不做任何改动 不使用变量\n            config.remove_option(''Section1'', ''bar'')                 # 删除读取配置文件获取bar的值\n            config.remove_option(''Section1'', ''baz'')\n            print config.get(''Section1'', ''foo'', 0, {''bar'': ''str1'', ''baz'': ''str1''})    # 读取配置参数的同时设置变量的值\n    \n    \n        import ConfigParser\n        import io\n\n        sample_config = """\n        [mysqld]\n        user = mysql\n        pid-file = /var/run/mysqld/mysqld.pid\n        skip-external-locking\n        old_passwords = 1\n        skip-bdb\n        skip-innodb\n        """\n        config = ConfigParser.RawConfigParser(allow_no_value=True)\n        config.readfp(io.BytesIO(sample_config))\n        config.get("mysqld", "user")\n\n    ftplib          [ftp客户端]\n\n        from ftplib import FTP\n        ftp = FTP(''ftp.debian.org'')     # 连接ftp地址   FTP(host,port,timeout)\n        ftp.login()                     # 使用默认anonymous登录  login(user,passwd) \n        ftp.cwd(''debian'')               # 切换到目录debian\n        ftp.retrlines(''LIST'')           # 打印目录列表\n        ftp.retrbinary(''RETR README'', open(''README'', ''wb'').write)       # 下载文件写到本地\n        ftp.delete(''filename'')          # 删除ftp中文件\n        ftp.mkd(''dirname'')              # 在ftp上创建目录\n        ftp.size(''filename'')            # 查看文件大小\n        ftp.quit() \n\n    difflib         [对象比较]\n\n        import difflib\n        s1 = [''bacon\\n'', ''eggs\\n'', ''ham\\n'', ''guido\\n'']\n        s2 = [''python\\n'', ''eggy\\n'', ''hamster\\n'', ''guido\\n'']\n        for line in difflib.context_diff(s1, s2, fromfile=''txt-s1'', tofile=''txt-s2''):    # 两字列表比较差异\n            sys.stdout.write(line)\n\n        difflib.get_close_matches(''appel'', [''ape'', ''apple'', ''peach'', ''puppy''])           # 模糊匹配 匹配列表与字符串相似的值，越相似越靠前\n\n    heapq           [优先队列算法]\n\n        from heapq import *\n        h = []\n        heappush(h, (5, ''write code''))          # 放入队列\n        heappush(h, (7, ''release product''))\n        heappush(h, (1, ''write spec''))\n        heappush(h, (3, ''create tests''))\n        heappop(h)                              # 从队列取出 第一次是1\n\n        from heapq import *\n        def heapsort(iterable):\n            h = []\n            for value in iterable:\n                heappush(h, value)\n            return [heappop(h) for i in range(len(h))]\n\n        heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])\n\n    linecache       [随机读取指定行]\n\n        import linecache\n        linecache.getline(''/etc/passwd'', 4)\n\n    json            [数据交换格式]\n\n        #!/usr/bin/python\n        import json\n\n        #json file temp.json\n        #{ "name":"00_sample_case1", "description":"an example."}\n\n        f = file("temp.json");\n        s = json.load(f)        # 直接读取json文件\n        print s\n        f.close\n\n        d = {"a":1}\n        j=json.dumps(d)  # 字典转json\n        json.loads(j)    # json转字典\n        \n        s = json.loads(''{"name":"test", "type":{"name":"seq", "parameter":["1", "2"]}}'')\n        print type(s)    # dic\n        print s\n        print s.keys()\n        print s["type"]["parameter"][1]\n        \n        json.dumps({''ret'':''cmd_ret0'', ''out'':''cmd_ret1''}, separators=('','', '':''))    # 紧凑的json格式,去掉空格\n\n    filecmp         [文件目录比较]\n\n        filecmp.cmp(''/etc/passwd'', ''/etc/passwd'')     # 比较两文件是否一致\n\n        # 比较两目录下文件是否一致\n        from filecmp import dircmp\n        def print_diff_files(dcmp):\n            for name in dcmp.diff_files:\n                print "diff_file %s found in %s and %s" % (name, dcmp.left, dcmp.right)\n            for sub_dcmp in dcmp.subdirs.values():\n                print_diff_files(sub_dcmp)\n\n        dcmp = dircmp(''dir1'', ''dir2'') \n        print_diff_files(dcmp) \n\n    errno           [符号错误码]\n\n        https://docs.python.org/2/library/errno.html#module-errno\n        \n        import errno\n\n        try:\n            fp = open("no.such.file")\n        except IOError, (error, message):\n            if error == errno.ENOENT:\n                print "no such file"\n            elif error == errno.EPERM:\n                print "permission denied"\n            else:\n                print message\n\n    Exceptions      [标准异常类]\n\n        # 详见官网 不需要导入\n        https://docs.python.org/2/library/exceptions.html#module-exceptions\n\n    ctypes          [调用C的动态库]\n        \n        提供和C语言兼容的数据类型,也可调用C的动态库\n\n        http://blog.csdn.net/linda1000/article/details/12623527\n        http://www.cnblogs.com/wuchang/archive/2010/04/04/1704456.html\n        http://www.ibm.com/developerworks/cn/linux/l-cn-pythonandc/\n\n    daemon          [守护进程]\n\n        daemon.py\n\n            # 创建守护进程的模块\n            #!/usr/bin/env python\n\n            import sys, os, time, atexit\n            from signal import SIGTERM\n\n            class Daemon:\n                """\n                A generic daemon class.\n               \n                Usage: subclass the Daemon class and override the run() method\n                """\n                def __init__(self, pidfile=''nbMon.pid'', stdin=''/dev/null'', stdout=''nbMon.log'', stderr=''nbMon.log''):\n                    self.stdin = stdin\n                    self.stdout = stdout\n                    self.stderr = stderr\n                    self.pidfile = pidfile\n               \n                def daemonize(self):\n                    """\n                    do the UNIX double-fork magic, see Stevens'' "Advanced\n                    Programming in the UNIX Environment" for details (ISBN 0201563177)\n                    http://www.erlenstar.demon.co.uk/unix/faq_2.html#SEC16\n                    """\n                    try:\n                        pid = os.fork()\n                        if pid > 0:\n                            # exit first parent\n                            sys.exit(0)\n                    except OSError, e:\n                        sys.stderr.write("fork #1 failed: %d (%s)\\n" % (e.errno, e.strerror))\n                        sys.exit(1)\n               \n                    # decouple from parent environment\n                    #os.chdir("/")\n                    os.setsid()\n                    os.umask(0)\n               \n                    # do second fork\n                    try:\n                        pid = os.fork()\n                        if pid > 0:\n                            # exit from second parent\n                            sys.exit(0)\n                    except OSError, e:\n                        sys.stderr.write("fork #2 failed: %d (%s)\\n" % (e.errno, e.strerror))\n                        sys.exit(1)\n               \n                    # redirect standard file descriptors\n                    sys.stdout.flush()\n                    sys.stderr.flush()\n                    si = file(self.stdin, ''r'')\n                    so = file(self.stdout, ''a+'')\n                    se = file(self.stderr, ''a+'', 0)\n                    os.dup2(si.fileno(), sys.stdin.fileno())\n                    os.dup2(so.fileno(), sys.stdout.fileno())\n                    os.dup2(se.fileno(), sys.stderr.fileno())\n               \n                    # write pidfile\n                    atexit.register(self.delpid)\n                    pid = str(os.getpid())\n                    file(self.pidfile,''w+'').write("%s\\n" % pid)\n               \n                def delpid(self):\n                    os.remove(self.pidfile)\n\n                def start(self):\n                    """\n                    Start the daemon\n                    """\n                    # Check for a pidfile to see if the daemon already runs\n                    try:\n                        pf = file(self.pidfile,''r'')\n                        pid = int(pf.read().strip())\n                        pf.close()\n                    except IOError:\n                        pid = None\n               \n                    if pid:\n                        message = "pidfile %s already exist. Daemon already running?\\n"\n                        sys.stderr.write(message % self.pidfile)\n                        sys.exit(1)\n                   \n                    # Start the daemon\n                    self.daemonize()\n                    self.run()\n\n                def stop(self):\n                    """\n                    Stop the daemon\n                    """\n                    # Get the pid from the pidfile\n                    try:\n                        pf = file(self.pidfile,''r'')\n                        pid = int(pf.read().strip())\n                        pf.close()\n                    except IOError:\n                        pid = None\n               \n                    if not pid:\n                        message = "pidfile %s does not exist. Daemon not running?\\n"\n                        sys.stderr.write(message % self.pidfile)\n                        return # not an error in a restart\n\n                    # Try killing the daemon process       \n                    try:\n                        while 1:\n                            os.kill(pid, SIGTERM)\n                            time.sleep(0.1)\n                    except OSError, err:\n                        err = str(err)\n                        if err.find("No such process") > 0:\n                            if os.path.exists(self.pidfile):\n                                os.remove(self.pidfile)\n                        else:\n                            print str(err)\n                            sys.exit(1)\n\n                def restart(self):\n                    """\n                    Restart the daemon\n                    """\n                    self.stop()\n                    self.start()\n\n                def run(self):\n                    """\n                    You should override this method when you subclass Daemon. It will be called after the process has been\n                    daemonized by start() or restart().\n                    """\n\n        run_daemon.py\n        \n            # 启动脚本,倒入需要后台启动的模块,继承Daemon类,覆盖run函数\n            # 启动方式  python run_daemon.py start\n\n            #!/usr/bin/env python\n            import Queue\n            import threading\n            import sys, time\n            import urllib2\n            import json\n            import framework\n            from moniItems import mon\n            from daemon import Daemon\n\n            class MyDaemon(Daemon):\n                def run(self):\n                    print ''start''\n                    framework.startTh()\n                    print ''stop2''\n             \n            if __name__ == "__main__":\n                daemon = MyDaemon()\n                if len(sys.argv) == 2:\n                    if ''start'' == sys.argv[1]:\n                        daemon.start()\n                    elif ''stop'' == sys.argv[1]:\n                        daemon.stop()\n                    elif ''restart'' == sys.argv[1]:\n                        daemon.restart()\n                    else:\n                        print "Unknown command"\n                        sys.exit(2)\n                    sys.exit(0)\n                else:\n                    print "usage: %s start|stop|restart" % sys.argv[0]\n                    sys.exit(2)\n\n    psutil          [获取系统信息]\n\n        pip install psutil                     # 安装\n\n        import psutil\n        dir(psutil)\n        psutil.boot_time()                     # 开机时间\n        psutil.virtual_memory()                # 内存详细信息\n        psutil.virtual_memory().total          # 内存总大小\n        psutil.disk_partitions()               # 获取磁盘信息\n        psutil.disk_io_counters()              # 磁盘IO信息\n        psutil.net_io_counters()               # 获取网络IO信息\n\n        psutil.pids()                          # 返回所有进程PID\n        psutil.Process(PID)                    # 获取进程信息 \n        psutil.Process(PID).name()             # 指定进程的进程名\n        psutil.Process(PID).exe()              # 进程的路径\n        psutil.Process(PID).cwd()              # 进程工作路径\n        psutil.Process(PID).status()           # 进程状态\n        psutil.Process(PID).create_time()      # 进程创建时间\n        psutil.Process(PID).memory_percent()   # 进程内存使用率\n        psutil.Process(PID).io_counters()      # 进程IO信息\n        psutil.Process(PID).num_threads()      # 进程线程数\n\n3 socket\n\n    socket.gethostname()     # 获取主机名\n    from socket import *     # 避免 socket.socket()\n    s=socket()\n    s.bind()                 # 绑定地址到套接字\n    s.listen()               # 开始TCP监听\n    s.accept()               # 被动接受TCP客户端连接，等待连接的到来\n    s.connect()              # 主动初始化TCP服务器连接\n    s.connect_ex()           # connect()函数的扩展版本，出错时返回出错码，而不是跑出异常\n    s.recv()                 # 接收TCP数据\n    s.send()                 # 发送TCP数据\n    s.sendall()              # 完整发送TCP数据\n    s.recvfrom()             # 接收UDP数据\n    s.sendto()               # 发送UDP数据\n    s.getpeername()          # 连接到当前套接字的远端的地址(TCP连接)\n    s.getsockname()          # 当前套接字的地址\n    s.getsockopt()           # 返回指定套接字的参数\n    s.setsockopt()           # 设置指定套接字的参数\n    s.close()                # 关闭套接字\n    s.setblocking()          # 设置套接字的阻塞与非阻塞模式\n    s.settimeout()           # 设置阻塞套接字操作的超时时间\n    s.gettimeout()           # 得到阻塞套接字操作的超时时间\n    s.filen0()               # 套接字的文件描述符\n    s.makefile()             # 创建一个与该套接字关联的文件对象\n\n    socket.AF_UNIX           # 只能够用于单一的Unix系统进程间通信\n    socket.AF_INET           # 服务器之间网络通信\n    socket.AF_INET6          # IPv6\n\n    socket.SOCK_STREAM       # 流式socket , for TCP\n    socket.SOCK_DGRAM        # 数据报式socket , for UDP\n    socket.SOCK_RAW          # 原始套接字，普通的套接字无法处理ICMP、IGMP等网络报文，而SOCK_RAW可以；其次，SOCK_RAW也可以处理特殊的IPv4报文；此外，利用原始套接字，可以通过IP_HDRINCL套接字选项由用户构造IP头。\n\n    socket.SOCK_RDM          # 是一种可靠的UDP形式，即保证交付数据报但不保证顺序。SOCK_RAM用来提供对原始协议的低级访问，在需要执行某些特殊操作时使用，如发送ICMP报文。SOCK_RAM通常仅限于高级用户或管理员运行的程序使用。\n\n    socket.SOCK_SEQPACKET    # 可靠的连续数据包服务\n\n    select          [IO多路复用的机制]\n\n        # select每次遍历都需要把fd集合从用户态拷贝到内核态,开销较大,受系统限制最大1024\n        select.select(rlist, wlist, xlist[, timeout])\n        # poll和select很像 通过一个pollfd数组向内核传递需要关注的事件,没有描述符1024限制\n        select.poll()\n        # 创建epoll句柄,注册监听事件,通过回调函数等待事件产生,不做主动扫描,整个过程对fd只做一次拷贝.打开最大文件数后,不受限制,1GB内存大约是10万链接\n        select.epoll([sizehint=-1])\n\n        select.epoll\n\n            EPOLLIN                # 监听可读事件\n            EPOLLET                # 高速边缘触发模式,即触发后不会再次触发直到新接收数据\n            EPOLLOUT               # 监听写事件\n\n            epoll.poll([timeout=-1[, maxevents=-1]]) # 等待事件,未指定超时时间[毫秒]则为一直阻塞等待\n            epoll.register(fd,EPOLLIN)               # 向epoll句柄中注册,新来socket链接,监听可读事件\n            epoll.modify(fd, EPOLLET | EPOLLOUT)     # 改变监听事件为边缘触发,监听写事件\n            epoll.fileno()                           # 通过链接对象得到fd\n            epoll.unregister(fd)                     # 取消fd监听事件\n\n    SocketServer\n    \n        #!/usr/bin/python\n        #server.py\n        import SocketServer\n        import os\n        class MyTCP(SocketServer.BaseRequestHandler):\n            def handle(self):\n                # 应该已经封装好了 不需要这层while了 可能会引起大量 close_wait\n                while True:\n                    self.data=self.request.recv(1024).strip()\n                    if self.data == ''quit'' or not self.data:break\n                    \n                    cmd=os.popen(self.data).read()\n                    if cmd == '''':cmd= self.data + '': Command not found''\n                    self.request.sendall(cmd)\n        if __name__ == ''__main__'':\n            HOST,PORT = ''10.0.0.119'',50007\n            server = SocketServer.ThreadingTCPServer((HOST,PORT),MyTCP)\n            server.serve_forever()\n\n    SocketClient\n\n        #!/usr/bin/python\n        #client.py\n        import socket\n\n        HOST=''10.0.0.119''\n        PORT=50007\n        s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n        s.connect((HOST,PORT))\n\n        while True:\n            while True:\n                cmd=raw_input(''CMD:'').strip()\n                if cmd != '''':break\n            s.sendall(cmd)      \n            data=s.recv(1024).split(''\\n'')\n            print ''cmd:''\n            for line in data:print line\n        s.close()\n\n    ftp\n\n        ftpserver\n\n            #!/usr/bin/python\n            #ftpserver.py\n\n            import SocketServer\n            import os\n            import cPickle\n            import md5\n            from time import sleep\n\n            def filer(file1):\n                try:\n                    f = file(file1,''rb'')\n                    return cPickle.load(f)\n                except IOError:\n                    return {}\n                except EOFError:\n                    return {}\n                f.close()\n\n            def filew(file1,content):\n                f = file(file1,''wb'')\n                cPickle.dump(content,f)\n                f.close()\n\n            class MyTCP(SocketServer.BaseRequestHandler):\n                def handle(self):\n                    i = 0\n                    while i<3:\n                        user=self.request.recv(1024).strip()\n                        userinfo=filer(''user.pkl'')\n                        if userinfo.has_key(user.split()[0]):\n                            if md5.new(user.split()[1]).hexdigest() == userinfo[user.split()[0]]:\n                                results=''login successful''\n                                self.request.sendall(results)\n                                login=''successful''\n                                break\n                            else:\n                                i = i + 1\n                                results=''Error:password not correct''\n                                self.request.sendall(results)\n                                continue\n                        else:\n                            i = i + 1\n                            results=''Error:password not correct''\n                            self.request.sendall(results)\n                            continue\n                        break\n                    else:\n                        results = ''Error:Wrong password too many times''\n                        self.request.sendall(results)\n                        login=''failure''\n                    home_path = os.popen(''pwd'').read().strip() + ''/'' + user.split()[0]\n                    current_path = ''/''\n                    print home_path\n                    while True:\n                        if login == ''failure'':\n                            break\n                        print ''home_path:%s=current_path:%s'' %(home_path,current_path)\n                        cmd=self.request.recv(1024).strip()\n                        print cmd\n                        if cmd == ''quit'':\n                            break\n                        elif cmd == ''dir'':\n                            list=os.listdir(''%s%s'' %(home_path,current_path))\n                            if list:\n                                dirlist,filelist = '''',''''\n                                for i in list:\n                                    if os.path.isdir(''%s%s%s'' %(home_path,current_path,i)):\n                                        dirlist = dirlist + ''\\033[32m'' + i + ''\\033[m\\t''\n                                    else:\n                                        filelist = filelist + i + ''\\t''\n                                results = dirlist + filelist\n                            else:\n                                results = ''\\033[31mnot find\\033[m''\n                            self.request.sendall(results)\n                        elif cmd == ''pdir'':\n                            self.request.sendall(current_path)\n                        elif cmd.split()[0] == ''mdir'':\n                            if cmd.split()[1].isalnum():\n                                tmppath=''%s%s%s'' %(home_path,current_path,cmd.split()[1])\n                                os.makedirs(tmppath)\n                                self.request.sendall(''\\033[32mcreating successful\\033[m'')\n                            else:\n                                self.request.sendall(''\\033[31mcreate failure\\033[m'')\n                        elif cmd.split()[0] == ''cdir'':\n                            if cmd.split()[1] == ''/'':\n                                tmppath=''%s%s'' %(home_path,cmd.split()[1])\n                                if os.path.isdir(tmppath):\n                                    current_path = cmd.split()[1]\n                                    self.request.sendall(current_path)\n                                else:\n                                    self.request.sendall(''\\033[31mnot_directory\\033[m'')\n                            elif cmd.split()[1].startswith(''/''):\n                                tmppath=''%s%s'' %(home_path,cmd.split()[1])\n                                if os.path.isdir(tmppath):\n                                    current_path = cmd.split()[1] + ''/''\n                                    self.request.sendall(current_path)\n                                else:\n                                    self.request.sendall(''\\033[31mnot_directory\\033[m'')\n                            else:\n                                tmppath=''%s%s%s'' %(home_path,current_path,cmd.split()[1])\n                                if os.path.isdir(tmppath):\n                                    current_path = current_path + cmd.split()[1] + ''/''\n                                    self.request.sendall(current_path)\n                                else:\n                                    self.request.sendall(''\\033[31mnot_directory\\033[m'')\n                        elif cmd.split()[0] == ''get'':\n                            if os.path.isfile(''%s%s%s'' %(home_path,current_path,cmd.split()[1])):\n                                f = file(''%s%s%s'' %(home_path,current_path,cmd.split()[1]),''rb'')\n                                self.request.sendall(''ready_file'')\n                                sleep(0.5)\n                                self.request.send(f.read())\n                                f.close()\n                                sleep(0.5)\n                            elif os.path.isdir(''%s%s%s'' %(home_path,current_path,cmd.split()[1])):\n                                self.request.sendall(''ready_dir'')\n                                sleep(0.5)\n                                for dirpath in os.walk(''%s%s%s'' %(home_path,current_path,cmd.split()[1])):\n                                    dir=dirpath[0].replace(''%s%s'' %(home_path,current_path),'''',1)\n                                    self.request.sendall(dir)\n                                    sleep(0.5)\n                                    for filename in dirpath[2]:\n                                        self.request.sendall(filename)\n                                        sleep(0.5)\n                                        f = file(''%s/%s'' %(dirpath[0],filename),''rb'')\n                                        self.request.send(f.read())\n                                        f.close()\n                                        sleep(0.5)\n                                        self.request.sendall(''file_get_done'')\n                                        sleep(0.5)\n                                    else:\n                                        self.request.sendall(''dir_get_done'')\n                                    sleep(0.5)\n                            else:\n                                self.request.sendall(''get_failure'')\n                                continue\n                            self.request.sendall(''get_done'')\n                    \n                        elif cmd.split()[0] == ''send'':\n                            if os.path.exists(''%s%s%s'' %(home_path,current_path,cmd.split()[1])):\n                                self.request.sendall(''existing'')\n                                action=self.request.recv(1024)\n                                if action == ''cancel'':\n                                    continue\n                            self.request.sendall(''ready'')\n                            msg=self.request.recv(1024)\n                            if msg == ''ready_file'':\n                                f = file(''%s%s%s'' %(home_path,current_path,cmd.split()[1]),''wb'')\n                                while True:\n                                    data=self.request.recv(1024)\n                                    if data == ''file_send_done'':break\n                                    f.write(data)\n                                f.close()\n\n                            elif msg == ''ready_dir'':\n                                os.system(''mkdir -p %s%s%s'' %(home_path,current_path,cmd.split()[1]))\n                                while True:\n                                    dir=self.request.recv(1024)\n                                    if dir == ''get_done'':break\n                                    os.system(''mkdir -p %s%s%s'' %(home_path,current_path,dir))\n                                    while True:\n                                        filename=self.request.recv(1024)\n                                        if filename == ''dir_send_done'':break\n                                        f = file(''%s%s%s/%s'' %(home_path,current_path,dir,filename),''wb'')\n                                        while True:\n                                            data=self.request.recv(1024)\n                                            if data == ''file_send_done'':break \n                                            f.write(data)\n                                        f.close()\n                                        self.request.sendall(''%s/%s\\t\\033[32mfile_done\\033[m'' %(dir,filename))\n                                    self.request.sendall(''%s\\t\\033[32mdir_done\\033[m'' %(dir))\n                            elif msg == ''unknown_file'':\n                                continue\n                            \n                        else:\n                            results = cmd.split()[0] + '': Command not found''\n                            self.request.sendall(results)\n\n            if __name__ == ''__main__'':\n                HOST,PORT = ''10.152.14.85'',50007\n                server = SocketServer.ThreadingTCPServer((HOST,PORT),MyTCP)\n                server.serve_forever()\n\n        ftpmanage\n\n            #!/usr/bin/python\n            #manage_ftp.py\n            import cPickle\n            import sys\n            import md5\n            import os\n            import getpass\n\n            def filer(file1):\n                try:\n                    f = file(file1,''rb'')\n                    return cPickle.load(f)\n                except IOError:\n                    return {}\n                except EOFError:\n                    return {}\n                f.close()\n\n            def filew(file1,content):\n                f = file(file1,''wb'')\n                cPickle.dump(content,f)\n                f.close()\n\n            while True:\n                print ''''''\n                1.add user\n                2.del user\n                3.change password\n                4.query user\n                0.exit\n                ''''''\n                i = raw_input('':'').strip()\n                userinfo=filer(''user.pkl'')\n                if i == '''':\n                    continue\n                elif i == ''1'':\n                    while True:\n                        user=raw_input(''user name:'').strip()\n                        if user.isalnum():\n                            i = 0\n                            while i<3:\n                                passwd=getpass.getpass(''passwd:'').strip()\n                                if passwd == '''':\n                                    continue\n                                else:\n                                    passwd1=getpass.getpass(''Confirm password:'').strip()\n                                    if passwd == passwd1:\n                                        mpasswd = md5.new(passwd).hexdigest()\n                                        userinfo[user] = mpasswd\n                                        os.system(''mkdir -p %s'' %user)\n                                        print ''%s creating successful '' %user\n                                        break\n                                    else:\n                                        print "Passwords don''t match "\n                                        i = i + 1\n                                        continue\n                            else:\n                                print ''Too many wrong''\n                                continue\n                            break\n                        else:\n                            print ''user not legal''\n                            continue\n                elif i == ''2'':\n                    user=raw_input(''user name:'').strip()\n                    if userinfo.has_key(user):\n                        del userinfo[user]\n                        print ''Delete users successfully''\n                    else:\n                        print ''user not exist''\n                        continue\n                elif i == ''3'':\n                    user=raw_input(''user name:'').strip()\n                    if userinfo.has_key(user):\n                        i = 0\n                        while i<3:\n                            passwd=getpass.getpass(''passwd:'').strip()\n                            if passwd == '''':\n                                continue\n                            else:\n                                passwd1=getpass.getpass(''Confirm password:'').strip()\n                                if passwd == passwd1:\n                                    mpasswd = md5.new(passwd).hexdigest()\n                                    userinfo[user] = mpasswd\n                                    print ''%s password is changed'' %user\n                                    break\n                                else:\n                                    print "Passwords don''t match "\n                                    i = i + 1\n                                    continue\n                        else:\n                            print ''Too many wrong''\n                            continue\n                    else:\n                        print ''user not exist''\n                        continue\n                elif i == ''4'':\n                    print userinfo.keys()\n                elif i == ''0'':\n                    sys.exit()\n                else:\n                    print ''select error''\n                    continue\n                filew(''user.pkl'',content=userinfo)\n        \n        ftpclient\n\n            #!/usr/bin/python\n            #ftpclient.py\n\n            import socket\n            import os\n            import getpass\n            from time import sleep\n\n            HOST=''10.152.14.85''\n            PORT=50007\n            s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n            s.connect((HOST,PORT))\n                \n            while True:\n                user = raw_input(''user:'').strip()\n                if user.isalnum():\n                    while True:\n                        passwd = getpass.getpass(''passwd:'').strip()\n                        s.sendall(user + '' '' + passwd)\n                        servercmd=s.recv(1024)\n                        if servercmd == ''login successful'':\n                            print ''\\033[32m%s\\033[m'' %servercmd\n                            break\n                        else:\n                            print servercmd\n\n                    while True:\n                        cmd=raw_input(''FTP>'').strip()\n                        if cmd == '''':\n                            continue\n                        if cmd.split()[0] == ''get'':\n                            if cmd == ''get'':continue\n                            for i in cmd.split()[1:]:\n                                if os.path.exists(i):\n                                    confirm = raw_input("\\033[31mPlease confirm whether the cover %s(Y/N):\\033[m" %(i)).upper().startswith(''Y'')\n                                    if not confirm:\n                                        print ''%s cancel'' %i\n                                        continue\n                                s.sendall(''get '' + i)\n                                servercmd=s.recv(1024)\n                                if servercmd == ''inexistence'':\n                                    print ''%s \\t\\033[32minexistence\\033[m'' %i\n                                    continue\n                                elif servercmd == ''ready_file'':\n                                    f = file(i,''wb'')\n                                    while True:\n                                        data=s.recv(1024)\n                                        if data == ''get_done'':break \n                                        f.write(data)\n                                    f.close()\n                                    print ''%s \\t\\033[32mfile_done\\033[m'' %(i)\n                                elif servercmd == ''ready_dir'':\n                                    try:\n                                        os.makedirs(i)\n                                    except:\n                                        pass\n                                    while True:\n                                        serverdir=s.recv(1024)\n                                        if serverdir == ''get_done'':break \n                                        os.system(''mkdir -p %s'' %serverdir)\n                                        print ''%s \\t\\033[32mdir_done\\033[m'' %(serverdir)\n                                        while True:\n                                            serverfile=s.recv(1024)\n                                            if serverfile == ''dir_get_done'':break \n                                            f = file(''%s/%s'' %(serverdir,serverfile),''wb'')\n                                            while True:\n                                                data=s.recv(1024)\n                                                if data == ''file_get_done'':break \n                                                f.write(data)\n                                            f.close()\n                                            print ''%s/%s \\t\\033[32mfile_done\\033[m'' %(serverdir,serverfile)\n\n                        elif cmd.split()[0] == ''send'':\n                        \n                            if cmd == ''send'':continue\n                            for i in cmd.split()[1:]:\n                                if not os.path.exists(i):\n                                    print ''%s\\t\\033[31minexistence\\033[m'' %i\n                                    continue\n                            \n                                s.sendall(''send '' + i)\n                                servercmd=s.recv(1024)\n                                if servercmd == ''existing'':\n                                    confirm = raw_input("\\033[31mPlease confirm whether the cover %s(Y/N):\\033[m" %(i)).upper().startswith(''Y'')\n                                    if confirm:\n                                        s.sendall(''cover'')\n                                        servercmd=s.recv(1024)\n                                    else:\n                                        s.sendall(''cancel'')\n                                        print ''%s\\tcancel'' %i\n                                        continue\n                                \n                                if os.path.isfile(i):\n                                    s.sendall(''ready_file'')\n                                    sleep(0.5)\n                                    f = file(i,''rb'')\n                                    s.send(f.read())\n                                    sleep(0.5)\n                                    s.sendall(''file_send_done'')\n                                    print ''%s\\t\\033[32mfile done\\033[m'' %(cmd.split()[1])\n                                    f.close()\n                                elif os.path.isdir(i):\n                                    s.sendall(''ready_dir'')\n                                    sleep(0.5)\n                                    for dirpath in os.walk(i):\n                                        dir=dirpath[0].replace(''%s/'' %os.popen(''pwd'').read().strip(),'''',1)\n                                        s.sendall(dir)\n                                        sleep(0.5)\n                                        for filename in dirpath[2]:\n                                            s.sendall(filename)\n                                            sleep(0.5)\n                                            f = file(''%s/%s'' %(dirpath[0],filename),''rb'')\n                                            s.send(f.read())\n                                            f.close()\n                                            sleep(0.5)\n                                            s.sendall(''file_send_done'')\n                                            msg=s.recv(1024)\n                                            print msg\n\n                                        else:\n                                            s.sendall(''dir_send_done'')\n                                            msg=s.recv(1024)\n                                            print msg\n                                    \n                                else:\n                                    s.sendall(''unknown_file'')\n                                    print ''%s\\t\\033[31munknown type\\033[m'' %i\n                                    continue\n                                sleep(0.5)\n                                s.sendall(''get_done'')\n                            \n                        elif cmd.split()[0] == ''cdir'':\n                            if cmd == ''cdir'':continue\n                            s.sendall(cmd)\n                            data=s.recv(1024)\n                            print data\n                            continue\n                        elif cmd == ''ls'':\n                            list=os.popen(cmd).read().strip().split(''\\n'')\n                            if list:\n                                dirlist,filelist = '''',''''\n                                for i in list:\n                                    if os.path.isdir(i):\n                                        dirlist = dirlist + ''\\033[32m'' + i + ''\\033[m\\t''\n                                    else:\n                                        filelist = filelist + i + ''\\t''\n                                results = dirlist + filelist\n                            else:\n                                results = ''\\033[31mnot find\\033[m''\n                            print results\n                            continue\n                        elif cmd == ''pwd'':\n                            os.system(cmd)\n                        elif cmd.split()[0] == ''cd'':\n                            try:\n                                os.chdir(cmd.split()[1])\n                            except:\n                                print ''\\033[31mcd failure\\033[m''\n                        elif cmd == ''dir'':\n                            s.sendall(cmd)\n                            data=s.recv(1024)\n                            print data\n                            continue\n                        elif cmd == ''pdir'':\n                            s.sendall(cmd)\n                            data=s.recv(1024)\n                            print data\n                            continue\n                        elif cmd.split()[0] == ''mdir'':\n                            if cmd == ''mdir'':continue\n                            s.sendall(cmd)\n                            data=s.recv(1024)\n                            print data\n                            continue\n                        elif cmd.split()[0] == ''help'':\n                            print ''''''\n                get [file] [dir]\n                send [file] [dir]\n\n                dir\n                mdir\n                cdir\n                pdir\n                \n                pwd\n                md\n                cd\n                ls\n                \n                help\n                quit\n                ''''''\n                            continue\n                        elif cmd == ''quit'':\n                            break\n                        else:\n                            print ''\\033[31m%s: Command not found,Please see the "help"\\033[m'' %cmd\n                else:\n                    continue        \n                break\n            s.close()\n\n    扫描主机开放端口\n        #!/usr/bin/env python\n\n        import socket\n\n        def check_server(address,port):\n            s=socket.socket()\n            try:\n                s.connect((address,port))\n                return True\n            except socket.error,e:\n                return False\n\n        if __name__==''__main__'':\n            from optparse import OptionParser\n            parser=OptionParser()\n            parser.add_option("-a","--address",dest="address",default=''localhost'',help="Address for server",metavar="ADDRESS")\n            parser.add_option("-s","--start",dest="start_port",type="int",default=1,help="start port",metavar="SPORT")\n            parser.add_option("-e","--end",dest="end_port",type="int",default=1,help="end port",metavar="EPORT")\n            (options,args)=parser.parse_args()\n            print ''options: %s, args: %s'' % (options, args)\n            port=options.start_port\n            while(port<=options.end_port):\n                check = check_server(options.address, port)\n                if (check):\n                    print ''Port  %s is on'' % port\n                port=port+1\n\n    zmq [网络通讯库]\n        \n        # https://github.com/zeromq/pyzmq\n        # pip install pyzmq\n        # ZMQ是一个开源的、跨语言的、非常简洁的、非常高性能、非常灵活的网络通讯库\n        \n        服务端程序\n            import zmq\n            context = zmq.Context()\n            socket = context.socket(zmq.REP)\n            socket.bind("tcp://127.0.0.1:1234")   # 提供传输协议  INPROC  IPC  MULTICAST  TCP\n\n            while True :\n                msg = socket.recv()\n                socket.send(msg)\n\n        客户端端程序\n            import zmq\n            context = zmq.Context()\n            socket = context.socket(zmq.REQ)\n            socket.connect("tcp://127.0.0.1:1234")\n            # socket.connect("tcp://127.0.0.1:6000")    # 设置2个可以均衡负载请求到2个监听的server\n            msg_send = "xxx"socket.send(msg_send)\n            print "Send:", msg_send\n            msg_recv = socket.recv()\n            print "Receive:", msg_recv\n\n    epoll\n        https://docs.python.org/2/library/select.html    # python官网\n\n        epoll短链接server\n            # 原文  http://my.oschina.net/moooofly/blog/147297\n            # 此代码还有改进地方，在接收数据和发送数据都是阻塞死循环处理，必须等待全部接收完毕才会继续操作\n            server端代码： \n\n                #!/usr/bin/python\n                #-*- coding:utf-8 -*-\n                 \n                import socket, logging\n                import select, errno\n                     \n                logger = logging.getLogger("network-server")\n                     \n                def InitLog():\n                    logger.setLevel(logging.DEBUG)\n                     \n                    fh = logging.FileHandler("network-server.log")\n                    fh.setLevel(logging.DEBUG)\n                    ch = logging.StreamHandler()\n                    ch.setLevel(logging.ERROR)\n                     \n                    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")\n                    ch.setFormatter(formatter)\n                    fh.setFormatter(formatter)\n                     \n                    logger.addHandler(fh)\n                    logger.addHandler(ch)\n\n                if __name__ == "__main__":\n                    InitLog()\n                 \n                    try:\n                        # 创建 TCP socket 作为监听 socket\n                        listen_fd = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n                    except socket.error, msg:\n                        logger.error("create socket failed")\n                 \n                    try:\n                        # 设置 SO_REUSEADDR 选项\n                        listen_fd.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                    except socket.error, msg:\n                        logger.error("setsocketopt SO_REUSEADDR failed")\n                 \n                    try:\n                        # 进行 bind -- 此处未指定 ip 地址，即 bind 了全部网卡 ip 上\n                        listen_fd.bind(('''', 2003))\n                    except socket.error, msg:\n                        logger.error("bind failed")\n                 \n                    try:\n                        # 设置 listen 的 backlog 数\n                        listen_fd.listen(10)\n                    except socket.error, msg:\n                        logger.error(msg)\n                     \n                    try:\n                        # 创建 epoll 句柄\n                        epoll_fd = select.epoll()\n                        # 向 epoll 句柄中注册 监听 socket 的 可读 事件\n                        epoll_fd.register(listen_fd.fileno(), select.EPOLLIN)\n                    except select.error, msg:\n                        logger.error(msg)\n                         \n                    connections = {}\n                    addresses = {}\n                    datalist = {}\n                    while True:\n                        # epoll 进行 fd 扫描的地方 -- 未指定超时时间则为阻塞等待\n                        epoll_list = epoll_fd.poll()\n                 \n                        for fd, events in epoll_list:\n                            # 若为监听 fd 被激活\n                            if fd == listen_fd.fileno():\n                                # 进行 accept -- 获得连接上来 client 的 ip 和 port，以及 socket 句柄\n                                conn, addr = listen_fd.accept()\n                                logger.debug("accept connection from %s, %d, fd = %d" % (addr[0], addr[1], conn.fileno()))\n                                # 将连接 socket 设置为 非阻塞\n                                conn.setblocking(0)\n                                # 向 epoll 句柄中注册 连接 socket 的 可读 事件\n                                epoll_fd.register(conn.fileno(), select.EPOLLIN | select.EPOLLET)\n                                # 将 conn 和 addr 信息分别保存起来\n                                connections[conn.fileno()] = conn\n                                addresses[conn.fileno()] = addr\n                            elif select.EPOLLIN & events:\n                                # 有 可读 事件激活\n                                datas = ''''\n                                while True:\n                                    try:\n                                        # 从激活 fd 上 recv 10 字节数据\n                                        data = connections[fd].recv(10)\n                                        # 若当前没有接收到数据，并且之前的累计数据也没有\n                                        if not data and not datas:\n                                            # 从 epoll 句柄中移除该 连接 fd\n                                            epoll_fd.unregister(fd)\n                                            # server 侧主动关闭该 连接 fd\n                                            connections[fd].close()\n                                            logger.debug("%s, %d closed" % (addresses[fd][0], addresses[fd][1]))\n                                            break\n                                        else:\n                                            # 将接收到的数据拼接保存在 datas 中\n                                            datas += data\n                                    except socket.error, msg:\n                                        # 在 非阻塞 socket 上进行 recv 需要处理 读穿 的情况\n                                        # 这里实际上是利用 读穿 出 异常 的方式跳到这里进行后续处理\n                                        if msg.errno == errno.EAGAIN:\n                                            logger.debug("%s receive %s" % (fd, datas))\n                                            # 将已接收数据保存起来\n                                            datalist[fd] = datas\n                                            # 更新 epoll 句柄中连接d 注册事件为 可写\n                                            epoll_fd.modify(fd, select.EPOLLET | select.EPOLLOUT)\n                                            break\n                                        else:\n                                            # 出错处理\n                                            epoll_fd.unregister(fd)\n                                            connections[fd].close()\n                                            logger.error(msg)\n                                            break\n                            elif select.EPOLLHUP & events:\n                                # 有 HUP 事件激活\n                                epoll_fd.unregister(fd)\n                                connections[fd].close()\n                                logger.debug("%s, %d closed" % (addresses[fd][0], addresses[fd][1]))\n                            elif select.EPOLLOUT & events:\n                                # 有 可写 事件激活\n                                sendLen = 0\n                                # 通过 while 循环确保将 buf 中的数据全部发送出去        \n                                while True:\n                                    # 将之前收到的数据发回 client -- 通过 sendLen 来控制发送位置\n                                    sendLen += connections[fd].send(datalist[fd][sendLen:])\n                                    # 在全部发送完毕后退出 while 循环\n                                    if sendLen == len(datalist[fd]):\n                                        break\n                                # 更新 epoll 句柄中连接 fd 注册事件为 可读\n                                epoll_fd.modify(fd, select.EPOLLIN | select.EPOLLET)\n                            else:\n                                # 其他 epoll 事件不进行处理\n                                continue\n\n            client 端代码\n\n                import socket\n                import time\n                import logging\n                 \n                logger = logging.getLogger("network-client")\n                logger.setLevel(logging.DEBUG)\n                 \n                fh = logging.FileHandler("network-client.log")\n                fh.setLevel(logging.DEBUG)\n                ch = logging.StreamHandler()\n                ch.setLevel(logging.ERROR)\n                 \n                formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")\n                ch.setFormatter(formatter)\n                fh.setFormatter(formatter)\n                 \n                logger.addHandler(fh)\n                logger.addHandler(ch)\n                 \n                if __name__ == "__main__":\n                    try:\n                        connFd = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n                    except socket.error, msg:\n                        logger.error(msg)\n                 \n                    try:\n                        connFd.connect(("127.0.0.1", 2003))\n                        logger.debug("connect to network server success")\n                    except socket.error,msg:\n                        logger.error(msg)\n                 \n                    for i in range(1, 11):\n                        data = "The Number is %d" % i\n                        if connFd.send(data) != len(data):\n                            logger.error("send data to network server failed")\n                            break\n                        readData = connFd.recv(1024)\n                        print readData\n                        time.sleep(1)\n                 \n                    connFd.close()\n\n4 mysql\n    \n    # yum install mysql-server\n    # yum install python-MySQLdb MySQL-python\n    help(MySQLdb.connections.Connection)      # 查看链接参数\n\n    conn=MySQLdb.connect(host=''localhost'',user=''root'',passwd=''123456'',db=''fortress'',port=3306)    # 定义连接\n    #conn=MySQLdb.connect(unix_socket=''/var/run/mysqld/mysqld.sock'',user=''root'',passwd=''123456'')   # 使用socket文件链接\n    cur=conn.cursor()                                            # 定义游标\n    conn.select_db(''fortress'')                                   # 选择数据库\n    sqlcmd = ''insert into user(name,age) value(%s,%s)''           # 定义sql命令\n    cur.executemany(sqlcmd,[(''aa'',1),(''bb'',2),(''cc'',3)])         # 插入多条值\n    cur.execute(''delete from user where id=20'')                  # 删除一条记录\n    cur.execute("update user set name=''a'' where id=20")          # 更细数据\n    sqlresult = cur.fetchall()                                   # 接收全部返回结果\n    conn.commit()                                                # 提交\n    cur.close()                                                  # 关闭游标\n    conn.close()                                                 # 关闭连接\n    \n    import MySQLdb\n    def mydb(dbcmdlist):\n        try:\n            conn=MySQLdb.connect(host=''localhost'',user=''root'',passwd=''123456'',db=''fortress'',port=3306)\n            cur=conn.cursor()\n            \n            cur.execute(''create database if not exists fortress;'')  # 创建数据库\n            conn.select_db(''fortress'')                              # 选择数据库\n            cur.execute(''drop table if exists log;'')                # 删除表\n            cur.execute(''CREATE TABLE log ( id BIGINT(20) NOT NULL AUTO_INCREMENT, loginuser VARCHAR(50) DEFAULT NULL, remoteip VARCHAR(50) DEFAULT NULL, PRIMARY KEY (id) );'')  # 创建表\n            \n            result=[]\n            for dbcmd in dbcmdlist:\n                cur.execute(dbcmd)           # 执行sql\n                sqlresult = cur.fetchall()   # 接收全部返回结果\n                result.append(sqlresult)\n            conn.commit()                    # 提交\n            cur.close()\n            conn.close()\n            return result\n        except MySQLdb.Error,e:\n            print ''mysql error msg: '',e\n    sqlcmd=[]\n    sqlcmd.append("insert into log (loginuser,remoteip)values(''%s'',''%s'');" %(loginuser,remoteip))\n    mydb(sqlcmd)\n\n    sqlcmd=[]\n    sqlcmd.append("select * from log;")\n    result = mydb(sqlcmd)\n    for i in result[0]:\n        print i\n\n5 处理信号\n\n    信号的概念\n\n        信号(signal): 进程之间通讯的方式，是一种软件中断。一个进程一旦接收到信号就会打断原来的程序执行流程来处理信号。\n        发送信号一般有两种原因:\n            1(被动式)  内核检测到一个系统事件.例如子进程退出会像父进程发送SIGCHLD信号.键盘按下control+c会发送SIGINT信号\n            2(主动式)  通过系统调用kill来向指定进程发送信号\n        操作系统规定了进程收到信号以后的默认行为，可以通过绑定信号处理函数来修改进程收到信号以后的行为，有两个信号是不可更改的 SIGTOP 和 SIGKILL\n        如果一个进程收到一个SIGUSR1信号，然后执行信号绑定函数，第二个SIGUSR2信号又来了，第一个信号没有被处理完毕的话，第二个信号就会丢弃。\n        进程结束信号 SIGTERM 和 SIGKILL 的区别:  SIGTERM 比较友好，进程能捕捉这个信号，根据您的需要来关闭程序。在关闭程序之前，您可以结束打开的记录文件和完成正在做的任务。在某些情况下，假如进程正在进行作业而且不能中断，那么进程可以忽略这个SIGTERM信号。\n\n    常见信号\n        kill -l      # 查看linux提供的信号\n\n        SIGHUP  1          A     # 终端挂起或者控制进程终止\n        SIGINT  2          A     # 键盘终端进程(如control+c)\n        SIGQUIT 3          C     # 键盘的退出键被按下\n        SIGILL  4          C     # 非法指令\n        SIGABRT 6          C     # 由abort(3)发出的退出指令\n        SIGFPE  8          C     # 浮点异常\n        SIGKILL 9          AEF   # Kill信号  立刻停止\n        SIGSEGV 11         C     # 无效的内存引用\n        SIGPIPE 13         A     # 管道破裂: 写一个没有读端口的管道\n        SIGALRM 14         A     # 闹钟信号 由alarm(2)发出的信号 \n        SIGTERM 15         A     # 终止信号,可让程序安全退出 kill -15\n        SIGUSR1 30,10,16   A     # 用户自定义信号1\n        SIGUSR2 31,12,17   A     # 用户自定义信号2\n        SIGCHLD 20,17,18   B     # 子进程结束自动向父进程发送SIGCHLD信号\n        SIGCONT 19,18,25         # 进程继续（曾被停止的进程）\n        SIGSTOP 17,19,23   DEF   # 终止进程\n        SIGTSTP 18,20,24   D     # 控制终端（tty）上按下停止键\n        SIGTTIN 21,21,26   D     # 后台进程企图从控制终端读\n        SIGTTOU 22,22,27   D     # 后台进程企图从控制终端写\n        \n        缺省处理动作一项中的字母含义如下:\n            A  缺省的动作是终止进程\n            B  缺省的动作是忽略此信号，将该信号丢弃，不做处理\n            C  缺省的动作是终止进程并进行内核映像转储(dump core),内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。\n            D  缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）\n            E  信号不能被捕获\n            F  信号不能被忽略\n\n    Python提供的信号\n        import signal\n        dir(signal)\n        [''NSIG'', ''SIGABRT'', ''SIGALRM'', ''SIGBUS'', ''SIGCHLD'', ''SIGCLD'', ''SIGCONT'', ''SIGFPE'', ''SIGHUP'', ''SIGILL'', ''SIGINT'', ''SIGIO'', ''SIGIOT'', ''SIGKILL'', ''SIGPIPE'', ''SIGPOLL'', ''SIGPROF'', ''SIGPWR'', ''SIGQUIT'', ''SIGRTMAX'', ''SIGRTMIN'', ''SIGSEGV'', ''SIGSTOP'', ''SIGSYS'', ''SIGTERM'', ''SIGTRAP'', ''SIGTSTP'', ''SIGTTIN'', ''SIGTTOU'', ''SIGURG'', ''SIGUSR1'', ''SIGUSR2'', ''SIGVTALRM'', ''SIGWINCH'', ''SIGXCPU'', ''SIGXFSZ'', ''SIG_DFL'', ''SIG_IGN'', ''__doc__'', ''__name__'', ''alarm'', ''default_int_handler'', ''getsignal'', ''pause'', ''signal'']\n\n    绑定信号处理函数\n        #encoding:utf8\n        import os,signal\n        from time import sleep\n        def onsignal_term(a,b):\n            print ''SIGTERM''      # kill -15\n        signal.signal(signal.SIGTERM,onsignal_term)     # 接收信号,执行相应函数\n\n        def onsignal_usr1(a,b):\n            print ''SIGUSR1''      # kill -10\n        signal.signal(signal.SIGUSR1,onsignal_usr1)\n\n        while 1:\n            print ''ID'',os.getpid()\n            sleep(10)\n\n    通过另外一个进程发送信号\n        import os,signal\n        os.kill(16175,signal.SIGTERM)    # 发送信号，16175是绑定信号处理函数的进程pid，需要自行修改\n        os.kill(16175,signal.SIGUSR1)\n\n    父进程接收子进程结束发送的SIGCHLD信号\n        #encoding:utf8\n        import os,signal\n        from time import sleep\n           \n        def onsigchld(a,b):\n            print ''收到子进程结束信号''\n        signal.signal(signal.SIGCHLD,onsigchld)\n           \n        pid = os.fork()                # 创建一个子进程,复制父进程所有资源操作\n        if pid == 0:                   # 通过判断子进程os.fork()是否等于0,分别同时执行父进程与子进程操作\n           print ''我是子进程,pid是'',os.getpid()\n           sleep(2)\n        else:\n            print ''我是父进程,pid是'',os.getpid()\n            os.wait()      # 等待子进程结束\n\n    接收信号的程序，另外一端使用多线程向这个进程发送信号，会遗漏一些信号\n        #encoding:utf8\n        import os\n        import signal\n        from time import sleep  \n        import Queue\n        QCOUNT = Queue.Queue()  # 初始化队列  \n        def onsigchld(a,b):  \n            ''''''收到信号后向队列中插入一个数字1''''''\n            print ''收到SIGUSR1信号''\n            sleep(1)\n            QCOUNT.put(1)       # 向队列中写入\n        signal.signal(signal.SIGUSR1,onsigchld)   # 绑定信号处理函数\n        while 1:\n            print ''我的pid是'',os.getpid()\n            print ''现在队列中元素的个数是'',QCOUNT.qsize()\n            sleep(2)\n\n    多线程发信号端的程序\n        #encoding:utf8\n        import threading\n        import os\n        import signal\n        def sendusr1():\n            print ''发送信号''\n            os.kill(17788, signal.SIGUSR1)     # 这里的进程id需要写前一个程序实际运行的pid\n        WORKER = []\n        for i in range(1, 7):                  # 开启6个线程\n            threadinstance = threading.Thread(target = sendusr1)\n            WORKER.append(threadinstance)  \n        for i in WORKER:\n            i.start()\n        for i in WORKER:\n            i.join()\n        print ''主线程完成''\n\n6 缓存数据库\n\n    python使用memcache\n\n        easy_install python-memcached   # 安装(python2.7+)\n        import memcache\n        mc = memcache.Client([''10.152.14.85:12000''],debug=True)    # 也可以使用socket直接连接IP端口\n        mc.set(''name'',''luo'',60)\n        mc.get(''name'')\n        mc.delete(''name1'')\n        \n        # 豆瓣的python-memcache模块，大于1M自动切割 性能是纯python的3倍+\n        https://code.google.com/p/python-libmemcached/\n        \n        保存数据\n\n            set(key,value,timeout)      # 把key映射到value，timeout指的是什么时候这个映射失效\n            add(key,value,timeout)      # 仅当存储空间中不存在键相同的数据时才保存\n            replace(key,value,timeout)  # 仅当存储空间中存在键相同的数据时才保存\n\n        获取数据\n\n            get(key)                    # 返回key所指向的value\n            get_multi(key1,key2,key3)   # 可以非同步地同时取得多个键值， 比循环调用get快数十倍\n\n    python使用mongodb\n\n        原文: http://blog.nosqlfan.com/html/2989.html\n        \n        easy_install pymongo      # 安装(python2.7+)\n        import pymongo\n        connection=pymongo.Connection(''localhost'',27017)   # 创建连接\n        db = connection.test_database                      # 切换数据库\n        collection = db.test_collection                    # 获取collection\n        # db和collection都是延时创建的，在添加Document时才真正创建\n\n        文档添加, _id自动创建\n            import datetime\n            post = {"author": "Mike",\n                "text": "My first blog post!",\n                "tags": ["mongodb", "python", "pymongo"],\n                "date": datetime.datetime.utcnow()}\n            posts = db.posts\n            posts.insert(post)\n            ObjectId(''...'')\n\n        批量插入\n            new_posts = [{"author": "Mike",\n                "text": "Another post!",\n                "tags": ["bulk", "insert"],\n                "date": datetime.datetime(2009, 11, 12, 11, 14)},\n                {"author": "Eliot",\n                "title": "MongoDB is fun",\n                "text": "and pretty easy too!",\n                "date": datetime.datetime(2009, 11, 10, 10, 45)}]\n            posts.insert(new_posts)\n            [ObjectId(''...''), ObjectId(''...'')]\n        \n        获取所有collection\n            db.collection_names()    # 相当于SQL的show tables\n            \n        获取单个文档\n            posts.find_one()\n\n        查询多个文档\n            for post in posts.find():\n                post\n\n        加条件的查询\n            posts.find_one({"author": "Mike"})\n\n        高级查询\n            posts.find({"date": {"$lt": "d"}}).sort("author")\n\n        统计数量\n            posts.count()\n\n        加索引\n            from pymongo import ASCENDING, DESCENDING\n            posts.create_index([("date", DESCENDING), ("author", ASCENDING)])\n\n        查看查询语句的性能\n            posts.find({"date": {"$lt": "d"}}).sort("author").explain()["cursor"]\n            posts.find({"date": {"$lt": "d"}}).sort("author").explain()["nscanned"]\n\n    python使用redis\n\n        https://pypi.python.org/pypi/redis                  # redis的python官网\n        pip install redis  OR easy_install redis            # 安装\n        http://redis.readthedocs.org/en/latest/index.html   # redis命令详解\n        http://redis.readthedocs.org/en/2.4/index.html      \n\n        import redis\n        rds = redis.Redis(host=host, port=port, password=passwd, socket_timeout=10,db=0)\n        rds.info()                           # redis信息\n        rds.set(key, value)                  # 将值value关联到key\n        rds.get(key)                         # 取key值\n        rds.del(key1,key2)                   # 删除key\n        rds.rename(key,new_key2)             # 将key改名 存在覆盖\n        rds.seten(key,value)                 # 将值value关联到key,如果key存在不做任何动作\n        rds.setex(key, value, 10800)         # 将值value关联到key,并设置key的过期时间\n        rds.mset()                           # 同时设置一个或多个key-value对  如果key存在则覆盖\n        rds.msetnx()                         # 同时设置一个或多个key-value对  如果有key存在则失败\n        rds.mget(key1, key2, key3)           # 取多个key值   不存在返回nil\n        rds.expire(key seconds)              # 设置key的过期时间\n        rds.persist(key)                     # 移除key的过期时间\n        rds.ttl(key)                         # 查看超时时间 -1为不过期\n        rds.sadd(key,value1)                 # 将value1加入集合中  集合不重复\n        rds.smembers(key)                    # 返回key中所有成员\n        rds.scard(key)                       # 集合中元素的数量\n        rds.srandmember(key)                 # 对集合随机返回一个元素 而不对集合改动  当key不存在或key是空集时，返回nil\n        rds.sinter(key1,key2)                # 两个集合的交集\n        rds.sdiff(key1,key2)                 # 两个集合的差集\n        rds.sismember(key,value)             # 判断value元素是否是集合key的成员 1存在 0不存在\n        rds.lpush(key,value1)                # 将value1加入列表中  从左到右\n        rds.lpop(key,value1)                 # 移除并返回列表key的头元素\n        rds.llen(key)                        # 返回列表长度\n        rds.sort(key)                        # 对列表、集合、有序集合排序[大列表排序非常影响性能，甚至把redis拖死]\n        rds.append(key,value)                # 字符串拼接为新的value\n        rds.ltrim(key, 0, -10)               # 保留指定区间内的元素，不在都被删除 0第一个 -1最后一个\n        rds.incr(key , amount=1)             # 计数加1 默认1或请先设置key的数值\n        rds.decr(key)                        # 计数减1 请先设置key的数值\n        rds.save()                           # 保存数据\n\n    python使用kestrel队列\n\n        # pykestrel\n        import kestrel\n\n        q = kestrel.Client(servers=[''127.0.0.1:22133''],queue=''test_queue'') \n        q.add(''some test job'') \n        job = q.get()    # 从队列读取工作\n        job = q.peek()   # 读取下一份工作\n        # 读取一组工作\n        while True:\n            job = q.next(timeout=10) # 完成工作并获取下一个工作，如果没有工作，则等待10秒\n            if job is not None:\n                try:\n                    # 流程工作\n                except:\n                    q.abort() # 标记失败工作\n\n        q.finish()  # 完成最后工作\n        q.close()   # 关闭连接\n        \n        kestrel状态检查\n            # kestrel支持memcache协议客户端\n            #!/usr/local/bin/python\n            # 10.13.81.125 22133  10000\n\n            import memcache\n            import sys\n            import traceback\n\n            ip="%s:%s" % (sys.argv[1],sys.argv[2])\n            try:\n                mc = memcache.Client([ip,])\n                st=mc.get_stats()\n            except:\n                print "kestrel connection exception"\n                sys.exit(2)\n\n            if st:\n                for s in st[0][1].keys():\n                    if s.startswith(''queue_'') and s.endswith(''_mem_items''):\n                        num = int(st[0][1][s])\n                        if num > int(sys.argv[3]):\n                            print "%s block to %s" %(s[6:-6],num)\n                            sys.exit(2)\n                print "kestrel ok!"\n                sys.exit(0)\n            else:\n                print "kestrel down"\n                sys.exit(2)\n\n    python使用tarantool\n\n        # pip install tarantool-queue\n\n        from tarantool_queue import Queue\n        queue = Queue("localhost", 33013, 0)     # 连接读写端口 空间0\n        tube = queue.tube("name_of_tube")        # \n        tube.put([1, 2, 3])\n\n        task = tube.take()\n        task.data     # take task and read data from it\n        task.ack()    # move this task into state DONE\n\n7 web页面操作\n\n    urllib2        [网络资源访问]\n\n        import urllib2\n        response = urllib2.urlopen(''http://baidu.com'')\n        print response.geturl()       # url\n        headers = response.info()\n        print headers                 # web页面头部信息\n        print headers[''date'']         # 头部信息中的时间\n        date = response.read()        # 返回页面所有信息[字符串]\n        # date = response.readlines() # 返回页面所有信息[列表]\n        \n        for i in urllib2.urlopen(''http://qq.com''):    # 可直接迭代\n            print i,\n\n        下载文件\n\n            #!/usr/bin/env python\n            #encoding:utf8\n            import urllib2\n\n            url = ''http://www.01happy.com/wp-content/uploads/2012/09/bg.png''\n            file("./pic/%04d.png" % i, "wb").write(urllib2.urlopen(url).read())\n            \n        抓取网页解析指定内容\n\n            #!/usr/bin/env python\n            #encoding:utf8\n\n            import urllib2\n            import urllib\n            import random\n            from bs4 import BeautifulSoup\n\n            url=''http://www.aaammm.com/aaa/''\n\n            ua=["Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)",\n            "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)",\n            "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.2; .NET4.0C; .NET4.0E)",\n            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36",\n            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36",\n            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36",\n            "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36",\n            "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36",\n            "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36",\n            "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36",\n            "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36",\n            "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20100101 Firefox/31.0",\n            "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36"]\n\n            browser = random.choice(ua)\n\n            req_header = {''User-Agent'':browser,\n            ''Accept'':''text/html;q=0.9,*/*;q=0.8'',\n            ''Cookie'':''BAIDUID=4C8274B52CFB79DEB4FBA9A7EC76A1BC:FG=1; BDUSS=1dCdU1WNFdxUll0R09XcnBZTkRrVVVNbWVnSkRKSVRPeVljOUswclBoLUNzVEpVQVFBQUFBJCQAAAAAAAAAAAEAAADEuZ8BcXVhbnpob3U3MjIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIIkC1SCJAtUY; BD_UPN=123143; BD_HOME=1'',    # 添真实登陆后的Cookie 谷歌浏览器[F12  Network  Documents  Headers]\n            ''Accept-Charset'':''ISO-8859-1,utf-8;q=0.7,*;q=0.3'',\n            ''Connection'':''close'',\n            }\n            #data = urllib.urlencode({''name'':''xuesong'',''id'':''30'' })          # urllib 的处理参数的方法，可以再urllib2中使用\n            data = urllib2.quote("pgv_ref=im.perinfo.perinfo.icon&rrr=pppp") \n            req_timeout = 10\n            try:\n                req = urllib2.Request(url,data=data,headers=req_header)      # data为None 则方法为get，有date为post方法\n                html = urllib2.urlopen(req,data=None,req_timeout).read()\n            except urllib2.HTTPError as err:\n                print str(err)\n            except:\n                print "timeout"\n            print(html)\n\n            # 百度带Cookie后查看自己的用户\n            #for i in html.split(''\\n''):\n            #    if ''bds.comm.user='' in i:\n            #        print i\n            \n            soup = BeautifulSoup(html)\n            for i in  soup.find_all(target="_blank",attrs={"class": "usr-pic"}):   # 条件看情况选择\n                if i.img:\n                    print(i.get(''href''))\n\n        模拟浏览器访问web页面 python3\n            #! /usr/bin/env python\n            # -*- coding=utf-8 -*- \n            import urllib.request\n\n            url = "http://www.baidu.com"\n            # AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11\n            headers = {''User-Agent'':''Mozilla/5.0 (Windows NT 6.1)'',\n            ''Accept'':''text/html;q=0.9,*/*;q=0.8'',\n            ''Accept-Charset'':''ISO-8859-1,utf-8;q=0.7,*;q=0.3'',\n            ''Connection'':''close'',\n            ''Referer'':None #注意如果依然不能抓取的话，这里可以设置抓取网站的host\n            }\n\n            opener = urllib.request.build_opener()\n            opener.addheaders = [headers]\n            data = opener.open(url).read()\n\n            print(data)\n                \n    requests       [替代urllib2]\n\n        # Requests是一个Python的HTTP客户端库\n        # 官方中文文档 http://cn.python-requests.org/zh_CN/latest/user/quickstart.html#id2\n        # 安装: sudo pip install requests\n        import requests\n\n        # get方法提交表单\n        url = r''http://dict.youdao.com/search?le=eng&q={0}''.format(word.strip())\n        r = requests.get(url,timeout=2)\n        \n        # get方法带参数 http://httpbin.org/get?key=val\n        payload = {''key1'': ''value1'', ''key2'': ''value2''}    \n        r = requests.get("http://httpbin.org/get", params=payload)  \n        \n        # post方法提交表单\n        QueryAdd=''http://www.anti-spam.org.cn/Rbl/Query/Result''\n        r = requests.post(url=QueryAdd, data={''IP'':''211.211.54.54''})        \n        \n        # 定制请求头post请求\n        payload = {''some'': ''data''}\n        headers = {''content-type'': ''application/json''}\n        r = requests.post(url, data=json.dumps(payload), headers=headers)\n\n        # https 需登录加auth\n        r = requests.get(''https://baidu.com'', auth=(''user'', ''pass''))\n\n        if r.ok:    # 判断请求是否正常\n            print r.url             # u''http://httpbin.org/get?key2=value2&key1=value1''\n            print r.status_code     # 状态码 \n            print r.content         # 获取到的原始内容  可使用 BeautifulSoup4 解析处理判定结果\n            print r.text            # 把原始内容转unicode编码\n            print r.headers         # 响应头\n            print r.headers[''content-type'']          # 网页头信息 不存在为None\n            print r.cookies[''example_cookie_name'']   # 查看cookie\n            print r.history         # 追踪重定向 [<Response [301]>]  开启重定向 allow_redirects=True  \n        \n        获取JSON\n            r = requests.get(''https://github.com/timeline.json'')\n            r.json()\n        \n        获取图片\n            from PIL import Image\n            from StringIO import StringIO\n            i = Image.open(StringIO(r.content))\n\n        发送cookies到服务器\n            url = ''http://httpbin.org/cookies''\n            cookies = dict(cookies_are=''working'')\n            r = requests.get(url, cookies=cookies)\n            r.text         ''{"cookies": {"cookies_are": "working"}}''\n\n        在同一个Session实例发出的所有请求之间保持cookies\n            s = requests.Session()\n            s.get(''http://httpbin.org/cookies/set/sessioncookie/123456789'')\n            r = s.get("http://httpbin.org/cookies")\n            print r.text\n        \n        会话对象能够跨请求保持某些参数\n            s = requests.Session()\n            s.auth = (''user'', ''pass'')\n            s.headers.update({''x-test'': ''true''})\n            s.get(''http://httpbin.org/headers'', headers={''x-test2'': ''true''})  # both ''x-test'' and ''x-test2'' are sent\n        \n        ssl证书验证\n            requests.get(''https://github.com'', verify=True)\n            requests.get(''https://kennethreitz.com'', verify=False)   # 忽略证书验证\n            requests.get(''https://kennethreitz.com'', cert=(''/path/server.crt'', ''/path/key''))   # 本地指定一个证书 正确 <Response [200]>  错误 SSLError\n\n        流式上传\n            with open(''massive-body'') as f:\n                requests.post(''http://some.url/streamed'', data=f)\n\n        流式请求\n            import requests\n            import json\n\n            r = requests.post(''https://stream.twitter.com/1/statuses/filter.json'',\n                data={''track'': ''requests''}, auth=(''username'', ''password''), stream=True)\n\n            for line in r.iter_lines():\n                if line: # filter out keep-alive new lines\n                    print json.loads(line)\n            \n        自定义身份验证\n            from requests.auth import AuthBase\n            class PizzaAuth(AuthBase):\n                """Attaches HTTP Pizza Authentication to the given Request object."""\n                def __init__(self, username):\n                    # setup any auth-related data here\n                    self.username = username\n                def __call__(self, r):\n                    # modify and return the request\n                    r.headers[''X-Pizza''] = self.username\n                    return r\n            requests.get(''http://pizzabin.org/admin'', auth=PizzaAuth(''kenneth''))\n        \n        基本身份认证\n            from requests.auth import HTTPBasicAuth\n            requests.get(''https://api.github.com/user'', auth=HTTPBasicAuth(''user'', ''pass'')) \n        \n        摘要式身份认证\n            from requests.auth import HTTPDigestAuth            \n            url = ''http://httpbin.org/digest-auth/auth/user/pass''\n            requests.get(url, auth=HTTPDigestAuth(''user'', ''pass'')) \n        \n        代理\n            import requests\n            proxies = {\n              "http": "http://10.10.1.10:3128",\n              # "http": "http://user:pass@10.10.1.10:3128/",  # 用户名密码\n              "https": "http://10.10.1.10:1080",\n            }\n            requests.get("http://example.org", proxies=proxies)\n            #也可以设置环境变量之间访问\n            export HTTP_PROXY="http://10.10.1.10:3128"\n            export HTTPS_PROXY="http://10.10.1.10:1080"\n\n    BeautifulSoup  [html\\xml解析器]\n\n        # BeautifulSoup中文官方文档\n        # http://www.crummy.com/software/BeautifulSoup/bs3/documentation.zh.html\n        # http://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html\n        # Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种: Tag , NavigableString , BeautifulSoup , Comment\n        \n        导入模块\n            from BeautifulSoup import BeautifulSoup          # For processing HTML  版本3.0 已停止更新\n            from BeautifulSoup import BeautifulStoneSoup     # For processing XML\n            import BeautifulSoup                             # To get everything\n            from bs4 import BeautifulSoup                    # 版本4.0 bs4 安装: pip install BeautifulSoup4\n\n        from bs4 import BeautifulSoup\n        soup = BeautifulSoup(html_doc)         # 解析html文本 可以是 requests 提交返回的页面 results.content\n        print(soup.prettify())                 # 输出解析后的结构\n        print(soup.title)                      # 指定标签内容\n        print(soup.title.name)                 # 标签名\n        print(soup.title.string)               # 标签内容\n        print(soup.title.parent.name)          # 上层标签名\n        print(soup.p)                          # <p class="title"><b>The Dormouse''s story</b></p>\n        print(soup.p[''class''])                 # u''title''  class属性值\n        print(soup.a)                          # 找到第一个a标签的标签行\n        print(soup.find_all(''a'',limit=2))      # 找到a标签的行,最多为limit个\n        print(soup.find(id="link3"))           # 标签内id为link3的标签行\n        print(soup.get_text())                 # 从文档中获取所有文字内容\n        soup.find_all("a", text="Elsie")       # 从文档中搜索关键字\n        soup.find(text=re.compile("sisters"))  # 从文档中正则搜索关键字\n        soup.find_all("a", class_="sister")    # 按CSS搜索\n        soup.find_all(id=''link2'',"table",attrs={"class": "status"},href=re.compile("elsie"))   # 搜索方法    \n        for i in  soup.find_all(''a'',attrs={"class": "usr-pic"}):    # 循环所有a标签的标签行\n                if i.a.img:\n                        print(i.a.img.get("src"))                   # 取出当前a标签中的连接\n        Tag\n            # find_all 后循环的值是 Tag 不是字符串 不能直接截取\n            tag.text                     # 文本\n            tag.name\n            tag.name = "blockquote"      # 查找name为 blockquote 的\n            tag[''class'']\n            tag.attrs                    # 按熟悉查找\n            tag[''class''] = ''verybold''\n\n            del tag[''class'']             # 删除\n            print(tag.get(''class''))      # 打印属性值\n            print(i.get(''href''))         # 打印连接\n\n    cookielib      [保留cookie登录页面]\n\n        ck = cookielib.CookieJar()   # 通过 这个就可以实现请求带过去的COOKIE与发送回来的COOKIE值了。\n        opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(ck))   # 获取到COOKIE\n        urllib2.install_opener(opener)   # 此句设置urllib2的全局opener\n        content = urllib2.urlopen(url).read()  \n        \n        登录cacti取图片\n            #encoding:utf8\n            import urllib2\n            import urllib\n            import cookielib\n            def renrenBrower(url,user,password):\n                #查找form标签中的action提交地址\n                login_page = "http://10.10.10.19/cacti/index.php"\n                try:\n                    #获得一个cookieJar实例\n                    cj = cookielib.CookieJar()\n                    #cookieJar作为参数，获得一个opener的实例\n                    opener=urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))\n                    #伪装成一个正常的浏览器，避免有些web服务器拒绝访问\n                    opener.addheaders = [(''User-agent'',''Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)'')]\n                    #生成Post数据,含有登陆用户名密码,所有表单内的input中name值\n                    data = urllib.urlencode({"action":"login","login_username":user,"login_password":password})\n                    #以post的方法访问登陆页面，访问之后cookieJar会自定保存cookie\n                    opener.open(login_page,data)\n                    #以带cookie的方式访问页面\n                    op=opener.open(url)\n                    #读取页面源码\n                    data=op.read()\n                    #将图片写到本地\n                    #file("1d.png" , "wb").write(data)\n                    return data\n                except Exception,e:\n                    print str(e)\n            print renrenBrower("http://10.10.10.19/cacti/graph_image.php?local_graph_id=1630&rra_id=0&view_type=tree&graph_start=1397525517&graph_end=1397611917","admin","admin")\n\n        例子2\n            import urllib, urllib2, cookielib  \n            import os, time  \n              \n            headers = []  \n              \n            def login():  \n                cj = cookielib.CookieJar()  \n                opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))  \n                login_url = r''http://zhixing.bjtu.edu.cn/member.php?mod=logging&action=login&loginsubmit=yes&infloat=yes&lssubmit=yes&inajax=1''  \n                login_data = urllib.urlencode({''cookietime'': ''2592000'', ''handlekey'': ''ls'', ''password'': ''xxx'',  \n                        ''quickforward'': ''yes'', ''username'': ''GuoYuan''})  \n                opener.addheaders = [(''Host'', ''zhixing.bjtu.edu.cn''),  \n                                   (''User-Agent'', ''Mozilla/5.0 (Ubuntu; X11; Linux i686; rv:8.0) Gecko/20100101 Firefox/8.0''),  \n                                   (''Accept'', ''text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8''),  \n                                   (''Accept-Language'', ''en-us,en;q=0.5''),  \n                                   (''Accept-Encoding'', ''gzip, deflate''),  \n                                   (''Accept-Charset'', ''ISO-8859-1,utf-8;q=0.7,*;q=0.7''),  \n                                   (''Connection'', ''keep-alive''),  \n                                   (''Referer'', ''http://zhixing.bjtu.edu.cn/forum.php''),]  \n                opener.open(login_url, login_data)  \n                return opener  \n              \n            if __name__ == ''__main__'':  \n                opener = login()  \n              \n                url = r''http://zhixing.bjtu.edu.cn/forum.php?mod=topicadmin&action=moderate&optgroup=2&modsubmit=yes&infloat=yes&inajax=1''      \n                data = {''fid'': ''601'', ''formhash'': ''0cdd1596'', ''frommodcp'': '''', ''handlekey'': ''mods'',  \n                         ''listextra'': ''page%3D62'', ''moderate[]'': ''496146'', ''operations[]'': ''type'', ''reason'': ''...'',  \n                         ''redirect'': r''http://zhixing.bjtu.edu.cn/thread-496146-1-1.html'', ''typeid'': ''779''}  \n                data2 = [(k, v) for k,v in data.iteritems()]  \n                  \n                cnt = 0  \n                for tid in range(493022, 496146 + 1):  \n                    cnt += 1  \n                    if cnt % 20 == 0: print  \n                    print tid,  \n                      \n                    data2.append((''moderate[]'', str(tid)))  \n                    if cnt % 40 == 0 or cnt == 496146:  \n                        request = urllib2.Request(url=url, data=urllib.urlencode(data2))  \n                        print opener.open(request).read()  \n                        data2 = [(k, v) for k,v in data.iteritems()]  \n\n    httplib        [http协议的客户端]\n\n        import httplib\n        conn3 = httplib.HTTPConnection(''www.baidu.com'',80,True,10) \n\n    aiohttp        [检索网页的客户端]\n\n        # 需要python3.3+\n        # http://aiohttp.readthedocs.org/en/v0.12.0/\n\n        import aiohttp\n\n        def get_body(url):\n            response = yield from aiohttp.request(''GET'', url)\n            return (yield from response.read())\n            \n        response = yield from aiohttp.request(''GET'', ''http://python.org'')\n        body = yield from response.read()\n        print(body)\n        \n        # 用 asyncio 配合协程抓取页面\n        yield from asyncio.wait_for(request(''GET'', url), 10)\n        \n        http_server\n        \n            import asyncio\n            from aiohttp import web\n\n            @asyncio.coroutine\n            def handle(request):\n                name = request.match_info.get(''name'', "Anonymous")\n                text = "Hello, " + name\n                return web.Response(body=text.encode(''utf-8''))\n\n            @asyncio.coroutine\n            def init(loop):\n                app = web.Application(loop=loop)\n                app.router.add_route(''GET'', ''/{name}'', handle)\n\n                srv = yield from loop.create_server(app.make_handler(),\n                                                    ''127.0.0.1'', 8080)\n                print("Server started at http://127.0.0.1:8080")\n                return srv\n\n            loop = asyncio.get_event_loop()\n            loop.run_until_complete(init(loop))\n            loop.run_forever()\n\n    查看网页图片尺寸类型\n        \n        #将图片读入内存\n        #!/usr/bin/env python\n        #encoding=utf-8\n        import cStringIO, urllib2, Image\n        url = ''http://www.01happy.com/wp-content/uploads/2012/09/bg.png''\n        file = urllib2.urlopen(url)\n        tmpIm = cStringIO.StringIO(file.read())\n        im = Image.open(tmpIm)\n        print im.format, im.size, im.mode\n        \n    爬虫\n        \n        #!/usr/bin/env python\n        #encoding:utf-8\n        #sudo pip install BeautifulSoup\n\n        import requests\n        from BeautifulSoup import BeautifulSoup\n        import re\n\n        baseurl = ''http://blog.sina.com.cn/s/articlelist_1191258123_0_1.html''\n\n        r = requests.get(baseurl)\n\n        for url in re.findall(''<a.*?</a>'', r.content, re.S):\n            if url.startswith(''<a title=''):\n                with open(r''d:/final.txt'', ''ab'') as f:\n                    f.write(url + ''\\n'')\n\n        linkfile = open(r''d:/final.txt'', ''rb'')\n        soup = BeautifulSoup(linkfile)\n        for link in soup.findAll(''a''):\n            #print link.get(''title'') + '':    '' + link.get(''href'')\n            ss = requests.get(link.get(''href''))\n            for content in re.findall(''<div id="sina_keyword_ad_area2" class="articalContent  ">.*?</div>'', ss.content, re.S):\n                with open(r''d:/myftp/%s.txt''%link.get(''title'').strip(''<>''), ''wb'') as f:\n                    f.write(content)\n                    print ''%s   has been copied.'' % link.get(''title'')\n\n    反垃圾邮件提交申诉\n\n        #很遗憾，反垃圾邮件联盟改版后加了验证码\n        \n        #!/usr/bin/env python\n        #encoding:utf-8\n        import requests\n        import re\n        \n        IpList=[''113.212.91.25'',''113.212.91.23'']\n        QueryAdd=''http://www.anti-spam.org.cn/Rbl/Query/Result''\n        ComplaintAdd=''http://www.anti-spam.org.cn/Rbl/Getout/Submit''\n        data = {\n        ''CONTENT'':''''''我们是一家正规的XXX。xxxxxxx。恳请将我们的发送服务器IP移出黑名单。谢谢！\n        处理措施：\n        1.XXXX。\n        2.XXXX。'''''',\n        ''CORP'':''abc.com'',\n        ''WWW'':''www.abc.cm'',\n        ''NAME'':''def'',\n        ''MAIL'':''def@163.com.cn'',\n        ''TEL'':''010-50000000'',\n        ''LEVEL'':''0'',\n        }\n\n        for Ip in IpList:\n            query = requests.post(url=QueryAdd, data={''IP'':Ip})                   # 黑名单查询\n            if query.ok:\n                if re.findall(u''\\u7533\\u8bc9\\u8131\\u79bb'', query.text, re.S):     # 查找关键字 申诉脱离 既表明在黑名单中\n                    data[''IP'']=Ip\n                    complaint = requests.post(url=ComplaintAdd, data=data)        # 提交申诉\n                    if complaint.ok:\n                        if re.findall(u''\\u60a8\\u7684\\u9ed1\\u540d\\u5355\\u8131\\u79bb\\u7533\\u8bf7\\u5df2\\u63d0\\u4ea4'', complaint.text, re.S):\n                            status=''申请提交''\n                        elif re.findall(u''\\u8131\\u79bb\\u7533\\u8bf7\\u5df2\\u88ab\\u4ed6\\u4eba\\u63d0\\u4ea4'', complaint.text, re.S):\n                            status=''重复提交''\n                        elif re.findall(u''\\u7533\\u8bf7\\u7531\\u4e8e\\u8fd1\\u671f\\u5185\\u6709\\u88ab\\u62d2\\u7edd\\u7684\\u8bb0\\u5f55'', complaint.text, re.S):\n                            status=''近期拒绝''\n                        else:\n                            status=''异常''\n                else:\n                    status=''正常''\n                print ''%s  %s'' %(Ip,status)\n\n    有道词典\n\n        #!/usr/bin/env python\n        import requests\n        from bs4 import BeautifulSoup\n        # bs4安装: pip install BeautifulSoup4\n\n        def youdao(word):\n            url = r''http://dict.youdao.com/search?le=eng&q={0}''.format(word.strip())\n            r = requests.get(url)\n            if r.ok:\n                soup = BeautifulSoup(r.content)\n                div = soup.find_all(''div'', class_=''trans-container'')[:1]    # find_all是bs4的方法\n                ul = BeautifulSoup(str(div[0]))\n                li = ul.find_all(''li'')\n                for mean in li:\n                    print mean.text\n\n        def query():\n            print(''Created by @littlepy, QQ:185635687'')\n            while True:\n                word = raw_input(''>>>'')\n                youdao(word)\n\n        if __name__ == ''__main__'':\n            query()\n\n    python启动http服务提供访问或下载\n\n        python -m SimpleHTTPServer  9900\n\n8 并发\n\n    #线程安全/竞争条件,锁/死锁检测,线程池,生产消费模型,伪并发,微线程,协程\n    #Stackless Python 是Python编程语言的一个增强版本，它使程序员从基于线程的编程方式中获得好处，并避免传统线程所带来的性能与复杂度问题。Stackless为 Python带来的微线程扩展，是一种低开销、轻量级的便利工具\n\n    threading多线程\n\n        thread\n            start_new_thread(function,args kwargs=None)    # 产生一个新的线程\n            allocate_lock()                                # 分配一个LockType类型的锁对象\n            exit()                                         # 让线程退出\n            acquire(wait=None)                             # 尝试获取锁对象\n            locked()                                       # 如果获取了锁对象返回True\n            release()                                      # 释放锁\n\n        thread例子\n\n            #!/usr/bin/env python\n            #thread_test.py\n            #不支持守护进程\n            import thread\n            from time import sleep,ctime\n\n            loops = [4,2]\n\n            def loop(nloop,nsec,lock):\n                print ''start loop %s at:%s'' % (nloop,ctime())\n                sleep(nsec)\n                print ''loop %s done at: %s'' % (nloop, ctime())\n                lock.release()              # 分配已获得的锁,操作结束后释放相应的锁通知主线程\n\n            def main():\n                print ''starting at:'',ctime()\n                locks = []\n                nloops = range(len(loops))\n                \n                for i in nloops:\n                    lock = thread.allocate_lock()     # 创建一个锁\n                    lock.acquire()                    # 调用各个锁的acquire()函数获得锁\n                    locks.append(lock)                # 把锁放到锁列表locks中\n                for i in nloops:\n                    thread.start_new_thread(loop,(i,loops[i],locks[i]))   # 创建线程\n                for i in nloops:\n                    while locks[i].locked():pass      # 等待全部解锁才继续运行\n                print ''all DONE at:'',ctime()\n\n            if __name__ == ''__main__'':\n                main()\n\n        thread例子1\n\n            #coding=utf-8\n            import thread,time,os\n\n            def f(name):\n                    i =3\n                    while i:\n                            time.sleep(1)\n                            print name\n                            i -= 1\n                    # os._exit()   会把整个进程关闭\n                    os._exit(22)\n\n            if __name__ == ''__main__'':\n                    thread.start_new_thread(f,("th1",))\n                    while 1:\n                            pass\n                    os._exit(0)\n                \n        threading\n            Thread                   # 表示一个线程的执行的对象\n                start()              # 开始线程的执行\n                run()                # 定义线程的功能的函数(一般会被子类重写)\n                join(timeout=None)   # 允许主线程等待线程结束,程序挂起,直到线程结束;如果给了timeout,则最多等待timeout秒.\n                getName()            # 返回线程的名字\n                setName(name)        # 设置线程的名字\n                isAlive()            # 布尔标志,表示这个线程是否还在运行中\n                isDaemon()           # 返回线程的daemon标志\n                setDaemon(daemonic)  # 后台线程,把线程的daemon标志设置为daemonic(一定要在调用start()函数前调用)\n                # 默认主线程在退出时会等待所有子线程的结束。如果希望主线程不等待子线程，而是在退出时自动结束所有的子线程，就需要设置子线程为后台线程(daemon)\n            Lock              # 锁原语对象\n            Rlock             # 可重入锁对象.使单线程可以在此获得已获得了的锁(递归锁定)\n            Condition         # 条件变量对象能让一个线程停下来,等待其他线程满足了某个条件.如状态改变或值的改变\n            Event             # 通用的条件变量.多个线程可以等待某个事件的发生,在事件发生后,所有的线程都会被激活\n            Semaphore         # 为等待锁的线程提供一个类似等候室的结构\n            BoundedSemaphore  # 与Semaphore类似,只是不允许超过初始值\n            Time              # 与Thread相似,只是他要等待一段时间后才开始运行\n            activeCount()     # 当前活动的线程对象的数量\n            currentThread()   # 返回当前线程对象\n            enumerate()       # 返回当前活动线程的列表\n            settrace(func)    # 为所有线程设置一个跟踪函数\n            setprofile(func)  # 为所有线程设置一个profile函数\n\n        threading例子1\n            \n            #!/usr/bin/env python\n            #encoding:utf8\n            import threading\n            from Queue import Queue\n            from time import sleep,ctime\n\n            class ThreadFunc(object):\n                    def __init__(self,func,args,name=''''):\n                            self.name=name\n                            self.func=func                    # loop\n                            self.args=args                    # (i,iplist[i],queue)\n                    def __call__(self):\n                            apply(self.func,self.args)        # 函数apply() 执行loop函数并传递元组参数\n            def loop(nloop,ip,queue):\n                    print ''start'',nloop,''at:'',ctime()\n                    queue.put(ip)\n                    sleep(2)\n                    print ''loop'',nloop,''done at:'',ctime()\n            if __name__ == ''__main__'':\n                    threads = []\n                    queue = Queue()\n                    iplist = [''192.168.1.2'',''192.168.1.3'',''192.168.1.4'',''192.168.1.5'',''192.168.1.6'',''192.168.1.7'',''192.168.1.8'']\n                    nloops = range(len(iplist))\n\n                    for i in nloops:\n                            t = threading.Thread(target=ThreadFunc(loop,(i,iplist[i],queue),loop.__name__))\n                            threads.append(t)\n                    for i in nloops:\n                            threads[i].start()\n                    for i in nloops:\n                            threads[i].join()\n                    for i in nloops:\n                            print queue.get()\n\n        threading例子2\n\n            #!/usr/bin/env python\n            #encoding:utf8\n            from Queue import Queue\n            import random,time,threading\n            \n            class Producer(threading.Thread):\n                def __init__(self, t_name, queue):\n                    threading.Thread.__init__(self, name=t_name)\n                    self.data=queue\n                def run(self):\n                    for i in range(5):\n                        print "%s: %s is producing %d to the queue!\\n" %(time.ctime(), self.getName(), i)\n                        self.data.put(i)\n                        self.data.put(i*i)\n                        time.sleep(2)\n                    print "%s: %s finished!" %(time.ctime(), self.getName())\n\n            class Consumer(threading.Thread):\n                def __init__(self, t_name, queue):\n                    threading.Thread.__init__(self, name=t_name)\n                    self.data=queue\n                def run(self):\n                    for i in range(10):\n                        val = self.data.get()\n                        print "%s: %s is consuming. %d in the queue is consumed!\\n" %(time.ctime(), self.getName(), val)\n                    print "%s: %s finished!" %(time.ctime(), self.getName())\n\n            if __name__ == ''__main__'':\n                queue = Queue()\n                producer = Producer(''Pro.'', queue)\n                consumer = Consumer(''Con.'', queue)\n                producer.start()\n                consumer.start()\n                producer.join()\n                consumer.join()\n\n        threading例子3\n        \n            # 启动线程后自动执行 run函数其他不可以\n            import threading\n            import time\n\n            class Th(threading.Thread):\n                def __init__(self,name):\n                    threading.Thread.__init__(self)\n                    self.t_name=name\n                    self.daemon = True     # 默认为false，让主线程等待处理完成\n                def run(self):\n                    time.sleep(1)\n                    print "this is " + self.t_name\n\n            if __name__ == ''__main__'':\n                thread1 = Th("Th_1")\n                thread1.start()\n\n        threading例子4\n        \n            import threading\n            import time\n            class Th(threading.Thread):\n                def __init__(self,thread_name):\n                    threading.Thread.__init__(self)\n                    self.setName(thread_name)\n                def run(self):\n                    threadLock.acquire()\n                    print self.getName()\n                    for i in range(3):\n                        time.sleep(1)\n                        print str(i)\n                    print self.getName() +  " is over"\n                    threadLock.release()\n\n            if __name__ == ''__main__'':\n                threadLock = threading.Lock()\n                thread1 = Th("Th_1")\n                thread2 = Th("Th_2")\n                thread1.start()\n                thread2.start()\n\n        后台线程\n\n            import threading\n            import time,random\n\n            class MyThread(threading.Thread):\n                def run(self):\n                    wait_time=random.randrange(1,10)\n                    print "%s will wait %d seconds" % (self.name, wait_time)\n                    time.sleep(wait_time)\n                    print "%s finished!" % self.name\n\n            if __name__=="__main__":\n                for i in range(5):\n                    t = MyThread()\n                    t.setDaemon(True)    # 设置为后台线程,主线程完成时不等待子线程完成就结束\n                    t.start()\n\n        threading控制最大并发_查询日志中IP信息\n\n            #!/usr/bin/env python\n            #coding:utf-8\n            import urllib2\n            import json\n            import threading\n            import time\n\n            ''''''\n            by:某大牛\n            QQ:185635687\n            这个是多线程并发控制. 如果要改成多进程，只需把threading 换成 mulitprocessing.Process ， 对， 就是换个名字而已.\n            ''''''\n\n            #获取ip 及其出现次数\n            def ip_dic(file_obj, dic):\n                for i in file_obj:\n                    if i:\n                        ip=i.split(''-'')[0].strip()\n                        if ip in dic.keys():\n                            dic[ip]=dic[ip] + 1\n                        else:\n                            dic[ip]=1\n                return dic.iteritems()\n\n            #目标函数\n            def get_data(url, ipcounts):\n                data=urllib2.urlopen(url).read()\n                datadict=json.loads(data)\n                fdata = u"ip:%s---%s,%s,%s,%s,%s" %(datadict["data"]["ip"],ipcounts,datadict["data"]["country"],datadict["data"]["region"],datadict["data"]["city"],datadict["data"]["isp"])\n                print fdata\n\n            #多线程\n            def threads(iters):\n                thread_pool = []\n                for k in iters:\n                    url = "http://ip.taobao.com/service/getIpInfo.php?ip="\n                    ipcounts = k[1]\n                    url = (url + k[0]).strip()\n                    t = threading.Thread(target=get_data, args=(url, ipcounts))\n                    thread_pool.append(t)\n                return thread_pool\n\n            #控制多线程\n            def startt(t_list, max,second):\n                l = len(t_list)\n                n = max\n                while l > 0:\n                    if l > max:\n                        nl = t_list[:max]\n                        t_list = t_list[max:]\n                        for t in nl:\n                            t.start()\n                        time.sleep(second)\n                        for t in nl:\n                            t.join()\n                        print ''*''*15,  str(n)+ '' ip has been queried''+''*''*15\n                        n += max\n                        l = len(t_list)\n                        continue\n                    elif l <= max:\n                        nl = t_list\n                        for t in nl:\n                            t.start()\n                        for t in nl:\n                            t.join()\n                        print ''>>> Totally '' + str(n+l ) + '' ip has been queried''\n                        l = 0\n\n            if __name__ =="__main__":\n                dic={}\n                with open(''access.log'') as file_obj:\n                    it = ip_dic(file_obj, dic)\n                    t_list= threads(it)\n                    startt(t_list, 15, 1)\n\n        多线程取队列\n        \n            #!/usr/bin/python\n\n            import Queue\n            import threading\n            import time\n\n            exitFlag = 0\n\n            class myThread(threading.Thread):\n                def __init__(self, threadID, name, q):\n                    threading.Thread.__init__(self)\n                    self.threadID = threadID\n                    self.name = name\n                    self.q = q\n                def run(self):\n                    print "Starting " + self.name\n                    process_data(self.name, self.q)\n                    print "Exiting " + self.name\n\n            def process_data(threadName, q):\n                while not exitFlag:      # 死循环等待\n                    queueLock.acquire()\n                    if not q.empty():    # 判断队列是否为空\n                        data = q.get()\n                        print "%s processing %s" % (threadName, data)\n                    queueLock.release()\n                    time.sleep(1)\n\n            threadList = ["Thread-1", "Thread-2", "Thread-3"]\n            nameList = ["One", "Two", "Three", "Four", "Five"]\n            queueLock = threading.Lock()     # 锁与队列并无任何关联，其他线程也进行取锁操作的时候就会检查是否有被占用，有就阻塞等待解锁为止\n            workQueue = Queue.Queue(10)\n            threads = []\n            threadID = 1\n\n            # Create new threads\n            for tName in threadList:\n                thread = myThread(threadID, tName, workQueue)\n                thread.start()\n                threads.append(thread)\n                threadID += 1\n\n            # Fill the queue\n            queueLock.acquire()\n            for word in nameList:\n                workQueue.put(word)\n            queueLock.release()\n\n            # Wait for queue to empty\n            while not workQueue.empty():   # 死循环判断队列被处理完毕\n                pass\n\n            # Notify threads it''s time to exit\n            exitFlag = 1\n\n            # Wait for all threads to complete\n            for t in threads:\n                t.join()\n            print "Exiting Main Thread"\n    \n    Queue通用队列\n\n        q=Queue(size)       # 创建大小size的Queue对象\n        qsize()             # 返回队列的大小(返回时候,可能被其他进程修改,近似值)\n        empty()             # 如果队列为空返回True，否则Fales\n        full()              # 如果队列已满返回True，否则Fales\n        put(item,block0)    # 把item放到队列中,如果给了block(不为0),函数会一直阻塞到队列中有空间为止\n        get(block=0)        # 从队列中取一个对象,如果给了block(不为0),函数会一直阻塞到队列中有对象为止\n        get_nowait          # 默认get阻塞，这个不阻塞\n\n    multiprocessing [多进程并发]\n\n        线程池\n        \n            import urllib2\n            from multiprocessing.dummy import Pool as ThreadPool\n\n            urls=[''http://www.baidu.com'',''http://www.sohu.com'']\n\n            pool=ThreadPool(4)   # 线程池\n            results=pool.map(urllib2.urlopen,urls)\n            pool.close()\n            pool.join()\n\n        进程并发\n\n            #!/usr/bin/env python\n            #encoding:utf8\n            from multiprocessing import Process\n            import time,os\n            def f(name):\n                time.sleep(1)\n                print ''hello '',name\n                print os.getppid()   # 取得父进程ID\n                print os.getpid()    # 取得进程ID\n            process_list = []\n\n            for i in range(10):\n                p = Process(target=f,args=(i,))\n                p.start()\n                process_list.append(p)\n            for j in process_list:\n                j.join()\n\n        进程池\n\n            #!/usr/bin/env python\n            #encoding:utf8\n            from multiprocessing import Pool\n            import time,os\n            def f(name):\n                time.sleep(1)\n                print ''hello '',name\n                print os.getppid() \n                print os.getpid() \n            process_list = []\n\n            pool = Pool(4)\n            res = pool.map(f, range(1,10))\n            pool.close()\n            pool.join()\n        \n        Queue进程间通信\n\n            from multiprocessing import Process,Queue\n            import time\n            def f(name):\n                time.sleep(1)\n                q.put([''hello''+str(name)])\n            process_list = []\n            q = Queue()\n            if __name__ == ''__main__'':\n                for i in range(10):\n                    p = Process(target=f,args=(i,))\n                    p.start()\n                    process_list.append(p)\n                for j in process_list:\n                    j.join()\n                for i in range(10):\n                    print q.get()\n\n        Pipe管道 # 单项通信\n        \n            from multiprocessing import Process,Pipe\n            import time\n            import os\n\n            def f(conn,name):\n                time.sleep(1)\n                conn.send([''hello''+str(name)])\n                print os.getppid(),''-----------'',os.getpid()\n            process_list = []\n            parent_conn,child_conn = Pipe()\n            if __name__ == ''__main__'':\n                for i in range(10):\n                    p = Process(target=f,args=(child_conn,i))\n                    p.start()\n                    process_list.append(p)\n                for j in process_list:\n                    j.join()\n                for p in range(10):\n                    print parent_conn.recv()\n\n        进程间同步\n            #加锁,使某一时刻只有一个进程,其他在调用同一个锁就会被阻塞\n            from multiprocessing import Process,Lock\n            import time\n            import os\n\n            def f(name):\n                lock.acquire()\n                time.sleep(1)\n                print ''hello--''+str(name)\n                print os.getppid(),''-----------'',os.getpid()\n                lock.release()\n            process_list = []\n            lock = Lock()\n            if __name__ == ''__main__'':\n                for i in range(10):\n                    p = Process(target=f,args=(i,))\n                    p.start()\n                    process_list.append(p)\n                for j in process_list:\n                    j.join()\n\n        共享内存 # 双向通信\n\n            # 通过使用Value或者Array把数据存储在一个共享的内存表中\n            # ''d''和''i''参数是num和arr用来设置类型，d表示一个双精浮点类型，i表示一个带符号的整型。\n            from multiprocessing import Process,Value,Array\n            import time\n            import os\n\n            def f(n,a,name):\n                time.sleep(1)\n                n.value = name * name\n                for i in range(len(a)):\n                    a[i] = -i\n            process_list = []\n            if __name__ == ''__main__'':\n                num = Value(''d'',0.0)\n                arr = Array(''i'',range(10))\n                for i in range(10):\n                    p = Process(target=f,args=(num,arr,i))\n                    p.start()\n                    process_list.append(p)\n                for j in process_list:\n                    j.join()\n                print num.value\n                print arr[:]\n\n        manager\n\n            # 比共享内存灵活,但缓慢\n            # 支持list,dict,Namespace,Lock,Semaphore,BoundedSemaphore,Condition,Event,Queue,Ｖalue,Array\n            from multiprocessing import Process,Manager\n            import time\n            import os\n\n            def f(d,name):\n                time.sleep(1)\n                d[name] = name * name\n                print d\n            process_list = []\n            if __name__ == ''__main__'':\n                manager = Manager()\n                d = manager.dict()\n                for i in range(10):\n                    p = Process(target=f,args=(d,i))\n                    p.start()\n                    process_list.append(p)\n                for j in process_list:\n                    j.join()\n                    print d\n\n        最大并发数\n\n            import multiprocessing\n            import time,os\n\n            result = []\n            def run(h):\n                print ''threading:'' ,h,os.getpid()\n            p = multiprocessing.Pool(processes=20)\n\n            for i in range(100):\n                result.append(p.apply_async(run,(i,)))\n            p.close()\n            \n            for res in result:\n                res.get(timeout=5)\n\n    gevent          [轻量级协程]\n\n        # 在gevent中用到的主要模式是Greenlet, 它是以C扩展模块形式接入Python的轻量级协程。 Greenlet全部运行在主程序操作系统进程的内部，但它们被协作式地调度。\n        # http://xlambda.com/gevent-tutorial/\n\n        锁的使用\n        \n            # 同时允许多个协程操作对象的锁,通过互斥访问,保证资源只在程序上下文被单次使用\n            from gevent import sleep\n            from gevent.pool import Pool\n            from gevent.coros import BoundedSemaphore\n\n            sem = BoundedSemaphore(2)        # 超过2就会阻塞等待\n\n            def worker1(n):\n                sem.acquire()\n                print(''Worker %i acquired semaphore'' % n)\n                sleep(0)\n                sem.release()\n                print(''Worker %i released semaphore'' % n)\n\n            def worker2(n):\n                with sem:\n                    print(''Worker %i acquired semaphore'' % n)\n                    sleep(0)\n                print(''Worker %i released semaphore'' % n)\n\n            pool = Pool()\n            pool.map(worker1, xrange(0,2))\n            pool.map(worker2, xrange(3,6))\n\n        事件\n            \n            # Event 阻塞事件\n            import gevent\n            from gevent.event import Event\n\n            evt = Event()\n\n            def setter():\n                ''''''After 3 seconds, wake all threads waiting on the value of evt''''''\n                print(''A: Hey wait for me, I have to do something'')\n                gevent.sleep(3)\n                print("Ok, I''m done")\n                evt.set()                 # 表示事件完成\n\n            def waiter():\n                ''''''After 3 seconds the get call will unblock''''''\n                print("I''ll wait for you")\n                evt.wait()                # 阻塞等待事件完成\n                print("It''s about time")\n\n            gevent.joinall([\n                gevent.spawn(setter),\n                gevent.spawn(waiter),\n                gevent.spawn(waiter),\n                gevent.spawn(waiter),\n                gevent.spawn(waiter),\n                gevent.spawn(waiter)\n            ])\n\n            # AsyncResult 可传值的事件\n            import gevent\n            from gevent.event import AsyncResult\n            a = AsyncResult()\n\n            def setter():\n                gevent.sleep(3)\n                a.set(''Hello!'')            # 事件传值\n\n            def waiter():\n                """\n                After 3 seconds the get call will unblock after the setter\n                puts a value into the AsyncResult.\n                """        \n                print(a.get())             # 获取时间值\n\n            gevent.joinall([\n                gevent.spawn(setter),\n                gevent.spawn(waiter),\n            ])\n\n        队列\n\n            #/usr/local/python\n            #encoding:utf8\n            import gevent\n            from gevent.pool import Pool\n            from gevent.coros import BoundedSemaphore\n            from gevent.queue import Queue, Empty\n            import os\n\n            tasks = Queue(maxsize=30)         # 队列 超过30引发 gevent.hub.LoopExit \n            tasks1 = Queue()     \n\n            def boss():\n                print ''放队列任务''\n                for i in xrange(1,25):\n                    tasks.put(i)\n\n            def worker1(n):\n                print len(pool)\n                while not tasks.empty():      # 判断队列是否为空\n                    task = tasks.get()        # 获取队列内容\n                    tasks1.put(os.popen(''id'').read()) \n                    print(''Worker %s got task %s'' % (n, task))\n                    gevent.sleep(0)           # 放弃当前任务\n\n            def worker2(name):\n                try:\n                    while True:\n                        task = tasks1.get(timeout=2)\n                        print ''获取后释放:%s'' % task\n                        gevent.sleep(0)\n                except Empty:                 # 等待超时报错完成\n                    print(''Quitting time!'')\n\n            gevent.spawn(boss).join()         # 执行单次协程任务\n\n            pool = Pool(5)                    # 协程池大小 \n            pool.map(worker1, xrange(0,20))   # 通过map方法把多个任务分发给池中的5个协程\n\n            gevent.joinall([                  # 同时执行多个协程任务\n                gevent.spawn(worker2, ''steve''),\n                gevent.spawn(worker2, ''john''),\n                gevent.spawn(worker2, ''nancy''),\n            ])\n\n9 框架\n\n    flask           [微型网络开发框架]\n    \n        # http://dormousehole.readthedocs.org/en/latest/\n        # html放在 ./templates/   js放在 ./static/\n        \n        request.args.get(''page'', 1)          # 获取参数 ?page=1\n        request.json                         # 获取传递的整个json数据\n        request.form.get("host",''127'')       # 获取表单值\n        request.form.getlist(''client'')       # 获取表单列表\n            \n        简单实例 # 接收数据和展示\n\n            import MySQLdb as mysql\n            from flask import Flask, request\n\n            app = Flask(__name__)\n            db.autocommit(True)\n            c = db.cursor()\n\n            """\n            CREATE TABLE `statusinfo` (\n              `id` int(11) unsigned NOT NULL AUTO_INCREMENT,\n              `hostname` varchar(32) NOT NULL,\n              `load` float(10) NOT NULL DEFAULT 0.00,\n              `time` int(15) NOT NULL,\n              `memtotal` int(15) NOT NULL,\n              `memusage` int(15) NOT NULL,\n              `memfree` int(15) NOT NULL,\n              PRIMARY KEY (`id`)\n            ) ENGINE=InnoDB AUTO_INCREMENT=161 DEFAULT CHARSET=utf8;\n            """\n\n            @app.route("/collect", methods=["GET", "POST"])\n            def collect():\n                sql = ""\n                if request.method == "POST":\n                    data = request.json                      # 获取传递的json\n                    hostname = data["Host"]\n                    load = data["LoadAvg"]\n                    time = data["Time"]\n                    memtotal = data["MemTotal"]\n                    memusage = data["MemUsage"]\n                    memfree = data["MemFree"]\n                    \n                    try:\n                        sql = "INSERT INTO `statusinfo` (`hostname`,`load`,`time`,`memtotal`,`memusage`,`memfree`) VALUES(''%s'', %s, %s, %s, %s, %s);" % (hostname, load,time,memtotal,memusage,memfree)\n                        ret = c.execute(sql)\n                        return ''ok''\n                    except mysql.IntegrityError:\n                        return ''errer''\n\n            @app.route("/show", methods=["GET", "POST"])\n            def show():\n                try:\n                    hostname = request.form.get("hostname")     # 获取表单方式的变量值\n                    sql = "SELECT `load` FROM `statusinfo` WHERE hostname = ''%s'';" % (hostname)\n                    c.execute(sql)\n                    ones = c.fetchall()\n                    return render_template("sysstatus.html", data=ones, sql = sql)\n                except:\n                    print ''hostname null''\n\n            from flask import render_template\n            @app.route("/xxx/<name>")\n            def hello_xx(name):\n                return render_template("sysstatus.html", name=''teach'')\n\n            if __name__ == "__main__":\n                app.run(host="0.0.0.0", port=50000, debug=True)\n\n    twisted         [非阻塞异步服务器框架]\n\n        # 较老 推荐使用 协程框架 或 微线程框架\n        # 用来进行网络服务和应用程序的编程。虽然 Twisted Matrix 中有大量松散耦合的模块化组件，但该框架的中心概念还是非阻塞异步服务器这一思想。对于习惯于线程技术或分叉服务器的开发人员来说，这是一种新颖的编程风格，但它却能在繁重负载的情况下带来极高的效率。\n        pip install twisted\n        \n        from twisted.internet import protocol, reactor, endpoints\n\n        class Echo(protocol.Protocol):\n            def dataReceived(self, data):\n                self.transport.write(data)\n        class EchoFactory(protocol.Factory):\n            def buildProtocol(self, addr):\n                return Echo()\n\n        endpoints.serverFromString(reactor, "tcp:1234").listen(EchoFactory())\n        reactor.run()\n\n        服务端\n\n            #!/usr/bin/env python\n\n            from twisted.application import service, internet\n            from txjsonrpc.netstring import jsonrpc\n\n            class Example(jsonrpc.JSONRPC):\n                """An example object to be published."""\n                def jsonrpc_echo(self,  x): \n                    """Return all passed args."""\n                    return x\n                def jsonrpc_add(self, a, b): \n                    """Return sum of arguments."""\n                    print "add", a, b\n                    return a + b \n\n            factory = jsonrpc.RPCFactory(Example())\n            application = service.Application("Example JSON-RPC Server")\n            jsonrpcServer = internet.TCPServer(7080, factory)\n            jsonrpcServer.setServiceParent(application)\n\n\n        客户端\n            #!/usr/bin/env python\n\n            import os\n            import sys\n            sys.path.insert(0, os.getcwd())\n            from twisted.internet import reactor\n            from txjsonrpc.netstring.jsonrpc import Proxy\n\n            def printValue(value):\n                print "Result: %s" % str(value)\n                reactor.stop()\n\n            def printError(error):\n                print ''error'', error\n                reactor.stop()\n\n            proxy = Proxy(''127.0.0.1'', 7080)\n            proxy.callRemote(''add'', 3, 5).addCallbacks(printValue, printError)\n            reactor.run()\n\n    tornado         [极轻量级Web服务器框架] \n\n        # 高可伸缩性和epoll非阻塞IO,响应快速,可处理数千并发连接,特别适用用于实时的Web服务 底层是gevent协程\n        # http://www.tornadoweb.cn/documentation\n        pip install tornado\n        \n        tornado 源码分析系列目录\n\n            tornado 简介: http://www.cnblogs.com/Bozh/archive/2012/07/17/2596458.html\n            tornado 网络层IOLoop: http://www.cnblogs.com/Bozh/archive/2012/07/18/2597114.html\n            tornado 网络层IOLoop: http://www.cnblogs.com/Bozh/archive/2012/07/19/2598696.html\n            tornado Buffer层IOStream: http://www.cnblogs.com/Bozh/archive/2012/07/20/2600520.html\n            tornado HTTPServer层: http://www.cnblogs.com/Bozh/archive/2012/07/22/2603963.html\n            tornado HTTPServer详解: http://www.cnblogs.com/Bozh/archive/2012/07/24/2606765.html\n\n        import tornado.ioloop\n        import tornado.web\n\n        class MainHandler(tornado.web.RequestHandler):\n            def get(self):\n                self.write("Hello, world")\n\n        application = tornado.web.Application([\n            (r"/", MainHandler),\n        ])\n\n        if __name__ == "__main__":\n            application.listen(8888)\n            tornado.ioloop.IOLoop.instance().start()\n\n    Scrapy          [web抓取框架]\n\n        # Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。\n        pip install scrapy\n        \n        from scrapy import Spider, Item, Field\n\n        class Post(Item):\n            title = Field()\n\n        class BlogSpider(Spider):\n            name, start_urls = ''blogspider'', [''http://blog.scrapinghub.com'']\n\n            def parse(self, response):\n                return [Post(title=e.extract()) for e in response.css("h2 a::text")]\n                \n        scrapy runspider myspider.py\n\n    django          [重量级web框架]\n\n    bottle          [轻量级的Web框架]\n\n    stackless       [增强版python]\n\n        微线程扩展，是一种低开销、轻量级的便利工具  避免传统线程所带来的性能与复杂度问题 \n    \n    greenlet        [微线程/协程框架]\n\n        # 更加原始的微线程的概念,没有调度,或者叫做协程。这在你需要控制你的代码时很有用。你可以自己构造微线程的 调度器；也可以使用"greenlet"实现高级的控制流。例如可以重新创建构造器；不同于Python的构造器，我们的构造器可以嵌套的调用函数，而被嵌套的函数也可以 yield 一个值。\n        pip install greenlet\n\n    asyncio         [异步I/O协同]\n\n        # https://docs.python.org/3/library/asyncio.html\n        需要python3.4+\n        asyncio: 协同程序和事件循环。协同程序像是方法，但是它们可以在代码中的特定点暂停和继续。当在等待一个IO（比如一个HTTP请求），同时执行另一个请求的时候，可以用来暂停一个协同程序。我们使用关键字yield from来设定一个状态，表明我们需要一个协同程序的返回值。而事件循环则被用来安排协同程序的执行。\n\n10例子\n\n    小算法\n\n        斐波那契\n            #将函数结果作为列表可用于循环\n            def fab(max): \n            n, a, b = 0, 0, 1 \n            while n < max: \n                yield b         \n                a, b = b, a + b \n                n = n + 1 \n            for n in fab(5): \n                print n\n\n        乘法口诀\n\n            #!/usr/bin/python\n            for i in range(1,10):\n                for j in range(1,i+1):\n                    print j,''*'',i,''='',j*i,\n                else:\n                    print ''''\n\n        最小公倍数\n\n            # 1-70的最小公倍数\n            def c(m,n):\n                    a1=m\n                    b1=n\n                    r=n%m\n                    while r!=0:\n                            n=m\n                            m=r\n                            r=n%m\n                    return (a1*b1)/m\n            d=1\n            for i in range(3,71,2):\n                    d = c(d,i)\n            print d\n\n        排序算法\n\n            插入排序\n                def insertion_sort(sort_list):\n                    iter_len = len(sort_list)\n                    if iter_len < 2:\n                        return sort_list\n                    for i in range(1, iter_len):\n                        key = sort_list[i]\n                        j = i - 1\n                        while j>=0 and sort_list[j]>key:\n                            sort_list[j+1] = sort_list[j]\n                            j -= 1\n                        sort_list[j+1] = key\n                    return sort_list\n\n            选择排序\n                def selection_sort(sort_list):\n                    iter_len = len(sort_list)\n                    if iter_len < 2:\n                        return sort_list\n                    for i in range(iter_len-1):\n                        smallest = sort_list[i]\n                        location = i\n                        for j in range(i, iter_len):\n                            if sort_list[j] < smallest:\n                                smallest = sort_list[j]\n                                location = j\n                        if i != location:\n                            sort_list[i], sort_list[location] = sort_list[location], sort_list[i]\n                    return sort_list    \n\n            冒泡排序\n                def bubblesort(numbers):\n                    for j in range(len(numbers)-1,-1,-1):\n                        for i in range(j):\n                            if numbers[i]>numbers[i+1]:\n                                numbers[i],numbers[i+1] = numbers[i+1],numbers[i]\n                            print(i,j)\n                            print(numbers)\n\n            快速排序\n\n                # 先从数列中取出一个数作为基准数。\n                # 分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。\n                # 再对左右区间重复第二步，直到各区间只有一个数。\n                #!/usr/bin/python\n                # -*- coding: utf-8 -*-\n\n                def sub_sort(array,low,high):\n                    key = array[low]\n                    while low < high:\n                        while low < high and array[high] >= key:\n                            high -= 1\n                        while low < high and array[high] < key:\n                            array[low] = array[high]\n                            low += 1\n                            array[high] = array[low]\n                    array[low] = key\n                    return low\n\n                def quick_sort(array,low,high):\n                     if low < high:\n                        key_index = sub_sort(array,low,high)\n                        quick_sort(array,low,key_index)\n                        quick_sort(array,key_index+1,high)\n\n                if __name__ == ''__main__'':\n                    array = [8,10,9,6,4,16,5,13,26,18,2,45,34,23,1,7,3]\n                    print array\n                    quick_sort(array,0,len(array)-1)\n                    print array\n\n        二分算法\n\n            #python 2f.py 123456789 4\n            # list(''123456789'')  =  [''1'', ''2'', ''3'', ''4'', ''5'', ''6'', ''7'', ''8'', ''9'']\n            #!/usr/bin/env python \n            import sys\n\n            def search2(a,m):\n                low = 0\n                high = len(a) - 1\n                while(low <= high):\n                    mid = (low + high)/2\n                    midval = a[mid]\n\n                    if midval < m:\n                        low = mid + 1\n                    elif midval > m:\n                        high = mid - 1\n                    else:\n                        print mid\n                        return mid\n                print -1\n                return -1\n\n            if __name__ == "__main__":\n                a = [int(i) for i in list(sys.argv[1])]\n                m = int(sys.argv[2])\n                search2(a,m)\n\n    1000以内是3或者是5的倍数的值的和\n\n        sum([ num for num in range(1, 1000) if num % 3 == 0 or num % 5 == 0 ])\n\n    将字典中所有time去掉\n    \n        a={''version01'': {''nba'': {''timenba'': ''valuesasdfasdf'', ''nbanbac'': ''vtimefasdf'', ''userasdf'': ''vtimasdf''}}}\n        eval(str(a).replace("time",""))\n\n    PIL图像处理\n\n        import Image\n        im = Image.open("j.jpg")            # 打开图片\n        print im.format, im.size, im.mode   # 打印图像格式、像素宽和高、模式\n        # JPEG (440, 330) RGB\n        im.show()                           # 显示最新加载图像\n        box = (100, 100, 200, 200)\n        region = im.crop(box)               # 从图像中提取出某个矩形大小的图像\n\n    图片等比缩小\n\n        # -*- coding: cp936 -*-\n        import Image  \n        import glob, os  \n          \n        #图片批处理  \n        def timage():  \n            for files in glob.glob(''D:\\\\1\\\\*.JPG''):  \n                filepath,filename = os.path.split(files)  \n                filterame,exts = os.path.splitext(filename)  \n                #输出路径  \n                opfile = r''D:\\\\22\\\\''  \n                #判断opfile是否存在，不存在则创建  \n                if (os.path.isdir(opfile)==False):  \n                    os.mkdir(opfile)  \n                im = Image.open(files)  \n                w,h = im.size  \n                #im_ss = im.resize((400,400))  \n                #im_ss = im.convert(''P'')  \n                im_ss = im.resize((int(w*0.12), int(h*0.12)))  \n                im_ss.save(opfile+filterame+''.jpg'')  \n          \n        if __name__==''__main__'':  \n            timage()\n\n    取系统返回值赋给序列\n\n        cmd = os.popen("df -Ph|awk ''NR!=1{print $5}''").readlines();\n        cmd = os.popen(''df -h'').read().split(''\\n'')\n        cmd = os.popen(''lo 2>&1'').read()\n        \n        #取磁盘使用空间\n        import commands\n        df = commands.getoutput("df -hP")\n        [ x.split()[4] for x in df.split("\\n") ] \n        [ (x.split()[0],x.split()[4]) for x in df.split("\\n") if x.split()[4].endswith("%") ] \n\n    打印表格\n\n        map = [["a","b","c"],\n               ["d","e","f"],\n               ["g","h","i"]]\n        def print_board():\n            for i in range(0,3):\n                for j in range(0,3):\n                    print "|",map[i][j],\n                    #if j != 2:\n                print ''|''\n\n    生成html文件表格\n\n        log_file = file(''check.html'', ''w'')\n        log_file.write("""\n        <!DOCTYPE HTML>\n        <html lang="utr-8">\n        <head>\n        <meta charset="UTF-8">\n        <title></title>\n        </head>\n        <body>\n        <table align=''center'' border=''0'' cellPadding=''0''  style=''font-size:24px;''><tr ><td>状态统计</td></tr></table>\n        <style>.font{font-size:13px}</style>\n        <table  align=''center'' border=''1'' borderColor=gray cellPadding=3 width=1350  class=''font''>\n        <tr style=''background-color:#666666''>\n          <th width=65>IP</th>\n          <th width=65>状态</th>\n        </tr>\n        """)\n        for i in list:\n            log_file.write(''<tr><td>%s</td><td>%s</td></tr>\\n'' %(i.split()[0],i.split()[1]) )\n        log_file.write("""\n        </table>\n        </body>\n        </html>\n        """)\n        log_file.flush()\n        log_file.close()\n\n    井字游戏\n\n        #!/usr/bin/python\n        # http://www.admin10000.com/document/2506.html\n        def print_board():\n            for i in range(0,3):\n                for j in range(0,3):\n                    print map[2-i][j],\n                    if j != 2:\n                        print "|",\n                print ""\n         \n        def check_done():\n            for i in range(0,3):\n                if map[i][0] == map[i][1] == map[i][2] != " " \\\n                or map[0][i] == map[1][i] == map[2][i] != " ":\n                    print turn, "won!!!"\n                    return True\n         \n            if map[0][0] == map[1][1] == map[2][2] != " " \\\n            or map[0][2] == map[1][1] == map[2][0] != " ":\n                print turn, "won!!!"\n                return True\n         \n            if " " not in map[0] and " " not in map[1] and " " not in map[2]:\n                print "Draw"\n                return True\n         \n            return False\n         \n        turn = "X"\n        map = [[" "," "," "],\n               [" "," "," "],\n               [" "," "," "]]\n        done = False\n         \n        while done != True:\n            print_board()\n         \n            print turn, "''s turn"\n            print\n         \n            moved = False\n            while moved != True:\n                print "Please select position by typing in a number between 1 and 9, see below for which number that is which position..."\n                print "7|8|9"\n                print "4|5|6"\n                print "1|2|3"\n                print\n         \n                try:\n                    pos = input("Select: ")\n                    if pos <=9 and pos >=1:\n                        Y = pos/3\n                        X = pos%3\n                        if X != 0:\n                            X -=1\n                        else:\n                             X = 2\n                             Y -=1\n         \n                        if map[Y][X] == " ":\n                            map[Y][X] = turn\n                            moved = True\n                            done = check_done()\n         \n                            if done == False:\n                                if turn == "X":\n                                    turn = "O"\n                                else:\n                                    turn = "X"\n         \n                except:\n                    print "You need to add a numeric value"\n\n    网段划分\n\n        题目\n            192.168.1\n            192.168.3\n            192.168.2\n            172.16.3\n            192.16.1\n            192.16.2\n            192.16.3\n            10.0.4\n\n            输出结果：\n            192.16.1-192.16.3\n            192.168.1-192.168.3\n            172.16.3\n            10.0.4\n\n        答案\n            #!/usr/bin/python\n\n            f = file(''a.txt'')\n            c = f.readlines()\n            dic={}\n\n            for i in c:\n                a=i.strip().split(''.'')\n                if a[0]+''.''+a[1] in dic.keys():\n                    key=dic["%s.%s" %(a[0],a[1])]\n                else:\n                    key=[]\n                key.append(a[2])\n                dic[a[0]+''.''+a[1]]=sorted(key)\n\n            for x,y in dic.items():\n                if y[0] == y[-1]:\n                    print ''%s.%s'' %(x,y[0])\n                else:\n                    print ''%s.%s-%s.%s'' %(x,y[0],x,y[-1])\n\n    统计日志IP\n        # 打印出独立IP，并统计独立IP数\n        219.140.190.130 - - [23/May/2006:08:57:59 +0800] "GET /fg172.exe HTTP/1.1" 200 2350253\n        221.228.143.52 - - [23/May/2006:08:58:08 +0800] "GET /fg172.exe HTTP/1.1" 206 719996\n        221.228.143.52 - - [23/May/2006:08:58:08 +0800] "GET /fg172.exe HTTP/1.1" 206 713242\n\n        #!/usr/bin/python\n        dic={}\n        a=open("a").readlines()\n        for i in a:\n            ip=i.strip().split()[0]\n            if ip in dic.keys():\n                dic[ip] = dic[ip] + 1\n            else:\n                dic[ip] = 1\n        for x,y in dic.items():\n            print x," ",y\n\n    多线程下载http\n    \n        # 先从文件头中或取content-length的值,即文件大小,在用header中指定Range范围来下载文件中一段字符串  \n        # ''Range'':''bytes=0-499''           # 表示头500个字节\n        # ''Range'':''bytes=-500''            # 表示最后500个字节\n        # ''Range'':''bytes=500-''            # 表示500字节以后的范围\n        # ''Range'':''bytes=0-0,-1''          # 第一个和最后一个字节\n        # ''Range'':''bytes=50-60,61-99''     # 同时指定几个范围\n\n        #!/usr/bin/env python\n        #encoding:utf8\n        import urllib2\n        import threading\n\n\n        class myThread(threading.Thread):\n\n            def __init__(self, url_file, scope, url):\n                threading.Thread.__init__(self)\n                self.url_file = url_file\n                self.scope = scope\n                self.url = url\n\n            def run(self):\n\n                req_header = {''User-Agent'':"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)",\n                ''Accept'':''text/html;q=0.9,*/*;q=0.8'',\n                ''Range'':''bytes=%s'' % self.scope,\n                ''Accept-Charset'':''ISO-8859-1,utf-8;q=0.7,*;q=0.3'',\n                ''Connection'':''close'',\n                }\n                \n                req = urllib2.Request(self.url, headers=req_header)\n                data = urllib2.urlopen(req, data=None).read()\n                start_value = int(self.scope.split(''-'')[0])\n                \n                threadLock.acquire()\n\n                self.url_file.seek(start_value)\n                self.url_file.write(data)\n                self.url_file.flush()\n                threadLock.release()\n\n        if __name__ == ''__main__'':\n\n            url = ''http://dldir1.qq.com/qqfile/qq/QQ7.1/14522/QQ7.1.exe''\n            size=int(urllib2.urlopen(url).info()[''content-length''])\n            print size\n            threadnum = 4\n            len = size / threadnum\n            current = 0\n\n            url_file = file(url.split(''/'')[-1],''wb+'')\n            threadLock = threading.Lock()\n            threads = []\n            for tName in range(1, threadnum + 1):\n            \n                if tName < threadnum:\n                    scope = "%d-%d" %(current,len * tName - 1)\n                    current = len * tName\n                elif tName == threadnum:\n                        scope = "%d-" %(current)\n                print scope\n                thread = myThread(url_file, scope, url)\n                thread.start()\n                threads.append(thread)\n\n            for t in threads:\n                t.join()\n\n            url_file.flush()\n            url_file.close()\n\n    LazyManage并发批量操作(判断非root交互到root操作)\n\n        #!/usr/bin/python\n        #encoding:utf8\n        # LzayManage.py\n        # config file: serverlist.conf\n\n        import paramiko\n        import multiprocessing\n        import sys,os,time,socket,re\n\n        def Ssh_Cmd(host_ip,Cmd,user_name,user_pwd,port=22):\n            s = paramiko.SSHClient()\n            s.load_system_host_keys()\n            s.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n            s.connect(hostname=host_ip,port=port,username=user_name,password=user_pwd)\n            stdin,stdout,stderr = s.exec_command(Cmd)\n            Result = ''%s%s'' %(stdout.read(),stderr.read())\n            q.put(''successful'')\n            s.close()\n            return Result.strip()\n\n        def Ssh_Su_Cmd(host_ip,Cmd,user_name,user_pwd,root_name,root_pwd,port=22):\n            s = paramiko.SSHClient()\n            s.load_system_host_keys()\n            s.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n            s.connect(hostname=host_ip,port=port,username=user_name,password=user_pwd)\n            ssh = s.invoke_shell()\n            time.sleep(0.1)\n            ssh.send(''su - %s\\n'' %(root_name))\n            buff = ''''\n            while not buff.endswith(''Password: ''):\n                resp = ssh.recv(9999)\n                buff +=resp\n            ssh.send(''%s\\n'' %(root_pwd))\n            buff = ''''\n            while True:\n                resp = ssh.recv(9999)\n                buff +=resp\n                if '': incorrect password'' in buff:\n                    su_correct=''passwd_error''\n                    break\n                elif buff.endswith(''# ''):\n                    su_correct=''passwd_correct''\n                    break\n            if su_correct == ''passwd_correct'':\n                ssh.send(''%s\\n'' %(Cmd))\n                buff = ''''\n                while True:\n                    resp = ssh.recv(9999)\n                    if resp.endswith(''# ''):\n                        buff +=re.sub(''\\[.*@.*\\]# $'','''',resp)\n                        break\n                    buff +=resp\n                Result = buff.lstrip(''%s'' %(Cmd))\n                q.put(''successful'')\n            elif su_correct == ''passwd_error'':\n                Result = "\\033[31mroot密码错误\\033[m"\n            s.close()\n            return Result.strip()\n\n        def Send_File(host_ip,PathList,user_name,user_pwd,Remote=''/tmp'',port=22):\n            s=paramiko.Transport((host_ip,port))\n            s.connect(username=user_name,password=user_pwd)\n            sftp=paramiko.SFTPClient.from_transport(s) \n            for InputPath in PathList:\n                LocalPath = re.sub(''^\\./'','''',InputPath.rstrip(''/''))\n                RemotePath = ''%s/%s'' %( Remote , os.path.basename( LocalPath ))\n                try:\n                    sftp.rmdir(RemotePath)\n                except:\n                    pass\n                try:\n                    sftp.remove(RemotePath)\n                except:\n                    pass\n                if os.path.isdir(LocalPath):\n                    sftp.mkdir(RemotePath)\n                    for path,dirs,files in os.walk(LocalPath):\n                        for dir in dirs:\n                            dir_path = os.path.join(path,dir)\n                            sftp.mkdir(''%s/%s'' %(RemotePath,re.sub(''^%s/'' %LocalPath,'''',dir_path)))\n                        for file in files:\n                            file_path = os.path.join(path,file)\n                            sftp.put( file_path,''%s/%s'' %(RemotePath,re.sub(''^%s/'' %LocalPath,'''',file_path)))\n                else:\n                    sftp.put(LocalPath,RemotePath)\n            q.put(''successful'')\n            sftp.close()\n            s.close()\n            Result = ''%s  \\033[32m传送完成\\033[m'' % PathList\n            return Result\n\n        def Ssh(host_ip,Operation,user_name,user_pwd,root_name,root_pwd,Cmd=None,PathList=None,port=22):\n            msg = "\\033[32m-----------Result:%s----------\\033[m" % host_ip\n            try:\n                if Operation == ''Ssh_Cmd'':\n                    Result = Ssh_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,port=port)\n                elif Operation == ''Ssh_Su_Cmd'':\n                    Result = Ssh_Su_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,root_name=root_name,root_pwd=root_pwd,port=port)\n                elif Operation == ''Ssh_Script'':\n                    Send_File(host_ip=host_ip,PathList=PathList,user_name=user_name,user_pwd=user_pwd,port=port)\n                    Script_Head = open(PathList[0]).readline().strip()\n                    LocalPath = re.sub(''^\\./'','''',PathList[0].rstrip(''/''))\n                    Cmd = ''%s /tmp/%s'' %( re.sub(''^#!'','''',Script_Head), os.path.basename( LocalPath ))\n                    Result = Ssh_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,port=port)\n                elif Operation == ''Ssh_Su_Script'':\n                    Send_File(host_ip=host_ip,PathList=PathList,user_name=user_name,user_pwd=user_pwd,port=port)\n                    Script_Head = open(PathList[0]).readline().strip()\n                    LocalPath = re.sub(''^\\./'','''',PathList[0].rstrip(''/''))\n                    Cmd = ''%s /tmp/%s'' %( re.sub(''^#!'','''',Script_Head), os.path.basename( LocalPath ))\n                    Result = Ssh_Su_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,root_name=root_name,root_pwd=root_pwd,port=port)\n                elif Operation == ''Send_File'':\n                    Result = Send_File(host_ip=host_ip,PathList=PathList,user_name=user_name,user_pwd=user_pwd,port=port)\n                else:\n                    Result = ''操作不存在''\n                \n            except socket.error:\n                Result = ''\\033[31m主机或端口错误\\033[m''\n            except paramiko.AuthenticationException:\n                Result = ''\\033[31m用户名或密码错误\\033[m''\n            except paramiko.BadHostKeyException:\n                Result = ''\\033[31mBad host key\\033[m[''\n            except IOError:\n                Result = ''\\033[31m远程主机已存在非空目录或没有写权限\\033[m''\n            except:\n                Result = ''\\033[31m未知错误\\033[m''\n            r.put(''%s\\n%s\\n'' %(msg,Result))\n\n        def Concurrent(Conf,Operation,user_name,user_pwd,root_name,root_pwd,Cmd=None,PathList=None,port=22):\n            # 读取配置文件\n            f=open(Conf)\n            list = f.readlines()\n            f.close()\n            # 执行总计\n            total = 0\n            # 并发执行\n            for host_info in list:\n                # 判断配置文件中注释行跳过\n                if host_info.startswith(''#''):\n                    continue\n                # 取变量,其中任意变量未取到就跳过执行\n                try:\n                    host_ip=host_info.split()[0]\n                    #user_name=host_info.split()[1]\n                    #user_pwd=host_info.split()[2]\n                except:\n                    print(''Profile error: %s'' %(host_info) )\n                    continue\n                try:\n                    port=int(host_info.split()[3])\n                except:\n                    port=22\n                total +=1\n                p = multiprocessing.Process(target=Ssh,args=(host_ip,Operation,user_name,user_pwd,root_name,root_pwd,Cmd,PathList,port))\n                p.start()\n            # 打印执行结果\n            for j in range(total):\n                print(r.get() )\n            if Operation == ''Ssh_Script'' or Operation == ''Ssh_Su_Script'':\n                successful = q.qsize() / 2\n            else:\n                successful = q.qsize()\n            print(''\\033[32m执行完毕[总执行:%s 成功:%s 失败:%s]\\033[m'' %(total,successful,total - successful) )\n            q.close()\n            r.close()\n\n        def Help():\n            print(''''''    1.执行命令\n            2.执行脚本      \\033[32m[位置1脚本(必须带脚本头),后可带执行脚本所需要的包\\文件\\文件夹路径,空格分隔]\\033[m\n            3.发送文件      \\033[32m[传送的包\\文件\\文件夹路径,空格分隔]\\033[m\n            退出: 0\\exit\\quit\n            帮助: help\\h\\?\n            注意: 发送文件默认为/tmp下,如已存在同名文件会被强制覆盖,非空目录则中断操作.执行脚本先将本地脚本及包发送远程主机上,发送规则同发送文件\n            '''''')\n\n        if __name__==''__main__'':\n            # 定义root账号信息\n            root_name = ''root''\n            root_pwd = ''peterli''\n            user_name=''peterli''\n            user_pwd=''<++(3Ie''\n            # 配置文件\n            Conf=''serverlist.conf''\n            if not os.path.isfile(Conf):\n                print(''\\033[33m配置文件 %s 不存在\\033[m'' %(Conf) )\n                sys.exit()\n            Help()\n            while True:\n                i = raw_input("\\033[35m[请选择操作]: \\033[m").strip()\n                q = multiprocessing.Queue()\n                r = multiprocessing.Queue()\n                if i == ''1'':\n                    if user_name == root_name:\n                        Operation = ''Ssh_Cmd''\n                    else:\n                        Operation = ''Ssh_Su_Cmd''\n                    Cmd = raw_input(''CMD: '').strip()\n                    if len(Cmd) == 0:\n                        print(''\\033[33m命令为空\\033[m'')\n                        continue\n                    Concurrent(Conf=Conf,Operation=Operation,user_name=user_name,user_pwd=user_pwd,root_name=root_name,root_pwd=root_pwd,Cmd=Cmd)\n                elif i == ''2'':\n                    if user_name == root_name:\n                        Operation = ''Ssh_Script''\n                    else:\n                        Operation = ''Ssh_Su_Script''\n                    PathList = raw_input(''\\033[36m本地脚本路径: \\033[m'').strip().split()\n                    if len(PathList) == 0:\n                        print(''\\033[33m路径为空\\033[m'')\n                        continue\n                    if not os.path.isfile(PathList[0]):\n                        print(''\\033[33m本地路径 %s 不存在或不是文件\\033[m'' %(PathList[0]) )\n                        continue\n                    for LocalPath in PathList[1:]:\n                        if not os.path.exists(LocalPath):\n                            print(''\\033[33m本地路径 %s 不存在\\033[m'' %(LocalPath) )\n                            break\n                    else:\n                        Concurrent(Conf=Conf,Operation=Operation,user_name=user_name,user_pwd=user_pwd,root_name=root_name,root_pwd=root_pwd,PathList=PathList)\n                elif i == ''3'':\n                    Operation = ''Send_File''\n                    PathList = raw_input(''\\033[36m本地路径: \\033[m'').strip().split()\n                    if len(PathList) == 0:\n                        print(''\\033[33m路径为空\\033[m'')\n                        continue\n                    for LocalPath in PathList:\n                        if not os.path.exists(LocalPath):\n                            print(''\\033[33m本地路径 %s 不存在\\033[m'' %(LocalPath) )\n                            break\n                    else:\n                        Concurrent(Conf=Conf,Operation=Operation,user_name=user_name,user_pwd=user_pwd,root_name=root_name,root_pwd=root_pwd,PathList=PathList)\n                elif i == ''0'' or i == ''exit'' or i == ''quit'':\n                    print("\\033[34m退出LazyManage脚本\\033[m")\n                    sys.exit()\n                elif i == ''help'' or i == ''h'' or i == ''?'':\n                    Help()\n\n    epoll非阻塞长链接\n        \n        server\n        \n            #!/usr/bin/python\n            #-*- coding:utf-8 -*-\n             \n            import socket, select, logging, errno\n            import os, sys, json\n\n            def cmdRunner(input):\n                import commands\n                cmd_ret = commands.getstatusoutput(input)\n                return json.dumps({''ret'':cmd_ret[0], ''out'':cmd_ret[1]}, separators=('','', '':''))\n\n            class _State:\n                def __init__(self):\n                    self.state = "read"\n                    self.have_read = 0\n                    self.need_read = 10\n                    self.have_write = 0\n                    self.need_write = 0\n                    self.data = ""\n\n            __all__ = [''nbNet'']\n\n            class nbNet:\n\n                def __init__(self, host, port, logic):\n                    self.host = host\n                    self.port = port\n                    self.logic = logic\n                    self.sm = {\n                        "read":self.aread,\n                        "write":self.awrite,\n                        "process":self.aprocess,\n                        "closing":self.aclose,\n                    }\n\n                def run(self):\n\n                    try:\n                        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n                    except socket.error, msg:\n                        print("create socket failed")\n\n                    try:\n                        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                    except socket.error, msg:\n                        print("setsocketopt SO_REUSEADDR failed")\n                 \n                    try:\n                        self.sock.bind((self.host, self.port))\n                    except socket.error, msg:\n                        print("bind failed")\n\n                    try:\n                        self.sock.listen(10)\n                    except socket.error, msg:\n                        print(msg)\n\n                    try:\n                        self.epoll_fd = select.epoll()\n                        # 向 epoll 句柄中注册 新来socket链接，监听可读事件\n                        self.epoll_fd.register(self.sock.fileno(), select.EPOLLIN )\n                    except select.error, msg:\n                        print(msg)\n\n                    self.STATE = {}\n\n                    while True:\n                        print self.STATE\n                        # epoll 等待事件回调收发数据\n                        epoll_list = self.epoll_fd.poll()\n                        for fd, events in epoll_list:\n                            if select.EPOLLHUP & events:\n                                print ''EPOLLHUP''\n                                self.STATE[fd][2].state = "closing"\n                            elif select.EPOLLERR & events:\n                                print ''EPOLLERR''\n                                self.STATE[fd][2].state = "closing"\n                            self.state_machine(fd)\n                def state_machine(self, fd):\n                    if fd == self.sock.fileno():\n                        print "state_machine fd %s accept" % fd\n                        # fd与初始监听的fd一致,新创建一个连接\n                        conn, addr = self.sock.accept()\n                        # 设置为非阻塞\n                        conn.setblocking(0)\n                        self.STATE[conn.fileno()] = [conn, addr, _State()]\n                        # 将新建立的链接注册在epoll句柄中,监听可读事件,并设置为EPOLLET高速边缘触发,即触发后不会再次触发直到新接收数据\n                        self.epoll_fd.register(conn.fileno(), select.EPOLLET | select.EPOLLIN )\n                    else:\n                        # 否则为历史已存在的fd，调用对应的状态方法\n                        print "state_machine fd %s %s" % (fd,self.STATE[fd][2].state) \n                        stat = self.STATE[fd][2].state\n                        self.sm[stat](fd)\n                def aread(self, fd):\n                    try:\n                        # 接收当前fd的可读事件中的数据\n                        one_read = self.STATE[fd][0].recv(self.STATE[fd][2].need_read)\n                        if len(one_read) == 0:\n                            # 接收错误改变状态为关闭\n                            self.STATE[fd][2].state = "closing"\n                            self.state_machine(fd)\n                            return\n                        # 将历史接收的数据叠加\n                        self.STATE[fd][2].data += one_read\n                        self.STATE[fd][2].have_read += len(one_read)\n                        self.STATE[fd][2].need_read -= len(one_read)\n                        # 接收协议的10个字符\n                        if self.STATE[fd][2].have_read == 10:\n                            # 通过10个字符得知下次应该具体接收多少字节,存入状态字典中\n                            self.STATE[fd][2].need_read += int(self.STATE[fd][2].data)\n                            self.STATE[fd][2].data = ''''\n                            # 调用状态机重新处理\n                            self.state_machine(fd)\n                        elif self.STATE[fd][2].need_read == 0:\n                            # 当接全部收完毕,改变状态,去执行具体服务\n                            self.STATE[fd][2].state = ''process''\n                            self.state_machine(fd)\n                    except socket.error, msg:\n                        self.STATE[fd][2].state = "closing"\n                        print(msg)\n                        self.state_machine(fd)\n                        return\n\n                def aprocess(self, fd):\n                    # 执行具体执行方法 cmdRunner 得到符合传输协议的返回结果\n                    response = self.logic(self.STATE[fd][2].data)\n                    self.STATE[fd][2].data = "%010d%s"%(len(response), response)\n                    self.STATE[fd][2].need_write = len(self.STATE[fd][2].data)\n                    # 改变为写的状态\n                    self.STATE[fd][2].state = ''write''\n                    # 改变监听事件为写\n                    self.epoll_fd.modify(fd, select.EPOLLET | select.EPOLLOUT)\n                    self.state_machine(fd)\n\n                def awrite(self, fd):\n                    try:\n                        last_have_send = self.STATE[fd][2].have_write\n                        # 发送返回给客户端的数据\n                        have_send = self.STATE[fd][0].send(self.STATE[fd][2].data[last_have_send:])\n                        self.STATE[fd][2].have_write += have_send\n                        self.STATE[fd][2].need_write -= have_send\n                        if self.STATE[fd][2].need_write == 0 and self.STATE[fd][2].have_write != 0:\n                            # 发送完成,重新初始化状态,并将监听写事件改回读事件\n                            self.STATE[fd][2] = _State()\n                            self.epoll_fd.modify(fd, select.EPOLLET | select.EPOLLIN)\n                    except socket.error, msg:\n                        self.STATE[fd][2].state = "closing"\n                        self.state_machine(fd)\n                        print(msg)\n                        return\n\n                def aclose(self, fd):\n                    try:\n                        print ''Error: %s:%d'' %(self.STATE[fd][1][0] ,self.STATE[fd][1][1])\n                        # 取消fd的事件监听\n                        self.epoll_fd.unregister(fd)\n                        # 关闭异常链接\n                        self.STATE[fd][0].close()\n                        # 删除fd的状态信息\n                        self.STATE.pop(fd)\n                    except:\n                        print ''Close the abnormal''\n\n            if __name__ == "__main__":\n                HOST = ''0.0.0.0''\n                PORT = 50005\n                nb = nbNet(HOST, PORT, cmdRunner)\n                nb.run()\n\n        client\n        \n            #!/usr/bin/env python\n\n            import socket, sys, os\n\n            HOST = ''0.0.0.0''\n            PORT = 50005\n\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            s.connect((HOST, PORT))\n\n            cmd = sys.argv[1]\n            while True:\n                s.sendall("%010d%s"%(len(cmd), cmd))\n                print cmd\n                count = s.recv(10)\n                if not count:\n                    print ''-----------''\n                    print count\n                    sys.exit()\n                count = int(count)\n                buf = s.recv(count)\n                print buf\n\n    \n\n不定期更新下载地址：\nhttp://pan.baidu.com/s/1sjsFrmX\nhttps://github.com/liquanzhou/ops_doc\n\n请勿删除信息, 植入广告, 抵制不道德行为\n\n\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(136, 'shell_man', '    shell实例手册\n\n0 说明{\n\n    手册制作: 雪松\n    更新日期: 2015-05-13\n\n    欢迎系统运维加入Q群: 198173206  # 加群请回答问题\n    欢迎运维开发加入Q群: 365534424  # 不定期技术分享\n\n    请使用"notepad++"或其它编辑器打开此文档, "alt+0"将函数折叠后方便查阅    \n    请勿删除信息, 转载请说明出处, 抵制不道德行为    \n    错误在所难免, 还望指正！    \n        \n    [python实例手册] [shell实例手册] [LazyManage运维批量管理(shell/python两个版本)]\n    网盘更新下载地址:    http://pan.baidu.com/s/1sjsFrmX\n    github更新下载地址:  https://github.com/liquanzhou/ops_doc\n\n}\n\n1 文件{\n    \n    ls -rtl                 # 按时间倒叙列出所有目录和文件 ll -rt\n    touch file              # 创建空白文件\n    rm -rf 目录名           # 不提示删除非空目录(-r:递归删除 -f强制)\n    dos2unix                # windows文本转linux文本  \n    unix2dos                # linux文本转windows文本\n    enca filename           # 查看编码  安装 yum install -y enca \n    md5sum                  # 查看md5值\n    ln 源文件 目标文件      # 硬链接\n    ln -s 源文件 目标文件   # 符号连接\n    readlink -f /data       # 查看连接真实目录\n    cat file | nl |less     # 查看上下翻页且显示行号  q退出\n    head                    # 查看文件开头内容\n    head -c 10m             # 截取文件中10M内容\n    split -C 10M            # 将文件切割大小为10M -C按行\n    tail -f file            # 查看结尾 监视日志文件\n    file                    # 检查文件类型\n    umask                   # 更改默认权限\n    uniq                    # 删除重复的行\n    uniq -c                 # 重复的行出现次数\n    uniq -u                 # 只显示不重复行\n    paste a b               # 将两个文件合并用tab键分隔开\n    paste -d''+'' a b         # 将两个文件合并指定''+''符号隔开\n    paste -s a              # 将多行数据合并到一行用tab键隔开\n    chattr +i /etc/passwd   # 不得任意改变文件或目录 -i去掉锁 -R递归\n    more                    # 向下分面器\n    locate 字符串           # 搜索\n    wc -l file              # 查看行数\n    cp filename{,.bak}      # 快速备份一个文件\n    \\cp a b                 # 拷贝不提示 既不使用别名 cp -i\n    rev                     # 将行中的字符逆序排列\n    comm -12 2 3            # 行和行比较匹配\n    iconv -f gbk -t utf8 原.txt > 新.txt    # 转换编码\n    rename 原模式 目标模式 文件             # 重命名 可正则\n    watch -d -n 1 ''df; ls -FlAt /path''      # 实时某个目录下查看最新改动过的文件\n    cp -v  /dev/dvd  /rhel4.6.iso9660       # 制作镜像\n    diff suzu.c suzu2.c  > sz.patch         # 制作补丁\n    patch suzu.c < sz.patch                 # 安装补丁\n    \n    sort排序{\n    \n        -t  # 指定排序时所用的栏位分隔字符\n        -n  # 依照数值的大小排序\n        -r  # 以相反的顺序来排序\n        -f  # 排序时，将小写字母视为大写字母\n        -d  # 排序时，处理英文字母、数字及空格字符外，忽略其他的字符\n        -c  # 检查文件是否已经按照顺序排序\n        -b  # 忽略每行前面开始处的空格字符\n        -M  # 前面3个字母依照月份的缩写进行排序\n        -k  # 指定域\n        -m  # 将几个排序好的文件进行合并\n        -T  # 指定临时文件目录,默认在/tmp\n        +<起始栏位>-<结束栏位>   # 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。\n        -o  # 将排序后的结果存入指定的文\n\n        sort -n               # 按数字排序\n        sort -nr              # 按数字倒叙\n        sort -u               # 过滤重复行\n        sort -m a.txt c.txt   # 将两个文件内容整合到一起\n        sort -n -t'' '' -k 2 -k 3 a.txt     # 第二域相同，将从第三域进行升降处理\n        sort -n -t'':'' -k 3r a.txt         # 以:为分割域的第三域进行倒叙排列\n        sort -k 1.3 a.txt                 # 从第三个字母起进行排序\n        sort -t" " -k 2n -u  a.txt        # 以第二域进行排序，如果遇到重复的，就删除\n\n    }\n\n    find查找{\n\n        # linux文件无创建时间\n        # Access 使用时间  \n        # Modify 内容修改时间  \n        # Change 状态改变时间(权限、属主)\n        # 时间默认以24小时为单位,当前时间到向前24小时为0天,向前48-72小时为2天\n        # -and 且 匹配两个条件 参数可以确定时间范围 -mtime +2 -and -mtime -4\n        # -or 或 匹配任意一个条件\n\n        find /etc -name "*http*"     # 按文件名查找\n        find . -type f               # 查找某一类型文件\n        find / -perm                 # 按照文件权限查找\n        find / -user                 # 按照文件属主查找\n        find / -group                # 按照文件所属的组来查找文件\n        find / -atime -n             # 文件使用时间在N天以内\n        find / -atime +n             # 文件使用时间在N天以前\n        find / -mtime +n             # 文件内容改变时间在N天以前\n        find / -ctime +n             # 文件状态改变时间在N天前\n        find / -mmin +30             # 按分钟查找内容改变\n        find / -size +1000000c -print                           # 查找文件长度大于1M字节的文件\n        find /etc -name "*passwd*" -exec grep "xuesong" {} \\;   # 按名字查找文件传递给-exec后命令\n        find . -name ''t*'' -exec basename {} \\;                  # 查找文件名,不取路径\n        find . -type f -name "err*" -exec  rename err ERR {} \\; # 批量改名(查找err 替换为 ERR {}文件\n        find 路径 -name *name1* -or -name *name2*               # 查找任意一个关键字\n\n    }\n\n    vim编辑器{\n\n        gconf-editor       # 配置编辑器\n        /etc/vimrc         # 配置文件路径\n        vim +24 file       # 打开文件定位到指定行\n        vim file1 file2    # 打开多个文件    \n        vim -O2 file1 file2    # 垂直分屏\n        vim -on file1 file2    # 水平分屏\n        sp filename        # 上下分割打开新文件\n        vsp filename       # 左右分割打开新文件\n        Ctrl+W [操作]      # 多个文件间操作  大写W  # 操作: 关闭当前窗口c  屏幕高度一样=  增加高度+  移动光标所在屏 右l 左h 上k 下j 中h  下一个w  \n        :n                 # 编辑下一个文件\n        :2n                # 编辑下二个文件\n        :N                 # 编辑前一个文件\n        :rew               # 回到首文件\n        :set nu            # 打开行号\n        :set nonu          # 取消行号\n        200G               # 跳转到200\n        :nohl              # 取消高亮\n        :set autoindent    # 设置自动缩进\n        :set ff            # 查看文本格式\n        :set binary        # 改为unix格式\n        ctrl+ U            # 向前翻页\n        ctrl+ D            # 向后翻页\n        %s/字符1/字符2/g   # 全部替换    \n        X                  # 文档加密\n    \n    }\n\n    归档解压缩{\n\n        tar zxvpf gz.tar.gz -C 放到指定目录 包中的目录       # 解包tar.gz 不指定目录则全解压\n        tar zcvpf /$path/gz.tar.gz * # 打包gz 注意*最好用相对路径\n        tar zcf /$path/gz.tar.gz *   # 打包正确不提示\n        tar ztvpf gz.tar.gz          # 查看gz\n        tar xvf 1.tar -C 目录        # 解包tar\n        tar -cvf 1.tar *             # 打包tar\n        tar tvf 1.tar                # 查看tar\n        tar -rvf 1.tar 文件名        # 给tar追加文件\n        tar --exclude=/home/dmtsai --exclude=*.tar -zcvf myfile.tar.gz /home/* /etc      # 打包/home, /etc ，但排除 /home/dmtsai\n        tar -N "2005/06/01" -zcvf home.tar.gz /home      # 在 /home 当中，比 2005/06/01 新的文件才备份\n        tar -zcvfh home.tar.gz /home                     # 打包目录中包括连接目录\n        tar zcf - ./ | ssh root@IP "tar zxf - -C /xxxx"  # 一边压缩一边解压\n        zgrep 字符 1.gz              # 查看压缩包中文件字符行\n        bzip2  -dv 1.tar.bz2         # 解压bzip2\n        bzip2 -v 1.tar               # bzip2压缩\n        bzcat                        # 查看bzip2\n        gzip A                       # 直接压缩文件 # 压缩后源文件消失\n        gunzip A.gz                  # 直接解压文件 # 解压后源文件消失\n        gzip -dv 1.tar.gz            # 解压gzip到tar\n        gzip -v 1.tar                # 压缩tar到gz\n        unzip zip.zip                # 解压zip\n        zip zip.zip *                # 压缩zip\n        # rar3.6下载:  http://www.rarsoft.com/rar/rarlinux-3.6.0.tar.gz\n        rar a rar.rar *.jpg          # 压缩文件为rar包\n        unrar x rar.rar              # 解压rar包\n        7z a 7z.7z *                 # 7z压缩\n        7z e 7z.7z                   # 7z解压\n\n    }\n    \n    文件ACL权限控制{\n\n        getfacl 1.test                      # 查看文件ACL权限\n        setfacl -R -m u:xuesong:rw- 1.test  # 对文件增加用户的读写权限 -R 递归\n\n    }\n    \n    svn更新代码{\n\n        --force # 强制覆盖\n        /usr/bin/svn --username user --password passwd co  $Code  ${SvnPath}src/                 # 检出整个项目\n        /usr/bin/svn --username user --password passwd up  $Code  ${SvnPath}src/                 # 更新项目\n        /usr/bin/svn --username user --password passwd export  $Code$File ${SvnPath}src/$File    # 导出个别文件\n        /usr/bin/svn --username user --password passwd export -r 版本号 svn路径 本地路径 --force # 导出指定版本\n\n    }\n    \n    git{\n\n        git clone git@10.10.10.10:gittest.git  ./gittest/  # 克隆项目到指定目录\n        git pull                                           # 更新项目 需要cd到项目目录中\n        git add .                                          # 更新所有文件\n        git commit -m "gittest up"                         # 提交操作并添加备注\n        git push                                           # 正式提交到远程git服务器\n        git rm -r -n --cached  ./img                       # -n执行命令时,不会删除任何文件,而是展示此命令要删除的文件列表预览\n        git rm -r --cached  ./img                          # 执行删除命令 需要commit和push让远程生效\n        git init --bare smc-content-check.git              # 初始化新git项目  需要手动创建此目录并给git用户权限 chown -R git:git smc-content-check.git\n\n    }\n\n    恢复rm删除的文件{\n\n        # debugfs针对 ext2   # ext3grep针对 ext3   # extundelete针对 ext4\n        df -T   # 首先查看磁盘分区格式\n        umount /data/     # 卸载挂载,数据丢失请首先卸载挂载,或重新挂载只读\n        ext3grep /dev/sdb1 --ls --inode 2         # 记录信息继续查找目录下文件inode信息\n        ext3grep /dev/sdb1 --ls --inode 131081    # 此处是inode\n        ext3grep /dev/sdb1 --restore-inode 49153  # 记录下inode信息开始恢复目录\n\n    }\n\n    openssl{\n\n        openssl rand 15 -base64            # 口令生成\n        openssl sha1 filename              # 哈希算法校验文件\n        openssl md5 filename               # MD5校验文件\n        openssl base64   filename.txt      # base64编码/解码文件(发送邮件附件之类功能会可以使用)\n        openssl base64 -d   filename.bin   # base64编码/解码二进制文件\n        openssl enc -aes-128-cbc   filename.aes-128-cbc                  # 加密文档 \n        # 推荐使用的加密算法是bf(Blowfish)和-aes-128-cbc(运行在CBC模式的128位密匙AES加密算法)，加密强度有保障\n        openssl enc -d -aes-128-cbc -in filename.aes-128-cbc > filename  # 解密文档\n\n    }\n\n}\n\n2 软件{\n\n    rpm{\n\n        rpm -ivh lynx          # rpm安装\n        rpm -e lynx            # 卸载包\n        rpm -e lynx --nodeps   # 强制卸载\n        rpm -qa                # 查看所有安装的rpm包\n        rpm -qa | grep lynx    # 查找包是否安装\n        rpm -ql                # 软件包路径\n        rpm -Uvh               # 升级包\n        rpm --test lynx        # 测试\n        rpm -qc                # 软件包配置文档\n        rpm --import  /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6     # 导入rpm的签名信息\n        rpm --initdb           # 初始化rpm 数据库 \n        rpm --rebuilddb        # 重建rpm数据库  在rpm和yum无响应的情况使用 先 rm -f /var/lib/rpm/__db.00* 在重建\n\n    }\n\n    yum{\n\n        yum list                 # 所有软件列表\n        yum install 包名         # 安装包和依赖包\n        yum -y update            # 升级所有包版本,依赖关系，系统版本内核都升级\n        yum -y update 软件包名   # 升级指定的软件包\n        yum -y upgrade           # 不改变软件设置更新软件，系统版本升级，内核不改变\n        yum search mail          # yum搜索相关包\n        yum grouplist            # 软件包组\n        yum -y groupinstall "Virtualization"   # 安装软件包组\n        repoquery -ql gstreamer  # 不安装软件查看包含文件\n        yum clean all            # 清除var下缓存\n        \n    }\n\n    yum使用epel源{\n\n        # 包下载地址: http://download.fedoraproject.org/pub/epel   # 选择版本5\\6\\7\n        rpm -Uvh  http://mirrors.hustunique.com/epel//6/x86_64/epel-release-6-8.noarch.rpm\n\n    }\n\n    自定义yum源{\n\n        find /etc/yum.repos.d -name "*.repo" -exec mv {} {}.bak \\;\n        \n        vim /etc/yum.repos.d/yum.repo\n        [yum]\n        #http\n        baseurl=http://10.0.0.1/centos5.5\n        #挂载iso\n        #mount -o loop CentOS-5.8-x86_64-bin-DVD-1of2.iso /data/iso/\n        #本地\n        #baseurl=file:///data/iso/\n        enable=1\n\n        #导入key\n        rpm --import  /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5\n\n    }\n\n    编译{\n\n        源码安装{\n\n            ./configure --help                   # 查看所有编译参数\n            ./configure  --prefix=/usr/local/    # 配置参数\n            make                                 # 编译\n            make install                         # 安装包\n            make clean                           # 清除编译结果\n\n        }\n\n        perl程序编译{\n\n            perl Makefile.PL\n            make\n            make test\n            make install\n\n        }\n\n        python程序编译{\n\n            python file.py\n            \n            # 源码包编译安装\n            python setup.py build\n            python setup.py install\n\n        }\n        \n        编译c程序{\n\n            gcc -g hello.c -o hello\n\n        }\n    \n    }\n    \n}\n\n3 系统{\n\n    wall        　  　          # 给其它用户发消息\n    whereis ls                  # 查找命令的目录\n    which                       # 查看当前要执行的命令所在的路径\n    clear                       # 清空整个屏幕\n    reset                       # 重新初始化屏幕\n    cal                         # 显示月历\n    echo -n 123456 | md5sum     # md5加密\n    mkpasswd                    # 随机生成密码   -l位数 -C大小 -c小写 -d数字 -s特殊字符\n    netstat -anlp | grep port   # 是否打开了某个端口\n    ntpdate stdtime.gov.hk      # 同步时间\n    tzselect                    # 选择时区 #+8=(5 9 1 1) # (TZ=''Asia/Shanghai''; export TZ)括号内写入 /etc/profile\n    /sbin/hwclock -w            # 时间保存到硬件\n    /etc/shadow                 # 账户影子文件\n    LANG=en                     # 修改语言\n    vim /etc/sysconfig/i18n     # 修改编码  LANG="en_US.UTF-8"\n    export LC_ALL=C             # 强制字符集\n    vi /etc/hosts               # 查询静态主机名\n    alias                       # 别名\n    watch uptime                # 监测命令动态刷新\n    ipcs -a                     # 查看Linux系统当前单个共享内存段的最大值\n    ldconfig                    # 动态链接库管理命令\n    ldd `which cmd`             # 查看命令的依赖库\n    dist-upgrade                # 会改变配置文件,改变旧的依赖关系，改变系统版本 \n    /boot/grub/grub.conf        # grub启动项配置\n    ps -mfL <PID>               # 查看指定进程启动的线程 线程数受 max user processes 限制\n    ps uxm |wc -l               # 查看当前用户占用的进程数 [包括线程]  max user processes\n    top -p  PID -H              # 查看指定PID进程及线程\n    lsof |wc -l                 # 查看当前文件句柄数使用数量  open files \n    lsof |grep /lib             # 查看加载库文件\n    sysctl -a                   # 查看当前所有系统内核参数\n    sysctl -p                   # 修改内核参数/etc/sysctl.conf，让/etc/rc.d/rc.sysinit读取生效\n    strace uptime 2>&1|grep open                  # 查看命令打开的相关文件\n    grep Hugepagesize /proc/meminfo               # 内存分页大小\n    mkpasswd -l 8  -C 2 -c 2 -d 4 -s 0            # 随机生成指定类型密码\n    echo 1 > /proc/sys/net/ipv4/tcp_syncookies    # 使TCP SYN Cookie 保护生效  # "SYN Attack"是一种拒绝服务的攻击方式\n    grep Swap  /proc/25151/smaps |awk ''{a+=$2}END{print a}''    # 查询某pid使用的swap大小\n\n    开机启动脚本顺序{\n\n        /etc/profile\n        /etc/profile.d/*.sh\n        ~/bash_profile\n        ~/.bashrc\n        /etc/bashrc\n\n    }\n\n    进程管理{\n\n        ps -eaf               # 查看所有进程\n        kill -9 PID           # 强制终止某个PID进程\n        kill -15 PID          # 安全退出 需程序内部处理信号\n        cmd &                 # 命令后台运行\n        nohup cmd &           # 后台运行不受shell退出影响\n        ctrl+z                # 将前台放入后台(暂停)\n        jobs                  # 查看后台运行程序\n        bg 2                  # 启动后台暂停进程\n        fg 2                  # 调回后台进程\n        pstree                # 进程树\n        vmstat 1 9            # 每隔一秒报告系统性能信息9次\n        sar                   # 查看cpu等状态\n        lsof file             # 显示打开指定文件的所有进程\n        lsof -i:32768         # 查看端口的进程\n        renice +1 180         # 把180号进程的优先级加1\n        \n        ps{\n\n            ps aux |grep -v USER | sort -nk +4 | tail       # 显示消耗内存最多的10个运行中的进程，以内存使用量排序.cpu +3    \n            # USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n            %CPU     # 进程的cpu占用率\n            %MEM     # 进程的内存占用率\n            VSZ      # 进程虚拟大小,单位K(即总占用内存大小,包括真实内存和虚拟内存)\n            RSS      # 进程使用的驻留集大小即实际物理内存大小\n            START    # 进程启动时间和日期\n            占用的虚拟内存大小 = VSZ - RSS\n            \n            ps -eo pid,lstart,etime,args         # 查看进程启动时间\n\n        }\n        \n        top{\n\n            前五行是系统整体的统计信息。\n            第一行: 任务队列信息，同 uptime 命令的执行结果。内容如下：\n                01:06:48 当前时间\n                up 1:22 系统运行时间，格式为时:分\n                1 user 当前登录用户数\n                load average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。\n                三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。\n\n            第二、三行:为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下：\n                Tasks: 29 total 进程总数\n                1 running 正在运行的进程数\n                28 sleeping 睡眠的进程数\n                0 stopped 停止的进程数\n                0 zombie 僵尸进程数\n                Cpu(s): 0.3% us 用户空间占用CPU百分比\n                1.0% sy 内核空间占用CPU百分比\n                0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比\n                98.7% id 空闲CPU百分比\n                0.0% wa 等待输入输出的CPU时间百分比\n                0.0% hi\n                0.0% si\n\n            第四、五行:为内存信息。内容如下：\n                Mem: 191272k total 物理内存总量\n                173656k used 使用的物理内存总量\n                17616k free 空闲内存总量\n                22052k buffers 用作内核缓存的内存量\n                Swap: 192772k total 交换区总量\n                0k used 使用的交换区总量\n                192772k free 空闲交换区总量\n                123988k cached 缓冲的交换区总量。\n                内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，\n                该数值即为这些内容已存在于内存中的交换区的大小。\n                相应的内存再次被换出时可不必再对交换区写入。\n\n            进程信息区,各列的含义如下:  # 显示各个进程的详细信息\n\n            序号 列名    含义\n            a   PID      进程id\n            b   PPID     父进程id\n            c   RUSER    Real user name\n            d   UID      进程所有者的用户id\n            e   USER     进程所有者的用户名\n            f   GROUP    进程所有者的组名\n            g   TTY      启动进程的终端名。不是从终端启动的进程则显示为 ?\n            h   PR       优先级\n            i   NI       nice值。负值表示高优先级，正值表示低优先级\n            j   P        最后使用的CPU，仅在多CPU环境下有意义\n            k   %CPU     上次更新到现在的CPU时间占用百分比\n            l   TIME     进程使用的CPU时间总计，单位秒\n            m   TIME+    进程使用的CPU时间总计，单位1/100秒\n            n   %MEM     进程使用的物理内存百分比\n            o   VIRT     进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\n            p   SWAP     进程使用的虚拟内存中，被换出的大小，单位kb。\n            q   RES      进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\n            r   CODE     可执行代码占用的物理内存大小，单位kb\n            s   DATA     可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb\n            t   SHR      共享内存大小，单位kb\n            u   nFLT     页面错误次数\n            v   nDRT     最后一次写入到现在，被修改过的页面数。\n            w   S        进程状态。\n                D=不可中断的睡眠状态\n                R=运行\n                S=睡眠\n                T=跟踪/停止\n                Z=僵尸进程\n            x   COMMAND  命令名/命令行\n            y   WCHAN    若该进程在睡眠，则显示睡眠中的系统函数名\n            z   Flags    任务标志，参考 sched.h\n\n        }\n\n        列出正在占用swap的进程{\n\n            #!/bin/bash\n            echo -e "PID\\t\\tSwap\\t\\tProc_Name"\n            # 拿出/proc目录下所有以数字为名的目录（进程名是数字才是进程，其他如sys,net等存放的是其他信息）\n            for pid in `ls -l /proc | grep ^d | awk ''{ print $9 }''| grep -v [^0-9]`\n            do\n                # 让进程释放swap的方法只有一个：就是重启该进程。或者等其自动释放。放\n                # 如果进程会自动释放，那么我们就不会写脚本来找他了，找他都是因为他没有自动释放。\n                # 所以我们要列出占用swap并需要重启的进程，但是init这个进程是系统里所有进程的祖先进程\n                # 重启init进程意味着重启系统，这是万万不可以的，所以就不必检测他了，以免对系统造成影响。\n                if [ $pid -eq 1 ];then continue;fi\n                grep -q "Swap" /proc/$pid/smaps 2>/dev/null\n                if [ $? -eq 0 ];then \n                    swap=$(grep Swap /proc/$pid/smaps \\\n                        | gawk ''{ sum+=$2;} END{ print sum }'')\n                    proc_name=$(ps aux | grep -w "$pid" | grep -v grep \\\n                        | awk ''{ for(i=11;i<=NF;i++){ printf("%s ",$i); }}'')\n                    if [ $swap -gt 0 ];then \n                        echo -e "${pid}\\t${swap}\\t${proc_name}"\n                    fi  \n                fi  \n            done | sort -k2 -n | awk -F''\\t'' ''{\n                pid[NR]=$1;\n                size[NR]=$2;\n                name[NR]=$3;\n            }\n            END{\n                for(id=1;id<=length(pid);id++)\n                {\n                    if(size[id]<1024)\n                        printf("%-10s\\t%15sKB\\t%s\\n",pid[id],size[id],name[id]);\n                    else if(size[id]<1048576)\n                        printf("%-10s\\t%15.2fMB\\t%s\\n",pid[id],size[id]/1024,name[id]);\n                    else\n                        printf("%-10s\\t%15.2fGB\\t%s\\n",pid[id],size[id]/1048576,name[id]);\n                }\n            }''\n\n        }\n        \n        linux操作系统提供的信号{\n            \n            kill -l                    # 查看linux提供的信号\n            trap "echo aaa"  2 3 15    # shell使用 trap 捕捉退出信号\n\n            # 发送信号一般有两种原因:\n            #   1(被动式)  内核检测到一个系统事件.例如子进程退出会像父进程发送SIGCHLD信号.键盘按下control+c会发送SIGINT信号\n            #   2(主动式)  通过系统调用kill来向指定进程发送信号                             \n            # 进程结束信号 SIGTERM 和 SIGKILL 的区别:  SIGTERM 比较友好，进程能捕捉这个信号，根据您的需要来关闭程序。在关闭程序之前，您可以结束打开的记录文件和完成正在做的任务。在某些情况下，假如进程正在进行作业而且不能中断，那么进程可以忽略这个SIGTERM信号。\n            # 如果一个进程收到一个SIGUSR1信号，然后执行信号绑定函数，第二个SIGUSR2信号又来了，第一个信号没有被处理完毕的话，第二个信号就会丢弃。\n\n            SIGHUP  1          A     # 终端挂起或者控制进程终止\n            SIGINT  2          A     # 键盘终端进程(如control+c)\n            SIGQUIT 3          C     # 键盘的退出键被按下\n            SIGILL  4          C     # 非法指令\n            SIGABRT 6          C     # 由abort(3)发出的退出指令\n            SIGFPE  8          C     # 浮点异常\n            SIGKILL 9          AEF   # Kill信号  立刻停止\n            SIGSEGV 11         C     # 无效的内存引用\n            SIGPIPE 13         A     # 管道破裂: 写一个没有读端口的管道\n            SIGALRM 14         A     # 闹钟信号 由alarm(2)发出的信号 \n            SIGTERM 15         A     # 终止信号,可让程序安全退出 kill -15\n            SIGUSR1 30,10,16   A     # 用户自定义信号1\n            SIGUSR2 31,12,17   A     # 用户自定义信号2\n            SIGCHLD 20,17,18   B     # 子进程结束自动向父进程发送SIGCHLD信号\n            SIGCONT 19,18,25         # 进程继续（曾被停止的进程）\n            SIGSTOP 17,19,23   DEF   # 终止进程\n            SIGTSTP 18,20,24   D     # 控制终端（tty）上按下停止键\n            SIGTTIN 21,21,26   D     # 后台进程企图从控制终端读\n            SIGTTOU 22,22,27   D     # 后台进程企图从控制终端写\n            \n            缺省处理动作一项中的字母含义如下:\n                A  缺省的动作是终止进程\n                B  缺省的动作是忽略此信号，将该信号丢弃，不做处理\n                C  缺省的动作是终止进程并进行内核映像转储(dump core),内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。\n                D  缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）\n                E  信号不能被捕获\n                F  信号不能被忽略\n        }\n        \n        系统性能状态{\n\n            vmstat 1 9\n            \n            r      # 等待执行的任务数。当这个值超过了cpu线程数，就会出现cpu瓶颈。\n            b      # 等待IO的进程数量,表示阻塞的进程。\n            swpd   # 虚拟内存已使用的大小，如大于0，表示机器物理内存不足，如不是程序内存泄露，那么该升级内存。\n            free   # 空闲的物理内存的大小\n            buff   # 已用的buff大小，对块设备的读写进行缓冲\n            cache  # cache直接用来记忆我们打开的文件,给文件做缓冲，(把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)\n            inact  # 非活跃内存大小，即被标明可回收的内存，区别于free和active -a选项时显示\n            active # 活跃的内存大小 -a选项时显示\n            si   # 每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露，要查找耗内存进程解决掉。\n            so   # 每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。\n            bi   # 块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte\n            bo   # 块设备每秒发送的块数量，例如读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。\n            in   # 每秒CPU的中断次数，包括时间中断。in和cs这两个值越大，会看到由内核消耗的cpu时间会越多\n            cs   # 每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用。\n            us   # 用户进程执行消耗cpu时间(user time)  us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期超过50%的使用，那么我们就该考虑优化程序算法或其他措施\n            sy   # 系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。\n            id   # 空闲 CPU时间，一般来说，id + us + sy = 100,一般认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。\n            wt   # 等待IOCPU时间。Wa过高时，说明io等待比较严重，这可能是由于磁盘大量随机访问造成的，也有可能是磁盘的带宽出现瓶颈。\n            \n            如果 r 经常大于4，且id经常少于40，表示cpu的负荷很重。\n            如果 pi po 长期不等于0，表示内存不足。\n            如果 b 队列经常大于3，表示io性能不好。\n\n        }\n\n    }\n\n    日志管理{\n\n        history                      # 历时命令默认1000条\n        HISTTIMEFORMAT="%Y-%m-%d %H:%M:%S "   # 让history命令显示具体时间\n        history  -c                  # 清除记录命令\n        cat $HOME/.bash_history      # 历史命令记录文件\n        lastb -a                     # 列出登录系统失败的用户相关信息  清空二进制日志记录文件 echo > /var/log/btmp  \n        last                         # 查看登陆过的用户信息  清空二进制日志记录文件 echo > /var/log/wtmp   默认打开乱码\n        who /var/log/wtmp            # 查看登陆过的用户信息\n        lastlog                      # 用户最后登录的时间\n        tail -f /var/log/messages    # 系统日志\n        tail -f /var/log/secure      # ssh日志\n\n    }\n\n    selinux{\n\n        sestatus -v                    # 查看selinux状态\n        getenforce                     # 查看selinux模式\n        setenforce 0                   # 设置selinux为宽容模式(可避免阻止一些操作)\n        semanage port -l               # 查看selinux端口限制规则\n        semanage port -a -t http_port_t -p tcp 8000  # 在selinux中注册端口类型\n        vi /etc/selinux/config         # selinux配置文件\n        SELINUX=enfoceing              # 关闭selinux 把其修改为  SELINUX=disabled\n\n    }\n\n    查看剩余内存{\n\n        free -m\n        #-/+ buffers/cache:       6458       1649\n        #6458M为真实使用内存  1649M为真实剩余内存(剩余内存+缓存+缓冲器)\n        #linux会利用所有的剩余内存作为缓存，所以要保证linux运行速度，就需要保证内存的缓存大小\n\n    }\n    \n    系统信息{\n\n        uname -a              # 查看Linux内核版本信息\n        cat /proc/version     # 查看内核版本\n        cat /etc/issue        # 查看系统版本\n        lsb_release -a        # 查看系统版本  需安装 centos-release\n        locale -a             # 列出所有语系\n        hwclock               # 查看时间\n        who                   # 当前在线用户\n        w                     # 当前在线用户\n        whoami                # 查看当前用户名\n        logname               # 查看初始登陆用户名\n        uptime                # 查看服务器启动时间\n        sar -n DEV 1 10       # 查看网卡网速流量\n        dmesg                 # 显示开机信息\n        lsmod                 # 查看内核模块\n\n    }\n    \n    硬件信息{\n\n        more /proc/cpuinfo                                       # 查看cpu信息\n        lscpu                                                    # 查看cpu信息\n        cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c    # 查看cpu型号和逻辑核心数\n        getconf LONG_BIT                                         # cpu运行的位数\n        cat /proc/cpuinfo | grep ''physical id'' |sort| uniq -c    # 物理cpu个数\n        cat /proc/cpuinfo | grep flags | grep '' lm '' | wc -l     # 结果大于0支持64位\n        cat /proc/cpuinfo|grep flags                             # 查看cpu是否支持虚拟化   pae支持半虚拟化  IntelVT 支持全虚拟化\n        more /proc/meminfo                                       # 查看内存信息\n        dmidecode                                                # 查看全面硬件信息\n        dmidecode | grep "Product Name"                          # 查看服务器型号\n        dmidecode | grep -P -A5 "Memory\\s+Device" | grep Size | grep -v Range       # 查看内存插槽\n        cat /proc/mdstat                                         # 查看软raid信息\n        cat /proc/scsi/scsi                                      # 查看Dell硬raid信息(IBM、HP需要官方检测工具)\n        lspci                                                    # 查看硬件信息\n        lspci|grep RAID                                          # 查看是否支持raid\n        lspci -vvv |grep Ethernet                                # 查看网卡型号\n        lspci -vvv |grep Kernel|grep driver                      # 查看驱动模块\n        modinfo tg2                                              # 查看驱动版本(驱动模块)\n        ethtool -i em1                                           # 查看网卡驱动版本\n\n    }\n    \n    终端快捷键{\n\n        Ctrl+A        　    # 行前\n        Ctrl+E        　    # 行尾\n        Ctrl+S        　    # 终端锁屏\n        Ctrl+Q        　　  # 解锁屏\n        Ctrl+D      　　    # 退出\n\n    }\n\n    开机启动模式{\n\n        vi /etc/inittab\n        id:3:initdefault:    # 3为多用户命令\n        #ca::ctrlaltdel:/sbin/shutdown -t3 -r now   # 注释此行 禁止 ctrl+alt+del 关闭计算机\n\n    }\n\n    终端提示显示{\n\n        echo $PS1                   # 环境变量控制提示显示\n        PS1=''[\\u@ \\H \\w \\A \\@#]\\$''\n        PS1=''[\\u@\\h \\W]\\$''\n\n    }\n\n    定时任务{\n\n        at 5pm + 3 days /bin/ls  # 单次定时任务 指定三天后下午5:00执行/bin/ls\n    \n        crontab -e               # 编辑周期任务\n        #分钟  小时    天  月  星期   命令或脚本\n        1,30  1-3/2    *   *   *      命令或脚本  >> file.log 2>&1\n        echo "40 7 * * 2 /root/sh">>/var/spool/cron/root    # 直接将命令写入周期任务\n        crontab -l                                          # 查看自动周期性任务\n        crontab -r                                          # 删除自动周期性任务\n        cron.deny和cron.allow                               # 禁止或允许用户使用周期任务\n        service crond start|stop|restart                    # 启动自动周期性服务\n\n    }\n\n    date{\n        \n        星期日[SUN] 星期一[MON] 星期二[TUE] 星期三[WED] 星期四[THU] 星期五[FRI] 星期六[SAT]\n        一月[JAN] 二月[FEB] 三月[MAR] 四月[APR] 五月[MAY] 六月[JUN] 七月[JUL] 八月[AUG] 九月[SEP] 十月[OCT] 十一月[NOV] 十二月[DEC]\n\n        date -s 20091112                     # 设日期\n        date -s 18:30:50                     # 设时间\n        date -d "7 days ago" +%Y%m%d         # 7天前日期\n        date -d "5 minute ago" +%H:%M        # 5分钟前时间\n        date -d "1 month ago" +%Y%m%d        # 一个月前\n        date -d ''1 days'' +%Y-%m-%d           # 一天后\n        date -d ''1 hours'' +%H:%M:%S          # 一小时后\n        date +%Y-%m-%d -d ''20110902''         # 日期格式转换\n        date +%Y-%m-%d_%X                    # 日期和时间\n        date +%N                             # 纳秒\n        date -d "2012-08-13 14:00:23" +%s    # 换算成秒计算(1970年至今的秒数)\n        date -d "@1363867952" +%Y-%m-%d-%T   # 将时间戳换算成日期\n        date -d "1970-01-01 UTC 1363867952 seconds" +%Y-%m-%d-%T  # 将时间戳换算成日期\n        date -d "`awk -F. ''{print $1}'' /proc/uptime` second ago" +"%Y-%m-%d %H:%M:%S"    # 格式化系统启动时间(多少秒前)\n\n    }\n\n    limits.conf{\n\n        ulimit -SHn 65535  # 临时设置文件描述符大小 进程最大打开文件柄数 还有socket最大连接数, 等同配置 nofile\n        ulimit -SHu 65535  # 临时设置用户最大进程数\n        ulimit -a          # 查看\n\n        /etc/security/limits.conf\n\n        # 文件描述符大小  open files \n        # lsof |wc -l   查看当前文件句柄数使用数量\n        * soft nofile 16384         # 设置太大，进程使用过多会把机器拖死\n        * hard nofile 32768\n\n        # 用户最大进程数  max user processes\n        # echo $((`ps uxm |wc -l`-`ps ux |wc -l`))  查看当前用户占用的进程数 [包括线程]\n        user soft nproc 16384\n        user hard nproc 32768\n\n        # 如果/etc/security/limits.d/有配置文件，将会覆盖/etc/security/limits.conf里的配置\n        # 即/etc/security/limits.d/的配置文件里就不要有同样的参量设置\n        /etc/security/limits.d/90-nproc.conf    # centos6.3的默认这个文件会覆盖 limits.conf\n        user soft nproc 16384\n        user hard nproc 32768\n\n        sysctl -p    # 修改配置文件后让系统生效\n\n    }\n\n    百万长链接设置{\n        \n        # 内存消耗需要较大\n        vim /root/.bash_profile\n        # 添加如下2行,退出bash重新登陆\n        echo 20000500 > /proc/sys/fs/nr_open\n        ulimit -n 10000000\n\n    }\n\n    libc.so故障修复{\n\n        # 由于升级glibc导致libc.so不稳定,突然报错,幸好还有未退出的终端\n        grep: error while loading shared libraries: /lib64/libc.so.6: ELF file OS ABI invalid\n\n        # 看看当前系统有多少版本 libc.so\n        ls /lib64/libc-[tab]\n\n        # 更改环境变量指向其他 libc.so 文件测试\n        export LD_PRELOAD=/lib64/libc-2.7.so\n\n        # 当前如果好使了，在执行下面强制替换软链接。如不好使，测试其他版本的libc.so文件\n        ln -f -s /lib64/libc-2.7.so /lib64/libc.so.6\n\n    }\n\n    sudo{\n\n        echo myPassword | sudo -S ls /tmp  # 直接输入sudo的密码非交互,从标准输入读取密码而不是终端设备\n        visudo                             # sudo命令权限添加  /etc/sudoers\n        用户  别名(可用all)=NOPASSWD:命令1,命令2\n        user  ALL=NOPASSWD:/bin/su         # 免root密码切换root身份\n        wangming linuxfan=NOPASSWD:/sbin/apache start,/sbin/apache restart\n        UserName ALL=(ALL) ALL\n        UserName ALL=(ALL) NOPASSWD: ALL\n        peterli        ALL=(ALL)       NOPASSWD:/sbin/service\n        Defaults requiretty                # sudo不允许后台运行,注释此行既允许\n        Defaults !visiblepw                # sudo不允许远程,去掉!既允许\n\n    }\n\n    grub开机启动项添加{\n\n        vim /etc/grub.conf\n        title ms-dos\n        rootnoverify (hd0,0)\n        chainloader +1\n\n    }\n\n    stty{\n\n        #stty时一个用来改变并打印终端行设置的常用命令\n\n        stty iuclc          # 在命令行下禁止输出大写\n        stty -iuclc         # 恢复输出大写\n        stty olcuc          # 在命令行下禁止输出小写\n        stty -olcuc         # 恢复输出小写\n        stty size           # 打印出终端的行数和列数\n        stty eof "string"   # 改变系统默认ctrl+D来表示文件的结束 \n        stty -echo          # 禁止回显\n        stty echo           # 打开回显\n        stty -echo;read;stty echo;read  # 测试禁止回显\n        stty igncr          # 忽略回车符\n        stty -igncr         # 恢复回车符\n        stty erase ''#''      # 将#设置为退格字符\n        stty erase ''^?''     # 恢复退格字符\n        \n        定时输入{\n        \n            timeout_read(){\n                timeout=$1\n                old_stty_settings=`stty -g`　　# save current settings\n                stty -icanon min 0 time 100　　# set 10seconds,not 100seconds\n                eval read varname　　          # =read $varname\n                stty "$old_stty_settings"　　  # recover settings\n            }\n        \n            read -t 10 varname    # 更简单的方法就是利用read命令的-t选项\n        \n        }\n\n        检测用户按键{\n\n            #!/bin/bash\n            old_tty_settings=$(stty -g)   # 保存老的设置(为什么?). \n            stty -icanon\n            Keypress=$(head -c1)          # 或者使用$(dd bs=1 count=1 2> /dev/null)\n            echo "Key pressed was \\""$Keypress"\\"."\n            stty "$old_tty_settings"      # 恢复老的设置. \n            exit 0\n\n        }\n\n    }\n\n    iptables{\n\n        内建三个表：nat mangle 和 filter\n        filter预设规则表，有INPUT、FORWARD 和 OUTPUT 三个规则链\n        vi /etc/sysconfig/iptables    # 配置文件\n        INPUT    # 进入\n        FORWARD  # 转发\n        OUTPUT   # 出去\n        ACCEPT   # 将封包放行\n        REJECT   # 拦阻该封包\n        DROP     # 丢弃封包不予处理\n        -A         # 在所选择的链(INPUT等)末添加一条或更多规则\n        -D       # 删除一条\n        -E       # 修改\n        -p         # tcp、udp、icmp    0相当于所有all    !取反\n        -P       # 设置缺省策略(与所有链都不匹配强制使用此策略)\n        -s         # IP/掩码    (IP/24)    主机名、网络名和清楚的IP地址 !取反\n        -j         # 目标跳转，立即决定包的命运的专用内建目标\n        -i         # 进入的（网络）接口 [名称] eth0\n        -o         # 输出接口[名称] \n        -m         # 模块\n        --sport  # 源端口\n        --dport  # 目标端口\n        \n        iptables -F                        # 将防火墙中的规则条目清除掉  # 注意: iptables -P INPUT ACCEPT\n        iptables-restore < 规则文件        # 导入防火墙规则\n        /etc/init.d/iptables save          # 保存防火墙设置\n        /etc/init.d/iptables restart       # 重启防火墙服务\n        iptables -L -n                     # 查看规则\n        iptables -t nat -nL                # 查看转发\n\n        iptables实例{\n            \n            iptables -L INPUT                   # 列出某规则链中的所有规则\n            iptables -X allowed                 # 删除某个规则链 ,不加规则链，清除所有非内建的\n            iptables -Z INPUT                   # 将封包计数器归零\n            iptables -N allowed                 # 定义新的规则链\n            iptables -P INPUT DROP              # 定义过滤政策\n            iptables -A INPUT -s 192.168.1.1    # 比对封包的来源IP   # ! 192.168.0.0/24  ! 反向对比\n            iptables -A INPUT -d 192.168.1.1    # 比对封包的目的地IP\n            iptables -A INPUT -i eth0           # 比对封包是从哪片网卡进入\n            iptables -A FORWARD -o eth0         # 比对封包要从哪片网卡送出 eth+表示所有的网卡\n            iptables -A INPUT -p tcp            # -p ! tcp 排除tcp以外的udp、icmp。-p all所有类型\n            iptables -D INPUT 8                 # 从某个规则链中删除一条规则\n            iptables -D INPUT --dport 80 -j DROP         # 从某个规则链中删除一条规则\n            iptables -R INPUT 8 -s 192.168.0.1 -j DROP   # 取代现行规则\n            iptables -I INPUT 8 --dport 80 -j ACCEPT     # 插入一条规则\n            iptables -A INPUT -i eth0 -j DROP            # 其它情况不允许\n            iptables -A INPUT -p tcp -s IP -j DROP       # 禁止指定IP访问\n            iptables -A INPUT -p tcp -s IP --dport port -j DROP               # 禁止指定IP访问端口\n            iptables -A INPUT -s IP -p tcp --dport port -j ACCEPT             # 允许在IP访问指定端口\n            iptables -A INPUT -p tcp --dport 22 -j DROP                       # 禁止使用某端口\n            iptables -A INPUT -i eth0 -p icmp -m icmp --icmp-type 8 -j DROP   # 禁止icmp端口\n            iptables -A INPUT -i eth0 -p icmp -j DROP                         # 禁止icmp端口\n            iptables -t filter -A INPUT -i eth0 -p tcp --syn -j DROP                  # 阻止所有没有经过你系统授权的TCP连接\n            iptables -A INPUT -f -m limit --limit 100/s --limit-burst 100 -j ACCEPT   # IP包流量限制\n            iptables -A INPUT -i eth0 -s 192.168.62.1/32 -p icmp -m icmp --icmp-type 8 -j ACCEPT  # 除192.168.62.1外，禁止其它人ping我的主机\n            iptables -A INPUT -p tcp -m tcp --dport 80 -m state --state NEW -m recent --update --seconds 5 --hitcount 20 --rttl --name WEB --rsource -j DROP  # 可防御cc攻击(未测试)\n\n        }\n\n        iptables配置实例文件{\n\n            # Generated by iptables-save v1.2.11 on Fri Feb  9 12:10:37 2007\n            *filter\n            :INPUT ACCEPT [637:58967]\n            :FORWARD DROP [0:0]\n            :OUTPUT ACCEPT [5091:1301533]\n            # 允许的IP或IP段访问 建议多个\n            -A INPUT -s 127.0.0.1 -p tcp -j ACCEPT\n            -A INPUT -s 192.168.0.0/255.255.0.0 -p tcp -j ACCEPT\n            # 开放对外开放端口\n            -A INPUT -p tcp --dport 80 -j ACCEPT\n            # 指定某端口针对IP开放\n            -A INPUT -s 192.168.10.37 -p tcp --dport 22 -j ACCEPT\n            # 拒绝所有协议(INPUT允许)\n            -A INPUT -p tcp -m tcp --tcp-flags FIN,SYN,RST,PSH,URG RST -j DROP\n            # 允许已建立的或相关连的通行\n            -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n            # 拒绝ping\n            -A INPUT -p tcp -m tcp -j REJECT --reject-with icmp-port-unreachable\n            COMMIT\n            # Completed on Fri Feb  9 12:10:37 2007\n\n        }\n\n        iptables配置实例{\n\n            # 允许某段IP访问任何端口\n            iptables -A INPUT -s 192.168.0.3/24 -p tcp -j ACCEPT\n            # 设定预设规则 (拒绝所有的数据包，再允许需要的,如只做WEB服务器.还是推荐三个链都是DROP)\n            iptables -P INPUT DROP\n            iptables -P FORWARD DROP\n            iptables -P OUTPUT ACCEPT\n            # 注意: 直接设置这三条会掉线\n            # 开启22端口\n            iptables -A INPUT -p tcp --dport 22 -j ACCEPT\n            # 如果OUTPUT 设置成DROP的，要写上下面一条\n            iptables -A OUTPUT -p tcp --sport 22 -j ACCEPT \n            # 注:不写导致无法SSH.其他的端口一样,OUTPUT设置成DROP的话,也要添加一条链\n            # 如果开启了web服务器,OUTPUT设置成DROP的话,同样也要添加一条链\n            iptables -A OUTPUT -p tcp --sport 80 -j ACCEPT\n            # 做WEB服务器,开启80端口 ,其他同理\n            iptables -A INPUT -p tcp --dport 80 -j ACCEPT\n            # 做邮件服务器,开启25,110端口\n            iptables -A INPUT -p tcp --dport 110 -j ACCEPT\n            iptables -A INPUT -p tcp --dport 25 -j ACCEPT\n            # 允许icmp包通过,允许ping\n            iptables -A OUTPUT -p icmp -j ACCEPT (OUTPUT设置成DROP的话) \n            iptables -A INPUT -p icmp -j ACCEPT  (INPUT设置成DROP的话)\n            # 允许loopback!(不然会导致DNS无法正常关闭等问题) \n            IPTABLES -A INPUT -i lo -p all -j ACCEPT (如果是INPUT DROP)\n            IPTABLES -A OUTPUT -o lo -p all -j ACCEPT(如果是OUTPUT DROP)\n\n        }\n\n        centos6的iptables基本配置{\n            *filter\n            :INPUT ACCEPT [0:0]\n            :FORWARD ACCEPT [0:0]\n            :OUTPUT ACCEPT [0:0]\n            -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n            -A INPUT -p icmp -j ACCEPT\n            -A INPUT -i lo -j ACCEPT\n            -A INPUT -s 222.186.135.61 -p tcp -j ACCEPT\n            -A INPUT -p tcp  --dport 80 -j ACCEPT\n            -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT\n            -A INPUT -j REJECT --reject-with icmp-host-prohibited\n            -A INPUT -p tcp -m tcp --tcp-flags FIN,SYN,RST,PSH,URG RST -j DROP\n            -A FORWARD -j REJECT --reject-with icmp-host-prohibited\n            COMMIT\n        }\n\n        添加网段转发{\n\n            # 例如通过vpn上网\n            echo 1 > /proc/sys/net/ipv4/ip_forward       # 在内核里打开ip转发功能\n            iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE  # 添加网段转发\n            iptables -t nat -A POSTROUTING -s 10.0.0.0/255.0.0.0 -o eth0 -j SNAT --to 192.168.10.158  # 原IP网段经过哪个网卡IP出去\n            iptables -t nat -nL                # 查看转发\n\n        }\n\n        端口映射{\n            \n            # 内网通过有外网IP的机器映射端口\n            # 内网主机添加路由\n            route add -net 10.10.20.0 netmask 255.255.255.0 gw 10.10.20.111     # 内网需要添加默认网关，并且网关开启转发\n            # 网关主机\n            echo 1 > /proc/sys/net/ipv4/ip_forward       # 在内核里打开ip转发功能\n            iptables -t nat -A PREROUTING -d 外网IP  -p tcp --dport 9999 -j DNAT --to 10.10.20.55:22    # 进入\n            iptables -t nat -A POSTROUTING -s 10.10.20.0/24 -j SNAT --to 外网IP                         # 转发回去\n            iptables -t nat -nL                # 查看转发\n\n        }\n\n    }\n\n}\n\n4 服务{\n\n    /etc/init.d/sendmail start                   # 启动服务  \n    /etc/init.d/sendmail stop                    # 关闭服务\n    /etc/init.d/sendmail status                  # 查看服务当前状态\n    /date/mysql/bin/mysqld_safe --user=mysql &   # 启动mysql后台运行\n    vi /etc/rc.d/rc.local                        # 开机启动执行  可用于开机启动脚本\n    /etc/rc.d/rc3.d/S55sshd                      # 开机启动和关机关闭服务连接    # S开机start  K关机stop  55级别 后跟服务名\n    ln -s -f /date/httpd/bin/apachectl /etc/rc.d/rc3.d/S15httpd   # 将启动程序脚本连接到开机启动目录\n    ipvsadm -ln                                  # lvs查看后端负载机并发\n    ipvsadm -C                                   # lvs清除规则\n    xm list                                      # 查看xen虚拟主机列表\n    virsh                                        # 虚拟化(xen\\kvm)管理工具  yum groupinstall Virtual*\n    ./bin/httpd -M                               # 查看httpd加载模块\n    httpd -t -D DUMP_MODULES                     # rpm包httpd查看加载模块\n    echo 内容| /bin/mail -s "标题" 收件箱 -f 发件人       # 发送邮件\n    "`echo "内容"|iconv -f utf8 -t gbk`" | /bin/mail -s "`echo "标题"|iconv -f utf8 -t gbk`" 收件箱     # 解决邮件乱码\n    /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg   # 检测nagios配置文件\n\n    chkconfig{\n\n        chkconfig 服务名 on|off|set              # 设置非独立服务启状态\n        chkconfig --level 35   httpd   off       # 让服务不自动启动\n        chkconfig --level 35   httpd   on        # 让服务自动启动 35指的是运行级别\n        chkconfig --list                         # 查看所有服务的启动状态\n        chkconfig --list |grep httpd             # 查看某个服务的启动状态\n        chkconfig –-list [服务名称]              # 查看服务的状态\n\n    }\n\n    httpd{\n\n        编译参数{\n\n            # so模块用来提供DSO支持的apache核心模块\n            # 如果编译中包含任何DSO模块，则mod_so会被自动包含进核心。\n            # 如果希望核心能够装载DSO，但不实际编译任何DSO模块，则需明确指定"--enable-so=static"\n\n            ./configure --prefix=/usr/local/apache --enable-so --enable-mods-shared=most --enable-rewrite --enable-forward  # 实例编译\n\n            --with-mpm=worker         # 已worker方式运行\n            --with-apxs=/usr/local/apache/bin/apxs  # 制作apache的动态模块DSO rpm包 httpd-devel  #编译模块 apxs -i -a -c mod_foo.c\n            --enable-so               # 让Apache可以支持DSO模式\n            --enable-mods-shared=most # 告诉编译器将所有标准模块都动态编译为DSO模块\n            --enable-rewrite          # 支持地址重写功能\n            --enable-module=most      # 用most可以将一些不常用的，不在缺省常用模块中的模块编译进来\n            --enable-mods-shared=all  # 意思是动态加载所有模块，如果去掉-shared话，是静态加载所有模块\n            --enable-expires          # 可以添加文件过期的限制，有效减轻服务器压力，缓存在用户端，有效期内不会再次访问服务器，除非按f5刷新，但也导致文件更新不及时\n            --enable-deflate          # 压缩功能，网页可以达到40%的压缩，节省带宽成本，但会对cpu压力有一点提高\n            --enable-headers          # 文件头信息改写，压缩功能需要\n            --disable-MODULE          # 禁用MODULE模块(仅用于基本模块)\n            --enable-MODULE=shared    # 将MODULE编译为DSO(可用于所有模块) \n            --enable-mods-shared=MODULE-LIST   # 将MODULE-LIST中的所有模块都编译成DSO(可用于所有模块) \n            --enable-modules=MODULE-LIST       # 将MODULE-LIST静态连接进核心(可用于所有模块)\n            \n            # 上述 MODULE-LIST 可以是:\n            1、用引号界定并且用空格分隔的模块名列表  --enable-mods-shared=''headers rewrite dav''\n            2、"most"(大多数模块)  --enable-mods-shared=most \n            3、"all"(所有模块)\n\n        }\n\n        转发{\n\n            #针对非80端口的请求处理\n            RewriteCond %{SERVER_PORT} !^80$\n            RewriteRule ^/(.*)         http://fully.qualified.domain.name:%{SERVER_PORT}/$1 [L,R]\n\n            RewriteCond %{HTTP_HOST} ^ss.aa.com [NC]\n            RewriteRule  ^(.*)  http://www.aa.com/so/$1/0/p0?  [L,R=301]\n            #RewriteRule 只对?前处理，所以会把?后的都保留下来\n            #在转发后地址后加?即可取消RewriteRule保留的字符\n            #R的含义是redirect，即重定向，该请求不会再被apache交给后端处理，而是直接返回给浏览器进行重定向跳转。301是返回的http状态码，具体可以参考http rfc文档，跳转都是3XX。\n            #L是last，即最后一个rewrite规则，如果请求被此规则命中，将不会继续再向下匹配其他规则。    \n\n        }\n\n    }\n\n    mysql源码安装{\n    \n        groupadd mysql\n        useradd mysql -g mysql -M -s /bin/false\n        tar zxvf mysql-5.0.22.tar.gz\n        cd mysql-5.0.22\n        ./configure  --prefix=/usr/local/mysql \\\n        --with-client-ldflags=-all-static \\\n        --with-mysqld-ldflags=-all-static \\\n        --with-mysqld-user=mysql \\\n        --with-extra-charsets=all \\\n        --with-unix-socket-path=/var/tmp/mysql.sock\n        make  &&   make  install\n        # 生成mysql用户数据库和表文件，在安装包中输入\n        scripts/mysql_install_db  --user=mysql\n        vi ~/.bashrc\n        export PATH="$PATH: /usr/local/mysql/bin"\n        # 配置文件,有large,medium,small三个，根据机器性能选择\n        cp support-files/my-medium.cnf /etc/my.cnf\n        cp support-files/mysql.server /etc/init.d/mysqld\n        chmod 700 /etc/init.d/mysqld\n        cd /usr/local\n        chmod 750 mysql -R\n        chgrp mysql mysql -R\n        chown mysql mysql/var -R\n        cp  /usr/local/mysql/libexec/mysqld mysqld.old\n        ln -s /usr/local/mysql/bin/mysql /sbin/mysql\n        ln -s /usr/local/mysql/bin/mysqladmin /sbin/mysqladmin\n        ln -s -f /usr/local/mysql/bin/mysqld_safe /etc/rc.d/rc3.d/S15mysql5\n        ln -s -f /usr/local/mysql/bin/mysqld_safe /etc/rc.d/rc0.d/K15mysql5\n        \n    }\n\n    mysql常用命令{\n        \n        ./mysql/bin/mysqld_safe --user=mysql &   # 启动mysql服务\n        ./mysql/bin/mysqladmin -uroot -p -S ./mysql/data/mysql.sock shutdown    # 停止mysql服务\n        mysqlcheck -uroot -p -S mysql.sock --optimize --databases account       # 检查、修复、优化MyISAM表\n        mysqlbinlog slave-relay-bin.000001              # 查看二进制日志(报错加绝对路径)\n        mysqladmin -h myhost -u root -p create dbname   # 创建数据库\n\n        flush privileges;             # 刷新\n        show databases;               # 显示所有数据库\n        use dbname;                   # 打开数据库\n        show tables;                  # 显示选中数据库中所有的表\n        desc tables;                  # 查看表结构\n        drop database name;           # 删除数据库\n        drop table name;              # 删除表\n        create database name;         # 创建数据库\n        select 列名称 from 表名称;    # 查询\n        show grants for repl;         # 查看用户权限\n        show processlist;             # 查看mysql进程\n        select user();                # 查看所有用户\n        show slave status\\G;          # 查看主从状态\n        show variables;               # 查看所有参数变量\n        show table status             # 查看表的引擎状态\n        drop table if exists user                       # 表存在就删除\n        create table if not exists user                 # 表不存在就创建\n        select host,user,password from user;            # 查询用户权限 先use mysql\n        create table ka(ka_id varchar(6),qianshu int);  # 创建表\n        SHOW VARIABLES LIKE ''character_set_%'';          # 查看系统的字符集和排序方式的设定\n        show variables like ''%timeout%'';                # 查看超时(wait_timeout)\n        delete from user where user='''';                 # 删除空用户\n        delete from user where user=''sss'' and host=''localhost'' ;    # 删除用户\n        ALTER TABLE mytable ENGINE = MyISAM ;                       # 改变现有的表使用的存储引擎\n        SHOW TABLE STATUS from  库名  where Name=''表名'';            # 查询表引擎\n        CREATE TABLE innodb (id int, title char(20)) ENGINE = INNODB                     # 创建表指定存储引擎的类型(MyISAM或INNODB)\n        grant replication slave on *.* to ''用户''@''%'' identified by ''密码'';               # 创建主从复制用户\n        ALTER TABLE player ADD INDEX weekcredit_faction_index (weekcredit, faction);     # 添加索引\n        alter table name add column accountid(列名)  int(11) NOT NULL(字段不为空);       # 插入字段\n        update host set monitor_state=''Y'',hostname=''xuesong'' where ip=''192.168.1.1'';     # 更新数据\n        \n        自增表{\n        \n            create table oldBoy  (id INTEGER  PRIMARY KEY AUTO_INCREMENT, name CHAR(30) NOT NULL, age integer , sex CHAR(15) );  # 创建自增表\n            insert into oldBoy(name,age,sex) values(%s,%s,%s)  # 自增插入数据\n            \n        }\n\n        登录mysql的命令{\n\n            # 格式： mysql -h 主机地址 -u 用户名 -p 用户密码\n            mysql -h110.110.110.110 -P3306 -uroot -p\n            mysql -uroot -p -S /data1/mysql5/data/mysql.sock -A  --default-character-set=GBK\n\n        }\n\n        shell执行mysql命令{\n            \n            mysql -u root -p''123'' xuesong < file.sql   # 针对指定库执行sql文件中的语句,好处不需要转义特殊符号,一条语句可以换行.不指定库执行时语句中需要先use\n            mysql -u$username -p$passwd -h$dbhost -P$dbport -A -e "      \n            use $dbname;\n            delete from data where date=(''$date1'');\n            "    # 执行多条mysql命令\n            mysql -uroot -p -S mysql.sock -e "use db;alter table gift add column accountid  int(11) NOT NULL;flush privileges;"    # 不登陆mysql插入字段\n            \n        }\n\n        备份数据库{\n\n            mysqldump -h host -u root -p --default-character-set=utf8 dbname >dbname_backup.sql               # 不包括库名，还原需先创建库，在use \n            mysqldump -h host -u root -p --database --default-character-set=utf8 dbname >dbname_backup.sql    # 包括库名，还原不需要创建库\n            /bin/mysqlhotcopy -u root -p    # mysqlhotcopy只能备份MyISAM引擎\n            mysqldump -u root -p -S mysql.sock --default-character-set=utf8 dbname table1 table2  > /data/db.sql    # 备份表\n            mysqldump -uroot -p123  -d database > database.sql    # 备份数据库结构\n            \n            innobackupex --user=root --password="" --defaults-file=/data/mysql5/data/my_3306.cnf --socket=/data/mysql5/data/mysql.sock --slave-info --stream=tar --tmpdir=/data/dbbackup/temp /data/dbbackup/ 2>/data/dbbackup/dbbackup.log | gzip 1>/data/dbbackup/db50.tar.gz   # xtrabackup备份需单独安装软件 优点: 速度快,压力小,可直接恢复主从复制\n\n        }\n\n        还原数据库{\n\n            mysql -h host -u root -p dbname < dbname_backup.sql   \n            source 路径.sql   # 登陆mysql后还原sql文件\n\n        }\n\n        赋权限{\n\n            # 指定IP: $IP  本机: localhost   所有IP地址: %   # 通常指定多条\n            grant all on zabbix.* to user@"$IP";             # 对现有账号赋予权限\n            grant select on database.* to user@"%" Identified by "passwd";     # 赋予查询权限(没有用户，直接创建)\n            grant all privileges on database.* to user@"$IP" identified by ''passwd'';         # 赋予指定IP指定用户所有权限(不允许对当前库给其他用户赋权限)\n            grant all privileges on database.* to user@"localhost" identified by ''passwd'' with grant option;   # 赋予本机指定用户所有权限(允许对当前库给其他用户赋权限)\n            grant select, insert, update, delete on database.* to user@''ip''identified by "passwd";   # 开放管理操作指令\n            revoke all on *.* from user@localhost;     # 回收权限\n\n        }\n\n        更改密码{\n\n            update user set password=password(''passwd'') where user=''root''\n            mysqladmin -u root password ''xuesong''\n\n        }\n\n        mysql忘记密码后重置{\n\n            cd /data/mysql5\n            /data/mysql5/bin/mysqld_safe --user=mysql --skip-grant-tables --skip-networking &\n            use mysql;\n            update user set password=password(''123123'') where user=''root'';\n\n        }\n\n        mysql主从复制失败恢复{\n\n            slave stop;\n            reset slave;\n            change master to master_host=''10.10.10.110'',master_port=3306,master_user=''repl'',master_password=''repl'',master_log_file=''master-bin.000010'',master_log_pos=107,master_connect_retry=60;\n            slave start;\n\n        }\n\n        sql语句使用变量{\n\n            use xuesong;\n            set @a=concat(''my'',weekday(curdate()));    # 组合时间变量\n            set @sql := concat(''CREATE TABLE IF NOT EXISTS '',@a,''( id INT(11) NOT NULL )'');   # 组合sql语句\n            select @sql;                    # 查看语句\n            prepare create_tb from @sql;    # 准备\n            execute create_tb;              # 执行\n\n        }\n\n        检测mysql主从复制延迟{\n            \n            1、在从库定时执行更新主库中的一个timeout数值\n            2、同时取出从库中的timeout值对比判断从库与主库的延迟\n        \n        }\n\n        mysql慢查询{\n\n            开启慢查询日志{\n                \n                # 配置文件 /etc/my.conf\n                [mysqld]\n                log-slow-queries=/var/lib/mysql/slowquery.log         # 指定日志文件存放位置，可以为空，系统会给一个缺省的文件host_name-slow.log\n                long_query_time=5                                     # 记录超过的时间，默认为10s\n                log-queries-not-using-indexes                         # log下来没有使用索引的query,可以根据情况决定是否开启  可不加\n                log-long-format                                       # 如果设置了，所有没有使用索引的查询也将被记录    可不加\n                # 直接修改生效\n                show variables like "%slow%";                         # 查看慢查询状态 \n                set global slow_query_log=''ON'';                       # 开启慢查询日志 变量可能不同，看上句查询出来的变量\n\n            }\n            \n            mysqldumpslow慢查询日志查看{\n\n                -s  # 是order的顺序，包括看了代码，主要有 c,t,l,r和ac,at,al,ar，分别是按照query次数，时间，lock的时间和返回的记录数来排序，前面加了a的时倒序 \n                -t  # 是top n的意思，即为返回前面多少条的数据 \n                -g  # 后边可以写一个正则匹配模式，大小写不敏感的\n                 \n                mysqldumpslow -s c -t 20 host-slow.log                # 访问次数最多的20个sql语句\n                mysqldumpslow -s r -t 20 host-slow.log                # 返回记录集最多的20个sql\n                mysqldumpslow -t 10 -s t -g "left join" host-slow.log # 按照时间返回前10条里面含有左连接的sql语句\n                \n                show global status like ''%slow%'';                     # 查看现在这个session有多少个慢查询\n                show variables like ''%slow%'';                         # 查看慢查询日志是否开启，如果slow_query_log和log_slow_queries显示为on，说明服务器的慢查询日志已经开启\n                show variables like ''%long%'';                         # 查看超时阀值\n                desc select * from wei where text=''xishizhaohua''\\G;   # 扫描整张表 tepe:ALL  没有使用索引 key:NULL\n                create index text_index on wei(text);                 # 创建索引\n\n            }\n        \n        }\n\n        mysql操作次数查询{\n\n            select * from information_schema.global_status\n\n            com_select\n            com_delete\n            com_insert\n            com_update\n\n        }\n\n    }\n\n    mongodb{\n\n        一、启动{\n        \n            # 不启动认证\n            ./mongod --port 27017 --fork --logpath=/opt/mongodb/mongodb.log --logappend --dbpath=/opt/mongodb/data/\n            # 启动认证\n            ./mongod --port 27017 --fork --logpath=/opt/mongodb/mongodb.log --logappend --dbpath=/opt/mongodb/data/ --auth\n\n            # 配置文件方式启动\n            cat /opt/mongodb/mongodb.conf\n              port=27017                       # 端口号\n              fork=true                        # 以守护进程的方式运行，创建服务器进程\n              auth=true                        # 开启用户认证\n              logappend=true                   # 日志采用追加方式\n              logpath=/opt/mongodb/mongodb.log # 日志输出文件路径\n              dbpath=/opt/mongodb/data/        # 数据库路径\n              shardsvr=true                    # 设置是否分片\n              maxConns=600                     # 数据库的最大连接数\n            ./mongod -f /opt/mongodb/mongodb.conf\n            \n            # 其他参数\n            bind_ip         # 绑定IP  使用mongo登录需要指定对应IP\n            journal         # 开启日志功能,降低单机故障的恢复时间,取代dur参数\n            syncdelay       # 系统同步刷新磁盘的时间,默认60秒\n            directoryperdb  # 每个db单独存放目录,建议设置.与mysql独立表空间类似\n            repairpath      # 执行repair时的临时目录.如果没开启journal,出现异常重启,必须执行repair操作\n            # mongodb没有参数设置内存大小.使用os mmap机制缓存数据文件,在数据量不超过内存的情况下,效率非常高.数据量超过系统可用内存会影响写入性能\n\n        }\n\n        二、关闭{\n\n            # 方法一:登录mongodb\n            ./mongo\n            use admin\n            db.shutdownServer()\n\n            # 方法:kill传递信号  两种皆可\n            kill -2 pid\n            kill -15 pid\n\n        }\n\n        三、开启认证与用户管理{\n\n            ./mongo                      # 先登录\n            use admin                    # 切换到admin库\n            db.addUser("root","123456")                     # 创建用户\n            db.addUser(''zhansan'',''pass'',true)               # 如果用户的readOnly为true那么这个用户只能读取数据，添加一个readOnly用户zhansan\n            ./mongo 127.0.0.1:27017/mydb -uroot -p123456    # 再次登录,只能针对用户所在库登录\n            #虽然是超级管理员，但是admin不能直接登录其他数据库，否则报错\n            #Fri Nov 22 15:03:21.886 Error: 18 { code: 18, ok: 0.0, errmsg: "auth fails" } at src/mongo/shell/db.js:228\n            show collections                                # 查看链接状态 再次登录使用如下命令,显示错误未经授权\n            db.system.users.find();                         # 查看创建用户信息\n            db.system.users.remove({user:"zhansan"})        # 删除用户\n\n            #恢复密码只需要重启mongodb 不加--auth参数\n\n        }\n\n        四、登录{\n\n            192.168.1.5:28017      # http登录后可查看状态\n            ./mongo                # 默认登录后打开 test 库\n            ./mongo 192.168.1.5:27017/databaseName      # 直接连接某个库 不存在则创建  启动认证需要指定对应库才可登录\n\n        }\n\n        五、查看状态{\n\n            #登录后执行命令查看状态\n            db.runCommand({"serverStatus":1})\n                globalLock         # 表示全局写入锁占用了服务器多少时间(微秒)\n                mem                # 包含服务器内存映射了多少数据,服务器进程的虚拟内存和常驻内存的占用情况(MB)\n                indexCounters      # 表示B树在磁盘检索(misses)和内存检索(hits)的次数.如果这两个比值开始上升,就要考虑添加内存了\n                backgroudFlushing  # 表示后台做了多少次fsync以及用了多少时间\n                opcounters         # 包含每种主要擦撞的次数\n                asserts            # 统计了断言的次数\n\n            #状态信息从服务器启动开始计算,如果过大就会复位,发送复位，所有计数都会复位,asserts中的roolovers值增加\n\n            #mongodb自带的命令\n            ./mongostat\n                insert     #每秒插入量\n                query      #每秒查询量\n                update     #每秒更新量\n                delete     #每秒删除量\n                locked     #锁定量\n                qr|qw      #客户端查询排队长度(读|写)\n                ar|aw      #活跃客户端量(读|写)\n                conn       #连接数\n                time       #当前时间\n\n        }\n\n        六、常用命令{\n\n            db.listCommands()     # 当前MongoDB支持的所有命令（同样可通过运行命令db.runCommand({"listCommands" : `1})来查询所有命令）\n\n            db.runCommand({"buildInfo" : 1})                # 返回MongoDB服务器的版本号和服务器OS的相关信息。\n            db.runCommand({"collStats" : 集合名})           # 返回该集合的统计信息，包括数据大小，已分配存储空间大小，索引的大小等。\n            db.runCommand({"distinct" : 集合名, "key" : 键, "query" : 查询文档})     # 返回特定文档所有符合查询文档指定条件的文档的指定键的所有不同的值。\n            db.runCommand({"dropDatabase" : 1})             # 清空当前数据库的信息，包括删除所有的集合和索引。\n            db.runCommand({"isMaster" : 1})                 # 检查本服务器是主服务器还是从服务器。\n            db.runCommand({"ping" : 1})                     # 检查服务器链接是否正常。即便服务器上锁，该命令也会立即返回。\n            db.runCommand({"repaireDatabase" : 1})          # 对当前数据库进行修复并压缩，如果数据库特别大，这个命令会非常耗时。\n            db.runCommand({"serverStatus" : 1})             # 查看这台服务器的管理统计信息。\n            # 某些命令必须在admin数据库下运行，如下两个命令：\n            db.runCommand({"renameCollection" : 集合名, "to"：集合名})     # 对集合重命名，注意两个集合名都要是完整的集合命名空间，如foo.bar, 表示数据库foo下的集合bar。\n            db.runCommand({"listDatabases" : 1})                           # 列出服务器上所有的数据库\n\n        }\n\n        七、进程控制{\n\n            db.currentOp()                  # 查看活动进程\n            db.$cmd.sys.inprog.findOne()    # 查看活动进程 与上面一样\n                opid   # 操作进程号\n                op     # 操作类型(查询\\更新)\n                ns     # 命名空间,指操作的是哪个对象\n                query  # 如果操作类型是查询,这里将显示具体的查询内容\n                lockType  # 锁的类型,指明是读锁还是写锁\n\n            db.killOp(opid值)                         # 结束进程\n            db.$cmd.sys.killop.findOne({op:opid值})   # 结束进程\n\n        }\n\n        八、备份还原{\n\n            ./mongoexport -d test -c t1 -o t1.dat                 # 导出JSON格式\n                -c         # 指明导出集合\n                -d         # 使用库\n            ./mongoexport -d test -c t1 -csv -f num -o t1.dat     # 导出csv格式\n                -csv       # 指明导出csv格式\n                -f         # 指明需要导出那些例\n\n            db.t1.drop()                    # 登录后删除数据\n            ./mongoimport -d test -c t1 -file t1.dat                           # mongoimport还原JSON格式\n            ./mongoimport -d test -c t1 -type csv --headerline -file t1.dat    # mongoimport还原csv格式数据\n                --headerline                # 指明不导入第一行 因为第一行是列名\n\n            ./mongodump -d test -o /bak/mongodump                # mongodump数据备份\n            ./mongorestore -d test --drop /bak/mongodump/*       # mongorestore恢复\n                --drop      #恢复前先删除\n            db.t1.find()    #查看\n\n            # mongodump 虽然能不停机备份,但市区了获取实时数据视图的能力,使用fsync命令能在运行时复制数据目录并且不会损坏数据\n            # fsync会强制服务器将所有缓冲区的数据写入磁盘.配合lock还阻止对数据库的进一步写入,知道释放锁为止\n            # 备份在从库上备份，不耽误读写还能保证实时快照备份\n            db.runCommand({"fsync":1,"lock":1})   # 执行强制更新与写入锁\n            db.$cmd.sys.unlock.findOne()          # 解锁\n            db.currentOp()                        # 查看解锁是否正常\n\n        }\n\n        九、修复{\n\n            # 当停电或其他故障引起不正常关闭时,会造成部分数据损坏丢失\n            ./mongod --repair      # 修复操作:启动时候加上 --repair\n            # 修复过程:将所有文档导出,然后马上导入,忽略无效文档.完成后重建索引。时间较长,会丢弃损坏文档\n            # 修复数据还能起到压缩数据库的作用\n            db.repairDatabase()    # 运行中的mongodb可使用 repairDatabase 修复当前使用的数据库\n            {"repairDatabase":1}   # 通过驱动程序\n\n        }\n\n        十、python使用mongodb{\n\n            原文: http://blog.nosqlfan.com/html/2989.html\n            \n            easy_install pymongo      # 安装(python2.7+)\n            import pymongo\n            connection=pymongo.Connection(''localhost'',27017)   # 创建连接\n            db = connection.test_database                      # 切换数据库\n            collection = db.test_collection                    # 获取collection\n            # db和collection都是延时创建的，在添加Document时才真正创建\n\n            文档添加, _id自动创建\n                import datetime\n                post = {"author": "Mike",\n                    "text": "My first blog post!",\n                    "tags": ["mongodb", "python", "pymongo"],\n                    "date": datetime.datetime.utcnow()}\n                posts = db.posts\n                posts.insert(post)\n                ObjectId(''...'')\n\n            批量插入\n                new_posts = [{"author": "Mike",\n                    "text": "Another post!",\n                    "tags": ["bulk", "insert"],\n                    "date": datetime.datetime(2009, 11, 12, 11, 14)},\n                    {"author": "Eliot",\n                    "title": "MongoDB is fun",\n                    "text": "and pretty easy too!",\n                    "date": datetime.datetime(2009, 11, 10, 10, 45)}]\n                posts.insert(new_posts)\n                [ObjectId(''...''), ObjectId(''...'')]\n            \n            获取所有collection\n                db.collection_names()    # 相当于SQL的show tables\n                \n            获取单个文档\n                posts.find_one()\n\n            查询多个文档\n                for post in posts.find():\n                    post\n\n            加条件的查询\n                posts.find_one({"author": "Mike"})\n\n            高级查询\n                posts.find({"date": {"$lt": "d"}}).sort("author")\n\n            统计数量\n                posts.count()\n\n            加索引\n                from pymongo import ASCENDING, DESCENDING\n                posts.create_index([("date", DESCENDING), ("author", ASCENDING)])\n\n            查看查询语句的性能\n                posts.find({"date": {"$lt": "d"}}).sort("author").explain()["cursor"]\n                posts.find({"date": {"$lt": "d"}}).sort("author").explain()["nscanned"]\n\n        }\n\n    }\n\n    JDK安装{\n\n        chmod 744 jdk-1_5_0_14-linux-i586.bin\n        ./jdk-1_5_0_14-linux-i586.bin\n        vi /etc/profile   # 添加环境变量\n        export JAVA_HOME=/usr/local/jdk1.5.0_14 \n        export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar \n        export PATH=$PATH:$JAVA_HOME/bin\n        . /etc/profile\n        \n        jps -ml   # 查看java进程\n    }\n\n    redis动态加内存{\n\n        ./redis-cli -h 10.10.10.11 -p 6401\n        save                                # 保存当前快照\n        config get *                        # 列出所有当前配置\n        config get maxmemory                # 查看指定配置\n        config set maxmemory  15360000000   # 动态修改最大内存配置参数\n\n    }\n\n    nfs{\n\n        # 依赖rpc服务通信 portmap[centos5] 或 rpcbind[centos6]\n        yum install nfs-utils portmap    # centos5安装  \n        yum install nfs-utils rpcbind    # centos6安装\n\n        vim /etc/exports                 # 配置文件        \n        # sync                           # 同步写入   \n        # async                          # 暂存并非直接写入\n        # no_root_squash                 # 开放用户端使用root身份操作   \n        # root_squash                    # 使用者身份为root则被压缩成匿名使用,即nobody,相对安全     \n        # all_squash                     # 所有NFS的使用者身份都被压缩为匿名\n        /data/images 10.10.10.0/24(rw,sync,no_root_squash)  \n\n        service  portmap restart         # 重启centos5的nfs依赖的rpc服务\n        service  rpcbind restart         # 重启centos6的nfs依赖的rpc服务\n        service  nfs restart             # 重启nfs服务  确保依赖 portmap 或 rpcbind 服务已启动\n        service  nfs reload              # 重载NFS服务配置文件  \n        showmount -e                     # 服务端查看自己共享的服务\n        showmount -a                     # 显示已经与客户端连接上的目录信息\n        showmount -e 10.10.10.3          # 列出服务端可供使用的NFS共享  客户端测试能否访问nfs服务\n        mount -t nfs 10.10.10.3:/data/images/  /data/img   # 挂载nfs  如果延迟影响大加参数 noac\n\n        # 服务端的 portmap 或 rpcbind 被停止后，nfs仍然工作正常，但是umout财会提示： not found / mounted or server not reachable  重启服务器的portmap 或 rpcbind 也无济于事。 nfs也要跟着重启，否则nfs工作仍然是不正常的。\n        # 同时已挂载会造成NFS客户端df卡住和挂载目录无法访问。请先用 mount 查看当前挂载情况，记录挂载信息，在强制卸载挂载目录，重新挂载\n        umount -f /data/img/             # 强制卸载挂载目录  如还不可以  umount -l /data/img/\n        \n        nfsstat -c                       # 客户机发送和拒绝的RPC和NFS调用数目的信息\n        nfsstat -cn                      # 显示和打印与客户机NFS调用相关的信息\n        nfsstat -r                       # 显示和打印客户机和服务器的与RPC调用相关的信息\n        nfsstat –s                       # 显示关于服务器接收和拒绝的RPC和NFS调用数目的信息\n\n    }\n\n    hdfs{\n        hdfs --help                  # 所有参数\n\n        hdfs dfs -help               # 运行文件系统命令在Hadoop文件系统\n        hdfs dfs -ls /logs           # 查看\n        hdfs dfs -ls /user/          # 查看用户\n        hdfs dfs -cat\n        hdfs dfs -df\n        hdfs dfs -du\n        hdfs dfs -rm\n        hdfs dfs -tail\n\n        hdfs dfsadmin -help          # hdfs集群节点管理\n        hdfs dfsadmin -report        # 基本的文件系统统计信息\n    }\n\n}\n\n5 网络{\n\n    rz   # 通过ssh上传小文件\n    sz   # 通过ssh下载小文件\n    ifconfig eth0 down                  # 禁用网卡\n    ifconfig eth0 up                    # 启用网卡\n    ifup eth0:0                         # 启用网卡\n    mii-tool em1                        # 查看网线是否连接\n    traceroute www.baidu.com            # 测试跳数\n    vi /etc/resolv.conf                 # 设置DNS  nameserver IP 定义DNS服务器的IP地址\n    nslookup www.moon.com               # 解析域名IP\n    dig -x www.baidu.com                # 解析域名IP\n    dig +short txt hacker.wp.dg.cx      # 通过 DNS 来读取 Wikipedia 的hacker词条\n    host -t txt hacker.wp.dg.cx         # 通过 DNS 来读取 Wikipedia 的hacker词条\n    tcpdump tcp port 22                 # 抓包\n    lynx                                # 文本上网\n    wget -P 路径 -O 重命名 http地址     # 下载  包名:wgetrc   -q 安静\n    dhclient eth1                       # 自动获取IP\n    mtr -r www.baidu.com                # 测试网络链路节点响应时间 # trace ping 结合\n    ipcalc -m "$ip" -p "$num"           # 根据IP和主机最大数计算掩码\n    curl -I www.baidu.com               # 查看网页http头\n    curl -s www.baidu.com               # 不显示进度\n    queryperf -d list -s DNS_IP -l 2    # BIND自带DNS压力测试  [list 文件格式:www.turku.fi A]\n    telnet ip port                      # 测试端口是否开放,有些服务可直接输入命令得到返回状态\n    echo "show " |nc $ip $port          # 适用于telnet一类登录得到命令返回\n    nc -l -p port                       # 监听指定端口\n    nc -nv -z 10.10.10.11 1080 |grep succeeded                            # 检查主机端口是否开放\n    curl -o /dev/null -s -m 10 --connect-timeout 10 -w %{http_code} $URL  # 检查页面状态\n    curl -d "user=xuesong&pwd=123" http://www.abc.cn/Result               # 提交web页面表单 需查看表单提交地址\n    curl -s http://20140507.ip138.com/ic.asp                              # 通过IP138取本机出口外网IP\n    rsync -avzP -e "ssh -p 22" /dir user@$IP:/dir                         # 同步目录 # --delete 无差同步 删除目录下其它文件\n    sshpass -p "$passwd"  rsync -avzP -e "ssh -p 22" /dir  user@$IP:/dir/ # 指定密码避免交互同步目录\n    ifconfig eth0:0 192.168.1.221 netmask 255.255.255.0                   # 增加逻辑IP地址\n    echo 1 > /proc/sys/net/ipv4/icmp_echo_ignore_all                      # 禁ping\n    net rpc shutdown -I IP_ADDRESS -U username%password                   # 远程关掉一台WINDOWS机器\n    wget --random-wait -r -p -e robots=off -U Mozilla www.example.com     # 递归方式下载整个网站\n    \n    网卡流量查看{\n\n        watch more /proc/net/dev    # 实时监控流量文件系统 累计值\n        iptraf                      # 网卡流量查看工具\n        nethogs -d 5 eth0 eth1      # 按进程实时统计网络流量 epel源nethogs\n        \n        sar {\n            -n参数有6个不同的开关: DEV | EDEV | NFS | NFSD | SOCK | ALL \n            DEV显示网络接口信息\n            EDEV显示关于网络错误的统计数据\n            NFS统计活动的NFS客户端的信息\n            NFSD统计NFS服务器的信息\n            SOCK显示套 接字信息\n            ALL显示所有5个开关\n            \n            sar -n DEV 1 10\n            \n            rxpck/s   # 每秒钟接收的数据包\n            txpck/s   # 每秒钟发送的数据包\n            rxbyt/s   # 每秒钟接收的字节数\n            txbyt/s   # 每秒钟发送的字节数\n            rxcmp/s   # 每秒钟接收的压缩数据包\n            txcmp/s   # 每秒钟发送的压缩数据包\n            rxmcst/s  # 每秒钟接收的多播数据包\n        \n        }\n\n    }\n    \n    netstat{\n\n        # 几十万并发的情况下netstat会没有响应，建议使用 ss 命令\n        -a     # 显示所有连接中的Socket\n        -t     # 显示TCP连接\n        -u     # 显示UDP连接\n        -n     # 显示所有已建立的有效连接\n        netstat -anlp           # 查看链接\n        netstat -r              # 查看路由表\n    }\n\n    ss{\n\n        # netstat是遍历/proc下面每个PID目录，ss直接读/proc/net下面的统计信息。所以ss执行的时候消耗资源以及消耗的时间都比netstat少很多\n        ss -s          # 列出当前socket详细信息\n        ss -l          # 显示本地打开的所有端口\n        ss -pl         # 显示每个进程具体打开的socket\n        ss -ant        # 显示所有TCP socket\n        ss -u -a       # 显示所有UDP Socekt\n        ss dst 192.168.119.113         # 匹配远程地址\n        ss dst 192.168.119.113:http    # 匹配远程地址和端口号\n        ss dst 192.168.119.113:3844    # 匹配远程地址和端口号\n        ss src 192.168.119.103:16021   # 匹配本地地址和端口号\n        ss -o state established ''( dport = :smtp or sport = :smtp )''        # 显示所有已建立的SMTP连接\n        ss -o state established ''( dport = :http or sport = :http )''        # 显示所有已建立的HTTP连接\n        ss -x src /tmp/.X11-unix/*         # 找出所有连接X服务器的进程\n\n    }\n    \n    并发数查看{\n\n        netstat -n | awk ''/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}''\n        SYN_RECV     # 正在等待处理的请求\n        ESTABLISHED  # 正常数据传输状态,既当前并发数\n        TIME_WAIT    # 处理完毕，等待超时结束的请求\n        CLOSE_WAIT   # 客户端异常关闭,没有完成4次挥手  如大量可能存在攻击行为\n\n    }\n\n    ssh{\n\n        ssh -p 22 user@192.168.1.209                            # 从linux ssh登录另一台linux \n        ssh -p 22 root@192.168.1.209 CMD                        # 利用ssh操作远程主机\n        scp -P 22 文件 root@ip:/目录                            # 把本地文件拷贝到远程主机\n        sshpass -p ''密码'' ssh -n root@$IP "echo hello"          # 指定密码远程操作\n        ssh -o StrictHostKeyChecking=no $IP                     # ssh连接不提示yes\n        ssh -t "su -"                                           # 指定伪终端 客户端以交互模式工作\n        scp root@192.168.1.209:远程目录 本地目录                # 把远程指定文件拷贝到本地\n        ssh -N -L2001:remotehost:80 user@somemachine            # 用SSH创建端口转发通道\n        ssh -t host_A ssh host_B                                # 嵌套使用SSH\n        ssh -t -p 22 $user@$Ip /bin/su - root -c {$Cmd};        # 远程su执行命令 Cmd="\\"/sbin/ifconfig eth0\\""\n        ssh-keygen -t rsa                                       # 生成密钥\n        ssh-copy-id -i xuesong@10.10.10.133                     # 传送key\n        vi $HOME/.ssh/authorized_keys                           # 公钥存放位置\n        sshfs name@server:/path/to/folder /path/to/mount/point  # 通过ssh挂载远程主机上的文件夹\n        fusermount -u /path/to/mount/point                      # 卸载ssh挂载的目录\n        ssh user@host cat /path/to/remotefile | diff /path/to/localfile -                # 用DIFF对比远程文件跟本地文件\n        su - user -c "ssh user@192.168.1.1 \\"echo -e aa |mail -s test mail@163.com\\""    # 切换用户登录远程发送邮件\n\n        SSH反向连接{\n\n            # 外网A要控制内网B\n\n            ssh -NfR 1234:localhost:2223 user1@123.123.123.123 -p22    # 将A主机的1234端口和B主机的2223端口绑定，相当于远程端口映射\n            ss -ant   # 这时在A主机上sshd会listen本地1234端口\n            # LISTEN     0    128    127.0.0.1:1234       *:*\n            ssh localhost -p1234    # 在A主机连接本地1234端口\n\n        }\n    }\n\n    网卡配置文件{\n\n        vi /etc/sysconfig/network-scripts/ifcfg-eth0\n\n        DEVICE=eth0\n        BOOTPROTO=none\n        BROADCAST=192.168.1.255\n        HWADDR=00:0C:29:3F:E1:EA\n        IPADDR=192.168.1.55\n        NETMASK=255.255.255.0\n        NETWORK=192.168.1.0\n        ONBOOT=yes\n        TYPE=Ethernet\n        GATEWAY=192.168.1.1\n        #ARPCHECK=no     # 进制arp检查\n\n    }\n\n    route {\n\n        route                           # 查看路由表\n        route add default  gw 192.168.1.1  dev eth0                        # 添加默认路由\n        route add -net 172.16.0.0 netmask 255.255.0.0 gw 10.39.111.254     # 添加静态路由网关\n        route del -net 172.16.0.0 netmask 255.255.0.0 gw 10.39.111.254     # 删除静态路由网关\n\n    }\n\n    静态路由{\n\n        vim /etc/sysconfig/static-routes\n        any net 192.168.12.0/24 gw 192.168.0.254\n        any net 192.168.13.0/24 gw 192.168.0.254\n\n    }\n\n    解决ssh链接慢{\n\n        sed -i ''s/GSSAPIAuthentication yes/GSSAPIAuthentication no/'' /etc/ssh/sshd_config\n        sed -i ''/#UseDNS yes/a\\UseDNS no'' /etc/ssh/sshd_config\n        /etc/init.d/sshd restart\n\n    }\n\n    ftp上传{\n\n        ftp -i -v -n $HOST <<END\n        user $USERNAME $PASSWORD\n        cd /ftp\n        mkdir data\n        cd data\n        mput *.tar.gz\n        bye\nEND\n\n    }\n\n    nmap{\n\n        nmap -PT 192.168.1.1-111             # 先ping在扫描主机开放端口\n        nmap -O 192.168.1.1                  # 扫描出系统内核版本\n        nmap -sV 192.168.1.1-111             # 扫描端口的软件版本\n        nmap -sS 192.168.1.1-111             # 半开扫描(通常不会记录日志)\n        nmap -P0 192.168.1.1-111             # 不ping直接扫描\n        nmap -d 192.168.1.1-111              # 详细信息\n        nmap -D 192.168.1.1-111              # 无法找出真正扫描主机(隐藏IP)\n        nmap -p 20-30,139,60000-             # 端口范围  表示：扫描20到30号端口，139号端口以及所有大于60000的端口\n        nmap -P0 -sV -O -v 192.168.30.251    # 组合扫描(不ping、软件版本、内核版本、详细信息)\n        \n        # 不支持windows的扫描(可用于判断是否是windows)\n        nmap -sF 192.168.1.1-111\n        nmap -sX 192.168.1.1-111\n        nmap -sN 192.168.1.1-111\n\n    }\n\n    流量切分线路{\n\n        # 程序判断进入IP线路，设置服务器路由规则控制返回\n        vi /etc/iproute2/rt_tables\n        #添加一条策略\n        252   bgp2  #注意策略的序号顺序\n        ip route add default via 第二个出口上线IP(非默认网关) dev eth1 table bgp2\n        ip route add from 本机第二个ip table bgp2\n        #查看\n        ip route list table 252\n        ip rule list\n        #成功后将语句添加开机启动\n\n    }\n\n    snmp{\n        \n        snmptranslate .1.3.6.1.2.1.1.3.0    # 查看映射关系\n            DISMAN-EVENT-MIB::sysUpTimeInstance\n        snmpdf -v 1 -c public localhost                            # SNMP监视远程主机的磁盘空间\n        snmpnetstat -v 2c -c public -a 192.168.6.53                # SNMP获取指定IP的所有开放端口状态\n        snmpwalk -v 2c -c public 10.152.14.117 .1.3.6.1.2.1.1.3.0  # SNMP获取主机启动时间\n        # MIB安装(ubuntu) \n        # sudo apt-get install snmp-mibs-downloader\n        # sudo download-mibs\n        snmpwalk -v 2c -c public 10.152.14.117 sysUpTimeInstance   # SNMP通过MIB库获取主机启动时间\n\n    }\n    \n}\n\n6 磁盘{\n    \n    df -Ph                                # 查看硬盘容量\n    df -T                                 # 查看磁盘分区格式\n    df -i                                 # 查看inode节点   如果inode用满后无法创建文件\n    du -h 目录                            # 检测目录下所有文件大小\n    du -sh *                              # 显示当前目录中子目录的大小\n    mount -l                              # 查看分区挂载情况\n    fdisk -l                              # 查看磁盘分区状态\n    fdisk /dev/hda3                       # 分区 \n    mkfs -t ext3  /dev/hda3               # 格式化分区\n    fsck -y /dev/sda6                     # 对文件系统修复\n    lsof |grep delete                     # 释放进程占用磁盘空间  列出进程后，查看文件是否存在，不存在则kill掉此进程\n    tmpwatch -afv 10   /tmp               # 删除10小时内未使用的文件  勿在重要目录使用\n    cat /proc/filesystems                 # 查看当前系统支持文件系统\n    mount -o remount,rw /                 # 修改只读文件系统为读写\n    smartctl -H /dev/sda                  # 检测硬盘状态\n    smartctl -i /dev/sda                  # 检测硬盘信息\n    smartctl -a /dev/sda                  # 检测所有信息\n    e2label /dev/sda5                     # 查看卷标\n    e2label /dev/sda5 new-label           # 创建卷标\n    ntfslabel -v /dev/sda8 new-label      # NTFS添加卷标\n    tune2fs -j /dev/sda                   # ext2分区转ext3分区\n    tune2fs -l /dev/sda                   # 查看文件系统信息\n    mke2fs -b 2048 /dev/sda5              # 指定索引块大小\n    dumpe2fs -h /dev/sda5                 # 查看超级块的信息\n    mount -t iso9660 /dev/dvd  /mnt       # 挂载光驱\n    mount -t ntfs-3g /dev/sdc1 /media/yidong        # 挂载ntfs硬盘\n    mount -t nfs 10.0.0.3:/opt/images/  /data/img   # 挂载nfs 需要重载 /etc/init.d/nfs reload  重启需要先启动 portmap 服务\n    mount -o loop  /software/rhel4.6.iso   /mnt/    # 挂载镜像文件\n    \n    磁盘IO性能检测{\n\n        iostat -x 1 10\n        \n        % user     # 显示了在用户级(应用程序)执行时生成的 CPU 使用率百分比。\n        % system   # 显示了在系统级(内核)执行时生成的 CPU 使用率百分比。\n        % idle     # 显示了在 CPU 空闲并且系统没有未完成的磁盘 I/O 请求时的时间百分比。\n        % iowait   # 显示了 CPU 空闲期间系统有未完成的磁盘 I/O 请求时的时间百分比。\n\n        rrqm/s       # 每秒进行 merge 的读操作数目。即 delta(rmerge)/s\n        wrqm/s       # 每秒进行 merge 的写操作数目。即 delta(wmerge)/s\n        r/s          # 每秒完成的读 I/O 设备次数。即 delta(rio)/s\n        w/s          # 每秒完成的写 I/O 设备次数。即 delta(wio)/s\n        rsec/s       # 每秒读扇区数。即 delta(rsect)/s\n        wsec/s       # 每秒写扇区数。即 delta(wsect)/s\n        rkB/s        # 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。(需要计算)\n        wkB/s        # 每秒写K字节数。是 wsect/s 的一半。(需要计算)\n        avgrq-sz     # 平均每次设备I/O操作的数据大小 (扇区)。delta(rsect+wsect)/delta(rio+wio)\n        avgqu-sz     # 平均I/O队列长度。即 delta(aveq)/s/1000 (因为aveq的单位为毫秒)。\n        await        # 平均每次设备I/O操作的等待时间 (毫秒)。即 delta(ruse+wuse)/delta(rio+wio)\n        svctm        # 平均每次设备I/O操作的服务时间 (毫秒)。即 delta(use)/delta(rio+wio)\n        %util        # 一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的。即 delta(use)/s/1000 (因为use的单位为毫秒)\n\n        IO性能衡量标准{\n            \n            1、 如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。\n            2、 idle 小于70% IO压力就较大了,一般读取速度有较多的wait.\n            3、 同时可以结合 vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比,高过30%时IO压力高)\n            4、 svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了),svctm 的大小一般和磁盘性能有关,CPU/内存的负荷也会对其有影响,请求过多也会间接导致 svctm 的增加. await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式. 如果 svctm 比较接近 await,说明 I/O 几乎没有等待时间;如果 await 远大于 svctm,说明 I/O 队列太长,应用得到的响应时间变慢,如果响应时间超过了用户可以容许的范围,这时可以考虑更换更快的磁盘,调整内核 elevator 算法,优化应用,或者升级 CPU\n            5、 队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。\n\n        }\n\n    }\n\n    创建swap文件方法{\n\n        dd if=/dev/zero of=/swap bs=1024 count=4096000            # 创建一个足够大的文件\n        # count的值等于1024 x 你想要的文件大小, 4096000是4G\n        mkswap /swap                      # 把这个文件变成swap文件\n        swapon /swap                      # 启用这个swap文件\n        /swap swap swap defaults 0 0      # 在每次开机的时候自动加载swap文件, 需要在 /etc/fstab 文件中增加一行\n        cat /proc/swaps                   # 查看swap\n        swapoff -a                        # 关闭swap\n        swapon -a                         # 开启swap\n\n    }\n\n    新硬盘挂载{\n\n        fdisk /dev/sdc \n        p    #  打印分区\n        d    #  删除分区\n        n    #  创建分区，（一块硬盘最多4个主分区，扩展占一个主分区位置。p主分区 e扩展）\n        w    #  保存退出\n        mkfs -t ext3 -L 卷标  /dev/sdc1        # 格式化相应分区\n        mount /dev/sdc1  /mnt        # 挂载\n        vi /etc/fstab               # 添加开机挂载分区\n        LABEL=/data            /data                   ext3    defaults        1 2      # 用卷标挂载\n        /dev/sdb1              /data4                  ext3    defaults        1 2      # 用真实分区挂载\n        /dev/sdb2              /data4                  ext3    noatime,defaults        1 2\n\n        第一个数字"1"该选项被"dump"命令使用来检查一个文件系统应该以多快频率进行转储，若不需要转储就设置该字段为0\n        第二个数字"2"该字段被fsck命令用来决定在启动时需要被扫描的文件系统的顺序，根文件系统"/"对应该字段的值应该为1，其他文件系统应该为2。若该文件系统无需在启动时扫描则设置该字段为0\n        当以 noatime 选项加载（mount）文件系统时，对文件的读取不会更新文件属性中的atime信息。设置noatime的重要性是消除了文件系统对文件的写操作，文件只是简单地被系统读取。由于写操作相对读来说要更消耗系统资源，所以这样设置可以明显提高服务器的性能.wtime信息仍然有效，任何时候文件被写，该信息仍被更新。\n\n    }\n\n    大磁盘2T和16T分区{\n\n        parted /dev/sdb                # 针对磁盘分区\n        (parted) mklabel gpt           # 设置为 gpt\n        (parted) print \n        (parted) mkpart  primary 0KB 22.0TB        # 指定分区大小\n        Is this still acceptable to you?\n        Yes/No? Yes\n        Ignore/Cancel? Ignore\n        (parted) print                                                            \n        Model: LSI MR9271-8i (scsi)\n        Disk /dev/sdb: 22.0TB\n        Sector size (logical/physical): 512B/512B\n        Partition Table: gpt\n        Number  Start   End     Size    File system  Name     Flags\n         1      17.4kB  22.0TB  22.0TB               primary\n        (parted) quit \n\n        mkfs.ext4 -b 4096 /dev/sdb1        # 小于16T如使用ext4指定块大小 块大小影响磁盘分区大小\n\n        # 大于16T的单个分区ext4格式化报错\n        Size of device /dev/sdb1 too big to be expressed in 32 bits using a blocksize of 4096.\n        # 修改ext4的文件添加一行，解决ext4格式化大于16T报错\n        vim /etc/mke2fs.conf\n\n        [fs_types] ext4 = {\n        features = has_journal,extent,huge_file,flex_bg,uninit_bg,dir_nlink,extra_isize\n        auto_64-bit_support = 1 # 添加此行\n        inode_size = 256\n        }\n\n        mkfs.xfs -f /dev/sdb1              # 大于16T单个分区或使用XFS分区也可\n\n    }\n\n    raid原理与区别{\n\n        raid0至少2块硬盘.吞吐量大,性能好,同时读写,但损坏一个就完蛋\n        raid1至少2块硬盘.相当镜像,一个存储,一个备份.安全性比较高.但是性能比0弱\n        raid5至少3块硬盘.分别存储校验信息和数据，坏了一个根据校验信息能恢复\n        raid6至少4块硬盘.两个独立的奇偶系统,可坏两块磁盘,写性能非常差\n\n    }\n\n}\n\n7 用户{\n\n    users                   # 显示所有的登录用户\n    groups                  # 列出当前用户和他所属的组\n    who -q                  # 显示所有的登录用户\n    groupadd                # 添加组\n    useradd user            # 建立用户\n    passwd 用户             # 修改密码\n    userdel -r              # 删除帐号及家目录\n    chown -R user:group     # 修改目录拥有者(R递归)\n    chown y\\.li:mysql       # 修改所有者用户中包含点"."\n    umask                   # 设置用户文件和目录的文件创建缺省屏蔽值\n    chgrp                   # 修改用户组\n    finger                  # 查找用户显示信息\n    echo "xuesong" | passwd user --stdin       # 非交互修改密码\n    useradd -g www -M  -s /sbin/nologin  www   # 指定组并不允许登录的用户,nologin允许使用服务\n    useradd -g www -M  -s /bin/false  www      # 指定组并不允许登录的用户,false最为严格\n    useradd -d /data/song -g song song         # 创建用户并指定家目录和组\n    usermod -l 新用户名 老用户名               # 修改用户名\n    usermod -g user group                      # 修改用户所属组\n    usermod -d 目录 -m 用户                    # 修改用户家目录\n    usermod -G group user                      # 将用户添加到附加组\n    gpasswd -d user group                      # 从组中删除用户\n    su - user -c " #命令1; "                   # 切换用户执行\n    \n    恢复密码{\n\n        # 即进入单用户模式: 在linux出现grub后，在安装的系统上面按"e"，然后出现grub的配置文件，按键盘移动光标到第二行"Ker……"，再按"e"，然后在这一行的结尾加上：空格 single或者空格1回车，然后按"b"重启，就进入了"单用户模式"\n    }\n    \n    特殊权限{\n\n        s或 S （SUID）：对应数值4\n        s或 S （SGID）：对应数值2\n        t或 T ：对应数值1\n        大S：代表拥有root权限，但是没有执行权限\n        小s：拥有特权且拥有执行权限，这个文件可以访问系统任何root用户可以访问的资源\n        T或T（Sticky）：/tmp和 /var/tmp目录供所有用户暂时存取文件，亦即每位用户皆拥有完整的权限进入该目录，去浏览、删除和移动文件\n\n    }\n\n}\n\n8 脚本{\n    \n    #!/bin/sh         # 在脚本第一行脚本头 # sh为当前系统默认shell,可指定为bash等shell\n    sh -x             # 执行过程\n    sh -n             # 检查语法\n    (a=bbk)           # 括号创建子shell运行\n    basename /a/b/c   # 从全路径中保留最后一层文件名或目录\n    dirname           # 取路径\n    $RANDOM           # 随机数\n    $$                # 进程号\n    source FileName   # 在当前bash环境下读取并执行FileName中的命令  # 等同 . FileName\n    sleep 5           # 间隔睡眠5秒\n    trap              # 在接收到信号后将要采取的行动\n    trap "" 2 3       # 禁止ctrl+c\n    $PWD              # 当前目录\n    $HOME             # 家目录\n    $OLDPWD           # 之前一个目录的路径\n    cd -              # 返回上一个目录路径\n    local ret         # 局部变量\n    yes               # 重复打印\n    yes |rm -i *      # 自动回答y或者其他\n    ls -p /home       # 区分目录和文件夹\n    ls -d /home/      # 查看匹配完整路径\n    time a.sh         # 测试程序执行时间\n    echo -n aa;echo bb                    # 不换行执行下一句话 将字符串原样输出\n    echo -e "s\\tss\\n\\n\\n"                 # 使转义生效\n    echo $a | cut -c2-6                   # 取字符串中字元\n    echo {a,b,c}{a,b,c}{a,b,c}            # 排列组合(括号内一个元素分别和其他括号内元素组合)\n    echo $((2#11010))                     # 二进制转10进制\n    echo aaa | tee file                   # 打印同时写入文件 默认覆盖 -a追加\n    echo {1..10}                          # 打印10个字符\n    printf ''%10s\\n''|tr " " a              # 打印10个字符\n    pwd | awk -F/ ''{ print $2 }''          # 返回目录名\n    tac file |sed 1,3d|tac                # 倒置读取文件  # 删除最后3行\n    tail -3 file                          # 取最后3行\n    outtmp=/tmp/$$`date +%s%N`.outtmp     # 临时文件定义\n    :(){ :|:& };:                         # 著名的 fork炸弹,系统执行海量的进程,直到系统僵死\n    echo -e "\\e[32m颜色\\e[0m"             # 打印颜色\n    echo -e "\\033[32m颜色\\033[m"          # 打印颜色\n    echo -e "\\033[0;31mL\\033[0;32mO\\033[0;33mV\\033[0;34mE\\t\\033[0;35mY\\033[0;36mO\\033[0;32mU\\e[m"    # 打印颜色\n\n    正则表达式{\n    \n        ^              # 行首定位\n        $              # 行尾定位\n        .              # 匹配除换行符以外的任意字符\n        *              # 匹配0或多个重复字符\n        +              # 重复一次或更多次\n        ?              # 重复零次或一次\n        ?              # 结束贪婪因子 .*? 表示最小匹配\n        []             # 匹配一组中任意一个字符\n        [^]            # 匹配不在指定组内的字符\n        \\              # 用来转义元字符\n        <              # 词首定位符(支持vi和grep)  <love\n        >              # 词尾定位符(支持vi和grep)  love>\n        x\\{m\\}         # 重复出现m次\n        x\\{m,\\}        # 重复出现至少m次\n        x\\{m,n\\}       # 重复出现至少m次不超过n次\n        X?             # 匹配出现零次或一次的大写字母 X\n        X+             # 匹配一个或多个字母 X\n        ()             # 括号内的字符为一组\n        (ab|de)+       # 匹配一连串的（最少一个） abc 或 def；abc 和 def 将匹配\n        [[:alpha:]]    # 代表所有字母不论大小写\n        [[:lower:]]    # 表示小写字母 \n        [[:upper:]]    # 表示大写字母\n        [[:digit:]]    # 表示数字字符\n        [[:digit:][:lower:]]    # 表示数字字符加小写字母 \n\n        元字符{\n\n            \\d       # 匹配任意一位数字\n            \\D       # 匹配任意单个非数字字符\n            \\w       # 匹配任意单个字母数字下划线字符，同义词是 [:alnum:]\n            \\W       # 匹配非数字型的字符\n\n        }\n\n        字符类:空白字符{\n\n            \\s       # 匹配任意的空白符\n            \\S       # 匹配非空白字符\n            \\b       # 匹配单词的开始或结束\n            \\n       # 匹配换行符\n            \\r       # 匹配回车符\n            \\t       # 匹配制表符\n            \\b       # 匹配退格符\n            \\0       # 匹配空值字符\n\n        }\n\n        字符类:锚定字符{\n\n            \\b       # 匹配字边界(不在[]中时)\n            \\B       # 匹配非字边界\n            \\A       # 匹配字符串开头\n            \\Z       # 匹配字符串或行的末尾\n            \\z       # 只匹配字符串末尾\n            \\G       # 匹配前一次m//g离开之处\n\n        }\n\n        捕获{\n\n            (exp)                # 匹配exp,并捕获文本到自动命名的组里\n            (?<name>exp)         # 匹配exp,并捕获文本到名称为name的组里，也可以写成(?''name''exp)\n            (?:exp)              # 匹配exp,不捕获匹配的文本，也不给此分组分配组号\n\n        }\n\n        零宽断言{\n\n            (?=exp)              # 匹配exp前面的位置\n            (?<=exp)             # 匹配exp后面的位置\n            (?!exp)              # 匹配后面跟的不是exp的位置\n            (?<!exp)             # 匹配前面不是exp的位置\n            (?#comment)          # 注释不对正则表达式的处理产生任何影响，用于注释\n\n        }\n\n        特殊字符{\n\n            http://en.wikipedia.org/wiki/Ascii_table\n            ^H  \\010 \\b  \n            ^M  \\015 \\r\n            匹配特殊字符: ctrl+V ctrl不放在按H或M 即可输出^H,用于匹配\n\n        }\n    \n    }\n\n    流程结构{\n    \n        if判断{\n\n            if [ $a == $b ]\n            then\n                echo "等于"\n            else\n                echo "不等于"\n            fi\n\n        }\n        \n        case分支选择{\n\n            case $xs in\n            0) echo "0" ;;\n            1) echo "1" ;;\n            *) echo "其他" ;;\n            esac\n\n        }\n        \n        while循环{\n\n            # while true  等同   while :\n            # 读文件为整行读入\n            num=1\n            while [ $num -lt 10 ]\n            do\n            echo $num\n            ((num=$num+2))\n            done\n            ###########################\n            grep a  a.txt | while read a\n            do\n                echo $a\n            done\n            ###########################\n            while read a\n            do\n                echo $a\n            done < a.txt \n\n        }\n        \n        for循环{\n\n            # 读文件已空格分隔\n            w=`awk -F ":" ''{print $1}'' c`\n            for d in $w\n            do\n                $d\n            done\n            ###########################\n            for ((i=0;i<${#o[*]};i++))\n            do\n            echo ${o[$i]}\n            done\n\n        }\n        \n        until循环{\n\n            #  当command不为0时循环\n            until command    \n            do\n                body\n            done\n\n        }\n        \n        流程控制{\n\n            break N     #  跳出几层循环\n            continue N  #  跳出几层循环，循环次数不变\n            continue    #  重新循环次数不变\n\n        }\n    \n    }\n\n    变量{\n        \n        A="a b c def"           # 将字符串复制给变量\n        A=`cmd`                 # 将命令结果赋给变量\n        A=$(cmd)                # 将命令结果赋给变量\n        eval a=\\$$a             # 间接调用\n        i=2&&echo $((i+3))      # 计算后打印新变量结果\n        i=2&&echo $[i+3]        # 计算后打印新变量结果\n        a=$((2>6?5:8))          # 判断两个值满足条件的赋值给变量\n        $1  $2  $*              # 位置参数 *代表所有\n        env                     # 查看环境变量\n        env | grep "name"       # 查看定义的环境变量\n        set                     # 查看环境变量和本地变量\n        read name               # 输入变量\n        readonly name           # 把name这个变量设置为只读变量,不允许再次设置\n        readonly                # 查看系统存在的只读文件\n        export name             # 变量name由本地升为环境\n        export name="RedHat"    # 直接定义name为环境变量\n        export Stat$nu=2222     # 变量引用变量赋值\n        unset name              # 变量清除\n        export -n name          # 去掉只读变量\n        shift                   # 用于移动位置变量,调整位置变量,使$3的值赋给$2.$2的值赋予$1\n        name + 0                # 将字符串转换为数字\n        number " "              # 将数字转换成字符串\n        \n        数组{\n\n            A=(a b c def)         # 将变量定义为数組\n            ${#A[*]}              # 数组个数\n            ${A[*]}               # 数组所有元素,大字符串\n            ${A[@]}               # 数组所有元素,类似列表可迭代\n            ${A[2]}               # 脚本的一个参数或数组第三位\n        \n        }\n\n        定义变量类型{\n\n            declare 或 typeset\n            -r 只读(readonly一样)\n            -i 整形\n            -a 数组\n            -f 函数\n            -x export\n            declare -i n=0\n\n        }\n\n        系统变量{\n\n            $0   #  脚本启动名(包括路径)\n            $n   #  第n个参数,n=1,2,…9\n            $*   #  所有参数列表(不包括脚本本身)\n            $@   #  所有参数列表(独立字符串)\n            $#   #  参数个数(不包括脚本本身)\n            $$   #  当前程式的PID\n            $!   #  执行上一个指令的PID\n            $?   #  执行上一个指令的返回值\n\n        }\n\n        变量引用技巧{\n\n            ${name:+value}        # 如果设置了name,就把value显示,未设置则为空\n            ${name:-value}        # 如果设置了name,就显示它,未设置就显示value\n            ${name:?value}        # 未设置提示用户错误信息value \n            ${name:=value}        # 如未设置就把value设置并显示<写入本地中>\n            ${#A}                 # 可得到变量中字节\n            ${A:4:9}              # 取变量中第4位到后面9位\n            ${A:(-1)}             # 倒叙取最后一个字符\n            ${A/www/http}         # 取变量并且替换每行第一个关键字\n            ${A//www/http}        # 取变量并且全部替换每行关键字\n                \n            定义了一个变量： file=/dir1/dir2/dir3/my.file.txt\n            ${file#*/}     # 去掉第一条 / 及其左边的字串：dir1/dir2/dir3/my.file.txt\n            ${file##*/}    # 去掉最后一条 / 及其左边的字串：my.file.txt\n            ${file#*.}     # 去掉第一个 .  及其左边的字串：file.txt\n            ${file##*.}    # 去掉最后一个 .  及其左边的字串：txt\n            ${file%/*}     # 去掉最后条 / 及其右边的字串：/dir1/dir2/dir3\n            ${file%%/*}    # 去掉第一条 / 及其右边的字串：(空值)\n            ${file%.*}     # 去掉最后一个 .  及其右边的字串：/dir1/dir2/dir3/my.file\n            ${file%%.*}    # 去掉第一个 .  及其右边的字串：/dir1/dir2/dir3/my\n            #   # 是去掉左边(在键盘上 # 在 $ 之左边)\n            #   % 是去掉右边(在键盘上 % 在 $ 之右边)\n            #   单一符号是最小匹配﹔两个符号是最大匹配\n\n        }\n            \n    }\n    \n    test条件判断{\n\n        # 符号 [ ] 等同  test命令\n\n        expression为字符串操作{\n\n            -n str   # 字符串str是否不为空\n            -z str   # 字符串str是否为空\n\n        }\n\n        expression为文件操作{\n\n            -a     # 并且，两条件为真\n            -b     # 是否块文件     \n            -p     # 文件是否为一个命名管道\n            -c     # 是否字符文件   \n            -r     # 文件是否可读\n            -d     # 是否一个目录   \n            -s     # 文件的长度是否不为零\n            -e     # 文件是否存在   \n            -S     # 是否为套接字文件\n            -f     # 是否普通文件   \n            -x     # 文件是否可执行，则为真\n            -g     # 是否设置了文件的 SGID 位 \n            -u     # 是否设置了文件的 SUID 位\n            -G     # 文件是否存在且归该组所有 \n            -w     # 文件是否可写，则为真\n            -k     # 文件是否设置了的粘贴位  \n            -t fd  # fd 是否是个和终端相连的打开的文件描述符（fd 默认为 1）\n            -o     # 或，一个条件为真\n            -O     # 文件是否存在且归该用户所有\n            !      # 取反\n\n        }\n\n        expression为整数操作{\n\n            expr1 -a expr2   # 如果 expr1 和 expr2 评估为真，则为真\n            expr1 -o expr2   # 如果 expr1 或 expr2 评估为真，则为真\n\n        }\n\n        两值比较{\n\n            整数     字符串\n            -lt      <         # 小于\n            -gt      >         # 大于\n            -le      <=        # 小于或等于\n            -ge      >=        # 大于或等于\n            -eq      ==        # 等于\n            -ne      !=        # 不等于\n\n        }\n\n        test 10 -lt 5       # 判断大小\n        echo $?             # 查看上句test命令返回状态  # 结果0为真,1为假\n        test -n "hello"     # 判断字符串长度是否为0\n        [ $? -eq 0 ] && echo "success" || exit　　　# 判断成功提示,失败则退出\n\n    }\n    \n    重定向{\n    \n        #  标准输出 stdout 和 标准错误 stderr  标准输入stdin\n        cmd 1> fiel              # 把 标准输出 重定向到 file 文件中\n        cmd > file 2>&1          # 把 标准输出 和 标准错误 一起重定向到 file 文件中\n        cmd 2> file              # 把 标准错误 重定向到 file 文件中\n        cmd 2>> file             # 把 标准错误 重定向到 file 文件中(追加)\n        cmd >> file 2>&1         # 把 标准输出 和 标准错误 一起重定向到 file 文件中(追加)\n        cmd < file >file2        # cmd 命令以 file 文件作为 stdin(标准输入)，以 file2 文件作为 标准输出\n        cat <>file               # 以读写的方式打开 file\n        cmd < file cmd           # 命令以 file 文件作为 stdin\n        cmd << delimiter\n        cmd; #从 stdin 中读入，直至遇到 delimiter 分界符\ndelimiter\n\n        >&n    # 使用系统调用 dup (2) 复制文件描述符 n 并把结果用作标准输出\n        <&n    # 标准输入复制自文件描述符 n\n        <&-    # 关闭标准输入（键盘）\n        >&-    # 关闭标准输出\n        n<&-   # 表示将 n 号输入关闭\n        n>&-   # 表示将 n 号输出关闭\n\n    }\n    \n    运算符{\n    \n        $[]等同于$(())  # $[]表示形式告诉shell求中括号中的表达式的值\n        ~var            # 按位取反运算符,把var中所有的二进制为1的变为0,为0的变为1\n        var\\<<str       # 左移运算符,把var中的二进制位向左移动str位,忽略最左端移出的各位,最右端的各位上补上0值,每做一次按位左移就有var乘2\n        var>>str        # 右移运算符,把var中所有的二进制位向右移动str位,忽略最右移出的各位,最左的各位上补0,每次做一次右移就有实现var除以2\n        var&str         # 与比较运算符,var和str对应位,对于每个二进制来说,如果二都为1,结果为1.否则为0\n        var^str         # 异或运算符,比较var和str对应位,对于二进制来说如果二者互补,结果为1,否则为0\n        var|str         # 或运算符,比较var和str的对应位,对于每个二进制来说,如二都该位有一个1或都是1,结果为1,否则为0\n\n        运算符优先级{\n            级别      运算符                                  说明\n            1      =,+=,-=,/=,%=,*=,&=,^=,|=,<<=,>>=      # 赋值运算符\n            2         ||                                  # 逻辑或 前面不成功执行\n            3         &&                                  # 逻辑与 前面成功后执行\n            4         |                                   # 按位或\n            5         ^                                   # 按位异或\n            6         &                                   # 按位与\n            7         ==,!=                               # 等于/不等于\n            8         <=,>=,<,>                           # 小于或等于/大于或等于/小于/大于 \n            9        \\<<,>>                               # 按位左移/按位右移 (无转意符号)\n            10        +,-                                 # 加减\n            11        *,/,%                               # 乘,除,取余\n            12        ! ,~                                # 逻辑非,按位取反或补码\n            13        -,+                                 # 正负\n        }\n        \n    }\n\n    数学运算{\n    \n        $(( ))        # 整数运算\n        + - * / **    # 分別为 "加、減、乘、除、密运算"\n        & | ^ !       # 分別为 "AND、OR、XOR、NOT" 运算\n        %             # 余数运算\n\n        let{\n        \n            let # 运算  \n            let x=16/4\n            let x=5**5\n            \n        }\n\n        expr{\n        \n            expr 14 % 9                    # 整数运算\n            SUM=`expr 2 \\* 3`              # 乘后结果赋值给变量\n            LOOP=`expr $LOOP + 1`          # 增量计数(加循环即可) LOOP=0\n            expr length "bkeep zbb"        # 计算字串长度\n            expr substr "bkeep zbb" 4 9    # 抓取字串\n            expr index "bkeep zbb" e       # 抓取第一个字符数字串出现的位置\n            expr 30 / 3 / 2                # 运算符号有空格\n            expr bkeep.doc : ''.*''          # 模式匹配(可以使用expr通过指定冒号选项计算字符串中字符数)\n            expr bkeep.doc : ''\\(.*\\).doc''  # 在expr中可以使用字符串匹配操作，这里使用模式抽取.doc文件附属名\n\n            数值测试{\n\n                #如果试图计算非整数，则会返回错误\n                rr=3.4\n                expr $rr + 1\n                expr: non-numeric argument\n                rr=5\n                expr $rr + 1\n                6\n\n            }\n            \n        }\n        \n        bc{\n\n            echo "m^n"|bc            # 次方计算\n            seq -s ''+'' 1000 |bc      # 从1加到1000\n            seq 1 1000 |tr "\\n" "+"|sed ''s/+$/\\n/''|bc   # 从1加到1000\n        }\n        \n    }\n    \n    grep{\n\n        -c    # 显示匹配到得行的数目，不显示内容\n        -h    # 不显示文件名\n        -i    # 忽略大小写\n        -l    # 只列出匹配行所在文件的文件名\n        -n    # 在每一行中加上相对行号\n        -s    # 无声操作只显示报错，检查退出状态\n        -v    # 反向查找\n        -e    # 使用正则表达式\n        -w    # 精确匹配\n        -wc   # 精确匹配次数\n        -o    # 查询所有匹配字段\n        -P    # 使用perl正则表达式\n        -A3   # 打印匹配行和下三行\n        -B3   # 打印匹配行和上三行\n        -C3   # 打印匹配行和上下三行\n\n        grep -v "a" txt                              # 过滤关键字符行\n        grep -w ''a\\>'' txt                            # 精确匹配字符串\n        grep -i "a" txt                              # 大小写敏感\n        grep  "a[bB]" txt                            # 同时匹配大小写\n        grep ''[0-9]\\{3\\}'' txt                        # 查找0-9重复三次的所在行\n        grep -E "word1|word2|word3"   file           # 任意条件匹配\n        grep word1 file | grep word2 |grep word3     # 同时匹配三个\n        echo quan@163.com |grep -Po ''(?<=@.).*(?=.$)''                           # 零宽断言截取字符串  #　63.co\n        echo "I''m singing while you''re dancing" |grep -Po ''\\b\\w+(?=ing\\b)''      # 零宽断言匹配        \n        echo ''Rx Optical Power: -5.01dBm, Tx Optical Power: -2.41dBm'' |grep -Po ''(?<=:).*?(?=d)''           # 取出d前面数字 # ?为最小匹配\n        echo ''Rx Optical Power: -5.01dBm, Tx Optical Power: -2.41dBm'' | grep -Po ''[-0-9.]+''                # 取出d前面数字 # ?为最小匹配\n        echo ''["mem",ok],["hardware",false],["filesystem",false]'' |grep -Po ''[^"]+(?=",false)''             # 取出false前面的字母\n        echo ''["mem",ok],["hardware",false],["filesystem",false]'' |grep -Po ''\\w+",false''|grep -Po ''^\\w+''   # 取出false前面的字母\n        \n        grep用于if判断{\n\n            if echo abc | grep "a"  > /dev/null 2>&1\n            then\n                echo "abc"\n            else\n                echo "null"\n            fi\n\n        }\n\n    }\n    \n    tr{\n    \n        -c          # 用字符串1中字符集的补集替换此字符集，要求字符集为ASCII\n        -d          # 删除字符串1中所有输入字符\n        -s          # 删除所有重复出现字符序列，只保留第一个:即将重复出现字符串压缩为一个字符串\n        [a-z]       # a-z内的字符组成的字符串\n        [A-Z]       # A-Z内的字符组成的字符串\n        [0-9]       # 数字串\n        \\octal      # 一个三位的八进制数，对应有效的ASCII字符\n        [O*n]       # 表示字符O重复出现指定次数n。因此[O*2]匹配OO的字符串\n\n        tr中特定控制字符表达方式{\n\n            \\a Ctrl-G    \\007    # 铃声\n            \\b Ctrl-H    \\010    # 退格符\n            \\f Ctrl-L    \\014    # 走行换页\n            \\n Ctrl-J    \\012    # 新行\n            \\r Ctrl-M    \\015    # 回车\n            \\t Ctrl-I    \\011    # tab键\n            \\v Ctrl-X    \\030\n\n        }\n\n        tr A-Z a-z                             # 将所有大写转换成小写字母\n        tr " " "\\n"                            # 将空格替换为换行\n        tr -s "[\\012]" < plan.txt              # 删除空行\n        tr -s ["\\n"] < plan.txt                # 删除空行\n        tr -s "[\\015]" "[\\n]" < file           # 删除文件中的^M，并代之以换行\n        tr -s "[\\r]" "[\\n]" < file             # 删除文件中的^M，并代之以换行\n        tr -s "[:]" "[\\011]" < /etc/passwd     # 替换passwd文件中所有冒号，代之以tab键\n        tr -s "[:]" "[\\t]" < /etc/passwd       # 替换passwd文件中所有冒号，代之以tab键\n        echo $PATH | tr ":" "\\n"               # 增加显示路径可读性\n        1,$!tr -d ''\\t''                         # tr在vi内使用，在tr前加处理行范围和感叹号(''$''表示最后一行)\n        tr "\\r" "\\n"<macfile > unixfile        # Mac -> UNIX\n        tr "\\n" "\\r"<unixfile > macfile        # UNIX -> Mac\n        tr -d "\\r"<dosfile > unixfile          # DOS -> UNIX  Microsoft DOS/Windows 约定，文本的每行以回车字符(\\r)并后跟换行符(\\n)结束\n        awk ''{ print $0"\\r" }''<unixfile > dosfile   # UNIX -> DOS：在这种情况下，需要用awk，因为tr不能插入两个字符来替换一个字符\n\n    }\n    \n    seq{\n\n        # 不指定起始数值，则默认为 1\n        -s   # 选项主要改变输出的分格符, 预设是 \\n\n        -w   # 等位补全，就是宽度相等，不足的前面补 0\n        -f   # 格式化输出，就是指定打印的格式\n\n        seq 10 100               # 列出10-100\n        seq 1 10 |tac            # 倒叙列出\n        seq -s ''+'' 90 100 |bc    # 从90加到100\n        seq -f ''dir%g'' 1 10 | xargs mkdir     # 创建dir1-10\n        seq -f ''dir%03g'' 1 10 | xargs mkdir   # 创建dir001-010\n\n    }\n\n    trap{\n\n        信号         说明\n        HUP(1)     # 挂起，通常因终端掉线或用户退出而引发\n        INT(2)     # 中断，通常因按下Ctrl+C组合键而引发\n        QUIT(3)    # 退出，通常因按下Ctrl+\\组合键而引发\n        ABRT(6)    # 中止，通常因某些严重的执行错误而引发\n        ALRM(14)   # 报警，通常用来处理超时\n        TERM(15)   # 终止，通常在系统关机时发送\n        \n        trap捕捉到信号之后，可以有三种反应方式：\n            1、执行一段程序来处理这一信号\n            2、接受信号的默认操作\n            3、忽视这一信号\n        \n        第一种形式的trap命令在shell接收到 signal list 清单中数值相同的信号时，将执行双引号中的命令串：\n        trap ''commands'' signal-list   # 单引号，要在shell探测到信号来的时候才执行命令和变量的替换，时间一直变\n        trap "commands" signal-list   # 双引号，shell第一次设置信号的时候就执行命令和变量的替换，时间不变\n\n    }\n\n    awk{\n    \n        # 默认是执行打印全部 print $0\n        # 1为真 打印$0\n        # 0为假 不打印\n\n        -F   # 改变FS值(分隔符)\n        ~    # 域匹配\n        ==   # 变量匹配\n        !~   # 匹配不包含\n        =    # 赋值\n        !=   # 不等于\n        +=   # 叠加\n        \n        \\b   # 退格\n        \\f   # 换页\n        \\n   # 换行\n        \\r   # 回车\n        \\t   # 制表符Tab\n        \\c   # 代表任一其他字符\n        \n        -F"[ ]+|[%]+"  # 多个空格或多个%为分隔符\n        [a-z]+         # 多个小写字母\n        [a-Z]          # 代表所有大小写字母(aAbB...zZ)\n        [a-z]          # 代表所有大小写字母(ab...z)\n        [:alnum:]      # 字母数字字符\n        [:alpha:]      # 字母字符\n        [:cntrl:]      # 控制字符\n        [:digit:]      # 数字字符\n        [:graph:]      # 非空白字符(非空格、控制字符等)\n        [:lower:]      # 小写字母\n        [:print:]      # 与[:graph:]相似，但是包含空格字符\n        [:punct:]      # 标点字符\n        [:space:]      # 所有的空白字符(换行符、空格、制表符)\n        [:upper:]      # 大写字母\n        [:xdigit:]     # 十六进制的数字(0-9a-fA-F)\n        [[:digit:][:lower:]]    # 数字和小写字母(占一个字符)\n\n\n        内建变量{\n            $n            # 当前记录的第 n 个字段，字段间由 FS 分隔\n            $0            # 完整的输入记录\n            ARGC          # 命令行参数的数目\n            ARGIND        # 命令行中当前文件的位置 ( 从 0 开始算 ) \n            ARGV          # 包含命令行参数的数组\n            CONVFMT       # 数字转换格式 ( 默认值为 %.6g)\n            ENVIRON       # 环境变量关联数组\n            ERRNO         # 最后一个系统错误的描述\n            FIELDWIDTHS   # 字段宽度列表 ( 用空格键分隔 ) \n            FILENAME      # 当前文件名\n            FNR           # 同 NR ，但相对于当前文件\n            FS            # 字段分隔符 ( 默认是任何空格 ) \n            IGNORECASE    # 如果为真（即非 0 值），则进行忽略大小写的匹配\n            NF            # 当前记录中的字段数(列)\n            NR            # 当前行数\n            OFMT          # 数字的输出格式 ( 默认值是 %.6g) \n            OFS           # 输出字段分隔符 ( 默认值是一个空格 ) \n            ORS           # 输出记录分隔符 ( 默认值是一个换行符 ) \n            RLENGTH       # 由 match 函数所匹配的字符串的长度\n            RS            # 记录分隔符 ( 默认是一个换行符 ) \n            RSTART        # 由 match 函数所匹配的字符串的第一个位置\n            SUBSEP        # 数组下标分隔符 ( 默认值是 /034) \n            BEGIN         # 先处理(可不加文件参数)\n            END           # 结束时处理\n        }\n\n        内置函数{\n            gsub(r,s)          # 在整个$0中用s替代r   相当于 sed ''s///g''\n            gsub(r,s,t)        # 在整个t中用s替代r \n            index(s,t)         # 返回s中字符串t的第一位置 \n            length(s)          # 返回s长度 \n            match(s,r)         # 测试s是否包含匹配r的字符串 \n            split(s,a,fs)      # 在fs上将s分成序列a \n            sprint(fmt,exp)    # 返回经fmt格式化后的exp \n            sub(r,s)           # 用$0中最左边最长的子串代替s   相当于 sed ''s///''\n            substr(s,p)        # 返回字符串s中从p开始的后缀部分 \n            substr(s,p,n)      # 返回字符串s中从p开始长度为n的后缀部分 \n        }\n\n        awk判断{\n            awk ''{print ($1>$2)?"第一排"$1:"第二排"$2}''      # 条件判断 括号代表if语句判断 "?"代表then ":"代表else\n            awk ''{max=($1>$2)? $1 : $2; print max}''          # 条件判断 如果$1大于$2,max值为为$1,否则为$2\n            awk ''{if ( $6 > 50) print $1 " Too high" ;\\\n            else print "Range is OK"}'' file\n            awk ''{if ( $6 > 50) { count++;print $3 } \\\n            else { x+5; print $2 } }'' file\n        }\n\n        awk循环{\n            awk ''{i = 1; while ( i <= NF ) { print NF, $i ; i++ } }'' file\n            awk ''{ for ( i = 1; i <= NF; i++ ) print NF,$i }'' file\n        }\n        \n        awk ''/Tom/'' file               # 打印匹配到得行\n        awk ''/^Tom/{print $1}''         # 匹配Tom开头的行 打印第一个字段\n        awk ''$1 !~ /ly$/''              # 显示所有第一个字段不是以ly结尾的行\n        awk ''$3 <40''                   # 如果第三个字段值小于40才打印\n        awk ''$4==90{print $5}''         # 取出第四列等于90的第五列\n        awk ''/^(no|so)/'' test          # 打印所有以模式no或so开头的行\n        awk ''$3 * $4 > 500''            # 算术运算(第三个字段和第四个字段乘积大于500则显示)\n        awk ''{print NR" "$0}''          # 加行号\n        awk ''/tom/,/suz/''              # 打印tom到suz之间的行\n        awk ''{a+=$1}END{print a}''      # 列求和\n        awk ''sum+=$1{print sum}''       # 将$1的值叠加后赋给sum\n        awk ''{a+=$1}END{print a/NR}''   # 列求平均值\n        awk ''!s[$1 $3]++'' file         # 根据第一列和第三列过滤重复行\n        awk -F''[ :\\t]'' ''{print $1,$2}''           # 以空格、:、制表符Tab为分隔符\n        awk ''{print "''"$a"''","''"$b"''"}''          # 引用外部变量\n        awk ''{if(NR==52){print;exit}}''           # 显示第52行\n        awk ''/关键字/{a=NR+2}a==NR {print}''      # 取关键字下第几行\n        awk ''gsub(/liu/,"aaaa",$1){print $0}''    # 只打印匹配替换后的行\n        ll | awk -F''[ ]+|[ ][ ]+'' ''/^$/{print $8}''             # 提取时间,空格不固定\n        awk ''{$1="";$2="";$3="";print}''                        # 去掉前三列\n        echo aada:aba|awk ''/d/||/b/{print}''                    # 匹配两内容之一\n        echo aada:abaa|awk -F: ''$1~/d/||$2~/b/{print}''         # 关键列匹配两内容之一\n        echo Ma asdas|awk ''$1~/^[a-Z][a-Z]$/{print }''          # 第一个域匹配正则\n        echo aada:aaba|awk ''/d/&&/b/{print}''                   # 同时匹配两条件\n        awk ''length($1)=="4"{print $1}''                        # 字符串位数\n        awk ''{if($2>3){system ("touch "$1)}}''                  # 执行系统命令\n        awk ''{sub(/Mac/,"Macintosh",$0);print}''                # 用Macintosh替换Mac\n        awk ''{gsub(/Mac/,"MacIntosh",$1); print}''              # 第一个域内用Macintosh替换Mac\n        awk -F '''' ''{ for(i=1;i<NF+1;i++)a+=$i  ;print a}''      # 多位数算出其每位数的总和.比如 1234， 得到 10\n        awk ''{ i=$1%10;if ( i == 0 ) {print i}}''               # 判断$1是否整除(awk中定义变量引用时不能带 $ )\n        awk ''BEGIN{a=0}{if ($1>a) a=$1 fi}END{print a}''        # 列求最大值  设定一个变量开始为0，遇到比该数大的值，就赋值给该变量，直到结束\n        awk ''BEGIN{a=11111}{if ($1<a) a=$1 fi}END{print a}''    # 求最小值\n        awk ''{if(A)print;A=0}/regexp/{A=1}''                    # 查找字符串并将匹配行的下一行显示出来，但并不显示匹配行\n        awk ''/regexp/{print A}{A=$0}''                          # 查找字符串并将匹配行的上一行显示出来，但并不显示匹配行\n        awk ''{if(!/mysql/)gsub(/1/,"a");print $0}''             # 将1替换成a，并且只在行中未出现字串mysql的情况下替换\n        awk ''BEGIN{srand();fr=int(100*rand());print fr;}''      # 获取随机数\n        awk ''{if(NR==3)F=1}{if(F){i++;if(i%7==1)print}}''       # 从第3行开始，每7行显示一次\n        awk ''{if(NF<1){print i;i=0} else {i++;print $0}}''      # 显示空行分割各段的行数\n        echo +null:null  |awk -F: ''$1!~"^+"&&$2!="null"{print $0}''       # 关键列同时匹配\n        awk -v RS=@ ''NF{for(i=1;i<=NF;i++)if($i) printf $i;print ""}''    # 指定记录分隔符\n        awk ''{b[$1]=b[$1]$2}END{for(i in b){print i,b[i]}}''              # 列叠加\n        awk ''{ i=($1%100);if ( $i >= 0 ) {print $0,$i}}''                 # 求余数\n        awk ''{b=a;a=$1; if(NR>1){print a-b}}''                            # 当前行减上一行\n        awk ''{a[NR]=$1}END{for (i=1;i<=NR;i++){print a[i]-a[i-1]}}''      # 当前行减上一行\n        awk -F: ''{name[x++]=$1};END{for(i=0;i<NR;i++)print i,name[i]}''   # END只打印最后的结果,END块里面处理数组内容\n        awk ''{sum2+=$2;count=count+1}END{print sum2,sum2/count}''         # $2的总和  $2总和除个数(平均值)\n        awk -v a=0 -F ''B'' ''{for (i=1;i<NF;i++){ a=a+length($i)+1;print a  }}''     # 打印所以B的所在位置\n        awk ''BEGIN{ "date" | getline d; split(d,mon) ; print mon[2]}'' file        # 将date值赋给d，并将d设置为数组mon，打印mon数组中第2个元素\n        awk ''BEGIN{info="this is a test2010test!";print substr(info,4,10);}''      # 截取字符串(substr使用)\n        awk ''BEGIN{info="this is a test2010test!";print index(info,"test")?"ok":"no found";}''      # 匹配字符串(index使用)\n        awk ''BEGIN{info="this is a test2010test!";print match(info,/[0-9]+/)?"ok":"no found";}''    # 正则表达式匹配查找(match使用)\n        awk ''{for(i=1;i<=4;i++)printf $i""FS; for(y=10;y<=13;y++)  printf $y""FS;print ""}''        # 打印前4列和后4列\n        awk ''BEGIN{for(n=0;n++<9;){for(i=0;i++<n;)printf i"x"n"="i*n" ";print ""}}''                # 乘法口诀\n        awk ''BEGIN{info="this is a test";split(info,tA," ");print length(tA);for(k in tA){print k,tA[k];}}''             # 字符串分割(split使用)\n        awk ''{if (system ("grep "$2" tmp/* > /dev/null 2>&1") == 0 ) {print $1,"Y"} else {print $1,"N"} }'' a            # 执行系统命令判断返回状态\n        awk  ''{for(i=1;i<=NF;i++) a[i,NR]=$i}END{for(i=1;i<=NF;i++) {for(j=1;j<=NR;j++) printf a[i,j] " ";print ""}}''   # 将多行转多列\n        netstat -an|awk -v A=$IP -v B=$PORT ''BEGIN{print "Clients\\tGuest_ip"}$4~A":"B{split($5,ip,":");a[ip[1]]++}END{for(i in a)print a[i]"\\t"i|"sort -nr"}''    # 统计IP连接个数\n        cat 1.txt|awk -F" # " ''{print "insert into user (user,password,email)values(""''\\''''"$1"''\\''\\,''""''\\''''"$2"''\\''\\,''""''\\''''"$3"''\\''\\)\\;''"}'' >>insert_1.txt     # 处理sql语句\n        awk ''BEGIN{printf "what is your name?";getline name < "/dev/tty" } $1 ~name {print "FOUND" name " on line ", NR "."} END{print "see you," name "."}'' file  # 两文件匹配\n        \n        取本机IP{\n            /sbin/ifconfig |awk -v RS="Bcast:" ''{print $NF}''|awk -F: ''/addr/{print $2}''\n            /sbin/ifconfig |awk ''/inet/&&$2!~"127.0.0.1"{split($2,a,":");print a[2]}''\n            /sbin/ifconfig |awk -v RS=''inet addr:'' ''$1!="eth0"&&$1!="127.0.0.1"{print $1}''|awk ''{printf"%s|",$0}''\n            /sbin/ifconfig |awk  ''{printf("line %d,%s\\n",NR,$0)}''         # 指定类型(%d数字,%s字符)\n        }\n\n        查看磁盘空间{\n            df -h|awk -F"[ ]+|%" ''$5>14{print $5}''\n            df -h|awk ''NR!=1{if ( NF == 6 ) {print $5} else if ( NF == 5) {print $4} }'' \n            df -h|awk ''NR!=1 && /%/{sub(/%/,"");print $(NF-1)}''\n            df -h|sed ''1d;/ /!N;s/\\n//;s/ \\+/ /;''    #将磁盘分区整理成一行   可直接用 df -P\n        }\n\n        排列打印{\n            awk ''END{printf "%-10s%-10s\\n%-10s%-10s\\n%-10s%-10s\\n","server","name","123","12345","234","1234"}'' txt\n            awk ''BEGIN{printf "|%-10s|%-10s|\\n|%-10s|%-10s|\\n|%-10s|%-10s|\\n","server","name","123","12345","234","1234"}''\n            awk ''BEGIN{\n            print "   *** 开 始 ***   ";\n            print "+-----------------+";\n            printf "|%-5s|%-5s|%-5s|\\n","id","name","ip";\n            }\n            $1!=1 && NF==4{printf "|%-5s|%-5s|%-5s|\\n",$1,$2,$3" "$11}\n            END{\n            print "+-----------------+";\n            print "   *** 结 束 ***   "\n            }'' txt\n        }\n\n        老男孩awk经典题{\n            分析图片服务日志，把日志（每个图片访问次数*图片大小的总和）排行，也就是计算每个url的总访问大小\n            说明：本题生产环境应用：这个功能可以用于IDC网站流量带宽很高，然后通过分析服务器日志哪些元素占用流量过大，进而进行优化或裁剪该图片，压缩js等措施。\n            本题需要输出三个指标： 【被访问次数】    【访问次数*单个被访问文件大小】   【文件名（带URL）】\n            测试数据\n            59.33.26.105 - - [08/Dec/2010:15:43:56 +0800] "GET /static/images/photos/2.jpg HTTP/1.1" 200 11299 \n\n            awk ''{array_num[$7]++;array_size[$7]+=$10}END{for(i in array_num) {print array_num[i]" "array_size[i]" "i}}''\n        }\n\n        awk练习题{\n\n            wang     4\n            cui      3\n            zhao     4\n            liu      3\n            liu      3\n            chang    5\n            li       2\n\n            1 通过第一个域找出字符长度为4的\n            2 当第二列值大于3时，创建空白文件，文件名为当前行第一个域$1 (touch $1)\n            3 将文档中 liu 字符串替换为 hong\n            4 求第二列的和\n            5 求第二列的平均值\n            6 求第二列中的最大值\n            7 将第一列过滤重复后，列出每一项，每一项的出现次数，每一项的大小总和\n\n            1、字符串长度\n                awk ''length($1)=="4"{print $1}''\n            2、执行系统命令\n                awk ''{if($2>3){system ("touch "$1)}}''\n            3、gsub(/r/,"s",域) 在指定域(默认$0)中用s替代r  (sed ''s///g'')\n                awk ''{gsub(/liu/,"hong",$1);print $0}'' a.txt\n            4、列求和\n                awk ''{a+=$2}END{print a}''\n            5、列求平均值\n                awk ''{a+=$2}END{print a/NR}''\n                awk ''{a+=$2;b++}END{print a,a/b}'' \n            6、列求最大值\n                awk ''BEGIN{a=0}{if($2>a) a=$2 }END{print a}''\n            7、将第一列过滤重复列出每一项，每一项的出现次数，每一项的大小总和\n                awk ''{a[$1]++;b[$1]+=$2}END{for(i in a){print i,a[i],b[i]}}''\n        }\n\n        awk处理复杂日志{\n            6.19： \n            DHB_014_号百总机服务业务日报：广州 到达数异常！\n            DHB_023_号百漏话提醒日报：珠海 到达数异常！\n            6.20： \n            DHB_014_号百总机服务业务日报：广州 到达数异常！到\n\n            awk -F ''[_ ：]+'' ''NF>2{print $4,$1"_"$2,b |"sort";next}{b=$1}''\n            \n            # 当前行NF小于等于2 只针对{print $4,$1"_"$2,b |"sort";next} 有效 即 6.19：行跳过此操作,  {b=$1} 仍然执行\n            # 当前行NF大于2 执行到 next 强制跳过本行，即跳过后面的 {b=$1}\n\n            广州 DHB_014 6.19\n        }\n    }\n\n    sed{\n    \n        # 先读取资料、存入模式空间、对其进行编辑、再输出、再用下一行替换模式空间内容\n        # 调试工具sedsed (参数 -d)   http://aurelio.net/sedsed/sedsed-1.0\n            \n        -n   # 输出由编辑指令控制(取消默认的输出,必须与编辑指令一起配合)\n        -i   # 直接对文件操作\n        -e   # 多重编辑\n        -r   # 正则可不转移特殊字符\n\n        b    # 跳过匹配的行\n        p    # 打印\n        d    # 删除\n        s    # 替换\n        g    # 配合s全部替换\n        i    # 行前插入\n        a    # 行后插入\n        r    # 读\n        y    # 转换\n        q    # 退出\n\n        &    # 代表查找的串内容\n        *    # 任意多个 前驱字符(前导符)\n        ?    # 0或1个 最小匹配 没加-r参数需转义 \\?\n        $    # 最后一行\n        .*   # 匹配任意多个字符\n        \\(a\\)   # 保存a作为标签1(\\1)\n\n        模式空间{\n\n            # 模式空间(两行两行处理) 模式匹配的范围，一般而言，模式空间是输入文本中某一行，但是可以通过使用N函数把多于一行读入模式空间\n            # 暂存空间里默认存储一个空行\n            n   # 读入下一行(覆盖上一行)\n            h   # 把模式空间里的行拷贝到暂存空间\n            H   # 把模式空间里的行追加到暂存空间\n            g   # 用暂存空间的内容替换模式空间的行\n            G   # 把暂存空间的内容追加到模式空间的行后\n            x   # 将暂存空间的内容于模式空间里的当前行互换\n            ！  # 对其前面的要匹配的范围取反\n            D   # 删除当前模式空间中直到并包含第一个换行符的所有字符(/.*/匹配模式空间中所有内容，匹配到就执行D,没匹配到就结束D)\n            N   # 追加下一个输入行到模式空间后面并在第二者间嵌入一个换行符，改变当前行号码,模式匹配可以延伸跨域这个内嵌换行\n            p   # 打印模式空间中的直到并包含第一个换行的所有字符 \n\n        }\n\n        标签函数{\n\n            : lable # 建立命令标记，配合b，t函数使用跳转\n            b lable # 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。\n            t labe  # 判断分支，从最后一行开始，条件一旦满足或者T,t命令，将导致分支到带有标号的命令出，或者到脚本末尾。与b函数不同在于t在执行跳转前会先检查其前一个替换命令是否成功，如成功，则执行跳转。\n\n            sed -e ''{:p1;/A/s/A/AA/;/B/s/B/BB/;/[AB]\\{10\\}/b;b p1;}''     # 文件内容第一行A第二行B:建立标签p1;两个替换函数(A替换成AA,B替换成BB)当A或者B达到10个以后调用b,返回\n            echo ''sd  f   f   [a    b      c    cddd    eee]'' | sed '':n;s#\\(\\[[^ ]*\\)  *#\\1#;tn''  # 标签函数t使用方法,替换[]里的空格\n            echo "198723124.03"|sed -r '':a;s/([0-9]+)([0-9]{3})/\\1,\\2/;ta''  # 每三个字符加一个逗号\n\n        }\n\n        引用外部变量{\n\n            sed -n ''''$a'',10p''\n            sed -n ""$a",10p"\n\n        }\n\n        sed 10q                                       # 显示文件中的前10行 (模拟"head")\n        sed -n ''$=''                                   # 计算行数(模拟 "wc -l")\n        sed -n ''5,/^no/p''                             # 打印从第5行到以no开头行之间的所有行\n        sed -i "/^$f/d" a     　　                  　# 删除匹配行\n        sed -i ''/aaa/,$d''                             # 删除匹配行到末尾\n        sed -i "s/=/:/" c                             # 直接对文本替换\n        sed -i "/^pearls/s/$/j/"                      # 找到pearls开头在行尾加j\n        sed ''/1/,/3/p'' file                           # 打印1和3之间的行\n        sed -n ''1p'' 文件                              # 取出指定行\n        sed ''5i\\aaa'' file                             # 在第5行之前插入行\n        sed ''5a\\aaa'' file                             # 在第5行之后抽入行\n        echo a|sed -e ''/a/i\\b''                        # 在匹配行前插入一行\n        echo a|sed -e ''/a/a\\b''                        # 在匹配行后插入一行\n        echo a|sed ''s/a/&\\nb/g''                       # 在匹配行后插入一行\n        seq 10| sed -e{1,3}''s/./a/''                   # 匹配1和3行替换\n        sed -n ''/regexp/!p''                           # 只显示不匹配正则表达式的行\n        sed ''/regexp/d''                               # 只显示不匹配正则表达式的行\n        sed ''$!N;s/\\n//''                              # 将每两行连接成一行\n        sed ''/baz/s/foo/bar/g''                        # 只在行中出现字串"baz"的情况下将"foo"替换成"bar" \n        sed ''/baz/!s/foo/bar/g''                       # 将"foo"替换成"bar"，并且只在行中未出现字串"baz"的情况下替换\n        echo a|sed -e ''s/a/#&/g''                      # 在a前面加#号\n        sed ''s/foo/bar/4''                             # 只替换每一行中的第四个字串\n        sed ''s/\\(.*\\)foo/\\1bar/''                      # 替换每行最后一个字符串\n        sed ''s/\\(.*\\)foo\\(.*foo\\)/\\1bar\\2/''           # 替换倒数第二个字符串\n        sed ''s/[0-9][0-9]$/&5''                        # 在以[0-9][0-9]结尾的行后加5\n        sed -n '' /^eth\\|em[01][^:]/{n;p;}''            # 匹配多个关键字\n        sed -n -r '' /eth|em[01][^:]/{n;p;}''           # 匹配多个关键字\n        echo -e "1\\n2"|xargs -i -t sed ''s/^/1/'' {}    # 同时处理多个文件\n        sed ''/west/,/east/s/$/*VACA*/''                # 修改west和east之间的所有行，在结尾处加*VACA*\n        sed  ''s/[^1-9]*\\([0-9]\\+\\).*/\\1/''             # 取出第一组数字，并且忽略掉开头的0\n        sed -n ''/regexp/{g;1!p;};h''                   # 查找字符串并将匹配行的上一行显示出来，但并不显示匹配行\n        sed -n '' /regexp/{n;p;}''                      # 查找字符串并将匹配行的下一行显示出来，但并不显示匹配行\n        sed -n ''s/\\(mar\\)got/\\1ianne/p''               # 保存\\(mar\\)作为标签1\n        sed -n ''s/\\([0-9]\\+\\).*\\(t\\)/\\2\\1/p''          # 保存多个标签\n        sed -i -e ''1,3d'' -e ''s/1/2/''                  # 多重编辑(先删除1-3行，在将1替换成2)\n        sed -e ''s/@.*//g'' -e ''/^$/d''                  # 删除掉@后面所有字符，和空行\n        sed -n -e "{s/文本(正则)/替换的内容/p}"       # 替换并打印出替换行\n        sed -n -e "{s/^ *[0-9]*//p}"                  # 打印并删除正则表达式的那部分内容\n        echo abcd|sed ''y/bd/BE/''                      # 匹配字符替换\n        sed ''/^#/b;y/y/P/'' 2                          # 非#号开头的行替换字符\n        sed ''/suan/r 读入文件''                        # 找到含suan的行，在后面加上读入的文件内容\n        sed -n ''/no/w 写入文件''                       # 找到含no的行，写入到指定文件中\n        sed ''/regex/G''                                # 在匹配式样行之后插入一空行\n        sed ''/regex/{x;p;x;G;}''                       # 在匹配式样行之前和之后各插入一空行\n        sed ''n;d''                                     # 删除所有偶数行\n        sed ''G;G''                                     # 在每一行后面增加两空行\n        sed ''/^$/d;G''                                 # 在输出的文本中每一行后面将有且只有一空行\n        sed ''n;n;n;n;G;''                              # 在每5行后增加一空白行\n        sed -n ''5~5p''                                 # 只打印行号为5的倍数\n        seq 1 30|sed  ''5~5s/.*/a/''                    # 倍数行执行替换\n        sed -n ''3,${p;n;n;n;n;n;n;}''                  # 从第3行开始，每7行显示一次\n        sed -n ''h;n;G;p''                              # 奇偶调换\n        seq 1 10|sed ''1!G;h;$!d''                      # 倒叙排列\n        ls -l|sed -n ''/^.rwx.*/p''                     # 查找属主权限为7的文件\n        sed = filename | sed ''N;s/\\n/\\t/''             # 为文件中的每一行进行编号(简单的左对齐方式)\n        sed ''s/^[ \\t]*//''                             # 将每一行前导的"空白字符"(空格，制表符)删除,使之左对齐 \n        sed ''s/^[ \\t]*//;s/[ \\t]*$//''                 # 将每一行中的前导和拖尾的空白字符删除\n        sed ''/{abc,def\\}\\/\\[111,222]/s/^/00000/''      # 匹配需要转行的字符: } / [\n        echo abcd\\\\nabcde |sed ''s/\\\\n/@/g'' |tr ''@'' ''\\n''        # 将换行符转换为换行\n        cat tmp|awk ''{print $1}''|sort -n|sed -n ''$p''           # 取一列最大值\n        sed -n ''{s/^[^\\/]*//;s/\\:.*//;p}'' /etc/passwd          # 取用户家目录(匹配不为/的字符和匹配:到结尾的字符全部删除)\n        sed = filename | sed ''N;s/^/      /; s/ *\\(.\\{6,\\}\\)\\n/\\1   /''   # 对文件中的所有行编号(行号在左，文字右端对齐)\n        /sbin/ifconfig |sed ''s/.*inet addr:\\(.*\\) Bca.*/\\1/g'' |sed -n ''/eth/{n;p}''   # 取所有IP\n\n        修改keepalive配置剔除后端服务器{\n\n            sed -i ''/real_server.*10.0.1.158.*8888/,+8 s/^/#/'' keepalived.conf\n            sed -i ''/real_server.*10.0.1.158.*8888/,+8 s/^#//'' keepalived.conf\n\n        }\n        \n        模仿rev功能{\n\n            echo 123 |sed ''/\\n/!G;s/\\(.\\)\\(.*\\n\\)/&\\2\\1/;//D;s/.//;''\n            /\\n/!G;         　　　　　　# 没有\\n换行符，要执行G,因为保留空间中为空，所以在模式空间追加一空行\n            s/\\(.\\)\\(.*\\n\\)/&\\2\\1/;     # 标签替换 &\\n23\\n1$ (关键在于& ,可以让后面//匹配到空行)\n            //D;            　　　　　　# D 命令会引起循环删除模式空间中的第一部分，如果删除后，模式空间中还有剩余行，则返回 D 之前的命令，重新执行，如果 D 后，模式空间中没有任何内容，则将退出。  //D 匹配空行执行D,如果上句s没有匹配到,//也无法匹配到空行, "//D;"命令结束\n            s/.//;          　　　　　　# D结束后,删除开头的 \\n\n\n        }\n\n    }\n\n    xargs{\n    \n        # 命令替换\n        -t 先打印命令，然后再执行\n        -i 用每项替换 {}\n        find / -perm +7000 | xargs ls -l                    # 将前面的内容，作为后面命令的参数\n        seq 1 10 |xargs  -i date -d "{} days " +%Y-%m-%d    # 列出10天日期\n\n    }\n\n    dialog菜单{\n    \n        # 默认将所有输出用 stderr 输出，不显示到屏幕   使用参数  --stdout 可将选择赋给变量\n        # 退出状态  0正确  1错误\n\n        窗体类型{\n            --calendar          # 日历\n            --checklist         # 允许你显示一个选项列表，每个选项都可以被单独的选择 (复选框)\n            --form              # 表单,允许您建立一个带标签的文本字段，并要求填写\n            --fselect           # 提供一个路径，让你选择浏览的文件\n            --gauge             # 显示一个表，呈现出完成的百分比，就是显示出进度条。\n            --infobox           # 显示消息后，（没有等待响应）对话框立刻返回，但不清除屏幕(信息框)\n            --inputbox          # 让用户输入文本(输入框)\n            --inputmenu         # 提供一个可供用户编辑的菜单（可编辑的菜单框）\n            --menu              # 显示一个列表供用户选择(菜单框)\n            --msgbox(message)   # 显示一条消息,并要求用户选择一个确定按钮(消息框)\n            --password          # 密码框，显示一个输入框，它隐藏文本\n            --pause             # 显示一个表格用来显示一个指定的暂停期的状态\n            --radiolist         # 提供一个菜单项目组，但是只有一个项目，可以选择(单选框)\n            --tailbox           # 在一个滚动窗口文件中使用tail命令来显示文本\n            --tailboxbg         # 跟tailbox类似，但是在background模式下操作\n            --textbox           # 在带有滚动条的文本框中显示文件的内容  (文本框)\n            --timebox           # 提供一个窗口，选择小时，分钟，秒\n            --yesno(yes/no)     # 提供一个带有yes和no按钮的简单信息框\n        }\n\n        窗体参数{\n            --separate-output          # 对于chicklist组件,输出结果一次输出一行,得到结果不加引号 \n            --ok-label "提交"          # 确定按钮名称\n            --cancel-label "取消"      # 取消按钮名称\n            --title "标题"             # 标题名称\n            --stdout                   # 将所有输出用 stdout 输出\n            --backtitle "上标"         # 窗体上标\n            --no-shadow                # 去掉窗体阴影\n            --menu "菜单名" 20 60 14   # 菜单及窗口大小\n            --clear                    # 完成后清屏操作\n            --no-cancel                # 不显示取消项\n            --insecure                 # 使用星号来代表每个字符\n            --begin <y> <x>            # 指定对话框左上角在屏幕的上的做坐标\n            --timeout <秒>             # 超时,返回的错误代码255,如果用户在指定的时间内没有给出相应动作,就按超时处理\n            --defaultno                # 使选择默认为no\n            --default-item <str>       # 设置在一份清单，表格或菜单中的默认项目。通常在框中的第一项是默认\n            --sleep 5                  # 在处理完一个对话框后静止(延迟)的时间(秒)\n            --max-input size           # 限制输入的字符串在给定的大小之内。如果没有指定，默认是2048\n            --keep-window              # 退出时不清屏和重绘窗口。当几个组件在同一个程序中运行时，对于保留窗口内容很有用的\n        }\n\n        dialog --title "Check me" --checklist "Pick Numbers" 15 25 3 1 "one" "off" 2 "two" "on"         # 多选界面[方括号]\n        dialog --title "title" --radiolist "checklist" 20 60 14 tag1 "item1" on tag2 "item2" off        # 多选界面(圆括号)\n        dialog --title "title" --menu "MENU" 20 60 14 tag1 "item1" tag2 "item2"                         # 单选界面\n        dialog --title "Installation" --backtitle "Star Linux" --gauge "Linux Kernel"  10 60 50         # 进度条\n        dialog --title "标题" --backtitle "Dialog" --yesno "说明" 20 60                                 # 选择yes/no        \n        dialog --title "公告标题" --backtitle "Dialog" --msgbox "内容" 20 60                            # 公告\n        dialog --title "hey" --backtitle "Dialog" --infobox "Is everything okay?" 10 60                 # 显示讯息后立即离开\n        dialog --title "hey" --backtitle "Dialog" --inputbox "Is okay?" 10 60 "yes"                     # 输入对话框\n        dialog --title "Array 30" --backtitle "All " --textbox /root/txt 20 75                          # 显示文档内容\n        dialog --title "Add" --form "input" 12 40 4 "user" 1 1 "" 1 15 15 0 "name" 2 1 "" 2 15 15 0     # 多条输入对话框\n        dialog --title  "Password"  --insecure  --passwordbox  "请输入密码"  10  35                     # 星号显示输入--insecure\n        dialog --stdout --title "日历"  --calendar "请选择" 0 0 9 1 2010                                # 选择日期\n        dialog --title "title" --menu "MENU" 20 60 14 tag1 "item1" tag2 "item2" 2>tmp                   # 取到结果放到文件中(以标准错误输出结果)\n        a=`dialog --title "title"  --stdout --menu "MENU" 20 60 14 tag1 "item1" tag2 "item2"`           # 选择操作赋给变量(使用标准输出)\n        \n        dialog菜单实例{\n            while :\n            do\n            clear\n            menu=`dialog --title "title"  --stdout --menu "MENU" 20 60 14 1 system 2 custom`\n            [ $? -eq 0 ] && echo "$menu" || exit         # 判断dialog执行,取消退出\n                while :\n                do\n                    case $menu in\n                    1)\n                        list="1a "item1" 2a "item2""     # 定义菜单列表变量\n                    ;;\n                    2)\n                        list="1b "item3" 2b "item4""\n                    ;;\n                    esac\n                    result=`dialog --title "title"  --stdout --menu "MENU" 20 60 14 $list` \n                    [ $? -eq 0 ] && echo "$result" || break    # 判断dialog执行,取消返回菜单,注意:配合上层菜单循环\n                    read\n                done\n            done\n        }\n        \n    }\n\n    select菜单{\n\n        # 输入项不在菜单自动会提示重新输入\n        select menuitem in pick1 pick2 pick3 退出\n        do\n            echo $menuitem\n            case $menuitem in\n            退出)\n                exit\n            ;;\n            *)\n                select area in area1 area2 area3 返回\n                do\n                    echo $area\n                    case $area in\n                    返回)\n                        break\n                    ;;\n                    *)\n                        echo "对$area操作"\n                    ;;\n                    esac\n                done\n            ;;\n            esac\n        done\n\n    }\n\n    shift{\n\n        ./cs.sh 1 2 3\n        #!/bin/sh\n        until [ $# -eq 0 ]\n        do\n            echo "第一个参数为: $1 参数个数为: $#"\n            #shift 命令执行前变量 $1 的值在shift命令执行后不可用\n            shift\n        done\n\n    }\n        \n    getopts给脚本加参数{\n\n        #!/bin/sh\n        while getopts :ab: name\n        do\n            case $name in\n            a)  \n                aflag=1\n            ;;\n            b)  \n                bflag=1\n                bval=$OPTARG\n            ;;\n            \\?) \n                echo "USAGE:`basename $0` [-a] [-b value]"\n                exit  1\n            ;;\n            esac\n        done\n        if [ ! -z $aflag ] ; then\n            echo "option -a specified"\n            echo "$aflag"\n            echo "$OPTIND"\n        fi\n        if [ ! -z $bflag ] ; then\n            echo  "option -b specified"\n            echo  "$bflag"\n            echo  "$bval"\n            echo  "$OPTIND"\n        fi\n        echo "here  $OPTIND"\n        shift $(($OPTIND -1))\n        echo "$OPTIND"\n        echo " `shift $(($OPTIND -1))`  "\n\n    }\n\n    tclsh{\n\n        set foo "a bc"                   # 定义变量\n        set b {$a};                      # 转义  b的值为" $a " ,而不是变量结果\n        set a 3; incr a 3;               # 数字的自增.  将a加3,如果要减3,则为 incr a –3;\n        set c [expr 20/5];               # 计算  c的值为4\n        puts $foo;                       # 打印变量\n        set qian(123) f;                 # 定义数组\n        set qian(1,1,1) fs;              # 多维数组\n        parray qian;                     # 打印数组的所有信息\n        string length $qian;             # 将返回变量qian的长度\n        string option string1 string2;   # 字符相关串操作\n        # option 的操作选项:\n        # compare           按照字典的排序方式进行比较。根据string1 <,=,>string2分别返回-1,0,1\n        # first             返回string2中第一次出现string1的位置，如果没有出现string1则返回-1\n        # last              和first相反\n        # trim              从string1中删除开头和结尾的出现在string2中的字符\n        # tolower           返回string1中的所有字符被转换为小写字符后的新字符串\n        # toupper           返回string1中的所有字符串转换为大写后的字符串\n        # length            返回string1的长度\n        set a 1;while {$a < 3} { set a [incr a 1;]; };puts $a    # 判断变量a小于3既循环\n        for {initialization} {condition} {increment} {body}      # 初始化变量,条件,增量,具体操作\n        for {set i 0} {$i < 10} {incr i} {puts $i;}              # 将打印出0到9\n        if { 表达式 } {\n             #运算;\n        } else {\n             #其他运算;\n        }\n        switch $x {\n            字符串1 { 操作1 ;}\n            字符串2 { 操作2 ;}\n        }\n        foreach element {0 m n b v} {    \n        # 将在一组变元中进行循环，并且每次都将执行他的循环体\n               switch $element {\n                     # 判断element的值\n             }\n        }\n\n        expect交互{\n\n            exp_continue         # 多个spawn命令时并行\n            interact             # 执行完成后保持交互状态，把控制权交给控制台\n            expect "password:"   # 判断关键字符\n            send "passwd\\r"      # 执行交互动作，与手工输入密码的动作等效。字符串结尾加"\\r"\n\n            ssh后sudo{\n\n                #!/bin/bash\n                #sudo注释下行允许后台运行\n                #Defaults requiretty\n                #sudo去掉!允许远程\n                #Defaults !visiblepw\n\n                /usr/bin/expect -c ''\n                set timeout 5\n                spawn ssh -o StrictHostKeyChecking=no xuesong1@192.168.42.128 "sudo grep xuesong1 /etc/passwd"\n                expect {\n                    "passphrase" {\n                        send_user "sshkey\\n"\n                        send "xuesong\\r";\n                        expect {\n                            "sudo" {\n                            send_user "sudo\\n"\n                            send "xuesong\\r"\n                            interact\n                            }\n                            eof {\n                            send_user "sudo eof\\n"\n                            }\n                        }\n                    }\n                    "password:" {\n                        send_user "ssh\\n"\n                        send "xuesong\\r";\n                        expect {\n                            "sudo" {\n                            send_user "sudo\\n"\n                            send "xuesong\\r"\n                            interact\n                            }\n                            eof {\n                            send_user "sudo eof\\n"\n                            }\n                        }\n                    }\n                    "sudo" {\n                            send_user "sudo\\n"\n                            send "xuesong\\r"\n                            interact\n                            }\n                    eof {\n                        send_user "ssh eof\\n"\n                    }\n                }\n                ''\n\n            }\n\n            ssh执行命令操作{\n            \n                /usr/bin/expect -c "\n                proc jiaohu {} {\n                    send_user expect_start\n                    expect {\n                        password {\n                            send ${RemotePasswd}\\r;\n                            send_user expect_eof\n                            expect {\n                                \\"does not exist\\" {\n                                    send_user expect_failure\n                                    exit 10\n                                }\n                                password {\n                                    send_user expect_failure\n                                    exit 5\n                                }\n                                Password {\n                                    send ${RemoteRootPasswd}\\r;\n                                    send_user expect_eof\n                                    expect {\n                                        incorrect {\n                                            send_user expect_failure\n                                            exit 6\n                                        }\n                                        eof \n                                    }\n                                }\n                                eof\n                            }\n                        }\n                        passphrase {\n                            send ${KeyPasswd}\\r;\n                            send_user expect_eof\n                            expect {\n                                \\"does not exist\\" {\n                                    send_user expect_failure\n                                    exit 10\n                                }\n                                passphrase{\n                                    send_user expect_failure\n                                    exit 7\n                                }\n                                Password {\n                                    send ${RemoteRootPasswd}\\r;\n                                    send_user expect_eof\n                                    expect {\n                                        incorrect {\n                                            send_user expect_failure\n                                            exit 6\n                                        }\n                                        eof\n                                    }\n                                }\n                                eof\n                            }\n                        }\n                        Password {\n                            send ${RemoteRootPasswd}\\r;\n                            send_user expect_eof\n                            expect {\n                                incorrect {\n                                    send_user expect_failure\n                                    exit 6\n                                }\n                                eof\n                            }\n                        }\n                        \\"No route to host\\" {\n                            send_user expect_failure\n                            exit 4\n                        }\n                        \\"Invalid argument\\" {\n                            send_user expect_failure\n                            exit 8\n                        }\n                        \\"Connection refused\\" {\n                            send_user expect_failure\n                            exit 9\n                        }\n                        \\"does not exist\\" {\n                            send_user expect_failure\n                            exit 10\n                        }\n                        \n                        \\"Connection timed out\\" {\n                            send_user expect_failure\n                            exit 11\n                        }\n                        timeout {\n                            send_user expect_failure\n                            exit 3\n                        }\n                        eof\n                    }\n                }\n                set timeout $TimeOut\n                switch $1 {\n                    Ssh_Cmd {\n                        spawn ssh -t -p $Port -o StrictHostKeyChecking=no $RemoteUser@$Ip /bin/su - root -c \\\\\\"$Cmd\\\\\\"\n                        jiaohu\n                    }\n                    Ssh_Script {\n                        spawn scp -P $Port -o StrictHostKeyChecking=no $ScriptPath $RemoteUser@$Ip:/tmp/${ScriptPath##*/};\n                        jiaohu\n                        spawn ssh -t -p $Port -o StrictHostKeyChecking=no $RemoteUser@$Ip /bin/su - root -c  \\\\\\"/bin/sh /tmp/${ScriptPath##*/}\\\\\\" ;\n                        jiaohu\n                    }\n                    Scp_File {\n                        spawn scp -P $Port -o StrictHostKeyChecking=no -r $ScpPath $RemoteUser@$Ip:${ScpRemotePath};\n                        jiaohu\n                    }\n                }\n                "\n                state=`echo $?`\n\n            }\n\n            交互双引号引用较长变量{\n            \n                #!/bin/bash\n                RemoteUser=xuesong12\n                Ip=192.168.1.2\n                RemotePasswd=xuesong\n                Cmd="/bin/echo "$PubKey" > "$RemoteKey"/authorized_keys"\n\n                /usr/bin/expect -c "\n                set timeout 10\n                spawn ssh -o StrictHostKeyChecking=no $RemoteUser@$Ip {$Cmd};\n                expect {\n                    password: {\n                        send_user RemotePasswd\\n\n                        send ${RemotePasswd}\\r;\n                        interact;\n                    }\n                    eof {\n                        send_user eof\\n\n                    }\n                }\n                "\n\n            }\n\n            telnet交互{\n            \n                #!/bin/bash\n                Ip="10.0.1.53"\n                a="\\{\\''method\\''\\:\\''doLogin\\''\\,\\''params\\''\\:\\{\\''uName\\''\\:\\''bobbietest\\''\\}"\n                /usr/bin/expect -c"\n                        set timeout 15\n                        spawn telnet ${Ip} 8000\n                        expect "Escape"\n                        send "${a}\\\\r"\n                        expect {\n                                -re "\\"err.*none\\"" {\n                                        exit 0\n                                }\n                                timeout {                       \n                                        exit 1\n                                }\n                                eof {\n                                        exit 2\n                                }\n                        }\n                "\n                echo $?\n\n            }\n\n            模拟ssh登录{\n                #好处:可加载环境变量\n\n                #!/bin/bash\n                Ip=''192.168.1.6''            # 循环就行\n                RemoteUser=''user''           # 普通用户\n                RemotePasswd=''userpasswd''   # 普通用户的密码\n                RemoteRootPasswd=''rootpasswd''\n                /usr/bin/expect -c "\n                set timeout -1\n                spawn ssh -t -p $Port -o StrictHostKeyChecking=no $RemoteUser@$Ip\n                expect {\n                    password {\n                        send_user RemotePasswd\n                        send ${RemotePasswd}\\r;\n                        expect {\n                            \\"does not exist\\" {\n                                send_user \\"root user does not exist\\n\\"\n                                exit 10\n                            }\n                            password {\n                                send_user \\"user passwd error\\n\\"\n                                exit 5\n                            }\n                            Last {\n                                send \\"su - batch\\n\\"\n                                expect {\n                                    Password {\n                                        send_user RemoteRootPasswd\n                                        send ${RemoteRootPasswd}\\r;\n                                        expect {\n                                            \\"]#\\" {\n                                                send \\"sh /tmp/update.sh update\\n \\"\n                                                expect {\n                                                    \\"]#\\" {\n                                                        send_user ${Ip}_Update_Done\\n\n                                                    }\n                                                    eof\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                    \\"No route to host\\" {\n                        send_user \\"host not found\\n\\"\n                        exit 4\n                    }\n                    \\"Invalid argument\\" {\n                        send_user \\"incorrect parameter\\n\\"\n                        exit 8\n                    }\n                    \\"Connection refused\\" {\n                        send_user \\"invalid port parameters\\n\\"\n                        exit 9\n                    }\n                    \\"does not exist\\" {\n                        send_user \\"root user does not exist\\"\n                        exit 10\n                    }\n                    timeout {\n                        send_user \\"connection timeout \\n\\"\n                        exit 3\n                    }\n                    eof\n                }\n                "\n                state=`echo $?`\n\n            }\n\n        }\n\n    }\n\n}\n\n9 实例{\n\n    从1叠加到100{\n\n        echo $[$(echo +{1..100})]\n        echo $[(100+1)*(100/2)]\n        seq -s ''+'' 100 |bc\n\n    }\n\n    判断参数是否为空-空退出并打印null{\n\n        #!/bin/sh\n        echo $1\n        name=${1:?"null"}\n        echo $name\n\n    }\n\n    循环数组{\n\n        for ((i=0;i<${#o[*]};i++))\n        do\n            echo ${o[$i]}\n        done\n\n    }\n\n    判断路径{\n\n        if [ -d /root/Desktop/text/123 ];then \n            echo "找到了123"\n            if [ -d /root/Desktop/text ]\n            then echo "找到了text"\n            else echo "没找到text"\n            fi\n        else echo "没找到123文件夹"\n        fi\n\n    }\n\n    找出出现次数最多{\n\n        awk ''{print $1}'' file|sort |uniq -c|sort -k1r\n\n    }\n    \n    判断脚本参数是否正确{\n\n        ./test.sh  -p 123 -P 3306 -h 127.0.0.1 -u root\n        #!/bin/sh\n        if [ $# -ne 8 ];then\n            echo "USAGE: $0 -u user -p passwd -P port -h host"\n            exit 1\n        fi\n\n        while getopts :u:p:P:h: name\n        do\n            case $name in\n            u)\n                mysql_user=$OPTARG\n            ;;\n            p)\n                mysql_passwd=$OPTARG\n            ;;\n            P)\n                mysql_port=$OPTARG\n            ;;\n            h)\n                mysql_host=$OPTARG\n            ;;\n            *)\n                echo "USAGE: $0 -u user -p passwd -P port -h host"\n                exit 1\n            ;;\n            esac\n        done\n\n        if [ -z $mysql_user ] || [ -z $mysql_passwd ] || [ -z $mysql_port ] || [ -z $mysql_host ]\n        then\n            echo "USAGE: $0 -u user -p passwd -P port -h host"\n            exit 1\n        fi\n\n        echo $mysql_user $mysql_passwd $mysql_port  $mysql_host\n        #结果 root 123 3306 127.0.0.1\n    \n    }\n\n    正则匹配邮箱{\n    \n        ^[_a-z0-9-]+(\\.[_a-z0-9-]+)*@[a-z0-9-]+(\\.[a-z0-9-]+)*(\\.[a-z]{2,4})$\n        \n    }\n    \n    打印表格{\n\n        #!/bin/sh\n        clear\n        awk ''BEGIN{\n        print "+--------------------+--------------------+";\n        printf "|%-20s|%-20s|\\n","Name","Number";\n        print "+--------------------+--------------------+";\n        }''\n        a=`grep "^[A-Z]" a.txt |sort +1 -n |awk ''{print $1":"$2}''`\n        #cat a.txt |sort +1 -n |while read list\n        for list in $a\n        do\n            name=`echo $list |awk -F: ''{print $1}''`\n            number=`echo $list |awk -F: ''{print $2}''`\n            awk ''BEGIN{printf "|%-20s|%-20s|\\n","''"$name"''","''"$number"''";\n            print "+--------------------+--------------------+";\n            }''\n        done\n        awk ''BEGIN{\n        print "              *** The End ***              "\n        print "                                           "\n        }''\n\n    }\n        \n    判断日期是否合法{\n\n        #!/bin/sh\n        while read a\n        do\n          if echo $a | grep -q "-" && date -d $a +%Y%m%d > /dev/null 2>&1\n          then\n            if echo $a | grep -e ''^[0-9]\\{4\\}-[01][0-9]-[0-3][0-9]$''\n            then \n                break\n            else\n                echo "您输入的日期不合法，请从新输入！"\n            fi\n          else\n            echo "您输入的日期不合法，请从新输入！"\n          fi\n        done\n        echo "日期为$a"\n\n    }\n        \n    打印日期段所有日期{\n\n        #!/bin/bash\n        qsrq=20010101\n        jsrq=20010227\n        n=0\n        >tmp\n        while :;do\n        current=$(date +%Y%m%d -d"$n day $qsrq")\n        if [[ $current == $jsrq ]];then\n            echo $current >>tmp;break\n        else\n            echo $current >>tmp\n            ((n++))\n        fi\n        done\n        rq=`awk ''NR==1{print}'' tmp`\n\n    }\n        \n    打印提示{\n\n        cat <<EOF\n        #内容\nEOF\n\n        }\n\n    登陆远程执行命令{\n\n        # 特殊符号需要 \\ 转义\n        ssh root@ip << EOF\n        #执行命令\nEOF\n\n        }\n\n    数学计算的小算法{\n\n        #!/bin/sh\n        A=1\n        B=1\n        while [ $A -le 10 ]\n        do\n            SUM=`expr $A \\* $B`\n            echo "$SUM"\n            if [ $A = 10 ]\n            then\n                B=`expr $B + 1`\n                A=1\n            fi\n            A=`expr $A + 1`\n        done\n\n    }\n\n    多行合并{\n\n        sed ''{N;s/\\n//}'' file                   # 将两行合并一行(去掉换行符)\n        awk ''{printf(NR%2!=0)?$0" ":$0" \\n"}''   # 将两行合并一行\n        awk ''{printf"%s ",$0}''                  # 将所有行合并\n        awk ''{if (NR%4==0){print $0} else {printf"%s ",$0}}'' file    # 将4行合并为一行(可扩展)\n\n    }\n    \n    横竖转换{\n\n        cat a.txt | xargs           # 列转行\n        cat a.txt | xargs -n1       # 行转列\n\n    }\n\n    竖行转横行{\n\n        cat file|tr ''\\n'' '' ''\n        echo $(cat file)\n        \n        #!/bin/sh\n        for i in `cat file`\n        do\n              a=${a}" "${i}\n        done\n        echo $a\n\n    }\n\n    取用户的根目录{\n\n        #! /bin/bash \n        while read name pass uid gid gecos home shell \n        do \n            echo $home \n        done < /etc/passwd\n    \n    }\n\n    远程打包{\n    \n        ssh -n $ip ''find ''$path'' /data /opt -type f  -name "*.sh" -or -name "*.py" -or -name "*.pl" |xargs tar zcvpf /tmp/data_backup.tar.gz''\n    \n    }\n\n    把汉字转成encode格式{\n\n        echo 论坛 | tr -d "\\n" | xxd -i | sed -e "s/ 0x/%/g" | tr -d " ,\\n"\n        %c2%db%cc%b3\n        echo 论坛 | tr -d "\\n" | xxd -i | sed -e "s/ 0x/%/g" | tr -d " ,\\n" | tr "[a-f]" "[A-F]"  # 大写的\n        %C2%DB%CC%B3\n\n    }\n\n    把目录带有大写字母的文件名改为全部小写{\n\n        #!/bin/bash\n        for f in *;do\n            mv $f `echo $f |tr "[A-Z]" "[a-z]"`\n        done\n\n    }\n\n    查找连续多行，在不连续的行前插入{\n\n        #/bin/bash\n        lastrow=null\n        i=0\n        cat incl|while read line\n        do\n        i=`expr $i + 1`\n        if echo "$lastrow" | grep "#include <[A-Z].h>"  \n        then\n            if echo "$line" | grep -v  "#include <[A-Z].h>" \n            then\n                sed -i ''''$i''i\\\\/\\/All header files are include'' incl\n                i=`expr $i + 1`\n            fi\n        fi\n        lastrow="$line"\n        done\n\n    }\n\n    查询数据库其它引擎{\n\n        #/bin/bash\n        path1=/data/mysql/data/\n        dbpasswd=db123\n        #MyISAM或InnoDB\n        engine=InnoDB\n\n        if [ -d $path1 ];then\n\n        dir=`ls -p $path1 |awk ''/\\/$/''|awk -F''/'' ''{print $1}''`\n            for db in $dir\n            do\n            number=`mysql -uroot -p$dbpasswd -A -S "$path1"mysql.sock -e "use ${db};show table status;" |grep -c $engine`\n                if [ $number -ne 0 ];then\n                echo "${db}"\n                fi\n            done\n        fi\n\n    }\n\n    批量修改数据库引擎{\n    \n        #/bin/bash\n        for db in test test1 test3\n        do\n            tables=`mysql -uroot -pdb123 -A -S /data/mysql/data/mysql.sock -e "use $db;show tables;" |awk ''NR != 1{print}''`\n\n            for table in $tables\n            do\n                mysql -uroot -pdb123 -A -S /data/mysql/data/mysql.sock -e "use $db;alter table $table engine=MyISAM;"\n            done\n        done\n        \n    }\n\n    将shell取到的数据插入mysql数据库{\n    \n        mysql -u$username -p$passwd -h$dbhost -P$dbport -A -e "\n        use $dbname;\n        insert into data values ('''',''$ip'',''$date'',''$time'',''$data'')\n        "\n\n    }\n\n    两日期间隔天数{\n    \n        D1=`date -d ''20070409'' +"%s"`\n        D2=`date -d ''20070304 '' +"%s"`\n        D3=$(($D1 - $D2))\n        echo $(($D3/60/60/24)) \n        \n    }\n\n    while执行ssh只循环一次{\n        \n        cat -    # 让cat读连接文件stdin的信息\n        seq 10 | while read line; do ssh localhost "cat -"; done        # 显示的9次是被ssh吃掉的\n        seq 10 | while read line; do ssh -n localhost "cat -"; done     # ssh加上-n参数可避免只循环一次\n        \n    }\n\n    ssh批量执行命令{\n\n        #版本1\n        #!/bin/bash\n        while read line\n        do \n        Ip=`echo $line|awk ''{print $1}''`\n        Passwd=`echo $line|awk ''{print $2}''`\n        ssh -n localhost "cat -"\n        sshpass -p "$Passwd" ssh -n -t -o StrictHostKeyChecking=no root@$Ip "id"  \n        done<iplist.txt\n\n        #版本2\n        #!/bin/bash\n        Iplist=`awk ''{print $1}'' iplist.txt`\n        for Ip in $Iplist\n        do\n        Passwd=`awk ''/''$Ip''/{print $2}'' iplist.txt`\n        sshpass -p "$Passwd" ssh -n -t -o StrictHostKeyChecking=no root@$Ip "id" \n        done\n\n    }\n\n    在同一位置打印字符{\n\n        #!/bin/bash\n        echo -ne "\\t"\n        for i in `seq -w 100 -1 1`\n        do\n            echo -ne "$i\\b\\b\\b";      # 关键\\b退格\n            sleep 1;\n        done\n\n    }\n\n    多进程后台并发简易控制{\n\n        #!/bin/bash\n        test () {\n            echo $a\n            sleep 5\n        }\n        for a in `seq 1 30`\n        do\n            test &\n            echo $!\n            ((num++))\n            if [ $num -eq 6 ];then\n            echo "wait..."\n            wait\n            num=0\n            fi\n        done\n        wait\n\n    }\n\n    shell并发{\n\n        #!/bin/bash\n        tmpfile=$$.fifo   # 创建管道名称\n        mkfifo $tmpfile   # 创建管道\n        exec 4<>$tmpfile  # 创建文件标示4，以读写方式操作管道$tmpfile\n        rm $tmpfile       # 将创建的管道文件清除\n        thred=4           # 指定并发个数\n        seq=(1 2 3 4 5 6 7 8 9 21 22 23 24 25 31 32 33 34 35) # 创建任务列表\n\n        # 为并发线程创建相应个数的占位\n        {\n        for (( i = 1;i<=${thred};i++ ))\n        do\n            echo;  # 因为read命令一次读取一行，一个echo默认输出一个换行符，所以为每个线程输出一个占位换行\n        done\n        } >&4      # 将占位信息写入管道\n\n        for id in ${seq}  # 从任务列表 seq 中按次序获取每一个任务\n        do\n          read  # 读取一行，即fd4中的一个占位符\n          (./ur_command ${id};echo >&4 ) &   # 在后台执行任务ur_command 并将任务 ${id} 赋给当前任务；任务执行完后在fd4种写入一个占位符\n        done <&4    # 指定fd4为整个for的标准输入\n        wait        # 等待所有在此shell脚本中启动的后台任务完成\n        exec 4>&-   # 关闭管道\n        \n        #!/bin/bash\n\n        FifoFile="$$.fifo"\n        mkfifo $FifoFile\n        exec 6<>$FifoFile\n        rm $FifoFile\n        for ((i=0;i<=20;i++));do echo;done >&6\n\n        for u in `seq 1 $1`\n        do\n            read -u6\n            {\n                curl -s http://ch.com >>/dev/null\n                [ $? -eq 0 ] && echo "${u} 次成功" || echo "${u} 次失败"\n                echo >&6 \n            } &\n        done\n        wait\n        exec 6>&-\n\n    }\n\n    shell并发函数{\n    \n        function ConCurrentCmd()\n        {\n            #进程数\n            Thread=30\n\n            #列表文件\n            CurFileName=iplist.txt\n\n            #定义fifo文件\n            FifoFile="$$.fifo"\n\n            #新建一个fifo类型的文件\n            mkfifo $FifoFile\n\n            #将fd6与此fifo类型文件以读写的方式连接起来\n            exec 6<>$FifoFile      \n            rm $FifoFile\n\n            #事实上就是在文件描述符6中放置了$Thread个回车符\n            for ((i=0;i<=$Thread;i++));do echo;done >&6\n\n            #此后标准输入将来自fd5\n            exec 5<$CurFileName\n\n            #开始循环读取文件列表中的行\n            Count=0\n            while read -u5 line\n            do\n                read -u6\n                let Count+=1\n                # 此处定义一个子进程放到后台执行\n                # 一个read -u6命令执行一次,就从fd6中减去一个回车符，然后向下执行\n                # fd6中没有回车符的时候,就停在这了,从而实现了进程数量控制\n                {        \n                    echo $Count\n                    \n                    #这段代码框就是执行具体的操作了\n                    function\n\n                    echo >&6 \n                    #当进程结束以后,再向fd6中追加一个回车符,即补上了read -u6减去的那个\n                } &\n            done\n\n            #等待所有后台子进程结束\n            wait  \n\n            #关闭fd6\n            exec 6>&-\n\n            #关闭fd5\n            exec 5>&-\n        }\n        \n        并发例子{\n        \n            #!/bin/bash\n\n            FifoFile="$$.fifo"\n            mkfifo $FifoFile\n            exec 6<>$FifoFile\n            rm $FifoFile\n            for ((i=0;i<=20;i++));do echo;done >&6\n\n            for u in `seq 1 $1`\n            do\n                read -u6\n                {\n                    curl -s http://m.chinanews.com/?tt_from=shownews >>/dev/null\n                    [ $? -eq 0 ] && echo "${u} 次成功" || echo "${u} 次失败"\n                    echo >&6 \n                } &\n            done\n            wait\n            exec 6>&-\n        \n        }\n    }\n\n    函数{\n\n        ip(){\n            echo "a 1"|awk ''$1=="''"$1"''"{print $2}''\n        }\n        web=a\n        ip $web\n\n    }\n\n    检测软件包是否存在{\n\n        rpm -q dialog >/dev/null\n        if [ "$?" -ge 1 ];then\n            echo "install dialog,Please wait..."\n            yum -y install dialog\n            rpm -q dialog >/dev/null\n            [ $? -ge 1 ] && echo "dialog installation failure,exit" && exit\n            echo "dialog done"\n            read\n        fi\n\n    }\n\n    游戏维护菜单-修改配置文件{\n    \n        #!/bin/bash\n\n        conf=serverlist.xml\n        AreaList=`awk -F ''"'' ''/<s/{print $2}'' $conf`\n\n        select area in $AreaList 全部 退出\n        do\n            echo ""\n            echo $area\n            case $area in\n            退出)\n                exit\n            ;;\n            *)\n                select operate in "修改版本号" "添加维护中" "删除维护中" "返回菜单"\n                do\n                    echo ""\n                    echo $operate\n                    case $operate in\n                    修改版本号)\n                        echo 请输入版本号\n                        while read version\n                        do\n                            if echo $version | grep -w 10[12][0-9][0-9][0-9][0-9][0-9][0-9] \n                            then\n                                break\n                            fi\n                            echo 请从新输入正确的版本号\n                        done\n                        case $area in\n                        全部)\n                            case $version in\n                            101*)\n                                echo "请确认操作对 $area 体验区 $operate"\n                                read\n                                sed -i ''s/101[0-9][0-9][0-9][0-9][0-9][0-9]/''$version''/'' $conf \n                            ;;\n                            102*)\n                                echo "请确认操作对 $area 正式区 $operate"\n                                read\n                                sed -i ''s/102[0-9][0-9][0-9][0-9][0-9][0-9]/''$version''/'' $conf \n                            ;;\n                            esac\n                        ;;\n                        *)\n                            type=`awk -F ''"'' ''/''$area''/{print $14}'' $conf |cut -c1-3`\n                            readtype=`echo $version |cut -c1-3`\n                            if [ $type != $readtype ]\n                            then\n                                echo "版本号不对应，请从新操作"\n                                continue\n                            fi\n                        \n                            echo "请确认操作对 $area 区 $operate"\n                            read\n\n                            awk -F ''"'' ''/''$area''/{print $12}'' $conf |xargs -i sed -i ''/''{}''/s/10[12][0-9][0-9][0-9][0-9][0-9][0-9]/''$version''/'' $conf\n                        ;;\n                        esac\n                    ;;\n                    添加维护中)\n                        case $area in\n                        全部)\n                            echo "请确认操作对 $area 区 $operate"\n                            read\n                            awk -F ''"'' ''/<s/{print $2}'' $conf |xargs -i sed -i ''s/''{}''/&维护中/'' $conf\n                        ;;\n                        *)\n                            echo "请确认操作对 $area 区 $operate"\n                            read\n                            sed -i ''s/''$area''/&维护中/'' $conf\n                        ;;\n                        esac\n                    ;;\n                    删除维护中)\n                        case $area in\n                        全部)\n                            echo "请确认操作对 $area 区 $operate"\n                            read\n                            sed -i ''s/维护中//'' $conf\n                        ;;\n                        *)\n                            echo "请确认操作对 $area 区 $operate"\n                            read\n                            sed -i ''/''$area''/s/维护中//'' $conf\n                        ;;\n                        esac\n                    ;;\n                    返回菜单)\n                        break\n                    ;;\n                    esac\n                done\n            ;;\n            esac\n            echo "回车重新选择区"\n        done\n\n    }\n\n    keepalive剔除后端服务{\n\n        #!/bin/bash\n        #行数请自定义,默认8行\n        if [ X$2 == X ];then\n            echo "error: IP null"\n            read\n            exit\n        fi\n        case $1 in\n        del)\n            sed -i ''/real_server.*''$2''.*8888/,+8 s/^/#/'' /etc/keepalived/keepalived.conf\n            /etc/init.d/keepalived reload\n        ;;\n        add)\n            sed -i ''/real_server.*''$2''.*8888/,+8 s/^#//'' /etc/keepalived/keepalived.conf\n            /etc/init.d/keepalived reload\n        ;;\n        *)\n            echo "Parameter error"\n        ;;\n        esac\n        \n    }\n\n    申诉中国反垃圾邮件联盟黑名单{\n\n        #!/bin/bash\n\n        IpList=`awk ''$1!~"^#"&&$1!=""{print $1}'' host.list`\n\n        QueryAdd=''http://www.anti-spam.org.cn/Rbl/Query/Result''\n        ComplaintAdd=''http://www.anti-spam.org.cn/Rbl/Getout/Submit''\n\n        CONTENT=''我们是一家正规的XXX。xxxxxxx。恳请将我们的发送服务器IP移出黑名单。谢谢！\n        处理措施：\n        1.XXXX。\n        2.XXXX。''\n        CORP=''abc.com''\n        WWW=''www.abc.cm''\n        NAME=''def''\n        MAIL=''def@163.com.cn''\n        TEL=''010-50000000''\n        LEVEL=''0''\n\n        for Ip in $IpList\n        do\n            Status=`curl -d "IP=$Ip" $QueryAdd |grep ''Getout/ShowForm?IP='' |grep -wc ''申诉脱离''`\n            if [ $Status -ge 1 ];then\n                IpStatus="黑名单中"\n                results=`curl -d "IP=${Ip}&CONTENT=${CONTENT}&CORP=${CORP}&WWW=${WWW}&NAME=${NAME}&MAIL=${MAIL}&TEL=${TEL}&LEVEL=${LEVEL}" $ComplaintAdd |grep -E ''您的黑名单脱离申请已提交|该IP的脱离申请已被他人提交|申请由于近期内有被拒绝的记录''`\n                echo $results\n                if echo $results | grep ''您的黑名单脱离申请已提交''  > /dev/null 2>&1\n                then\n                    complaint=''申诉成功''\n                elif echo $results | grep ''该IP的脱离申请已被他人提交''  > /dev/null 2>&1\n                then\n                    complaint=''申诉重复''\n                elif echo $results | grep ''申请由于近期内有被拒绝的记录''  > /dev/null 2>&1\n                then\n                    complaint=''申诉拒绝''\n                else\n                    complaint=''异常''\n                fi\n            else\n                IpStatus=''正常''\n                complaint=''无需申诉''\n            fi\n            echo "$Ip    $IpStatus    $complaint" >> $(date +%Y%m%d_%H%M%S).log\n        done\n\n}\n\n    Web Server in Awk{\n    \n        #gawk -f file\n        BEGIN { \n          x        = 1                         # script exits if x < 1 \n          port     = 8080                      # port number \n          host     = "/inet/tcp/" port "/0/0"  # host string \n          url      = "http://localhost:" port  # server url \n          status   = 200                       # 200 == OK \n          reason   = "OK"                      # server response \n          RS = ORS = "\\r\\n"                    # header line terminators \n          doc      = Setup()                   # html document \n          len      = length(doc) + length(ORS) # length of document \n          while (x) { \n             if ($1 == "GET") RunApp(substr($2, 2)) \n             if (! x) break   \n             print "HTTP/1.0", status, reason |& host \n             print "Connection: Close"        |& host \n             print "Pragma: no-cache"         |& host \n             print "Content-length:", len     |& host \n             print ORS doc                    |& host \n             close(host)     # close client connection \n             host |& getline # wait for new client request \n          } \n          # server terminated... \n          doc = Bye() \n          len = length(doc) + length(ORS) \n          print "HTTP/1.0", status, reason |& host \n          print "Connection: Close"        |& host \n          print "Pragma: no-cache"         |& host \n          print "Content-length:", len     |& host \n          print ORS doc                    |& host \n          close(host) \n        } \n\n        function Setup() { \n          tmp = "<html>\\\n          <head><title>Simple gawk server</title></head>\\\n          <body>\\\n          <p><a href=" url "/xterm>xterm</a>\\\n          <p><a href=" url "/xcalc>xcalc</a>\\\n          <p><a href=" url "/xload>xload</a>\\\n          <p><a href=" url "/exit>terminate script</a>\\\n          </body>\\\n          </html>" \n          return tmp \n        } \n\n        function Bye() { \n          tmp = "<html>\\\n          <head><title>Simple gawk server</title></head>\\\n          <body><p>Script Terminated...</body>\\\n          </html>" \n          return tmp \n        } \n\n        function RunApp(app) { \n          if (app == "xterm")  {system("xterm&"); return} \n          if (app == "xcalc" ) {system("xcalc&"); return} \n          if (app == "xload" ) {system("xload&"); return} \n          if (app == "exit")   {x = 0} \n        }\n\n    }\n\n}\n\n\n\n不定期更新下载地址：\nhttp://pan.baidu.com/s/1sjsFrmX\nhttps://github.com/liquanzhou/ops_doc\n\n请勿删除信息, 植入广告, 抵制不道德行为\n\n\n\n\n\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(137, 'top_man', 'Top 截屏\r\n	    08:28:14 up 30 days, 5:28, 4 users, load average: 0.00, 0.00, 0.00\r\n\r\n	　　Tasks: 150 total, 1 running, 149 sleeping, 0 stopped, 0 zombie\r\n\r\n	　　Cpu(s): 0.0% us, 0.0% sy, 0.0% ni, 99.9% id, 0.0% wa, 0.1% hi, 0.0% si\r\n\r\n	　　Mem: 2070564k total, 1340828k used, 729736k free, 168636k buffers\r\n\r\n	　　Swap: 4192924k total, 0k used, 4192924k free, 894080k cached\r\n\r\n	　　PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND\r\n\r\n	　　1 root 20 0 1696 544 468 S 0 0.0 0:05.96 init\r\n\r\n	　　2 root 15 -5 0 0 0 S 0 0.0 0:00.00 kthreadd\r\n\r\n	　　3 root RT -5 0 0 0 S 0 0.0 0:00.10 migration/0\r\n\r\n	　　4 root 15 -5 0 0 0 S 0 0.0 0:00.00 ksoftirqd/0\r\n\r\n	　　5 root RT -5 0 0 0 S 0 0.0 0:00.74 watchdog/0\r\n\r\n	　　6 root RT -5 0 0 0 S 0 0.0 0:00.16 migration/1\r\n\r\n	　　7 root 15 -5 0 0 0 S 0 0.0 0:00.02 ksoftirqd/1\r\n\r\n统计信息区\r\n\r\n	　　前五行是系统整体的统计信息。第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下：\r\n\r\n	　　01:06:48 当前时间\r\n\r\n	　　up 1:22 系统运行时间，格式为时:分\r\n\r\n	　　1 user 当前登录用户数\r\n\r\n	　　load average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。\r\n\r\n	　　三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。\r\n\r\n	　  第二、三行为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下：\r\n\r\n	　　Tasks: 29 total 进程总数\r\n\r\n	　　1 running 正在运行的进程数\r\n\r\n	　　28 sleeping 睡眠的进程数\r\n\r\n	　　0 stopped 停止的进程数\r\n\r\n	　　0 zombie 僵尸进程数\r\n\r\n	　　Cpu(s): 0.3% us 用户空间占用CPU百分比\r\n\r\n	　　1.0% sy 内核空间占用CPU百分比\r\n\r\n	　　0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比\r\n\r\n	　　98.7% id 空闲CPU百分比\r\n\r\n	　　0.0% wa 等待输入输出的CPU时间百分比\r\n\r\n	　　0.0% hi\r\n\r\n	　　0.0% si\r\n\r\n	　　最后两行为内存信息。内容如下：\r\n\r\n	　　Mem: 2070564k total 物理内存总量\r\n\r\n	　　1340828k used 使用的物理内存总量\r\n\r\n	　　729736k free 空闲内存总量\r\n\r\n	　　168636k buffers 用作内核缓存的内存量\r\n\r\n	　　Swap: 4192924k total 交换区总量\r\n\r\n	　　0k used 使用的交换区总量\r\n\r\n	　　4192924k free 空闲交换区总量\r\n\r\n	　　894080k cached 缓冲的交换区总量。\r\n\r\n	　　内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，\r\n\r\n	　　该数值即为这些内容已存在于内存中的交换区的大小。\r\n\r\n	　　相应的内存再次被换出时可不必再对交换区写入。\r\n\r\n进程信息区\r\n\r\n	　　统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。\r\n\r\n	　　序号 列名 含义\r\n\r\n	　　a PID 进程id\r\n\r\n	　　b PPID 父进程id\r\n\r\n	　　c RUSER Real user name\r\n\r\n	　　d UID 进程所有者的用户id\r\n\r\n	　　e USER 进程所有者的用户名\r\n\r\n	　　f GROUP 进程所有者的组名\r\n\r\n	　　g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ?\r\n\r\n	　　h PR 优先级\r\n\r\n	　　i NI nice值。负值表示高优先级，正值表示低优先级\r\n\r\n	　　j P 最后使用的CPU，仅在多CPU环境下有意义\r\n\r\n	　　k %CPU 上次更新到现在的CPU时间占用百分比\r\n\r\n	　　l TIME 进程使用的CPU时间总计，单位秒\r\n\r\n	　　m TIME+ 进程使用的CPU时间总计，单位1/100秒\r\n\r\n	　　n %MEM 进程使用的物理内存百分比\r\n\r\n	　　o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\r\n\r\n	　　p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。\r\n\r\n	　　q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\r\n\r\n	　　r CODE 可执行代码占用的物理内存大小，单位kb\r\n\r\n	　　s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb\r\n\r\n	　　t SHR 共享内存大小，单位kb\r\n\r\n	　　u nFLT 页面错误次数\r\n\r\n	　　v nDRT 最后一次写入到现在，被修改过的页面数。\r\n\r\n	　　w S 进程状态。\r\n\r\n	　　D=不可中断的睡眠状态\r\n\r\n	　　R=运行\r\n\r\n	　　S=睡眠\r\n\r\n	　　T=跟踪/停止\r\n\r\n	　　Z=僵尸进程\r\n\r\n	　　x COMMAND 命令名/命令行\r\n\r\n	　　y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名\r\n\r\n	　　z Flags 任务标志，参考 sched.h\r\n\r\n	　　默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷键来更改显示内容。\r\n\r\n更改显示内容\r\n\r\n	通过f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。\r\n\r\n	按o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z 可以将相应的列向左移动。最后按回车键确定。\r\n\r\n	按大写的F 或O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的R 键可以将当前的排序倒转。\r\n\r\n命令使用\r\n\r\n1． 工具（命令）名称\r\n	top\r\n2．工具（命令）作用\r\n	显示系统当前的进程和其他状况； top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定. \r\n3．环境设置\r\n	在Linux下使用。\r\n4．使用方法\r\n4．1使用格式\r\n	top [-] [d] [p] [q] [c] [C] [S] [s] [n] \r\n4．2参数说明\r\n	d 指定每两次屏幕信息刷新之间的时间间隔。当然用户可以使用s交互命令来改变之。\r\n	p 通过指定监控进程ID来仅仅监控某个进程的状态。\r\n	q该选项将使top没有任何延迟的进行刷新。如果调用程序有超级用户权限，那么top将以尽可能高的优先级运行。\r\n	S 指定累计模式\r\n	s 使top命令在安全模式中运行。这将去除交互命令所带来的潜在危险。\r\n	i 使top不显示任何闲置或者僵死进程。\r\n	c 显示整个命令行而不只是显示命令名\r\n4.3其他\r\n	下面介绍在top命令执行过程中可以使用的一些交互命令。从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。这些命令都是单字母的，如果在命令行选项中使用了s选项，则可能其中一些命令会被屏蔽掉。\r\n	Ctrl+L 擦除并且重写屏幕。\r\n	h或者? 显示帮助画面，给出一些简短的命令总结说明。\r\n	k 终止一个进程。系统将提示用户输入需要终止的进程PID，以及需要发送给该进程什么样的信号。一般的终止进程可以使用15信号；如果不能正常结束那就使用信号9强制结束该进程。默认值是信号15。在安全模式中此命令被屏蔽。\r\n	i 忽略闲置和僵死进程。这是一个开关式命令。\r\n	q 退出程序。\r\n	r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程PID以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是10。\r\n	S 切换到累计模式。\r\n	s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为s。如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。\r\n	f或者F 从当前显示中添加或者删除项目。\r\n	o或者O 改变显示项目的顺序。\r\n	l 切换显示平均负载和启动时间信息。\r\n	m 切换显示内存信息。\r\n	t 切换显示进程和CPU状态信息。\r\n	c 切换显示命令名称和完整命令行。\r\n	M 根据驻留内存大小进行排序。\r\n	P 根据CPU使用百分比大小进行排序。\r\n	T 根据时间/累计时间进行排序。\r\n	W 将当前设置写入~/.toprc文件中。这是写top配置文件的推荐方法。', ''),
(140, 'install', 'sys=`grep -Eio "(centos|ubuntu)" /etc/issue`\n\nsys=$(echo $sys|tr ''[A-Z]'' ''[a-z]'')\n\n\ninstall_centos(){\n\nyum groupinstall -y "Development tools"\nyum install -y python-devel\nyum install -y unzip\n\n\n}\n\ninstall_ubuntu(){\n\napt-get install -y build-essential\napt-get install -y python-devel\napt-get install -y unzip\n\n\n}\n\n\n\nis_install(){\n\n yy=$(echo echo `which "$1"`|grep -o "$1")\n\n\n if [ -z $yy ];then\n\n  return 0\n\n else\n\n  return 1\n\n fi \n\n}\n\n\ninstall_pip()\n{\nis_install pip\n\nif [ $? -eq 0 ];then\n\nwget https:\n\ntar xzvf /tmp/setuptools-0.6c11.tar.gz\n\nwget https://github.com/sjqzhang/pylib/raw/master/pip-6.1.1.tar.gz  -O /tmp/pip-6.1.1.tar.gz\n\ntar xzvf /tmp/pip-6.1.1.tar.gz\n\ncd setuptools-0.6c11\n\npython setup.py install\n\ncd ..\n\ncd pip-6.1.1\n\npython setup.py install\n\n\nfi \n\n}\n\n\n\ninstall_pycodeigniter(){\n\n\n\nwget https://github.com/sjqzhang/PyCodeigniter/archive/master.zip -O PyCodeigniter.zip\n\nunzip -o PyCodeigniter.zip\n\n\ncd PyCodeigniter-master\n\n\npip install -r requirements.txt\n\npython setup.py install \n      \n\n}\n\n\n\n\n\n\n\nwhile getopts i:h name\ndo\n    case $OPTARG in\n    all)\n	intall_${sys}\n        install_pip\n	install_pycodeigniter\n    ;;\n    sys)  \n        \n        install_${sys}\n    ;;\n    pip)  \n        install_pip\n    ;;\n    pycodeigniter)  \n	install_pycodeigniter\n    ;;\n    \\?) \n        echo "USAGE:`basename $0` [-i sys pip pycodeigniter]"\n        exit  1\n    ;;\n    *) \n        echo "USAGE:`basename $0` [-i sys pip pycodeigniter]"\n        exit  1\n    ;;\n    esac\ndone\n      \nif [ 0 -eq $# ];then\n	echo "USAGE:`basename $0` [-i sys pip pycodeigniter]"\nfi\n', ''),
(139, 'egrep', 'egrep -v (#|^$) /usr/local/zabbix/etc/zabbix_agent.conf', ''),
(141, 'fuser', 'fuser -m /mnt/', ''),
(142, 'ln', ' -n /abc /cdf', ''),
(165, 'cmd', '#!/usr/bin/python\n\nserver_url="172.16.3.92:8044"\n#server_url="10.2.155.100:8044"\nserver_url="cmdhelp.applinzi.com/cmdhelp.php/"\n\nimport sys,os,urllib2,urllib\n\nimport time\nimport re\n\n\n\ndef urlencode(str):\n    reprStr=repr(str).replace(r''\\x'',''%'')\n    return reprStr[1:-1]\n\ndef download(filename):\n    data={''file'':filename}\n    data=urllib.urlencode(data)\n    http_url=''http://%s/Index/download?%s'' % (server_url,data)\n    conn = urllib2.urlopen(http_url)\n    f = open(filename,''wb'')\n    f.write(conn.read())\n    f.close()\n\ndef upload(filepath):\n    boundary = ''----------%s'' % hex(int(time.time() * 1000))\n    data = []\n    data.append(''--%s'' % boundary)\n    fr=open(filepath,''rb'')\n    filename=os.path.basename(filepath)\n    data.append(''Content-Disposition: form-data; name="%s"; filename="%s"'' % (''file'',filename))\n    data.append(''Content-Type: %s\\r\\n'' % ''image/png'')\n    data.append(fr.read())\n    fr.close()\n    data.append(''--%s--\\r\\n'' % boundary)\n\n\n    http_url=''http://%s/Index/upload'' % server_url\n    # http_url=''http://172.16.136.98:8005/Index/index''\n    http_body=''\\r\\n''.join(data)\n    try:\n        req=urllib2.Request(http_url, data=http_body)\n        req.add_header(''Content-Type'', ''multipart/form-data; boundary=%s'' % boundary)\n        req.add_header(''User-Agent'',''Mozilla/5.0'')\n        req.add_header(''Referer'',''http://remotserver.com/'')\n        resp = urllib2.urlopen(req, timeout=5)\n        qrcont=resp.read()\n        print qrcont\n    except Exception,e:\n        print ''http error''\n\ndef url_fetch(url,data=None):\n        html='''';\n        # print(url)\n        try:\n            headers = {\n                ''User-Agent'':''Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6''\n            }\n            if data!=None:\n                data=urllib.urlencode(data)\n            req = urllib2.Request(\n                url =url,\n                headers = headers,\n                data=data\n            )\n            html=urllib2.urlopen(req,timeout=15).read()\n            charset=re.compile(r''<meta[^>]*charset=[\\''\\"]*?([a-z0-8\\-]+)[\\''\\"]?[^>]*?>'',re.IGNORECASE).findall(html)\n            if len(charset) >0:\n                if charset[0]==''gb2312'':\n                    charset[0]=''gbk''\n                html=unicode(html,charset[0])\n            # print(html)\n        except Exception as e:\n            print e\n        return html\n\ndef help():\n    help=''''''\nhelp:\ncmd add command 	# save the command to server\ncmd list 		# show server command\ncmd search/help command 	# search command from server\ncmd addfile/file command filename # upload configfile to server\ncmd del cmd No      # delete cmd for exmale: cmd del 1\n''''''\n    print help\n    sys.exit(0)\n\n\ndef main(action,server_url):\n    if action==''add'' or action==''a'':\n        cmdinfo= str( " ".join(sys.argv[2:]))\n        try:\n            cmdinfo=unicode(cmdinfo,"utf-8")\n        except Exception as e:\n            try:\n                cmdinfo=unicode(cmdinfo,"gbk").encode("utf-8")\n            except Exception as ee:\n                print "error param"\n                sys.exit(0)\n        print url_fetch(''http://%s/add''%server_url,{''cmdinfo'':" ".join(sys.argv[2:])})\n    elif action==''listfile'':\n        result= url_fetch(''http://%s/listfile''%server_url)\n        if result=='''':\n            print "not found"\n        result=re.sub(r''^\\"|\\"$'',"",result)\n        rs= re.split(r''\\<brbr\\>'',result)\n        for r in rs:\n            print str(r).decode(''utf-8'')\n    elif action==''list'' or action==''l'':\n        result= url_fetch(''http://%s/list''%server_url)\n        if result=='''':\n            print "not found"\n        result=re.sub(r''^\\"|\\"$'',"",result)\n        rs= re.split(r''\\<brbr\\>'',result)\n        for r in rs:\n            print str(r).decode(''utf-8'')\n    elif action==''get'':\n        if len(sys.argv)>2:\n            print url_fetch(''http://%s/get''%server_url,{''id'':sys.argv[2]})\n        else:\n            print ""\n    elif action==''delfile'':\n        if len(sys.argv)>2:\n            print url_fetch(''http://%s/delfile''%server_url,{''id'':sys.argv[2]})\n        else:\n            print ""\n    elif action==''del'':\n        if len(sys.argv)>2:\n            print url_fetch(''http://%s/delete''%server_url,{''id'':sys.argv[2]})\n        else:\n            print ""\n    elif action==''download'':\n        download(sys.argv[2])\n    elif action==''upload'':\n        upload(sys.argv[2])\n        return\n    elif action==''file'' or action==''addfile'':\n        if len(sys.argv)<3:\n            print "cmd file command file name"\n            return\n        if len(sys.argv)==5:\n            description=sys.argv[4]\n        else:\n            description=''''\n        filepath=sys.argv[3]\n        cmd=sys.argv[2]\n        content=''''\n        if os.path.exists(filepath):\n            content=open(filepath,''r'').read()\n\n        if content=='''':\n            print ''read error''\n            return\n\n        print url_fetch(''http://%s/add_file''%server_url,{''cmd'':cmd, ''cmdinfo'':content,''description'':description})\n\n    elif action==''upgrade'':\n        result= url_fetch(''http://%s/upgrade''%server_url)\n        if result=='''':\n            print "not found"\n            sys.exit(0)\n        result=re.sub(r''^\\"|\\"$'',"",result)\n        rs= re.split(r''\\<brbr\\>'',result)\n        open(''/bin/cmd'',''w'').write(result)\n\n    elif action==''gen'' or action==''update'':\n        result= url_fetch(''http://%s/list''%server_url)\n        if result=='''':\n            print "not found"\n            sys.exit(0)\n        result=re.sub(r''^\\"|\\"$'',"",result)\n        rs= re.split(r''\\<brbr\\>'',result)\n        cmds=[''update'',''upgrade'',''add'',''addfile'',''list'',''search'',''del'']\n        rs=rs+cmds\n        cpl=''complete -W "''+ '' ''.join(rs) +''" cmd''\n        tmp=''''''\n        cat > /tmp/cmdhelp.sh<<EOF\n\n%s\n\nEOF'''''' % cpl\n        os.system(tmp)\n        #os.system(''sh /tmp/cmdhelp.sh'')\n        #os.system(''sh /tmp/cmdhelp.sh'')\n        #print cpl\n        print(''source /tmp/cmdhelp.sh'')\n\n    elif action==''--help'' or action==''-h'':\n\n        help()\n    else:\n        result=''''\n        if len(sys.argv)>2:\n            result= url_fetch(''http://%s/search''%server_url,{''keyword'':sys.argv[2]})\n        else:\n            result= url_fetch(''http://%s/search''%server_url,{''keyword'':action})\n        if result=='''':\n            print "not found"\n	if isinstance(result,unicode):\n	    result= unicode.encode(result,''utf-8'')\n            rs= re.split(r''\\<brbr\\>'',result)\n	    print "\\n".join(rs)\n        else:\n            rs= re.split(r''\\<brbr\\>'',result)\n	    print "\\n".join(rs)\nif len(sys.argv)<2:\n    help()\n    sys.exit(0)\naction=sys.argv[1]\n\n\n#print sys.argv\n\nif __name__ == ''__main__'':\n    main(action,server_url)\n\n\n\n\n\n\n\n\n\n#url.url_fetch(''http://127.0.0.1:8005/add'',{''cmdinfo'':"rm -rf abc"})\n\n\n\n\n\n\n\n\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(149, 'go', '	引言\r\n\r\n	示例\r\n\r\n	格式化\r\n\r\n	注释\r\n\r\n	命名\r\n\r\n	包名\r\n\r\n	获取器\r\n\r\n	接口名\r\n\r\n	驼峰记法\r\n\r\n	分号\r\n\r\n	控制结构\r\n\r\n	If\r\n\r\n	重新声明与再次赋值\r\n\r\n	For\r\n\r\n	Switch\r\n\r\n	类型选择\r\n\r\n	函数\r\n\r\n	多值返回\r\n\r\n	可命名结果形参\r\n\r\n	Defer\r\n\r\n	数据\r\n\r\n	new 分配\r\n\r\n	构造函数与复合字面\r\n\r\n	make 分配\r\n\r\n	数组\r\n\r\n	切片\r\n\r\n	二维切片\r\n\r\n	映射\r\n\r\n	打印\r\n\r\n	追加\r\n\r\n	初始化\r\n\r\n	常量\r\n\r\n	变量\r\n\r\n	init 函数\r\n\r\n	方法\r\n\r\n	指针 vs. 值\r\n\r\n	接口与其它类型\r\n\r\n	接口\r\n\r\n	类型转换\r\n\r\n	接口转换与类型断言\r\n\r\n	通用性\r\n\r\n	接口和方法\r\n\r\n	空白标识符\r\n\r\n	多重赋值中的空白标识符\r\n\r\n	未使用的导入和变量\r\n\r\n	为副作用而导入\r\n\r\n	接口检查\r\n\r\n	内嵌\r\n\r\n	并发\r\n\r\n	通过通信共享内存\r\n\r\n	Go程\r\n\r\n	信道\r\n\r\n	信道中的信道\r\n\r\n	并行化\r\n\r\n	可能泄露的缓冲区\r\n\r\n	错误\r\n\r\n	Panic\r\n\r\n	恢复\r\n\r\n	一个Web服务器\r\n\r\n\r\n\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(150, 'go', '	引言\r\n\r\n	示例\r\n\r\n	格式化\r\n\r\n	注释\r\n\r\n	命名\r\n\r\n	包名\r\n\r\n	获取器\r\n\r\n	接口名\r\n\r\n	驼峰记法\r\n\r\n	分号\r\n\r\n	控制结构\r\n\r\n	If\r\n\r\n	重新声明与再次赋值\r\n\r\n	For\r\n\r\n	Switch\r\n\r\n	类型选择\r\n\r\n	函数\r\n\r\n	多值返回\r\n\r\n	可命名结果形参\r\n\r\n	Defer\r\n\r\n	数据\r\n\r\n	new 分配\r\n\r\n	构造函数与复合字面\r\n\r\n	make 分配\r\n\r\n	数组\r\n\r\n	切片\r\n\r\n	二维切片\r\n\r\n	映射\r\n\r\n	打印\r\n\r\n	追加\r\n\r\n	初始化\r\n\r\n	常量\r\n\r\n	变量\r\n\r\n	init 函数\r\n\r\n	方法\r\n\r\n	指针 vs. 值\r\n\r\n	接口与其它类型\r\n\r\n	接口\r\n\r\n	类型转换\r\n\r\n	接口转换与类型断言\r\n\r\n	通用性\r\n\r\n	接口和方法\r\n\r\n	空白标识符\r\n\r\n	多重赋值中的空白标识符\r\n\r\n	未使用的导入和变量\r\n\r\n	为副作用而导入\r\n\r\n	接口检查\r\n\r\n	内嵌\r\n\r\n	并发\r\n\r\n	通过通信共享内存\r\n\r\n	Go程\r\n\r\n	信道\r\n\r\n	信道中的信道\r\n\r\n	并行化\r\n\r\n	可能泄露的缓冲区\r\n\r\n	错误\r\n\r\n	Panic\r\n\r\n	恢复\r\n\r\n	一个Web服务器\r\n\r\n\r\n\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(151, 'go', '	引言\r\n\r\n	示例\r\n\r\n	格式化\r\n\r\n	注释\r\n\r\n	命名\r\n\r\n	包名\r\n\r\n	获取器\r\n\r\n	接口名\r\n\r\n	驼峰记法\r\n\r\n	分号\r\n\r\n	控制结构\r\n\r\n	If\r\n\r\n	重新声明与再次赋值\r\n\r\n	For\r\n\r\n	Switch\r\n\r\n	类型选择\r\n\r\n	函数\r\n\r\n	多值返回\r\n\r\n	可命名结果形参\r\n\r\n	Defer\r\n\r\n	数据\r\n\r\n	new 分配\r\n\r\n	构造函数与复合字面\r\n\r\n	make 分配\r\n\r\n	数组\r\n\r\n	切片\r\n\r\n	二维切片\r\n\r\n	映射\r\n\r\n	打印\r\n\r\n	追加\r\n\r\n	初始化\r\n\r\n	常量\r\n\r\n	变量\r\n\r\n	init 函数\r\n\r\n	方法\r\n\r\n	指针 vs. 值\r\n\r\n	接口与其它类型\r\n\r\n	接口\r\n\r\n	类型转换\r\n\r\n	接口转换与类型断言\r\n\r\n	通用性\r\n\r\n	接口和方法\r\n\r\n	空白标识符\r\n\r\n	多重赋值中的空白标识符\r\n\r\n	未使用的导入和变量\r\n\r\n	为副作用而导入\r\n\r\n	接口检查\r\n\r\n	内嵌\r\n\r\n	并发\r\n\r\n	通过通信共享内存\r\n\r\n	Go程\r\n\r\n	信道\r\n\r\n	信道中的信道\r\n\r\n	并行化\r\n\r\n	可能泄露的缓冲区\r\n\r\n	错误\r\n\r\n	Panic\r\n\r\n	恢复\r\n\r\n	一个Web服务器\r\n\r\n\r\n\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n 实效Go编程\r\n\r\n\r\n 引言\r\n\r\n\r\n	Go 是一门全新的语言。尽管它从既有的语言中借鉴了许多理念，但其与众不同的特性，\r\n	使得使用Go编程在本质上就不同于其它语言。将现有的C++或Java程序直译为Go\r\n	程序并不能令人满意——毕竟Java程序是用Java编写的，而不是Go。\r\n	另一方面，若从Go的角度去分析问题，你就能编写出同样可行但大不相同的程序。\r\n	换句话说，要想将Go程序写得好，就必须理解其特性和风格。了解命名、格式化、\r\n	程序结构等既定规则也同样重要，这样你编写的程序才能更容易被其他程序员所理解。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n	本文档就如何编写清晰、地道的Go代码提供了一些技巧。它是对[语言规范](http://172.16.132.221:8081/ref/spec)、\r\n	[Go语言之旅](https://go-tour-zh.appspot.com/)以及\r\n	[如何使用Go编程](http://172.16.132.221:8081/doc/code.html)的补充说明，因此我们建议您先阅读这些文档。\r\n\r\n 示例\r\n\r\n\r\n	[Go包的源码](http://172.16.132.221:8081/src/pkg/)不仅是核心库，同时也是学习如何使用Go语言的示例源码。\r\n	此外，其中的一些包还包含了可工作的，独立的可执行示例，你可以直接在\r\n	[golang.org](http://golang.org)网站上运行它们，比如\r\n	[这个例子](http://zh.golanger.com/pkg/strings/#example_Map)\r\n	（单击文字“示例”来展开它）。如果你有任何关于某些问题如何解决，或某些东西如何实现的疑问，\r\n	也可以从中获取相关的答案、思路以及后台实现。\r\n\r\n 格式化\r\n\r\n\r\n	格式化问题总是充满了争议，但却始终没有形成统一的定论。虽说人们可以适应不同的编码风格，\r\n	但抛弃这种适应过程岂不更好？若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。\r\n	问题就在于如何实现这种设想，而无需冗长的语言风格规范。\r\n\r\n	在Go中我们另辟蹊径，让机器来处理大部分的格式化问题。gofmt\r\n	程序（也可用 go fmt，它以包为处理对象而非源文件）将Go程序按照标准风格缩进、\r\n	对齐，保留注释并在需要时重新格式化。若你想知道如何处理一些新的代码布局，请尝试运行\r\n	gofmt；若结果仍不尽人意，请重新组织你的程序（或提交有关 gofmt\r\n	的Bug），而不必为此纠结。\r\n\r\n	举例来说，你无需花时间将结构体中的字段注释对齐，gofmt 将为你代劳。\r\n	假如有以下声明：\r\n\r\n	```\r\n	type T struct {\r\n		name string // 对象名\r\n		value int // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	gofmt 会将它按列对齐为：\r\n\r\n	```\r\n	type T struct {\r\n		name    string // 对象名\r\n		value   int    // 对象值\r\n	}\r\n\r\n	```\r\n\r\n	标准包中所有的Go代码都已经用 gofmt 格式化过了。\r\n\r\n	还有一些关于格式化的细节，它们非常简短：\r\n\r\n	缩进\r\n		\r\n		我们使用制表符（tab）缩进，gofmt 默认也使用它。在你认为确实有必要时再使用空格。\r\n		\r\n		行的长度\r\n		\r\n		Go对行的长度没有限制，别担心打孔纸不够长。如果一行实在太长，也可进行折行并插入适当的tab缩进。\r\n		\r\n		括号\r\n		\r\n		比起C和Java，Go所需的括号更少：控制结构（if、for 和\r\n		switch）在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁，因此\r\n\r\n	```\r\n	x<<8 + y<<16\r\n\r\n	```\r\n\r\n		正表述了空格符所传达的含义。\r\n		\r\n\r\n 注释\r\n\r\n\r\n	Go语言支持C风格的块注释 /* */ 和C++风格的行注释 //。\r\n	行注释更为常用，而块注释则主要用作包的注释，当然也可在禁用一大段代码时使用。\r\n\r\n	godoc 既是一个程序，又是一个Web服务器，它对Go的源码进行处理，并提取包中的文档内容。\r\n	出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。\r\n	这些注释的类型和风格决定了 godoc 生成的文档质量。\r\n\r\n	每个包都应包含一段包注释，即放置在包子句前的一个块注释。对于包含多个文件的包，\r\n	包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。\r\n	它将出现在 godoc 页面中的最上面，并为紧随其后的内容建立详细的文档。\r\n\r\n	```\r\n	/*\r\n		regexp 包为正则表达式实现了一个简单的库。\r\n\r\n		该库接受的正则表达式语法为：\r\n\r\n		正则表达式:\r\n			串联 { ''|'' 串联 }\r\n		串联:\r\n			{ 闭包 }\r\n		闭包:\r\n			条目 [ ''*'' | ''+'' | ''?'' ]\r\n		条目:\r\n			''^''\r\n			''$''\r\n			''.''\r\n			字符\r\n			''['' [ ''^'' ] 字符遍历 '']''\r\n			''('' 正则表达式 '')''\r\n	*/\r\n	package regexp\r\n\r\n	```\r\n\r\n	若某个包比较简单，包注释同样可以简洁些。\r\n\r\n	```\r\n	// path 包实现了一些常用的工具，以便于操作用反斜杠分隔的路径.\r\n\r\n	```\r\n\r\n	注释无需进行额外的格式化，如用星号来突出等。生成的输出甚至可能无法以等宽字体显示，\r\n	因此不要依赖于空格对齐，godoc 会像 gofmt 那样处理好这一切。\r\n	注释是不会被解析的纯文本，因此像HTML或其它类似于 _这样_ 的东西将按照\r\n	原样 输出，因此不应使用它们。godoc 所做的调整，\r\n	就是将已缩进的文本以等宽字体显示，来适应对应的程序片段。\r\n	[fmt 包](http://golang.org/pkg/fmt/)的注释就用了这种不错的效果。\r\n\r\n	godoc 是否会重新格式化注释取决于上下文，因此必须确保它们看起来清晰易辨：\r\n	使用正确的拼写、标点和语句结构以及折叠长行等。\r\n\r\n	在包中，任何顶级声明前面的注释都将作为该声明的文档注释。\r\n	在程序中，每个可导出（首字母大写）的名称都应该有文档注释。\r\n\r\n	文档注释最好是完整的句子，这样它才能适应各种自动化的展示。\r\n	第一句应当以被声明的东西开头，并且是单句的摘要。\r\n\r\n	```\r\n	// Compile 用于解析正则表达式并返回，如果成功，则 Regexp 对象就可用于匹配所针对的文本。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n\r\n	```\r\n\r\n	若注释总是以名称开头，godoc 的输出就能通过 grep\r\n	变得更加有用。假如你记不住“Compile”这个名称，而又在找正则表达式的解析函数，\r\n	那就可以运行\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n\r\n	```\r\n\r\n	若包中的所有文档注释都以“此函数…”开头，grep 就无法帮你记住此名称。\r\n	但由于每个包的文档注释都以其名称开头，你就能看到这样的内容，它能显示你正在寻找的词语。\r\n\r\n	```\r\n	$ godoc regexp | grep parse\r\n		Compile parses a regular expression and returns, if successful, a Regexp\r\n		parsed. It simplifies safe initialization of global variables holding\r\n		cannot be parsed. It simplifies safe initialization of global variables\r\n	$\r\n\r\n	```\r\n\r\n	Go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。\r\n	由于是整体声明，这种注释往往较为笼统。\r\n\r\n	```\r\n	// 表达式解析失败后返回错误代码。\r\n	var (\r\n		ErrInternal      = errors.New("regexp: internal error")\r\n		ErrUnmatchedLpar = errors.New("regexp: unmatched ''(''")\r\n		ErrUnmatchedRpar = errors.New("regexp: unmatched '')''")\r\n		...\r\n	)\r\n\r\n	```\r\n\r\n	即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。\r\n\r\n	```\r\n	var (\r\n		countLock   sync.Mutex\r\n		inputCount  uint32\r\n		outputCount uint32\r\n		errorCount  uint32\r\n	)\r\n\r\n	```\r\n\r\n 命名\r\n\r\n\r\n	正如命名在其它语言中的地位，它在 Go 中同样重要。有时它们甚至会影响语义：\r\n	例如，某个名称在包外是否可见，就取决于其首个字符是否为大写字母。\r\n	因此有必要花点时间来讨论Go程序中的命名约定。\r\n\r\n 包名\r\n\r\n\r\n	当一个包被导入后，包名就会成了内容的访问器。在\r\n\r\n	```\r\n	import "bytes"\r\n\r\n	```\r\n\r\n	之后，被导入的包就能通过 bytes.Buffer 来引用了。\r\n	若所有人都以相同的名称来引用其内容将大有裨益，\r\n	这也就意味着包应当有个恰当的名称：其名称应该简洁明了而易于理解。按照惯例，\r\n	包应当以小写的单个单词来命名，且不应使用下划线或驼峰记法。err\r\n	的命名就是出于简短考虑的，因为任何使用该包的人都会键入该名称。\r\n	不必担心引用次序的冲突。包名就是导入时所需的唯一默认名称，\r\n	它并不需要在所有源码中保持唯一，即便在少数发生冲突的情况下，\r\n	也可为导入的包选择一个别名来局部使用。\r\n	无论如何，通过文件名来判定使用的包，都是不会产生混淆的。\r\n\r\n	另一个约定就是包名应为其源码目录的基本名称。在 src/pkg/encoding/base64\r\n	中的包应作为 "encoding/base64" 导入，其包名应为 base64，\r\n	而非 encoding_base64 或 encodingBase64。\r\n\r\n	包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。\r\n	（请勿使用 import . 记法，它可以简化必须在被测试包外运行的测试，\r\n	除此之外应尽量避免使用。）例如，bufio 包中的缓存读取器类型叫做\r\n	Reader 而非 BufReader，因为用户将它看做\r\n	bufio.Reader，这是个清楚而简洁的名称。\r\n	此外，由于被导入的项总是通过它们的包名来确定，因此 bufio.Reader\r\n	不会与 io.Reader 发生冲突。同样，用于创建 ring.Ring\r\n	的新实例的函数（这就是Go中的\r\n\r\n 构造函数\r\n\r\n\r\n	）一般会称之为\r\n	NewRing，但由于 Ring 是该包所导出的唯一类型，且该包也叫\r\n	ring，因此它可以只叫做 New，它跟在包的后面，就像\r\n	ring.New。使用包结构可以帮助你选择好的名称。\r\n\r\n	另一个简短的例子是 once.Do，once.Do(setup) 表述足够清晰，\r\n	使用 once.DoOrWaitUntilDone(setup) 完全就是画蛇添足。\r\n	长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。\r\n\r\n 获取器\r\n\r\n\r\n	Go并不对获取器（getter）和设置器（setter）提供自动支持。\r\n	你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get\r\n	放到获取器的名字中，既不符合习惯，也没有必要。若你有个名为 owner\r\n	（小写，未导出）的字段，其获取器应当名为 Owner（大写，可导出）而非\r\n	GetOwner。大写字母即为可导出的这种规定为区分方法和字段提供了便利。\r\n	若要提供设置器方法，SetOwner 是个不错的选择。两个命名看起来都很合理：\r\n\r\n	```\r\n	owner := obj.Owner()\r\n	if owner != user {\r\n		obj.SetOwner(user)\r\n	}\r\n\r\n	```\r\n\r\n 接口名\r\n\r\n\r\n	按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如\r\n	Reader、Writer、\r\n	Formatter、CloseNotifier 等。\r\n\r\n	诸如此类的命名有很多，遵循它们及其代表的函数名会让事情变得简单。\r\n	Read、Write、Close、Flush、\r\n	String 等都具有典型的签名和意义。为避免冲突，请不要用这些名称为你的方法命名，\r\n	除非你明确知道它们的签名和意义相同。反之，若你的类型实现了的方法，\r\n	与一个众所周知的类型的方法拥有相同的含义，那就使用相同的命名。\r\n	请将字符串转换方法命名为 String 而非 ToString。\r\n\r\n 驼峰记法\r\n\r\n\r\n	最后，Go中约定使用驼峰记法 MixedCaps 或 mixedCaps。\r\n\r\n 分号\r\n\r\n\r\n	和C一样，Go的正式语法使用分号来结束语句；和C不同的是，这些分号并不在源码中出现。\r\n	取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此因此源码中基本就不用分号了。\r\n\r\n	规则是这样的：若在新行前的最后一个标记为标识符（包括 int 和\r\n	float64 这类的单词）、数值或字符串常量之类的基本字面或以下标记之一\r\n\r\n	```\r\n	break continue fallthrough return ++ -- ) }\r\n\r\n	```\r\n\r\n	则词法分析将始终在该标记后面插入分号。这点可以概括为：\r\n	“如果新行前的标记为语句的末尾，则插入分号”。\r\n\r\n	分号也可在闭括号之前直接省略，因此像\r\n\r\n	```\r\n		go func() { for { dst <- <-src } }()\r\n\r\n	```\r\n\r\n	这样的语句无需分号。通常Go程序只在诸如 for 循环子句这样的地方使用分号，\r\n	以此来将初始化器、条件及增量元素分开。如果你在一行中写多个语句，也需要用分号隔开。\r\n\r\n	警告：无论如何，你都不应将一个控制结构（if、for、switch\r\n	或 select）的左大括号放在下一行。如果这样做，就会在大括号前面插入一个分号，这可能引起不需要的效果。\r\n	你应该这样写\r\n\r\n	```\r\n	if i < f() {\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n	而不是这样\r\n\r\n	```\r\n	if i < f()  // 错！\r\n	{           // 错！\r\n		g()\r\n	}\r\n\r\n	```\r\n\r\n 控制结构\r\n\r\n\r\n	Go中的结构控制与C有许多相似之处，但其不同之处才是独到之处。\r\n	Go不再使用 do 或 while 循环，只有一个更通用的\r\n	for；switch 要更灵活一点；if 和\r\n	switch 像 for一样可接受可选的初始化语句；\r\n	此外，还有一个包含类型选择和多路通信复用器的新控制结构：select。\r\n	其语法也有些许不同：没有圆括号，而其主体必须始终使用大括号括住。\r\n\r\n If\r\n\r\n\r\n	在Go中，一个简单的 if 语句看起来像这样：\r\n\r\n	```\r\n	if x > 0 {\r\n		return y\r\n	}\r\n\r\n	```\r\n\r\n	强制的大括号促使你将简单的 if 语句分成多行。特别是在主体中包含\r\n	return 或 break 等控制语句时，这种编码风格的好处一比便知。\r\n\r\n	由于 if 和 switch 可接受初始化语句，\r\n	因此用它们来设置局部变量十分常见。\r\n\r\n	```\r\n	if err := file.Chmod(0664); err != nil {\r\n		log.Print(err)\r\n		return err\r\n	}\r\n\r\n	```\r\n\r\n	在Go的库中，你会发现若 if 语句不会执行到下一条语句时，亦即其执行体\r\n	以 break、continue、goto 或\r\n	return 结束时，不必要的 else 会被省略。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	codeUsing(f)\r\n\r\n	```\r\n\r\n	下例是一种常见的情况，代码必须防范一系列的错误条件。若控制流成功继续，\r\n	则说明程序已排除错误。由于出错时将以return 结束，\r\n	之后的代码也就无需 else 了。\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n	if err != nil {\r\n		return err\r\n	}\r\n	d, err := f.Stat()\r\n	if err != nil {\r\n		f.Close()\r\n		return err\r\n	}\r\n	codeUsing(f, d)\r\n\r\n	```\r\n\r\n 重新声明与再次赋值\r\n\r\n\r\n	题外话：上一节中最后一个示例展示了短声明 := 如何使用。\r\n	调用了 os.Open 的声明为\r\n\r\n	```\r\n	f, err := os.Open(name)\r\n\r\n	```\r\n\r\n	该语句声明了两个变量 f 和 err。在几行之后，又通过\r\n\r\n	```\r\n	d, err := f.Stat()\r\n\r\n	```\r\n\r\n	调用了 f.Stat。它看起来似乎是声明了 d 和 err。\r\n	注意，尽管两个语句中都出现了 err，但这种重复仍然是合法的：err\r\n	在第一条语句中被声明，但在第二条语句中只是被再次赋值罢了。也就是说，调用\r\n	f.Stat 使用的是前面已经声明的 err，它只是被重新赋值了而已。\r\n\r\n	在满足下列条件时，已被声明的变量 v 可出现在:= 声明中：\r\n\r\n	本次声明与已声明的 v 处于同一作用域中（若 v\r\n	已在外层作用域中声明过，则此次声明会创建一个新的变量§），\r\n\r\n	在初始化中与其类型相应的值才能赋予 v，且\r\n\r\n	在此次声明中至少另有一个变量是新声明的。\r\n\r\n	这个特性简直就是纯粹的实用主义体现，它使得我们可以很方面地只使用一个\r\n	err 值，例如，在一个相当长的 if-else 语句链中，\r\n	你会发现它用得很频繁。\r\n\r\n	§值得一提的是，即便Go中的函数形参和返回值在词法上处于大括号之外，\r\n	但它们的作用域和该函数体仍然相同。\r\n\r\n For\r\n\r\n\r\n	Go的 for 循环类似于C，但却不尽相同。它统一了 for 和\r\n	while，不再有 do-while 了。它有三种形式，但只有一种需要分号。\r\n\r\n	```\r\n	// 如同C的for循环\r\n	for init; condition; post { }\r\n\r\n	// 如同C的while循环\r\n	for condition { }\r\n\r\n	// 如同C的for(;;)循环\r\n	for { }\r\n\r\n	```\r\n\r\n	简短声明能让我们更容易在循环中声明下标变量：\r\n\r\n	```\r\n	sum := 0\r\n	for i := 0; i < 10; i++ {\r\n		sum += i\r\n	}\r\n\r\n	```\r\n\r\n	若你想遍历数组、切片、字符串或者映射，或从信道中读取消息，\r\n	range 子句能够帮你轻松实现循环。\r\n\r\n	```\r\n	for key, value := range oldMap {\r\n		newMap[key] = value\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第一个项（键或下标），去掉第二个就行了：\r\n\r\n	```\r\n	for key := range m {\r\n		if key.expired() {\r\n			delete(m, key)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	若你只需要该遍历中的第二个项（值），请使用空白标识符，即下划线来丢弃第一个值：\r\n\r\n	```\r\n	sum := 0\r\n	for _, value := range array {\r\n		sum += value\r\n	}\r\n\r\n	```\r\n\r\n	空白标识符还有多种用法，它会在[后面的小节](#%E7%A9%BA%E7%99%BD)中描述。\r\n\r\n	对于字符串，range 能够提供更多便利。它能通过解析UTF-8，\r\n	将每个独立的Unicode码点分离出来。错误的编码将占用一个字节，并以符文U+FFFD来代替。\r\n	（名称“符文”和内建类型 rune 是Go对单个Unicode码点的成称谓。\r\n	详情见[语言规范](http://golang.org/ref/spec#%E7%AC%A6%E6%96%87%E5%AD%97%E9%9D%A2)）。循环\r\n\r\n	```\r\n	for pos, char := range "日本\\x80語" { // \\x80 是个非法的UTF-8编码\r\n		fmt.Printf("字符 %#U 始于字节位置 %d\\n", char, pos)\r\n	}\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	字符 U+65E5 ''日'' 始于字节位置 0\r\n	字符 U+672C ''本'' 始于字节位置 3\r\n	字符 U+FFFD ''�'' 始于字节位置 6\r\n	字符 U+8A9E ''語'' 始于字节位置 7\r\n\r\n	```\r\n\r\n	最后，Go没有逗号操作符，而 ++ 和 -- 为语句而非表达式。\r\n	因此，若你想要在 for 中使用多个变量，应采用平行赋值的方式\r\n	（因为它会拒绝 ++ 和 --）.\r\n\r\n	```\r\n	// 反转 a\r\n	for i, j := 0, len(a)-1; i < j; i, j = i+1, j-1 {\r\n		a[i], a[j] = a[j], a[i]\r\n	}\r\n\r\n	```\r\n\r\n Switch\r\n\r\n\r\n	Go的 switch 比C的更通用。其表达式无需为常量或整数，case\r\n	语句会自上而下逐一进行求值直到匹配为止。若 switch 后面没有表达式，它将匹配\r\n	true，因此，我们可以将 if-else-if-else 链写成一个\r\n	switch，这也更符合Go的风格。\r\n\r\n	```\r\n	func unhex(c byte) byte {\r\n		switch {\r\n		case ''0'' <= c && c <= ''9'':\r\n			return c - ''0''\r\n		case ''a'' <= c && c <= ''f'':\r\n			return c - ''a'' + 10\r\n		case ''A'' <= c && c <= ''F'':\r\n			return c - ''A'' + 10\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	switch 并不会自动下溯，但 case\r\n	可通过逗号分隔来列举相同的处理条件。\r\n\r\n	```\r\n	func shouldEscape(c byte) bool {\r\n		switch c {\r\n		case '' '', ''?'', ''&'', ''='', ''#'', ''+'', ''%'':\r\n			return true\r\n		}\r\n		return false\r\n	}\r\n\r\n	```\r\n\r\n	尽管它们在Go中的用法和其它类C语言差不多，但 break\r\n	语句可以使 switch 提前终止。不仅是 switch，\r\n	有时候也必须打破层层的循环。在Go中，我们只需将标签放置到循环外，然后\r\n	“蹦”到那里即可。下面的例子展示了二者的用法。\r\n\r\n	```\r\n	Loop:\r\n		for n := 0; n < len(src); n += size {\r\n			switch {\r\n			case src[n] < sizeOne:\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 1\r\n				update(src[n])\r\n\r\n			case src[n] < sizeTwo:\r\n				if n+1 >= len(src) {\r\n					err = errShortInput\r\n					break Loop\r\n				}\r\n				if validateOnly {\r\n					break\r\n				}\r\n				size = 2\r\n				update(src[n] + src[n+1]<<shift)\r\n			}\r\n		}\r\n\r\n	```\r\n\r\n	当然，continue 语句也能接受一个可选的标签，不过它只能在循环中使用。\r\n\r\n	作为这一节的结束，此程序通过使用两个 switch 语句对字节数组进行比较：\r\n\r\n	```\r\n	// Compare 按字典顺序比较两个字节切片并返回一个整数。\r\n	// 若 a == b，则结果为零；若 a < b；则结果为 -1；若 a > b，则结果为 +1。\r\n	func Compare(a, b []byte) int {\r\n		for i := 0; i < len(a) && i < len(b); i++ {\r\n			switch {\r\n			case a[i] > b[i]:\r\n				return 1\r\n			case a[i] < b[i]:\r\n				return -1\r\n			}\r\n		}\r\n		switch {\r\n		case len(a) > len(b):\r\n			return 1\r\n		case len(a) < len(b):\r\n			return -1\r\n		}\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n 类型选择\r\n\r\n\r\n	switch 也可用于判断接口变量的动态类型。如 类型选择\r\n	通过圆括号中的关键字 type 使用类型断言语法。若 switch\r\n	在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。\r\n\r\n	```\r\n	var t interface{}\r\n	t = functionOfSomeType()\r\n	switch t := t.(type) {\r\n	default:\r\n		fmt.Printf("unexpected type %T", t)       // %T 输出 t 是什么类型\r\n	case bool:\r\n		fmt.Printf("boolean %t\\n", t)             // t 是 bool 类型\r\n	case int:\r\n		fmt.Printf("integer %d\\n", t)             // t 是 int 类型\r\n	case *bool:\r\n		fmt.Printf("pointer to boolean %t\\n", *t) // t 是 *bool 类型\r\n	case *int:\r\n		fmt.Printf("pointer to integer %d\\n", *t) // t 是 *int 类型\r\n	}\r\n\r\n	```\r\n\r\n 函数\r\n\r\n\r\n 多值返回\r\n\r\n\r\n	Go与众不同的特性之一就是函数和方法可返回多个值。这种形式可以改善C中一些笨拙的习惯：\r\n	将错误值返回（例如用 -1 表示 EOF）和修改通过地址传入的实参。\r\n\r\n	在C中，写入操作发生的错误会用一个负数标记，而错误码会隐藏在某个不确定的位置。\r\n	而在Go中，Write 会返回写入的字节数以及一个错误：\r\n	“是的，您写入了一些字节，但并未全部写入，因为设备已满”。\r\n	在 os 包中，File.Write 的签名为：\r\n\r\n	```\r\n	func (file *File) Write(b []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	正如文档所述，它返回写入的字节数，并在n != len(b) 时返回一个非\r\n	nil 的 error 错误值。\r\n	这是一种常见的编码风格，更多示例见错误处理一节。\r\n\r\n	我们可以采用一种简单的方法。来避免为模拟引用参数而传入指针。\r\n	以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。\r\n\r\n	```\r\n	func nextInt(b []byte, i int) (int, int) {\r\n		for ; i < len(b) && !isDigit(b[i]); i++ {\r\n		}\r\n		x := 0\r\n		for ; i < len(b) && isDigit(b[i]); i++ {\r\n			x = x*10 + int(b[i]) - ''0''\r\n		}\r\n		return x, i\r\n	}\r\n\r\n	```\r\n\r\n	你可以像下面这样，通过它扫描输入的切片 b 来获取数字。\r\n\r\n	```\r\n		for i := 0; i < len(b); {\r\n			x, i = nextInt(b, i)\r\n			fmt.Println(x)\r\n		}\r\n\r\n	```\r\n\r\n 可命名结果形参\r\n\r\n\r\n	Go函数的返回值或结果“形参”可被命名，并作为常规变量使用，就像传入的形参一样。\r\n	命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；\r\n	若该函数执行了一条不带实参的 return 语句，则结果形参的当前值将被返回。\r\n\r\n	此名称不是强制性的，但它们能使代码更加简短清晰：它们就是文档。若我们命名了\r\n	nextInt 的结果，那么它返回的 int 就值如其意了。\r\n\r\n	```\r\n	func nextInt(b []byte, pos int) (value, nextPos int) {\r\n\r\n	```\r\n\r\n	由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。\r\n	下面的 io.ReadFull 就是个很好的例子：\r\n\r\n	```\r\n	func ReadFull(r Reader, buf []byte) (n int, err error) {\r\n		for len(buf) > 0 && err == nil {\r\n			var nr int\r\n			nr, err = r.Read(buf)\r\n			n += nr\r\n			buf = buf[nr:]\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n Defer\r\n\r\n\r\n	Go的 defer 语句用于预设一个函数调用（即推迟执行函数），\r\n	该函数会在执行 defer 的函数返回之前立即执行。它显得非比寻常，\r\n	但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。\r\n	典型的例子就是解锁互斥和关闭文件。\r\n\r\n	```\r\n	// Contents 将文件的内容作为字符串返回。\r\n	func Contents(filename string) (string, error) {\r\n		f, err := os.Open(filename)\r\n		if err != nil {\r\n			return "", err\r\n		}\r\n		defer f.Close()  // f.Close 会在我们结束后运行。\r\n\r\n		var result []byte\r\n		buf := make([]byte, 100)\r\n		for {\r\n			n, err := f.Read(buf[0:])\r\n			result = append(result, buf[0:n]...) // append 将在后面讨论。\r\n			if err != nil {\r\n				if err == io.EOF {\r\n					break\r\n				}\r\n				return "", err  // 我们在这里返回后，f 就会被关闭。\r\n			}\r\n		}\r\n		return string(result), nil // 我们在这里返回后，f 就会被关闭。\r\n	}\r\n\r\n	```\r\n\r\n	推迟诸如 Close 之类的函数调用有两点好处：第一，\r\n	它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，\r\n	这种情况往往就会发生。第二，它意味着“关闭”离“打开”很近，\r\n	这总比将它放在函数结尾处要清晰明了。\r\n\r\n	被推迟函数的实参（如果该函数为方法则还包括接收者）在推迟执行时就会求值，\r\n	而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变，\r\n	同时还意味着单个已推迟的调用可推迟多个函数的执行。下面是个简单的例子。\r\n\r\n	```\r\n	for i := 0; i < 5; i++ {\r\n		defer fmt.Printf("%d ", i)\r\n	}\r\n\r\n	```\r\n\r\n	被推迟的函数按照后进先出（LIFO）的顺序执行，因此以上代码在函数返回时会打印\r\n	4 3 2 1 0。一个更具实际意义的例子是通过一种简单的方法，\r\n	用程序来跟踪函数的执行。我们可以编写一对简单的跟踪例程：\r\n\r\n	```\r\n	func trace(s string)   { fmt.Println("entering:", s) }\r\n	func untrace(s string) { fmt.Println("leaving:", s) }\r\n\r\n	// 像这样使用它们：\r\n	func a() {\r\n		trace("a")\r\n		defer untrace("a")\r\n		// 做一些事情....\r\n	}\r\n\r\n	```\r\n\r\n	我们可以充分利用这个特点，即被推迟函数的实参在 defer 执行时才会被求值。\r\n	跟踪例程可针对反跟踪例程设置实参。以下例子：\r\n\r\n	```\r\n	func trace(s string) string {\r\n		fmt.Println("entering:", s)\r\n		return s\r\n	}\r\n\r\n	func un(s string) {\r\n		fmt.Println("leaving:", s)\r\n	}\r\n\r\n	func a() {\r\n		defer un(trace("a"))\r\n		fmt.Println("in a")\r\n	}\r\n\r\n	func b() {\r\n		defer un(trace("b"))\r\n		fmt.Println("in b")\r\n		a()\r\n	}\r\n\r\n	func main() {\r\n		b()\r\n	}\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	entering: b\r\n	in b\r\n	entering: a\r\n	in a\r\n	leaving: a\r\n	leaving: b\r\n\r\n	```\r\n\r\n	对于习惯其它语言中块级资源管理的程序员，defer 似乎有点怪异，\r\n	但它最有趣而强大的应用恰恰来自于其基于函数而非块的特点。在 panic\r\n	和 recover 这两节中，我们将看到关于它可能性的其它例子。\r\n\r\n 数据\r\n\r\n\r\n	new 分配\r\n\r\n	Go提供了两种分配原语，即内建函数 new 和 make。\r\n	它们所做的事情不同，所应用的类型也不同。它们可能会引起混淆，但规则却很简单。\r\n	让我们先来看看 new。这是个用来分配内存的内建函数，\r\n	但与其它语言中的同名函数不同，它不会初始化内存，只会将内存置零。\r\n	也就是说，new(T) 会为类型为 T 的新项分配已置零的内存空间，\r\n	并返回它的地址，也就是一个类型为 *T 的值。用Go的术语来说，它返回一个指针，\r\n	该指针指向新分配的，类型为 T 的零值。\r\n\r\n	既然 new 返回的内存已置零，那么当你设计数据结构时，\r\n	每种类型的零值就不必进一步初始化了，这意味着该数据结构的使用者只需用\r\n	new 创建一个新的对象就能正常工作。例如，bytes.Buffer\r\n	的文档中提到“零值的 Buffer 就是已准备就绪的缓冲区。"\r\n	同样，sync.Mutex 并没有显式的构造函数或 Init 方法，\r\n	而是零值的 sync.Mutex 就已经被定义为已解锁的互斥锁了。\r\n\r\n	“零值属性”可以带来各种好处。考虑以下类型声明。\r\n\r\n	```\r\n	type SyncedBuffer struct {\r\n		lock    sync.Mutex\r\n		buffer  bytes.Buffer\r\n	}\r\n\r\n	```\r\n\r\n	SyncedBuffer 类型的值也是在声明时就分配好内存就绪了。后续代码中，\r\n	p 和 v 无需进一步处理即可正确工作。\r\n\r\n	```\r\n	p := new(SyncedBuffer)  // type *SyncedBuffer\r\n	var v SyncedBuffer      // type  SyncedBuffer\r\n\r\n	```\r\n\r\n 构造函数与复合字面\r\n\r\n\r\n	有时零值还不够好，这时就需要一个初始化构造函数，如来自 os 包中的这段代码所示。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := new(File)\r\n		f.fd = fd\r\n		f.name = name\r\n		f.dirinfo = nil\r\n		f.nepipe = 0\r\n		return f\r\n	}\r\n\r\n	```\r\n\r\n	这里显得代码过于冗长。我们可通过复合字面来简化它，\r\n	该表达式在每次求值时都会创建新的实例。\r\n\r\n	```\r\n	func NewFile(fd int, name string) *File {\r\n		if fd < 0 {\r\n			return nil\r\n		}\r\n		f := File{fd, name, nil, 0}\r\n		return &f\r\n	}\r\n\r\n	```\r\n\r\n	请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据\r\n	在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存，\r\n	因此我们可以将上面的最后两行代码合并：\r\n\r\n	```\r\n		return &File{fd, name, nil, 0}\r\n\r\n	```\r\n\r\n	复合字面的字段必须按顺序全部列出。但如果以 字段:值\r\n	对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。\r\n	因此，我们可以用如下形式：\r\n\r\n	```\r\n		return &File{fd: fd, name: name}\r\n\r\n	```\r\n\r\n	少数情况下，若复合字面不包括任何字段，它将创建该类型的零值。表达式\r\n	new(File) 和 &File{} 是等价的。\r\n\r\n	复合字面同样可用于创建数组、切片以及映射，字段标签是索引还是映射键则视情况而定。\r\n	在下例初始化过程中，无论 Enone、Eio 和\r\n	Einval 的值是什么，只要它们的标签不同就行。\r\n\r\n	```\r\n	a := [...]string   {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	s := []string      {Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n	m := map[int]string{Enone: "no error", Eio: "Eio", Einval: "invalid argument"}\r\n\r\n	```\r\n\r\n	make 分配\r\n\r\n	再回到内存分配上来。内建函数 make(T, args)\r\n	的目的不同于 new(T)。它只用于创建切片、映射和信道，并返回类型为\r\n	T（而非 *T）的一个已初始化 （而非置零）的值。\r\n	出现这种用差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。\r\n	例如，切片是一个具有三项内容的描述符，包含一个指向（数组内部）数据的指针、长度以及容量，\r\n	在这三项被初始化之前，该切片为 nil。对于切片、映射和信道，make\r\n	用于初始化其内部的数据结构并准备好将要使用的值。例如，\r\n\r\n	```\r\n	make([]int, 10, 100)\r\n\r\n	```\r\n\r\n	会分配一个具有100个 int 的数组空间，接着创建一个长度为10，\r\n	容量为100并指向该数组中前10个元素的切片结构。（生成切片时，其容量可以省略，更多信息见切片一节。）\r\n	与此相反，new([]int) 会返回一个指向新分配的，已置零的切片结构，\r\n	即一个指向 nil 切片值的指针。\r\n\r\n	下面的例子阐明了 new 和 make 之间的区别：\r\n\r\n	```\r\n	var p *[]int = new([]int)       // 分配切片结构；*p == nil；基本没用\r\n	var v  []int = make([]int, 100) // 切片 v 现在引用了一个具有 100 个 int 元素的新数组\r\n\r\n	// 没必要的复杂：\r\n	var p *[]int = new([]int)\r\n	*p = make([]int, 100, 100)\r\n\r\n	// 习惯用法：\r\n	v := make([]int, 100)\r\n\r\n	```\r\n\r\n	请记住，make 只适用于映射、切片和信道且不返回指针。若要获得明确的指针，\r\n	请使用 new 分配内存。\r\n\r\n 数组\r\n\r\n\r\n	在详细规划内存布局时，数组是非常有用的，有时还能避免过多的内存分配，\r\n	但它们主要用作切片的构件。这是下一节的主题了，不过要先说上几句来为它做铺垫。\r\n\r\n	以下为数组在Go和C中的主要区别。在Go中，\r\n\r\n	数组是值。将一个数组赋予另一个数组会复制其所有元素。\r\n\r\n	特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。\r\n\r\n	数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。\r\n\r\n	数组为值的属性很有用，但代价高昂；若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。\r\n\r\n	```\r\n	func Sum(a *[3]float64) (sum float64) {\r\n		for _, v := range *a {\r\n			sum += v\r\n		}\r\n		return\r\n	}\r\n\r\n	array := [...]float64{7.0, 8.5, 9.1}\r\n	x := Sum(&array)  // 注意显式的取址操作\r\n\r\n	```\r\n\r\n	但这并不是Go的习惯用法，切片才是。\r\n\r\n 切片\r\n\r\n\r\n	切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。\r\n	除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。\r\n\r\n	切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。\r\n	若某个函数将一个切片作为参数传入，则它对该切片元素的修改对调用者而言同样可见，\r\n	这可以理解为传递了底层数组的指针。因此，Read 函数可接受一个切片实参\r\n	而非一个指针和一个计数；切片的长度决定了可读取数据的上限。以下为 os\r\n	包中 File 类型的 Read 方法签名:\r\n\r\n	```\r\n	func (file *File) Read(buf []byte) (n int, err error)\r\n\r\n	```\r\n\r\n	该方法返回读取的字节数和一个错误值（若有的话）。若要从更大的缓冲区 b\r\n	中读取前32个字节，只需对其进行切片即可。\r\n\r\n	```\r\n		n, err := f.Read(buf[0:32])\r\n\r\n	```\r\n\r\n	这种切片的方法常用且高效。若不谈效率，以下片段同样能读取该缓冲区的前32个字节。\r\n\r\n	```\r\n		var n int\r\n		var err error\r\n		for i := 0; i < 32; i++ {\r\n			nbytes, e := f.Read(buf[i:i+1])  // 读取一个字节\r\n			if nbytes == 0 || e != nil {\r\n				err = e\r\n				break\r\n			}\r\n			n += nbytes\r\n		}\r\n\r\n	```\r\n\r\n	只要切片不超出底层数组的限制，它的长度就是可变的，只需将它赋予其自身的切片即可。\r\n	切片的容量可通过内建函数 cap 获得，它将给出该切片可取得的最大长度。\r\n	以下是将数据追加到切片的函数。若数据超出其容量，则会重新分配该切片。返回值即为所得的切片。\r\n	该函数中所使用的 len 和 cap 在应用于 nil\r\n	切片时是合法的，它会返回0.\r\n\r\n	```\r\n	func Append(slice, data[]byte) []byte {\r\n		l := len(slice)\r\n		if l + len(data) > cap(slice) {  // 重新分配\r\n			// 为了后面的增长，需分配两份。\r\n			newSlice := make([]byte, (l+len(data))*2)\r\n			// copy 函数是预声明的，且可用于任何切片类型。\r\n			copy(newSlice, slice)\r\n			slice = newSlice\r\n		}\r\n		slice = slice[0:l+len(data)]\r\n		for i, c := range data {\r\n			slice[l+i] = c\r\n		}\r\n		return slice\r\n	}\r\n\r\n	```\r\n\r\n	最终我们必须返回切片，因为尽管 Append 可修改 slice\r\n	的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。\r\n\r\n	向切片追加东西的想法非常有用，因此有专门的内建函数 append。\r\n	要理解该函数的设计，我们还需要一些额外的信息，我们将稍后再介绍它。\r\n\r\n 二维切片\r\n\r\n\r\n	Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组，\r\n	或切片的切片，就像这样：\r\n\r\n	```\r\n	type Transform [3][3]float64  // 一个 3x3 的数组，其实是包含多个数组的一个数组。\r\n	type LinesOfText [][]byte     // 包含多个字节切片的一个切片。\r\n\r\n	```\r\n\r\n	由于切片长度是可变的，因此其内部可能拥有多个不同长度的切片。在我们的\r\n	LinesOfText 例子中，这是种常见的情况：每行都有其自己的长度。\r\n\r\n	```\r\n	text := LinesOfText{\r\n		[]byte("Now is the time"),\r\n		[]byte("for all good gophers"),\r\n		[]byte("to bring some fun to the party."),\r\n	}\r\n\r\n	```\r\n\r\n	有时必须分配一个二维数组，例如在处理像素的扫描行时，这种情况就会发生。\r\n	我们有两种方式来达到这个目的。一种就是独立地分配每一个切片；而另一种就是只分配一个数组，\r\n	将各个切片都指向它。采用哪种方式取决于你的应用。若切片会增长或收缩，\r\n	就应该通过独立分配来避免覆盖下一行；若不会，用单次分配来构造对象会更加高效。\r\n	以下是这两种方法的大概代码，仅供参考。首先是一次一行的：\r\n\r\n	```\r\n	// 分配顶层切片。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 遍历行，为每一行都分配切片\r\n	for i := range picture {\r\n		picture[i] = make([]uint8, XSize)\r\n	}\r\n\r\n	```\r\n\r\n	现在是一次分配，对行进行切片：\r\n\r\n	```\r\n	// 分配顶层切片，和前面一样。\r\n	picture := make([][]uint8, YSize) // 每 y 个单元一行。\r\n	// 分配一个大的切片来保存所有像素\r\n	pixels := make([]uint8, XSize*YSize) // 拥有类型 []uint8，尽管图片是 [][]uint8.\r\n	// 遍历行，从剩余像素切片的前面切出每行来。\r\n	for i := range picture {\r\n		picture[i], pixels = pixels[:XSize], pixels[XSize:]\r\n	}\r\n\r\n	```\r\n\r\n 映射\r\n\r\n\r\n	映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型，\r\n	如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。\r\n	切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。\r\n	若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。\r\n\r\n	映射可使用一般的复合字面语法进行构建，其键-值对使用逗号分隔，因此可在初始化时很容易地构建它们。\r\n\r\n	```\r\n	var timeZone = map[string]int{\r\n		"UTC":  0*60*60,\r\n		"EST": -5*60*60,\r\n		"CST": -6*60*60,\r\n		"MST": -7*60*60,\r\n		"PST": -8*60*60,\r\n	}\r\n\r\n	```\r\n\r\n	赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数。\r\n\r\n	```\r\n	offset := timeZone["EST"]\r\n\r\n	```\r\n\r\n	若试图通过映射中不存在的键来取值，就会返回与该映射中项的类型对应的零值。\r\n	例如，若某个映射包含整数，当查找一个不存在的键时会返回 0。\r\n	集合可实现成一个值类型为 bool 的映射。将该映射中的项置为\r\n	true 可将该值放入集合中，此后通过简单的索引操作即可判断是否存在。\r\n\r\n	```\r\n	attended := map[string]bool{\r\n		"Ann": true,\r\n		"Joe": true,\r\n		...\r\n	}\r\n\r\n	if attended[person] { // 若某人不在此映射中，则为 false\r\n		fmt.Println(person, "正在开会")\r\n	}\r\n\r\n	```\r\n\r\n	有时你需要区分某项是不存在还是其值为零值。如对于一个值本应为零的 "UTC"\r\n	条目，也可能是由于不存在该项而得到零值。你可以使用多重赋值的形式来分辨这种情况。\r\n\r\n	```\r\n	var seconds int\r\n	var ok bool\r\n	seconds, ok = timeZone[tz]\r\n\r\n	```\r\n\r\n	显然，我们可称之为“逗号 ok”惯用法。在下面的例子中，若 tz 存在，\r\n	seconds 就会被赋予适当的值，且 ok 会被置为 true；\r\n	若不存在，seconds 则会被置为零，而 ok 会被置为 false。\r\n\r\n	```\r\n	func offset(tz string) int {\r\n		if seconds, ok := timeZone[tz]; ok {\r\n			return seconds\r\n		}\r\n		log.Println("unknown time zone:", tz)\r\n		return 0\r\n	}\r\n\r\n	```\r\n\r\n	若仅需判断映射中是否存在某项而不关心实际的值，可使用[空白标识符](#%E7%A9%BA%E7%99%BD)\r\n	（_）来代替该值的一般变量。\r\n\r\n	```\r\n	_, present := timeZone[tz]\r\n\r\n	```\r\n\r\n	要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。\r\n	即便对应的键不在该映射中，此操作也是安全的。\r\n\r\n	```\r\n	delete(timeZone, "PDT")  // 现在用标准时间\r\n\r\n	```\r\n\r\n 打印\r\n\r\n\r\n	Go采用的格式化打印风格和C的 printf 族类似，但却更加丰富而通用。\r\n	这些函数位于 fmt 包中，且函数名首字母均为大写：如\r\n	fmt.Printf、fmt.Fprintf，fmt.Sprintf 等。\r\n	字符串函数（Sprintf 等）会返回一个字符串，而非填充给定的缓冲区。\r\n\r\n	你无需提供一个格式字符串。每个 Printf、Fprintf 和\r\n	Sprintf 都分别对应另外的函数，如 Print 与 Println。\r\n	这些函数并不接受格式字符串，而是为每个实参生成一种默认格式。Println\r\n	系列的函数还会在实参中插入空格，并在输出时追加一个换行符，而 Print\r\n	版本仅在操作数两侧都没有字符串时才添加空白。以下示例中各行产生的输出都是一样的。\r\n\r\n	```\r\n	fmt.Printf("Hello %d\\n", 23)\r\n	fmt.Fprint(os.Stdout, "Hello ", 23, "\\n")\r\n	fmt.Println("Hello", 23)\r\n	fmt.Println(fmt.Sprint("Hello ", 23))\r\n\r\n	```\r\n\r\n	fmt.Fprint 一类的格式化打印函数可接受任何实现了 io.Writer\r\n	接口的对象作为第一个实参；变量os.Stdout 与 os.Stderr\r\n	都是人们熟知的例子。\r\n\r\n	从这里开始，就与C有些不同了。首先，像 %d 这样的数值格式并不接受表示符号或大小的标记，\r\n	打印例程会根据实参的类型来决定这些属性。\r\n\r\n	```\r\n	var x uint64 = 1<<64 - 1\r\n	fmt.Printf("%d %x; %d %x\\n", x, x, int64(x), int64(x))\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	18446744073709551615 ffffffffffffffff; -1 -1\r\n\r\n	```\r\n\r\n	若你只想要默认的转换，如使用十进制的整数，你可以使用通用的格式\r\n	%v（对应“值”）；其结果与 Print 和 Println\r\n	的输出完全相同。此外，这种格式还能打印任意值，甚至包括数组、结构体和映射。\r\n	以下是打印上一节中定义的时区映射的语句。\r\n\r\n	```\r\n	fmt.Printf("%v\\n", timeZone)  // 或只用 fmt.Println(timeZone)\r\n\r\n	```\r\n\r\n	这会输出\r\n\r\n	```\r\n	map[CST:-21600 PST:-28800 EST:-18000 UTC:0 MST:-25200]\r\n\r\n	```\r\n\r\n	当然，映射中的键可能按任意顺序输出。当打印结构体时，改进的格式 %+v\r\n	会为结构体的每个字段添上字段名，而另一种格式 %#v 将完全按照Go的语法打印值。\r\n\r\n	```\r\n	type T struct {\r\n		a int\r\n		b float64\r\n		c string\r\n	}\r\n	t := &T{ 7, -2.35, "abc\\tdef" }\r\n	fmt.Printf("%v\\n", t)\r\n	fmt.Printf("%+v\\n", t)\r\n	fmt.Printf("%#v\\n", t)\r\n	fmt.Printf("%#v\\n", timeZone)\r\n\r\n	```\r\n\r\n	将打印\r\n\r\n	```\r\n	&{7 -2.35 abc   def}\r\n	&{a:7 b:-2.35 c:abc     def}\r\n	&main.T{a:7, b:-2.35, c:"abc\\tdef"}\r\n	map[string] int{"CST":-21600, "PST":-28800, "EST":-18000, "UTC":0, "MST":-25200}\r\n\r\n	```\r\n\r\n	（请注意其中的&符号）当遇到 string 或 []byte 值时，\r\n	可使用 %q 产生带引号的字符串；而格式 %#q 会尽可能使用反引号。\r\n	（%q 格式也可用于整数和符文，它会产生一个带单引号的符文常量。）\r\n	此外，%x 还可用于字符串、字节数组以及整数，并生成一个很长的十六进制字符串，\r\n	而带空格的格式（% x）还会在字节之间插入空格。\r\n\r\n	另一种实用的格式是 %T，它会打印某个值的类型.\r\n\r\n	```\r\n	fmt.Printf("%T\\n", timeZone)\r\n\r\n	```\r\n\r\n	会打印\r\n\r\n	```\r\n	map[string] int\r\n\r\n	```\r\n\r\n	若你想控制自定义类型的默认格式，只需为该类型定义一个具有 String() string\r\n	签名的方法。对于我们简单的类型 T，可进行如下操作。\r\n\r\n	```\r\n	func (t *T) String() string {\r\n		return fmt.Sprintf("%d/%g/%q", t.a, t.b, t.c)\r\n	}\r\n	fmt.Printf("%v\\n", t)\r\n\r\n	```\r\n\r\n	会打印出如下格式：\r\n\r\n	```\r\n	7/-2.35/"abc\\tdef"\r\n\r\n	```\r\n\r\n	（如果你需要像指向 T 的指针那样打印类型 T 的值，\r\n	String 的接收者就必须是值类型的；上面的例子中接收者是一个指针，\r\n	因为这对结构来说更高效而通用。更多详情见[指针vs.值接收者](#%E6%8C%87%E9%92%88vs%E5%80%BC)一节.）\r\n\r\n	我们的 String 方法也可调用 Sprintf，\r\n	因为打印例程可以完全重入并按这种方式封装。不过要理解这种方式，还有一个重要的细节：\r\n	请勿通过调用 Sprintf 来构造 String\r\n	方法，因为它会无限递归你的的 String 方法。\r\n\r\n	```\r\n	type MyString string\r\n\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", m) // 错误：会无限递归\r\n	}\r\n\r\n	```\r\n\r\n	要解决这个问题也很简单：将该实参转换为基本的字符串类型，它没有这个方法。\r\n\r\n	```\r\n	type MyString string\r\n	func (m MyString) String() string {\r\n		return fmt.Sprintf("MyString=%s", string(m)) // 可以：注意转换\r\n	}\r\n\r\n	```\r\n\r\n	在[初始化](#%E5%88%9D%E5%A7%8B%E5%8C%96)一节中，我们将看到避免这种递归的另一种技术。\r\n\r\n	另一种打印技术就是将打印例程的实参直接传入另一个这样的例程。Printf\r\n	的签名为其最后的实参使用了 ...interface{}\r\n	类型，这样格式的后面就能出现任意数量，任意类型的形参了。\r\n\r\n	```\r\n	func Printf(format string, v ...interface{}) (n int, err error) {\r\n\r\n	```\r\n\r\n	在 Printf 函数中，v 看起来更像是 []interface{}\r\n	类型的变量，但如果将它传递到另一个变参函数中，它就像是常规实参列表了。\r\n	以下是我们之前用过的 log.Println 的实现。它直接将其实参传递给\r\n	fmt.Sprintln 进行实际的格式化。\r\n\r\n	```\r\n	// Println 通过 fmt.Println 的方式将日志打印到标准记录器。\r\n	func Println(v ...interface{}) {\r\n		std.Output(2, fmt.Sprintln(v...))  // Output 接受形参 (int, string)\r\n	}\r\n\r\n	```\r\n\r\n	在该 Sprintln 嵌套调用中，我们将 ... 写在 v\r\n	之后来告诉编译器将 v 视作一个实参列表，否则它会将 v\r\n	当做单一的切片实参来传递。\r\n\r\n	还有很多关于打印知识点没有提及。详情请参阅 godoc 对 fmt 包的说明文档。\r\n\r\n	顺便一提，... 形参可指定具体的类型，例如从整数列表中选出最小值的函数\r\n	min，其形参可为 ...int 类型。\r\n\r\n	```\r\n	func Min(a ...int) int {\r\n		min := int(^uint(0) >> 1)  // 最大的 int\r\n		for _, i := range a {\r\n			if i < min {\r\n				min = i\r\n			}\r\n		}\r\n		return min\r\n	}\r\n\r\n	```\r\n\r\n 追加\r\n\r\n\r\n	现在我们要对内建函数 append 的设计进行补充说明。append\r\n	函数的签名不同于前面我们自定义的 Append 函数。大致来说，它就像这样：\r\n\r\n	```\r\n	func append(slice []T, 元素 ...T) []T\r\n\r\n	```\r\n\r\n	其中的 T 为任意给定类型的占位符。实际上，你无法在Go中编写一个类型\r\n	T 由调用者决定的函数。这也就是为何 append\r\n	为内建函数的原因：它需要编译器的支持。\r\n\r\n	append 会在切片末尾追加元素并返回结果。我们必须返回结果，\r\n	原因与我们手写的 Append 一样，即底层数组可能会被改变。以下简单的例子\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	x = append(x, 4, 5, 6)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	将打印 [1 2 3 4 5 6]。因此 append 有点像 Printf\r\n	那样，可接受任意数量的实参。\r\n\r\n	但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？\r\n	很简单：在调用的地方使用 ...，就像我们在上面调用 Output\r\n	那样。以下代码片段的输出与上一个相同。\r\n\r\n	```\r\n	x := []int{1,2,3}\r\n	y := []int{4,5,6}\r\n	x = append(x, y...)\r\n	fmt.Println(x)\r\n\r\n	```\r\n\r\n	如果没有 ...，它就会由于类型错误而无法编译，因为 y\r\n	不是 int 类型的。\r\n\r\n 初始化\r\n\r\n\r\n	尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。\r\n	在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。\r\n\r\n 常量\r\n\r\n\r\n	Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。\r\n	常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制，\r\n	定义它们的表达式必须也是可被编译器求值的常量表达式。例如 1<<3\r\n	就是一个常量表达式，而 math.Sin(math.Pi/4)\r\n	则不是，因为对 math.Sin 的函数调用在运行时才会发生。\r\n\r\n	在Go中，枚举常量使用枚举器 iota 创建。由于 iota\r\n	可为表达式的一部分，而表达式可以被隐式地重复，这样也就更容易构建复杂的值的集合了。\r\n\r\n	```\r\n	type ByteSize float64\r\n\r\n	const (\r\n	    // 通过赋予空白标识符来忽略第一个值\r\n	    _           = iota // ignore first value by assigning to blank identifier\r\n	    KB ByteSize = 1 << (10 * iota)\r\n	    MB\r\n	    GB\r\n	    TB\r\n	    PB\r\n	    EB\r\n	    ZB\r\n	    YB\r\n	)\r\n	```\r\n\r\n	由于可将 String 之类的方法附加在用户定义的类型上，\r\n	因此它就为打印时自动格式化任意值提供了可能性，即便是作为一个通用类型的一部分。\r\n	尽管你常常会看到这种技术应用于结构体，但它对于像 ByteSize\r\n	之类的浮点数标量等类型也是有用的。\r\n\r\n	```\r\n	func (b ByteSize) String() string {\r\n	    switch {\r\n	    case b >= YB:\r\n		return fmt.Sprintf("%.2fYB", b/YB)\r\n	    case b >= ZB:\r\n		return fmt.Sprintf("%.2fZB", b/ZB)\r\n	    case b >= EB:\r\n		return fmt.Sprintf("%.2fEB", b/EB)\r\n	    case b >= PB:\r\n		return fmt.Sprintf("%.2fPB", b/PB)\r\n	    case b >= TB:\r\n		return fmt.Sprintf("%.2fTB", b/TB)\r\n	    case b >= GB:\r\n		return fmt.Sprintf("%.2fGB", b/GB)\r\n	    case b >= MB:\r\n		return fmt.Sprintf("%.2fMB", b/MB)\r\n	    case b >= KB:\r\n		return fmt.Sprintf("%.2fKB", b/KB)\r\n	    }\r\n	    return fmt.Sprintf("%.2fB", b)\r\n	}\r\n	```\r\n\r\n	表达式 YB 会打印出 1.00YB，而\r\n	ByteSize(1e13) 则会打印出 9.09。\r\n\r\n	在这里用 Sprintf 实现 ByteSize 的 String\r\n	方法很安全（不会无限递归），这倒不是因为类型转换，而是它以 %f\r\n	调用了 Sprintf，它并不是一种字符串格式：Sprintf\r\n	只会在它需要字符串时才调用 String 方法，而 %f\r\n	需要一个浮点数值。\r\n\r\n 变量\r\n\r\n\r\n	变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。\r\n\r\n	```\r\n	var (\r\n		home   = os.Getenv("HOME")\r\n		user   = os.Getenv("USER")\r\n		gopath = os.Getenv("GOPATH")\r\n	)\r\n\r\n	```\r\n\r\n	init 函数\r\n\r\n	最后，每个源文件都可以通过定义自己的无参数 init 函数来设置一些必要的状态。\r\n	（其实每个文件都可以拥有多个 init 函数。）而它的结束就意味着初始化结束：\r\n	只有该包中的所有变量声明都通过它们的初始化器求值后 init 才会被调用，\r\n	而那些 init 只有在所有已导入的包都被初始化后才会被求值。\r\n\r\n	除了那些不能被表示成声明的初始化外，init\r\n	函数还常被用在程序真正开始执行前，检验或校正程序的状态。\r\n\r\n	```\r\n	func init() {\r\n		if user == "" {\r\n			log.Fatal("$USER not set")\r\n		}\r\n		if home == "" {\r\n			home = "/home/" + user\r\n		}\r\n		if gopath == "" {\r\n			gopath = home + "/go"\r\n		}\r\n		// gopath 可通过命令行中的 --gopath 标记覆盖掉。\r\n		flag.StringVar(&gopath, "gopath", gopath, "override default GOPATH")\r\n	}\r\n\r\n	```\r\n\r\n 方法\r\n\r\n\r\n 指针 vs. 值\r\n\r\n\r\n	正如 ByteSize 那样，我们可以为任何已命名的类型（除了指针或接口）定义方法；\r\n	接收者可不必为结构体。\r\n\r\n	在之前讨论切片时，我们编写了一个 Append 函数。\r\n	我们也可将其定义为切片的方法。为此，我们首先要声明一个已命名的类型来绑定该方法，\r\n	然后使该方法的接收者成为该类型的值。\r\n\r\n	```\r\n	type ByteSlice []byte\r\n\r\n	func (slice ByteSlice) Append(data []byte) []byte {\r\n		// 主体和前面相同。\r\n	}\r\n\r\n	```\r\n\r\n	我们仍然需要该方法返回更新后的切片。为了消除这种不便，我们可通过重新定义该方法，\r\n	将一个指向 ByteSlice 的指针作为该方法的接收者，\r\n	这样该方法就能重写调用者提供的切片了。\r\n\r\n	```\r\n	func (p *ByteSlice) Append(data []byte) {\r\n		slice := *p\r\n		// 主体和前面相同，但没有 return。\r\n		*p = slice\r\n	}\r\n\r\n	```\r\n\r\n	其实我们做得更好。若我们将函数修改为与标准 Write 类似的方法，就像这样，\r\n\r\n	```\r\n	func (p *ByteSlice) Write(data []byte) (n int, err error) {\r\n		slice := *p\r\n		// 依旧和前面相同。\r\n		*p = slice\r\n		return len(data), nil\r\n	}\r\n\r\n	```\r\n\r\n	那么类型 *ByteSlice 就满足了标准的 io.Writer 接口，这将非常实用。\r\n	例如，我们可以通过打印将内容写入。\r\n\r\n	```\r\n		var b ByteSlice\r\n		fmt.Fprintf(&b, "This hour has %d days\\n", 7)\r\n\r\n	```\r\n\r\n	我们将 ByteSlice 的地址传入，因为只有 *ByteSlice\r\n	才满足 io.Writer。以指针或值为接收者的区别在于：值方法可通过指针和值调用，\r\n	而指针方法只能通过指针来调用。\r\n\r\n	之所以会有这条规则是因为指针方法可以修改接收者；通过值调用它们会导致方法接收到该值的副本，\r\n	因此任何修改都将被丢弃，因此该语言不允许这种错误。不过有个方便的例外：若该值是可寻址的，\r\n	那么该语言就会自动插入取址操作符来对付一般的通过值调用的指针方法。在我们的例子中，变量\r\n	b 是可寻址的，因此我们只需通过 b.Write 来调用它的\r\n	Write 方法，编译器会将它重写为 (&b).Write。\r\n\r\n	顺便一提，在字节切片上使用 Write 的想法已被 bytes.Buffer 所实现。\r\n\r\n 接口与其它类型\r\n\r\n\r\n 接口\r\n\r\n\r\n	Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个，\r\n	那么它就可以用在这里。我们已经见过许多简单的示例了；通过实现\r\n	String 方法，我们可以自定义打印函数，而通过 Write\r\n	方法，Fprintf 则能对任何对象产生输出。在Go代码中，\r\n	仅包含一两种方法的接口很常见，且其名称通常来自于实现它的方法，\r\n	如 io.Writer 就是实现了 Write 的一类对象。\r\n\r\n	每种类型都能实现多个接口。例如一个实现了 sort.Interface 接口的集合就可通过\r\n	sort 包中的例程进行排序。该接口包括 Len()、Less(i, j int) bool\r\n	以及 Swap(i, j int)，另外，该集合仍然可以有一个自定义的格式化器。\r\n	以下特意构建的例子 Sequence 就同时满足这两种情况。\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// Methods required by sort.Interface.\r\n	// sort.Interface 所需的方法。\r\n	func (s Sequence) Len() int {\r\n	    return len(s)\r\n	}\r\n	func (s Sequence) Less(i, j int) bool {\r\n	    return s[i] < s[j]\r\n	}\r\n	func (s Sequence) Swap(i, j int) {\r\n	    s[i], s[j] = s[j], s[i]\r\n	}\r\n\r\n	// Method for printing - sorts the elements before printing.\r\n	// 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n	    sort.Sort(s)\r\n	    str := "["\r\n	    for i, elem := range s {\r\n		if i > 0 {\r\n		    str += " "\r\n		}\r\n		str += fmt.Sprint(elem)\r\n	    }\r\n	    return str + "]"\r\n	}\r\n	```\r\n\r\n 类型转换\r\n\r\n\r\n	Sequence 的 String 方法重新实现了 Sprint\r\n	为切片实现的功能。若我们在调用 Sprint 之前将 Sequence\r\n	转换为纯粹的 []int，就能共享已实现的功能。\r\n\r\n	```\r\n	func (s Sequence) String() string {\r\n		sort.Sort(s)\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	该方法是通过类型转换技术，在 String 方法中安全调用 Sprintf\r\n	的另个一例子。若我们忽略类型名的话，这两种类型（Sequence和\r\n	[]int）其实是相同的，因此在二者之间进行转换是合法的。\r\n	转换过程并不会创建新值，它只是值暂让现有的时看起来有个新类型而已。\r\n	（还有些合法转换则会创建新值，如从整数转换为浮点数等。）\r\n\r\n	在Go程序中，为访问不同的方法集而进行类型转换的情况非常常见。\r\n	例如，我们可使用现有的 sort.IntSlice 类型来简化整个示例：\r\n\r\n	```\r\n	type Sequence []int\r\n\r\n	// // 用于打印的方法 - 在打印前对元素进行排序。\r\n	func (s Sequence) String() string {\r\n		sort.IntSlice(s).Sort()\r\n		return fmt.Sprint([]int(s))\r\n	}\r\n\r\n	```\r\n\r\n	现在，不必让 Sequence 实现多个接口（排序和打印），\r\n	我们可通过将数据条目转换为多种类型（Sequence、sort.IntSlice\r\n	和 []int）来使用相应的功能，每次转换都完成一部分工作。\r\n	这在实践中虽然有些不同寻常，但往往却很有效。\r\n\r\n 接口转换与类型断言\r\n\r\n\r\n	[类型选择](#%E7%B1%BB%E5%9E%8B%E9%80%89%E6%8B%A9)是类型转换的一种形式：它接受一个接口，在选择\r\n	（switch）中根据其判断选择对应的情况（case），\r\n	并在某种意义上将其转换为该种类型。以下代码为 fmt.Printf\r\n	通过类型选择将值转换为字符串的简化版。若它已经为字符串，我们需要该接口中实际的字符串值；\r\n	若它有 String 方法，我们则需要调用该方法所得的结果。\r\n\r\n	```\r\n	type Stringer interface {\r\n		String() string\r\n	}\r\n\r\n	var value interface{} // 调用者提供的值。\r\n	switch str := value.(type) {\r\n	case string:\r\n		return str\r\n	case Stringer:\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n	第一种情况获取具体的值，第二种将该接口转换为另一个接口。这种方式对于混合类型来说非常完美。\r\n\r\n	若我们只关心一种类型呢？若我们知道该值拥有一个 string 而想要提取它呢？\r\n	只需一种情况的类型选择就行，但它需要类型断言。类型断言接受一个接口值，\r\n	并从中提取指定的明确类型的值。其语法借鉴自类型选择开头的子句，但它需要一个明确的类型，\r\n	而非 type 关键字：\r\n\r\n	```\r\n	value.(typeName)\r\n\r\n	```\r\n\r\n	而其结果则是拥有静态类型 typeName 的新值。该类型必须为该接口所拥有的具体类型，\r\n	或者该值可转换成的第二种接口类型。要提取我们知道在该值中的字符串，可以这样：\r\n\r\n	```\r\n	str := value.(string)\r\n\r\n	```\r\n\r\n	但若它所转换的值中不包含字符串，该程序就会以运行时错误崩溃。为避免这种情况，\r\n	需使用“逗号, ok”惯用测试它能安全地判断该值是否为字符串：\r\n\r\n	```\r\n	str, ok := value.(string)\r\n	if ok {\r\n		fmt.Printf("字符串值为 %q\\n", str)\r\n	} else {\r\n		fmt.Printf("该值非字符串\\n")\r\n	}\r\n\r\n	```\r\n\r\n	若类型断言失败，str 将继续存在且为字符串类型，但它将拥有零值，即空字符串。\r\n\r\n	作为对能量的说明，这里有个 if-else 语句，它等价于本节开头的类型选择。\r\n\r\n	```\r\n	if str, ok := value.(string); ok {\r\n		return str\r\n	} else if str, ok := value.(Stringer); ok {\r\n		return str.String()\r\n	}\r\n\r\n	```\r\n\r\n 通用性\r\n\r\n\r\n	若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。\r\n	仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。\r\n	这也能够避免为每个通用接口的实例重复编写文档。\r\n\r\n	在这种情况下，构造函数应当返回一个接口值而非实现的类型。例如在 hash\r\n	库中，crc32.NewIEEE 和 adler32.New 都返回接口类型\r\n	hash.Hash32。要在Go程序中用Adler-32算法替代CRC-32，\r\n	只需修改构造函数调用即可，其余代码则不受算法改变的影响。\r\n\r\n	同样的方式能将 crypto 包中多种联系在一起的流密码算法与块密码算法分开。\r\n	crypto/cipher 包中的 Block 接口指定了块密码算法的行为，\r\n	它为单独的数据块提供加密。接着，和 bufio\r\n	包类似，任何实现了该接口的密码包都能被用于构造以 Stream\r\n	为接口表示的流密码，而无需知道块加密的细节。\r\n\r\n	crypto/cipher 接口看其来就像这样：\r\n\r\n	```\r\n	type Block interface {\r\n		BlockSize() int\r\n		Encrypt(src, dst []byte)\r\n		Decrypt(src, dst []byte)\r\n	}\r\n\r\n	type Stream interface {\r\n		XORKeyStream(dst, src []byte)\r\n	}\r\n\r\n	```\r\n\r\n	这是计数器模式CTR流的定义，它将块加密改为流加密，注意块加密的细节已被抽象化了。\r\n\r\n	```\r\n	// NewCTR 返回一个 Stream，其加密/解密使用计数器模式中给定的 Block 进行。\r\n	// iv 的长度必须与 Block 的块大小相同。\r\n	func NewCTR(block Block, iv []byte) Stream\r\n\r\n	```\r\n\r\n	NewCTR 的应用并不仅限于特定的加密算法和数据源，它适用于任何对\r\n	Block 接口和 Stream 的实现。因为它们返回接口值，\r\n	所以用其它加密模式来代替CTR只需做局部的更改。构造函数的调用过程必须被修改，\r\n	但由于其周围的代码只能将它看做 Stream，因此它们不会注意到其中的区别。\r\n\r\n 接口和方法\r\n\r\n\r\n	由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。一个很直观的例子就是\r\n	http 包中定义的 Handler 接口。任何实现了\r\n	Handler 的对象都能够处理HTTP请求。\r\n\r\n	```\r\n	type Handler interface {\r\n		ServeHTTP(ResponseWriter, *Request)\r\n	}\r\n\r\n	```\r\n\r\n	ResponseWriter 接口提供了对方法的访问，这些方法需要响应客户端的请求。\r\n	由于这些方法包含了标准的 Write 方法，因此 http.ResponseWriter\r\n	可用于任何 io.Writer 适用的场景。Request\r\n	结构体包含已解析的客户端请求。\r\n\r\n	为简单起见，我们假设所有的HTTP请求都是GET方法，而忽略POST方法，\r\n	这种简化不会影响处理程序的建立方式。这里有个短小却完整的处理程序实现，\r\n	它用于记录某个页面被访问的次数。\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter struct {\r\n		n int\r\n	}\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ctr.n++\r\n		fmt.Fprintf(w, "counter = %d\\n", ctr.n)\r\n	}\r\n\r\n	```\r\n\r\n	（紧跟我们的主题，注意 Fprintf 如何能输出到\r\n	http.ResponseWriter。）\r\n	作为参考，这里演示了如何将这样一个服务器添加到URL树的一个节点上。\r\n\r\n	```\r\n	import "net/http"\r\n	...\r\n	ctr := new(Counter)\r\n	http.Handle("/counter", ctr)\r\n\r\n	```\r\n\r\n	但为什么 Counter 要是结构体呢？一个整数就够了。  An integer is all that''s needed.\r\n	（接收者必须为指针，增量操作对于调用者才可见。）\r\n\r\n	```\r\n	// 简单的计数器服务。\r\n	type Counter int\r\n\r\n	func (ctr *Counter) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		*ctr++\r\n		fmt.Fprintf(w, "counter = %d\\n", *ctr)\r\n	}\r\n\r\n	```\r\n\r\n	当页面被访问时，怎样通知你的程序去更新一些内部状态呢？为Web页面绑定个信道吧。\r\n\r\n	```\r\n	// 每次浏览该信道都会发送一个提醒。\r\n	// （可能需要带缓冲的信道。）\r\n	type Chan chan *http.Request\r\n\r\n	func (ch Chan) ServeHTTP(w http.ResponseWriter, req *http.Request) {\r\n		ch <- req\r\n		fmt.Fprint(w, "notification sent")\r\n	}\r\n\r\n	```\r\n\r\n	最后，假设我们需要输出调用服务器二进制程序时使用的实参 /args。\r\n	很简单，写个打印实参的函数就行了。\r\n\r\n	```\r\n	func ArgServer() {\r\n		fmt.Println(os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	我们如何将它转换为HTTP服务器呢？我们可以将 ArgServer\r\n	实现为某种可忽略值的方法，不过还有种更简单的方法。\r\n	既然我们可以为除指针和接口以外的任何类型定义方法，同样也能为一个函数写一个方法。\r\n	http 包包含以下代码：\r\n\r\n	```\r\n	// HandlerFunc 类型是一个适配器，它允许将普通函数用做HTTP处理程序。\r\n	// 若 f 是个具有适当签名的函数，HandlerFunc(f) 就是个调用 f 的处理程序对象。\r\n	type HandlerFunc func(ResponseWriter, *Request)\r\n\r\n	// ServeHTTP calls f(c, req).\r\n	func (f HandlerFunc) ServeHTTP(w ResponseWriter, req *Request) {\r\n		f(w, req)\r\n	}\r\n\r\n	```\r\n\r\n	HandlerFunc 是个具有 ServeHTTP 方法的类型，\r\n	因此该类型的值就能处理HTTP请求。我们来看看该方法的实现：接收者是一个函数\r\n	f，而该方法调用 f。这看起来很奇怪，但不必大惊小怪，\r\n	区别在于接收者变成了一个信道，而方法通过该信道发送消息。\r\n\r\n	为了将 ArgServer 实现成HTTP服务器，首先我们得让它拥有合适的签名。\r\n\r\n	```\r\n	// 实参服务器。\r\n	func ArgServer(w http.ResponseWriter, req *http.Request) {\r\n		fmt.Fprintln(w, os.Args)\r\n	}\r\n\r\n	```\r\n\r\n	ArgServer 和 HandlerFunc 现在拥有了相同的签名，\r\n	因此我们可将其转换为这种类型以访问它的方法，就像我们将 Sequence\r\n	转换为 IntSlice 以访问 IntSlice.Sort 那样。\r\n	建立代码非常简单：\r\n\r\n	```\r\n	http.Handle("/args", http.HandlerFunc(ArgServer))\r\n\r\n	```\r\n\r\n	当有人访问 /args 页面时，安装到该页面的处理程序就有了值\r\n	ArgServer 和类型 HandlerFunc。\r\n	HTTP服务器会以 ArgServer 为接收者，调用该类型的\r\n	ServeHTTP 方法，它会反过来调用 ArgServer（通过\r\n	f(c, req)），接着实参就会被显示出来。\r\n\r\n	在本节中，我们通过一个结构体，一个整数，一个信道和一个函数，建立了一个HTTP服务器，\r\n	这一切都是因为接口只是方法的集和，而几乎任何类型都能定义方法。\r\n\r\n 空白标识符\r\n\r\n\r\n	我们在 [for-range 循环](#for)和[映射](#%E6%98%A0%E5%B0%84)中提过几次空白标识符。\r\n	空白标识符可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的\r\n	/dev/null 文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。\r\n	我们在前面已经见过它的用法了。\r\n\r\n 多重赋值中的空白标识符\r\n\r\n\r\n	for range 循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。\r\n\r\n	若某次赋值需要匹配多个左值，但其中某个变量不会被程序使用，\r\n	那么用空白标识符来代替该变量可避免创建无用的变量，并能清楚地表明该值将被丢弃。\r\n	例如，当调用某个函数时，它会返回一个值和一个错误，但只有错误很重要，\r\n	那么可使用空白标识符来丢弃无关的值。\r\n\r\n	```\r\n	if _, err := os.Stat(path); os.IsNotExist(err) {\r\n		fmt.Printf("%s does not exist\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n	你偶尔会看见为忽略错误而丢弃错误值的代码，这是种糟糕的实践。请务必检查错误返回，\r\n	它们会提供错误的理由。\r\n\r\n	```\r\n	// 烂代码！若路径不存在，它就会崩溃。\r\n	fi, _ := os.Stat(path)\r\n	if fi.IsDir() {\r\n		fmt.Printf("%s is a directory\\n", path)\r\n	}\r\n\r\n	```\r\n\r\n 未使用的导入和变量\r\n\r\n\r\n	若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度，\r\n	而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。\r\n	然而在程序开发过程中，经常会产生未使用的导入和变量。虽然以后会用到它们，\r\n	但为了完成编译又不得不删除它们才行，这很让人烦恼。空白标识符就能提供一个工作空间。\r\n\r\n	这个写了一半的程序有两个未使用的导入（fmt 和\r\n	io）以及一个未使用的变量（fd），因此它不能编译，\r\n	但若到目前为止代码还是正确的，我们还是很乐意看到它们的。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	}\r\n	```\r\n\r\n	要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。\r\n	同样，将未使用的变量 fd 赋予空白标识符也能关闭未使用变量错误。\r\n	该程序的以下版本可以编译。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "fmt"\r\n	    "io"\r\n	    "log"\r\n	    "os"\r\n	)\r\n\r\n	var _ = fmt.Printf // For debugging; delete when done. // 用于调试，结束时删除。\r\n	var _ io.Reader    // For debugging; delete when done. // 用于调试，结束时删除。\r\n\r\n	func main() {\r\n	    fd, err := os.Open("test.go")\r\n	    if err != nil {\r\n		log.Fatal(err)\r\n	    }\r\n	    // TODO: use fd.\r\n	    _ = fd\r\n	}\r\n	```\r\n\r\n	按照惯例，我们应在导入并加以注释后，再使全局声明导入错误静默，这样可以让它们更易找到，\r\n	并作为以后清理它的提醒。\r\n\r\n 为副作用而导入\r\n\r\n\r\n	像前例中 fmt 或 io 这种未使用的导入总应在最后被使用或移除：\r\n	空白赋值会将代码标识为工作正在进行中。但有时导入某个包只是为了其副作用，\r\n	而没有任何明确的使用。例如，在 [net/http/pprof](http://172.16.132.221:8081/pkg/net/http/pprof/)\r\n	包的 init 函数中记录了HTTP处理程序的调试信息。它有个可导出的API，\r\n	但大部分客户端只需要该处理程序的记录和通过Web叶访问数据。只为了其副作用来哦导入该包，\r\n	只需将包重命名为空白标识符：\r\n\r\n	```\r\n	import _ "net/http/pprof"\r\n\r\n	```\r\n\r\n	这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能：\r\n	在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。）\r\n\r\n 接口检查\r\n\r\n\r\n	就像我们在前面[接口](#%E6%8E%A5%E5%8F%A3%E4%B8%8E%E7%B1%BB%E5%9E%8B)中讨论的那样，\r\n	一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法，\r\n	其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。\r\n	例如，将一个 *os.File 传入一个预期的 io.Reader 函数将不会被编译，\r\n	除非 *os.File 实现了 io.Reader 接口。\r\n\r\n	尽管有些接口检查会在运行时进行。[encoding/json](http://172.16.132.221:8081/pkg/encoding/json/)\r\n	包中就有个实例它定义了一个 [Marshaler](http://172.16.132.221:8081/pkg/encoding/json/#Marshaler)\r\n	接口。当JSON编码器接收到一个实现了该接口的值，那么该编码器就会调用该值的编组方法，\r\n	将其转换为JSON，而非进行标准的类型转换。\r\n	编码器在运行时通过[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)检查其属性，就像这样：\r\n\r\n	```\r\n	m, ok := val.(json.Marshaler)\r\n\r\n	```\r\n\r\n	若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身\r\n	（可能是错误检查部分），就使用空白标识符来忽略类型断言的值：\r\n\r\n	```\r\n	if _, ok := val.(json.Marshaler); ok {\r\n		fmt.Printf("value %v of type %T implements json.Marshaler\\n", val, val)\r\n	}\r\n\r\n	```\r\n\r\n	当需要确保某个包中实现的类型一定满足该接口时，就会遇到这种情况。\r\n	若某个类型（例如 [json.RawMessage](http://172.16.132.221:8081/pkg/encoding/json/#RawMessage)）\r\n	需要一种定制的JSON表现时，它应当实现 json.Marshaler，\r\n	不过现在没有静态转换可以让编译器去自动验证它。若该类型通过忽略转换失败来满足该接口，\r\n	那么JSON编码器仍可工作，但它却不会使用定制的实现。为确保其实现正确，\r\n	可在该包中用空白标识符声明一个全局变量：\r\n\r\n	```\r\n	var _ json.Marshaler = (*RawMessage)(nil)\r\n\r\n	```\r\n\r\n	在此声明中，我们调用了一个 *RawMessage 转换并将其赋予了\r\n	Marshaler，以此来要求 *RawMessage 实现\r\n	Marshaler，这时其属性就会在编译时被检测。\r\n	若 json.Marshaler 接口被更改，此包将无法通过编译，\r\n	而我们则会注意到它需要更新。\r\n\r\n	在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。\r\n	不过请不要为满足接口就将它用于任何类型。作为约定，\r\n	仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。\r\n\r\n 内嵌\r\n\r\n\r\n	Go并不提供典型的，类型驱动的子类化概念，但通过将类型<内嵌到结构体或接口中，\r\n	它就能“借鉴”部分实现。\r\n\r\n	接口内嵌非常简单。我们之前提到过 io.Reader 和 io.Writer\r\n	接口，这里是它们的定义。\r\n\r\n	```\r\n	type Reader interface {\r\n		Read(p []byte) (n int, err error)\r\n	}\r\n\r\n	type Writer interface {\r\n		Write(p []byte) (n int, err error)\r\n	}\r\n\r\n	```\r\n\r\n	io 包也导出了一些其它接口，以此来阐明对象所需实现的方法。\r\n	例如 io.ReadWriter 就是个包含 Read 和 Write\r\n	的接口。我们可以通过显示地列出这两个方法来指明 io.ReadWriter，\r\n	但通过将这两个接口内嵌到新的接口中显然更容易且更具启发性，就像这样：\r\n\r\n	```\r\n	// ReadWriter 接口结合了 Reader 和 Writer 接口。\r\n	type ReadWriter interface {\r\n		Reader\r\n		Writer\r\n	}\r\n\r\n	```\r\n\r\n	正如它看起来那样：ReadWriter 能够做任何 Reader\r\n	和 Writer 可以做到的事情，它是内嵌接口的联合体\r\n	（它们必须是不相交的方法集）。只有接口能被嵌入到接口中。\r\n\r\n	同样的基本想法可以应用在结构体中，但其意义更加深远。bufio\r\n	包中有 bufio.Reader 和 bufio.Writer 这两个结构体类型，\r\n	它们每一个都实现了与 io 包中相同意义的接口。此外，bufio\r\n	还通过结合 reader/writer 并将其内嵌到结构体中，实现了带缓冲的\r\n	reader/writer：它列出了结构体中的类型，但并未给予它们字段名。\r\n\r\n	```\r\n	// ReadWriter 存储了指向 Reader 和 Writer 的指针。\r\n	// 它实现了 io.ReadWriter。\r\n	type ReadWriter struct {\r\n		*Reader  // *bufio.Reader\r\n		*Writer  // *bufio.Writer\r\n	}\r\n\r\n	```\r\n\r\n	内嵌的元素为指向结构体的指针，当然它们在使用前必须被初始化为指向有效结构体的指针。\r\n	ReadWriter 结构体和通过如下方式定义：\r\n\r\n	```\r\n	type ReadWriter struct {\r\n		reader *Reader\r\n		writer *Writer\r\n	}\r\n\r\n	```\r\n\r\n	但为了提升该字段的方法并满足 io 接口，我们同样需要提供转发的方法，\r\n	就像这样：\r\n\r\n	```\r\n	func (rw *ReadWriter) Read(p []byte) (n int, err error) {\r\n		return rw.reader.Read(p)\r\n	}\r\n\r\n	```\r\n\r\n	而通过直接内嵌结构体，我们就能避免如此繁琐。\r\n	内嵌类型的方法可以直接引用，这意味着 bufio.ReadWriter 不仅包括\r\n	bufio.Reader 和 bufio.Writer 的方法，它还同时满足下列三个接口：\r\n	io.Reader、io.Writer 以及 io.ReadWriter。\r\n\r\n	还有种区分内嵌与子类的重要手段。当内嵌一个类型时，该类型的方法会成为外部类型的方法，\r\n	但当它们被调用时，该方法的接收者是内部类型，而非外部的。在我们的例子中，当\r\n	bufio.ReadWriter 的 Read 方法被调用时，\r\n	它与之前写的转发方法具有同样的效果；接收者是 ReadWriter 的 reader\r\n	字段，而非 ReadWriter 本身。\r\n\r\n	内嵌同样可以提供便利。这个例子展示了一个内嵌字段和一个常规的命名字段。\r\n\r\n	```\r\n	type Job struct {\r\n		Command string\r\n		*log.Logger\r\n	}\r\n\r\n	```\r\n\r\n	Job 类型现在有了 Log、Logf 和\r\n	*log.Logger 的其它方法。我们当然可以为 Logger\r\n	提供一个字段名，但完全不必这么做。现在，一旦初始化后，我们就能记录 Job 了：\r\n\r\n	```\r\n	job.Log("starting now...")\r\n\r\n	```\r\n\r\n	Logger 是 Job 结构体的常规字段，\r\n	因此我们可在 Job 的构造函数中，通过一般的方式来初始化它，就像这样：\r\n\r\n	```\r\n	func NewJob(command string, logger *log.Logger) *Job {\r\n		return &Job{command, logger}\r\n	}\r\n\r\n	```\r\n\r\n	或通过复合字面：\r\n\r\n	```\r\n	job := &Job{command, log.New(os.Stderr, "Job: ", log.Ldate)}\r\n\r\n	```\r\n\r\n	若我们需要直接引用内嵌字段，可以忽略包限定名，直接将该字段的类型名作为字段名，\r\n	就像我们在 ReaderWriter 结构体的 Read 方法中做的那样。\r\n	若我们需要访问 Job 类型的变量 job 的 *log.Logger，\r\n	可以直接写作 job.Logger。若我们想精炼 Logger 的方法时，\r\n	这会非常有用。\r\n\r\n	```\r\n	func (job *Job) Logf(format string, args ...interface{}) {\r\n		job.Logger.Logf("%q: %s", job.Command, fmt.Sprintf(format, args...))\r\n	}\r\n\r\n	```\r\n\r\n	内嵌类型会引入命名冲突的问题，但解决规则却很简单。首先，字段或方法 X\r\n	会隐藏该类型中更深层嵌套的其它项 X。若 log.Logger\r\n	包含一个名为 Command 的字段或方法，Job 的 Command\r\n	字段会覆盖它。\r\n\r\n	其次，若相同的嵌套层级上出现同名冲突，通常会产生一个错误。若 Job\r\n	结构体中包含名为 Logger 的字段或方法，再将 log.Logger\r\n	内嵌到其中的话就会产生错误。然而，若重名永远不会在该类型定义之外的程序中使用，那就不会出错。\r\n	这种限定能够在外部嵌套类型发生修改时提供某种保护。\r\n	因此，就算添加的字段与另一个子类型中的字段相冲突，只要这两个相同的字段永远不会被使用就没问题。\r\n\r\n 并发\r\n\r\n\r\n 通过通信共享内存\r\n\r\n\r\n	并发编程是个很大的论题。但限于篇幅，这里仅讨论一些Go特有的东西。\r\n\r\n	在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。\r\n	Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。\r\n	在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。\r\n	为了提倡这种思考方式，我们将它简化为一句口号：\r\n\r\n	```\r\n\r\n	不要通过共享内存来通信，而应通过通信来共享内存。\r\n\r\n	```\r\n\r\n	这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。\r\n	但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。\r\n\r\n	我们可以从典型的单线程运行在单CPU之上的情形来审视这种模型。它无需提供同步原语。\r\n	现在考虑另一种情况，它也无需同步。现在让它们俩进行通信。若将通信过程看做同步着，\r\n	那就完全不需要其它同步了。例如，Unix管道就与这种模型完美契合。\r\n	尽管Go的并发处理方式来源于Hoare的通信顺序处理（CSP），\r\n	它依然可以看做是类型安全的Unix管道的实现。\r\n\r\n Go程\r\n\r\n\r\n	我们称之为Go程是因为现有的术语—线程、协程、进程等等—无法准确传达它的含义。\r\n	Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的，\r\n	所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价，\r\n	仅在需要时才会随着堆空间的分配（和释放）而变化。\r\n\r\n	Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O，\r\n	那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。\r\n\r\n	在函数或方法前添加 go 关键字能够在新的Go程中调用它。当调用完成后，\r\n	该Go程也会安静地退出。（效果有点像Unix Shell中的 &\r\n	符号，它能让命令在后台运行。）\r\n\r\n	```\r\n	go list.Sort()  // 并发运行 list.Sort，无需等它结束。\r\n\r\n	```\r\n\r\n	函数字面在Go程调用中非常有用。\r\n\r\n	```\r\n	func Announce(message string, delay time.Duration) {\r\n		go func() {\r\n			time.Sleep(delay)\r\n			fmt.Println(message)\r\n		}()  // 注意括号 - 必须调用该函数。\r\n	}\r\n\r\n	```\r\n\r\n	在Go中，函数字面都是闭包：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。\r\n\r\n	这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。\r\n\r\n 信道\r\n\r\n\r\n	信道与映射一样，也需要通过 make 来分配内存。其结果值充当了对底层数据结构的引用。\r\n	若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲的或同步的信道。\r\n\r\n	```\r\n	ci := make(chan int)            // 整数类型的无缓冲信道\r\n	cj := make(chan int, 0)         // 整数类型的无缓冲信道\r\n	cs := make(chan *os.File, 100)  // 指向文件指针的带缓冲信道\r\n\r\n	```\r\n\r\n	无缓冲信道在通信时会同步交换数据，它能确保（两个Go程的）计算处于确定状态。\r\n\r\n	信道有很多惯用法，我们从这里开始了解。在上一节中，我们在后台启动了排序操作。\r\n	信道使得启动的Go程等待排序完成。\r\n\r\n	```\r\n	c := make(chan int)  // 分配一个信道\r\n	// 在Go程中启动排序。当它完成后，在信道上发送信号。\r\n	go func() {\r\n		list.Sort()\r\n		c <- 1  // 发送信号，什么值无所谓。\r\n	}()\r\n	doSomethingForAWhile()\r\n	<-c   // 等待排序结束，丢弃发来的值。\r\n\r\n	```\r\n\r\n	接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前，\r\n	发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞；\r\n	若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。\r\n\r\n	带缓冲的信道可被用作信号量，例如限制吞吐量。在此例中，进入的请求会被传递给\r\n	handle，它从信道中接收值，处理请求后将值发回该信道中，以便让该\r\n	“信号量”准备迎接下一次请求。信道缓冲区的容量决定了同时调用 process\r\n	的数量上限，因此我们在初始化时首先要填充至它的容量上限。\r\n\r\n	```\r\n	var sem = make(chan int, MaxOutstanding)\r\n\r\n	func handle(r *Request) {\r\n		sem <- 1 // 等待活动队列清空。\r\n		process(r)  // 可能需要很长时间。\r\n		<-sem    // 完成；使下一个请求可以运行。\r\n	}\r\n\r\n	func Serve(queue chan *Request) {\r\n		for {\r\n			req := <-queue\r\n			go handle(req)  // 无需等待 handle 结束。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	由于数据同步发生在信道的接收端（也就是说发送发生在>接受之前，参见\r\n	[Go内存模型](http://172.16.132.221:8081/ref/mem)），因此信号必须在信道的接收端获取，而非发送端。\r\n\r\n	然而，它却有个设计问题：尽管只有 MaxOutstanding 个Go程能同时运行，但\r\n	Serve 还是为每个进入的请求都创建了新的Go程。其结果就是，若请求来得很快，\r\n	该程序就会无限地消耗资源。为了弥补这种不足，我们可以通过修改 Serve\r\n	来限制创建Go程，这是个明显的解决方案，但要当心我们修复后出现的Bug。\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func() {\r\n				process(req) // 这儿有Bug，解释见下。\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n	```\r\n\r\n	Bug出现在Go的 for 循环中，该循环变量在每次迭代时会被重用，因此\r\n	req 变量会在所有的Go程间共享，这不是我们想要的。我们需要确保\r\n	req 对于每个Go程来说都是唯一的。有一种方法能够做到，就是将\r\n	req 的值作为实参传入到该Go程的闭包中：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			sem <- 1\r\n			go func(req *Request) {\r\n				process(req)\r\n				<-sem\r\n			}(req)\r\n		}\r\n	}\r\n	```\r\n\r\n	比较前后两个版本，观察该闭包声明和运行中的差别。\r\n	另一种解决方案就是以相同的名字创建新的变量，如例中所示：\r\n\r\n	```\r\n	func Serve(queue chan *Request) {\r\n		for req := range queue {\r\n			req := req // 为该Go程创建 req 的新实例。\r\n			sem <- 1\r\n			go func() {\r\n				process(req)\r\n				<-sem\r\n			}()\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	它的写法看起来有点奇怪\r\n\r\n	```\r\n	req := req\r\n\r\n	```\r\n\r\n	但在Go中这样做是合法且惯用的。你用相同的名字获得了该变量的一个新的版本，\r\n	以此来局部地刻意屏蔽循环变量，使它对每个Go程保持唯一。\r\n\r\n	回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的\r\n	handle Go程，一起从请求信道中读取数据。Go程的数量限制了同时调用\r\n	process 的数量。Serve 同样会接收一个通知退出的信道，\r\n	在启动所有Go程后，它将阻塞并暂停从信道中接收消息。\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for r := range queue {\r\n			process(r)\r\n		}\r\n	}\r\n\r\n	func Serve(clientRequests chan *Request, quit chan bool) {\r\n		// 启动处理程序\r\n		for i := 0; i < MaxOutstanding; i++ {\r\n			go handle(clientRequests)\r\n		}\r\n		<-quit  // 等待通知退出。\r\n	}\r\n\r\n	```\r\n\r\n 信道中的信道\r\n\r\n\r\n	Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。\r\n	这种特性通常被用来实现安全、并行的多路分解。\r\n\r\n	在上一节的例子中，handle 是个非常理想化的请求处理程序，\r\n	但我们并未定义它所处理的请求类型。若该类型包含一个可用于回复的信道，\r\n	那么每一个客户端都能为其回应提供自己的路径。以下为 Request\r\n	类型的大概定义。\r\n\r\n	```\r\n	type Request struct {\r\n		args        []int\r\n		f           func([]int) int\r\n		resultChan  chan int\r\n	}\r\n\r\n	```\r\n\r\n	客户端提供了一个函数及其实参，此外在请求对象中还有个接收应答的信道。\r\n\r\n	```\r\n	func sum(a []int) (s int) {\r\n		for _, v := range a {\r\n			s += v\r\n		}\r\n		return\r\n	}\r\n\r\n	request := &Request{[]int{3, 4, 5}, sum, make(chan int)}\r\n	// 发送请求\r\n	clientRequests <- request\r\n	// 等待回应\r\n	fmt.Printf("answer: %d\\n", <-request.resultChan)\r\n\r\n	```\r\n\r\n	On the server side, the handler function is the only thing that changes.\r\n\r\n	```\r\n	func handle(queue chan *Request) {\r\n		for req := range queue {\r\n			req.resultChan <- req.f(req.args)\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	要使其实际可用还有很多工作要做，这些代码仅能实现一个速率有限、并行、非阻塞RPC系统的\r\n	框架，而且它并不包含互斥锁。\r\n\r\n 并行化\r\n\r\n\r\n	这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块\r\n	可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。\r\n\r\n	让我们看看这个理想化的例子。我们在对一系列向量项进行极耗资源的操作，\r\n	而每个项的值计算是完全独立的。\r\n\r\n	```\r\n	type Vector []float64\r\n\r\n	// 将此操应用至 v[i], v[i+1] ... 直到 v[n-1]\r\n	func (v Vector) DoSome(i, n int, u Vector, c chan int) {\r\n		for ; i < n; i++ {\r\n			v[i] += u.Op(v[i])\r\n		}\r\n		c <- 1    // 发信号表示这一块计算完成。\r\n	}\r\n\r\n	```\r\n\r\n	我们在循环中启动了独立的处理块，每个CPU将执行一个处理。\r\n	它们有可能以乱序的形式完成并结束，但这没有关系；\r\n	我们只需在所有Go程开始后接收，并统计信道中的完成信号即可。\r\n\r\n	```\r\n	const NCPU = 4  // CPU核心数\r\n\r\n	func (v Vector) DoAll(u Vector) {\r\n		c := make(chan int, NCPU)  // 缓冲区是可选的，但明显用上更好\r\n		for i := 0; i < NCPU; i++ {\r\n			go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)\r\n		}\r\n		// 排空信道。\r\n		for i := 0; i < NCPU; i++ {\r\n			<-c    // 等待任务完成\r\n		}\r\n		// 一切完成。\r\n	}\r\n\r\n	```\r\n\r\n	目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。\r\n	任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。\r\n	它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行，\r\n	就必须告诉运行时你希望同时有多少Go程能执行代码。有两种途径可意识形态，要么\r\n	在运行你的工作时将 GOMAXPROCS 环境变量设为你要使用的核心数，\r\n	要么导入 runtime 包并调用 runtime.GOMAXPROCS(NCPU)。\r\n	runtime.NumCPU() 的值可能很有用，它会返回当前机器的逻辑CPU核心数。\r\n	当然，随着调度算法和运行时的改进，将来会不再需要这种方法。\r\n\r\n	注意不要混淆并发和并行的概念：并发是用可独立执行的组件构造程序的方法，\r\n	而并行则是为了效率在多CPU上平行地进行计算。尽管Go的并发特性能够让某些问题更易构造成并行计算，\r\n	但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。\r\n	关于其中区别的讨论，见\r\n	[此博文](http://blog.golang.org/2013/01/concurrency-is-not-parallelism.html)。\r\n\r\n 可能泄露的缓冲区\r\n\r\n\r\n	并发编程的工具甚至能很容易地表达非并发的思想。这里有个提取自RPC包的例子。\r\n	客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区，\r\n	它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。\r\n	一旦消息缓冲区就绪，它将通过 serverChan 被发送到服务器。\r\n	serverChan.\r\n\r\n	```\r\n	var freeList = make(chan *Buffer, 100)\r\n	var serverChan = make(chan *Buffer)\r\n\r\n	func client() {\r\n		for {\r\n			var b *Buffer\r\n			// 若缓冲区可用就用它，不可用就分配个新的。\r\n			select {\r\n			case b = <-freeList:\r\n				// 获取一个，不做别的。\r\n			default:\r\n				// 非空闲，因此分配一个新的。\r\n				b = new(Buffer)\r\n			}\r\n			load(b)              // 从网络中读取下一条消息。\r\n			serverChan <- b   // 发送至服务器。\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。\r\n\r\n	```\r\n	func server() {\r\n		for {\r\n			b := <-serverChan    // 等待工作。\r\n			process(b)\r\n			// 若缓冲区有空间就重用它。\r\n			select {\r\n			case freeList <- b:\r\n				// 将缓冲区放大空闲列表中，不做别的。\r\n			default:\r\n				// 空闲列表已满，保持就好。\r\n			}\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n	客户端试图从 freeList 中获取缓冲区；若没有缓冲区可用，\r\n	它就将分配一个新的。服务器将 b 放回空闲列表 freeList\r\n	中直到列表已满，此时缓冲区将被丢弃，并被垃圾回收器回收。（select\r\n	语句中的 default 子句在没有条件符合时执行，这也就意味着\r\n	selects 永远不会被阻塞。）依靠带缓冲的信道和垃圾回收器的记录，\r\n	我们仅用短短几行代码就构建了一个可能导致缓冲区槽位泄露的空闲列表。\r\n\r\n 错误\r\n\r\n\r\n	库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性，\r\n	使得它在返回常规的值时，还能轻松地返回详细的错误描述。按照约定，错误的类型通常为\r\n	error，这是一个内建的简单接口。\r\n\r\n	```\r\n	type error interface {\r\n		Error() string\r\n	}\r\n\r\n	```\r\n\r\n	库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误，\r\n	还能提供一些上下文。例如，os.Open 可返回一个 os.PathError。\r\n\r\n	```\r\n	// PathError 记录一个错误以及产生该错误的路径和操作。\r\n	type PathError struct {\r\n		Op string    // "open"、"unlink" 等等。\r\n		Path string  // 相关联的文件。\r\n		Err error    // 由系统调用返回。\r\n	}\r\n\r\n	func (e *PathError) Error() string {\r\n		return e.Op + " " + e.Path + ": " + e.Err.Error()\r\n	}\r\n\r\n	```\r\n\r\n	PathError的 Error 会生成如下错误信息：\r\n\r\n	```\r\n	open /etc/passwx: no such file or directory\r\n\r\n	```\r\n\r\n	这种错误包含了出错的文件名、操作和触发的操作系统错误，即便在产生该错误的调用\r\n	和输出的错误信息相距甚远时，它也会非常有用，这比苍白的“不存在该文件或目录”更具说明性。\r\n\r\n	错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。例如在\r\n	image 包中，由于未知格式导致解码错误的字符串为“image: unknown format”。\r\n\r\n	若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。\r\n	对于 PathErrors，它应该还包含检查内部的 Err\r\n	字段以进行可能的错误恢复。\r\n\r\n	```\r\n	for try := 0; try < 2; try++ {\r\n		file, err = os.Create(filename)\r\n		if err == nil {\r\n			return\r\n		}\r\n		if e, ok := err.(*os.PathError); ok && e.Err == syscall.ENOSPC {\r\n			deleteTempFiles()  // 恢复一些空间。\r\n			continue\r\n		}\r\n		return\r\n	}\r\n\r\n	```\r\n\r\n	这里的第二条 if 是另一种[类型断言](#%E6%8E%A5%E5%8F%A3%E8%BD%AC%E6%8D%A2)。若它失败，\r\n	ok 将为 false，而 e 则为nil.\r\n	若它成功，ok 将为 true，这意味着该错误属于\r\n	*os.PathError 类型，而 e 能够检测关于该错误的更多信息。\r\n\r\n Panic\r\n\r\n\r\n	向调用者报告错误的一般方式就是将 error 作为额外的值返回。\r\n	标准的 Read 方法就是个众所周知的实例，它返回一个字节计数和一个\r\n	error。但如果错误时不可恢复的呢？有时程序就是不能继续运行。\r\n\r\n	为此，我们提供了内建的 panic 函数，它会产生一个运行时错误并终止程序\r\n	（但请继续看下一节）。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。\r\n	它还能表明发生了意料之外的事情，比如从无限循环中退出了。\r\n\r\n	```\r\n	// 用牛顿法计算立方根的一个玩具实现。\r\n	func CubeRoot(x float64) float64 {\r\n		z := x/3   // 任意初始值\r\n		for i := 0; i < 1e6; i++ {\r\n			prevz := z\r\n			z -= (z*z*z-x) / (3*z*z)\r\n			if veryClose(z, prevz) {\r\n				return z\r\n			}\r\n		}\r\n		// 一百万次迭代并未收敛，事情出错了。\r\n		panic(fmt.Sprintf("CubeRoot(%g) did not converge", x))\r\n	}\r\n\r\n	```\r\n\r\n	这仅仅是个示例，实际的库函数应避免 panic。若问题可以被屏蔽或解决，\r\n	最好就是让程序继续运行而不是终止整个程序。一个可能的反例就是初始化：\r\n	若某个库真的不能让自己工作，且有足够理由产生Panic，那就由它去吧。\r\n\r\n	```\r\n	var user = os.Getenv("USER")\r\n\r\n	func init() {\r\n		if user == "" {\r\n			panic("no value for $USER")\r\n		}\r\n	}\r\n\r\n	```\r\n\r\n 恢复\r\n\r\n\r\n	当 panic 被调用后（包括不明确的运行时错误，例如切片检索越界或类型断言失败），\r\n	程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。\r\n	若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的 recover\r\n	函数来重新或来取回Go程的控制权限并使其恢复正常执行。\r\n\r\n	调用 recover 将停止回溯过程，并返回传入 panic 的实参。\r\n	由于在回溯时只有被推迟函数中的代码在运行，因此 recover\r\n	只能在被推迟的函数中才有效。\r\n\r\n	recover 的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。\r\n\r\n	```\r\n	func server(workChan <-chan *Work) {\r\n		for work := range workChan {\r\n			go safelyDo(work)\r\n		}\r\n	}\r\n\r\n	func safelyDo(work *Work) {\r\n		defer func() {\r\n			if err := recover(); err != nil {\r\n				log.Println("work failed:", err)\r\n			}\r\n		}()\r\n		do(work)\r\n	}\r\n\r\n	```\r\n\r\n	在此例中，若 do(work) 触发了Panic，其结果就会被记录，\r\n	而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情，\r\n	recover 会处理好这一切。\r\n\r\n	由于直接从被推迟函数中调用 recover 时不会返回 nil，\r\n	因此被推迟的代码能够调用本身使用了 panic 和 recover\r\n	的库函数而不会失败。例如在 safelyDo 中，被推迟的函数可能在调用\r\n	recover 前先调用记录函数，而该记录函数应当不受Panic状态的代码的影响。\r\n\r\n	通过恰当地使用恢复模式，do 函数（及其调用的任何代码）可通过调用\r\n	panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。\r\n	让我们看看 regexp 包的理想化版本，它会以局部的错误类型调用 panic\r\n	来报告解析错误。以下是一个 error 类型的 Error 方法和一个\r\n	Compile 函数的定义：\r\n\r\n	```\r\n	// Error 是解析错误的类型，它满足 error 接口。\r\n	type Error string\r\n	func (e Error) Error() string {\r\n		return string(e)\r\n	}\r\n\r\n	// error 是 *Regexp 的方法，它通过用一个 Error 触发Panic来报告解析错误。\r\n	func (regexp *Regexp) error(err string) {\r\n		panic(Error(err))\r\n	}\r\n\r\n	// Compile 返回该正则表达式解析后的表示。\r\n	func Compile(str string) (regexp *Regexp, err error) {\r\n		regexp = new(Regexp)\r\n		// doParse will panic if there is a parse error.\r\n		defer func() {\r\n			if e := recover(); e != nil {\r\n				regexp = nil    // 清理返回值。\r\n				err = e.(Error) // 若它不是解析错误，将重新触发Panic。\r\n			}\r\n		}()\r\n		return regexp.doParse(str), nil\r\n	}\r\n\r\n	```\r\n\r\n	若 doParse 触发了Panic，恢复块会将返回值设为 nil\r\n	—被推迟的函数能够修改已命名的返回值。在 err 的赋值过程中，\r\n	我们将通过断言它是否拥有局部类型 Error 来检查它。若它没有，\r\n	类型断言将会失败，此时会产生运行时错误，并继续栈的回溯，仿佛一切从未中断过一样。\r\n	该检查意味着若发生了一些像索引越界之类的意外，那么即便我们使用了 panic\r\n	和 recover 来处理解析错误，代码仍然会失败。\r\n\r\n	通过适当的错误处理，error 方法（由于它是个绑定到具体类型的方法，\r\n	因此即便它与内建的 error 类型名字相同也没有关系）\r\n	能让报告解析错误变得更容易，而无需手动处理回溯的解析栈：\r\n\r\n	```\r\n	if pos == 0 {\r\n		re.error("''*'' illegal at start of expression")\r\n	}\r\n\r\n	```\r\n\r\n	尽管这种模式很有用，但它应当仅在包内使用。Parse 会将其内部的\r\n	panic 调用转为 error 值，它并不会向调用者暴露出\r\n	panic。这是个值得遵守的良好规则。\r\n\r\n	顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。\r\n	然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。\r\n	这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。\r\n	但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。\r\n	这里就将这个练习留给读者了。\r\n\r\n 一个Web服务器\r\n\r\n\r\n	让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。\r\n	Google在[http://chart.apis.google.com](http://chart.apis.google.com)\r\n	上提供了一个将表单数据自动转换为图表的服务。不过，该服务很难交互，\r\n	因为你需要将数据作为查询放到URL中。此程序为一种数据格式提供了更好的的接口：\r\n	给定一小段文本，它将调用图表服务器来生成二维码（QR码），这是一种编码文本的点格矩阵。\r\n	该图像可被你的手机摄像头捕获，并解释为一个字符串，比如URL，\r\n	这样就免去了你在狭小的手机键盘上键入URL的麻烦。\r\n\r\n	以下为完整的程序，随后有一段解释。\r\n\r\n	```\r\n	package main\r\n\r\n	import (\r\n	    "flag"\r\n	    "html/template"\r\n	    "log"\r\n	    "net/http"\r\n	)\r\n\r\n	var addr = flag.String("addr", ":1718", "http service address") // Q=17, R=18\r\n\r\n	var templ = template.Must(template.New("qr").Parse(templateStr))\r\n\r\n	func main() {\r\n	    flag.Parse()\r\n	    http.Handle("/", http.HandlerFunc(QR))\r\n	    err := http.ListenAndServe(*addr, nil)\r\n	    if err != nil {\r\n		log.Fatal("ListenAndServe:", err)\r\n	    }\r\n	}\r\n\r\n	func QR(w http.ResponseWriter, req *http.Request) {\r\n	    templ.Execute(w, req.FormValue("s"))\r\n	}\r\n\r\n	const templateStr = `\r\n	<html>\r\n	<head>\r\n	<title>QR Link Generator</title>\r\n	</head>\r\n	<body>\r\n	{{if .}}\r\n	<img src="http://chart.apis.google.com/chart?chs=300x300&cht=qr&choe=UTF-8&chl={{.}}" />\r\n	<br>\r\n	{{.}}\r\n	<br>\r\n	<br>\r\n	{{end}}\r\n	<form action="/" name=f method="GET"><input maxLength=1024 size=70\r\n	name=s value="" title="Text to QR Encode"><input type=submit\r\n	value="Show QR" name=qr>\r\n	</form>\r\n	</body>\r\n	</html>\r\n	`\r\n	```\r\n\r\n	main 之前的代码应该比较容易理解。我们通过一个标志为服务器设置了默认端口。\r\n	模板变量  templ 正式有趣的地方。它构建的HTML模版将会被服务器执行并显示在页面中。\r\n	稍后我们将详细讨论。\r\n\r\n	main 函数解析了参数标志并使用我们讨论过的机制将 QR\r\n	函数绑定到服务器的根路径。然后调用 http.ListenAndServe\r\n	启动服务器；它将在服务器运行时处于阻塞状态。\r\n\r\n	QR 仅接受包含表单数据的请求，并为表单值 s 中的数据执行模板。\r\n\r\n	模板包 html/template 非常强大；该程序只是浅尝辄止。\r\n	本质上，它通过在运行时将数据项中提取的元素（在这里是表单值）传给\r\n	templ.Execute 执行因而重写了HTML文本。\r\n	在模板文本（templateStr）中，双大括号界定的文本表示模板的动作。\r\n	从 {{if .}} 到 {{end}}\r\n	的代码段仅在当前数据项（这里是点 .）的值非空时才会执行。\r\n	也就是说，当字符串为空时，此部分模板段会被忽略。\r\n\r\n	其中两段 {{.}} 表示要将数据显示在模板中\r\n	（即将查询字符串显示在Web页面上）。HTML模板包将自动对文本进行转义，\r\n	因此文本的显示是安全的。\r\n\r\n	余下的模板字符串只是页面加载时将要显示的HTML。如果这段解释你无法理解，请参考\r\n	[文档](http://172.16.132.221:8081/pkg/html/template/) 获得更多有关模板包的解释。\r\n\r\n	你终于如愿以偿了：以几行代码实现的，包含一些数据驱动的HTML文本的Web服务器。\r\n	Go语言强大到能让很多事情以短小精悍的方式解决。\r\n\r\n', '');
INSERT INTO `cmdhelp` (`id`, `cmd`, `cmdinfo`, `description`) VALUES
(155, 'vmstat', 'vmstat命令是最常见的Linux/Unix监控工具，可以展现给定时间间隔的服务器的状态值,包括服务器的CPU使用率，内存使用，虚拟内存交换情况,IO读写情况。这个命令是我查看Linux/Unix最喜爱的命令，一个是Linux/Unix都支持，二是相比top，我可以看到整个机器的CPU,内存,IO的使用情况，而不是单单看到各个进程的CPU使用率和内存使用率(使用场景不一样)。\n\n一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:\n\nroot@ubuntu:~# vmstat 2 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\n  1  0      0 3498472 315836 3819540    0    0     0     1    2    0  0  0 100  0\n\n  2表示每个两秒采集一次服务器状态，1表示只采集一次。\n\n  实际上，在应用过程中，我们会在一段时间内一直监控，不想监控直接结束vmstat就行了,例如:\n  复制代码\n\n  root@ubuntu:~# vmstat 2\n  procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\n   r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\n   1  0      0 3499840 315836 3819660    0    0     0     1    2    0  0  0 100  0\n   0  0      0 3499584 315836 3819660    0    0     0     0   88  158  0  0 100  0\n   0  0      0 3499708 315836 3819660    0    0     0     2   86  162  0  0 100  0\n   0  0      0 3499708 315836 3819660    0    0     0    10   81  151  0  0 100  0\n   1  0      0 3499732 315836 3819660    0    0     0     2   83  154  0  0 100  0\n\n\n 这表示vmstat每2秒采集数据，一直采集，直到我结束程序，这里采集了5次数据我就结束了程序。\n\n 好了，命令介绍完毕，现在开始实战讲解每个参数的意思。\n\n参数说明：\n\n     r 表示运行队列(就是说多少个进程真的分配到CPU)，我测试的服务器目前CPU比较空闲，没什么程序在跑，当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。\n\n     b 表示阻塞的进程,这个不多说，进程阻塞，大家懂的。\n\n     swpd 虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。\n\n     free   空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。\n\n     buff   Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M\n\n     cache cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)\n\n     si  每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。\n\n     so  每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。\n\n     bi  块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒\n\n     bo 块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。\n\n     in 每秒CPU的中断次数，包括时间中断\n\n     cs 每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。\n\n     us 用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。\n\n     sy 系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。\n\n     id  空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。\n\n     wt 等待IO CPU时间。\n', ''),
(156, 'virsh', 'virsh 使用说明 \r\n   \r\n   Domain Management (help keyword ''domain'') \r\n      attach-device                  attach device from an XML file \r\n      attach-disk                    attach disk device \r\n      attach-interface               attach network interface \r\n      autostart                      autostart a domain \r\n      blkdeviotune                   Set or query a block device I/O tuning parameters.  \r\n      blkiotune                      Get or set blkio parameters \r\n      blockcommit                    Start a block commit operation.  \r\n      blockcopy                      Start a block copy operation.  \r\n      blockjob                       Manage active block operations \r\n      blockpull                      Populate a disk from its backing image.  \r\n      blockresize                    Resize block device of domain.  \r\n      change-media                   Change media of CD or floppy drive \r\n      console                        connect to the guest console \r\n      cpu-baseline                   compute baseline CPU \r\n      cpu-compare                    compare host CPU with a CPU described by an XML file \r\n      cpu-stats                      show domain cpu statistics \r\n      create                         create a domain from an XML file \r\n      define                         define (but don''t start) a domain from an XML file \r\n      desc                           show or set domain''s description or title \r\n      destroy                        destroy (stop) a domain \r\n      detach-device                  detach device from an XML file \r\n      detach-disk                    detach disk device \r\n      detach-interface               detach network interface \r\n      domdisplay                     domain display connection URI \r\n      domhostname                    print the domain''s hostname \r\n      domid                          convert a domain name or UUID to domain id \r\n      domif-setlink                  set link state of a virtual interface \r\n      domiftune                      get/set parameters of a virtual interface \r\n      domjobabort                    abort active domain job \r\n      domjobinfo                     domain job information \r\n      domname                        convert a domain id or UUID to domain name \r\n      dompmsuspend                   suspend a domain gracefully using power management functions \r\n      dompmwakeup                    wakeup a domain from pmsuspended state \r\n      domuuid                        convert a domain name or id to domain UUID \r\n      domxml-from-native             Convert native config to domain XML \r\n      domxml-to-native               Convert domain XML to native config \r\n      dump                           dump the core of a domain to a file for analysis \r\n      dumpxml                        domain information in XML \r\n      edit                           edit XML configuration for a domain \r\n      inject-nmi                     Inject NMI to the guest \r\n      send-key                       Send keycodes to the guest \r\n      managedsave                    managed save of a domain state \r\n      managedsave-remove             Remove managed save of a domain \r\n      maxvcpus                       connection vcpu maximum \r\n      memtune                        Get or set memory parameters \r\n      migrate                        migrate domain to another host \r\n      migrate-setmaxdowntime         set maximum tolerable downtime \r\n      migrate-setspeed               Set the maximum migration bandwidth \r\n      migrate-getspeed               Get the maximum migration bandwidth \r\n      numatune                       Get or set numa parameters \r\n      reboot                         reboot a domain \r\n      reset                          reset a domain \r\n      restore                        restore a domain from a saved state in a file \r\n      resume                         resume a domain \r\n      save                           save a domain state to a file \r\n      save-image-define              redefine the XML for a domain''s saved state file \r\n      save-image-dumpxml             saved state domain information in XML \r\n      save-image-edit                edit XML for a domain''s saved state file \r\n      schedinfo                      show/set scheduler parameters \r\n      screenshot                     take a screenshot of a current domain console and store it into a file \r\n      setmaxmem                      change maximum memory limit \r\n      setmem                         change memory allocation \r\n      setvcpus                       change number of virtual CPUs \r\n      shutdown                       gracefully shutdown a domain \r\n      start                          start a (previously defined) inactive domain \r\n      suspend                        suspend a domain \r\n      ttyconsole                     tty console \r\n      undefine                       undefine a domain \r\n      update-device                  update device from an XML file \r\n      vcpucount                      domain vcpu counts \r\n      vcpuinfo                       detailed domain vcpu information \r\n      vcpupin                        control or query domain vcpu affinity \r\n      emulatorpin                    control or query domain emulator affinity \r\n      vncdisplay                     vnc display \r\n   \r\n   Domain Monitoring (help keyword ''monitor'') \r\n      domblkerror                    Show errors on block devices \r\n      domblkinfo                     domain block device size information \r\n      domblklist                     list all domain blocks \r\n      domblkstat                     get device block stats for a domain \r\n      domcontrol                     domain control interface state \r\n      domif-getlink                  get link state of a virtual interface \r\n      domiflist                      list all domain virtual interfaces \r\n      domifstat                      get network interface stats for a domain \r\n      dominfo                        domain information \r\n      dommemstat                     get memory statistics for a domain \r\n      domstate                       domain state \r\n      list                           list domains \r\n   \r\n   Host and Hypervisor (help keyword ''host'') \r\n      capabilities                   capabilities \r\n      freecell                       NUMA free memory \r\n      hostname                       print the hypervisor hostname \r\n      node-memory-tune               Get or set node memory parameters \r\n      nodecpustats                   Prints cpu stats of the node.  \r\n      nodeinfo                       node information \r\n      nodememstats                   Prints memory stats of the node.  \r\n      nodesuspend                    suspend the host node for a given time duration \r\n      qemu-attach                    QEMU Attach \r\n      qemu-monitor-command           QEMU Monitor Command \r\n      qemu-agent-command             QEMU Guest Agent Command \r\n      sysinfo                        print the hypervisor sysinfo \r\n      uri                            print the hypervisor canonical URI \r\n      version                        show version \r\n   \r\n   Interface (help keyword ''interface'') \r\n      iface-begin                    create a snapshot of current interfaces settings, which can be later committed (iface-commit) or restored (iface-rollback) \r\n      iface-bridge                   create a bridge device and attach an existing network device to it \r\n      iface-commit                   commit changes made since iface-begin and free restore point \r\n      iface-define                   define (but don''t start) a physical host interface from an XML file \r\n      iface-destroy                  destroy a physical host interface (disable it / "if-down") \r\n      iface-dumpxml                  interface information in XML \r\n      iface-edit                     edit XML configuration for a physical host interface \r\n      iface-list                     list physical host interfaces \r\n      iface-mac                      convert an interface name to interface MAC address \r\n      iface-name                     convert an interface MAC address to interface name \r\n      iface-rollback                 rollback to previous saved configuration created via iface-begin \r\n      iface-start                    start a physical host interface (enable it / "if-up") \r\n      iface-unbridge                 undefine a bridge device after detaching its slave device \r\n      iface-undefine                 undefine a physical host interface (remove it from configuration) \r\n   \r\n   Network Filter (help keyword ''filter'') \r\n      nwfilter-define                define or update a network filter from an XML file \r\n      nwfilter-dumpxml               network filter information in XML \r\n      nwfilter-edit                  edit XML configuration for a network filter \r\n      nwfilter-list                  list network filters \r\n      nwfilter-undefine              undefine a network filter \r\n   \r\n   Networking (help keyword ''network'') \r\n      net-autostart                  autostart a network \r\n      net-create                     create a network from an XML file \r\n      net-define                     define (but don''t start) a network from an XML file \r\n      net-destroy                    destroy (stop) a network \r\n      net-dumpxml                    network information in XML \r\n      net-edit                       edit XML configuration for a network \r\n      net-info                       network information \r\n      net-list                       list networks \r\n      net-name                       convert a network UUID to network name \r\n      net-start                      start a (previously defined) inactive network \r\n      net-undefine                   undefine an inactive network \r\n      net-update                     update parts of an existing network''s configuration \r\n      net-uuid                       convert a network name to network UUID \r\n   \r\n   Node Device (help keyword ''nodedev'') \r\n      nodedev-create                 create a device defined by an XML file on the node \r\n      nodedev-destroy                destroy (stop) a device on the node \r\n      nodedev-detach                 detach node device from its device driver \r\n      nodedev-dumpxml                node device details in XML \r\n      nodedev-list                   enumerate devices on this host \r\n      nodedev-reattach               reattach node device to its device driver \r\n      nodedev-reset                  reset node device \r\n   \r\n   Secret (help keyword ''secret'') \r\n      secret-define                  define or modify a secret from an XML file \r\n      secret-dumpxml                 secret attributes in XML \r\n      secret-get-value               Output a secret value \r\n      secret-list                    list secrets \r\n      secret-set-value               set a secret value \r\n      secret-undefine                undefine a secret \r\n   \r\n   Snapshot (help keyword ''snapshot'') \r\n      snapshot-create                Create a snapshot from XML \r\n      snapshot-create-as             Create a snapshot from a set of args \r\n      snapshot-current               Get or set the current snapshot \r\n      snapshot-delete                Delete a domain snapshot \r\n      snapshot-dumpxml               Dump XML for a domain snapshot \r\n      snapshot-edit                  edit XML for a snapshot \r\n      snapshot-info                  snapshot information \r\n      snapshot-list                  List snapshots for a domain \r\n      snapshot-parent                Get the name of the parent of a snapshot \r\n      snapshot-revert                Revert a domain to a snapshot \r\n   \r\n   Storage Pool (help keyword ''pool'') \r\n      find-storage-pool-sources-as   find potential storage pool sources \r\n      find-storage-pool-sources      discover potential storage pool sources \r\n      pool-autostart                 autostart a pool \r\n      pool-build                     build a pool \r\n      pool-create-as                 create a pool from a set of args \r\n      pool-create                    create a pool from an XML file \r\n      pool-define-as                 define a pool from a set of args \r\n      pool-define                    define (but don''t start) a pool from an XML file \r\n      pool-delete                    delete a pool \r\n      pool-destroy                   destroy (stop) a pool \r\n      pool-dumpxml                   pool information in XML \r\n      pool-edit                      edit XML configuration for a storage pool \r\n      pool-info                      storage pool information \r\n      pool-list                      list pools \r\n      pool-name                      convert a pool UUID to pool name \r\n      pool-refresh                   refresh a pool \r\n      pool-start                     start a (previously defined) inactive pool \r\n      pool-undefine                  undefine an inactive pool \r\n      pool-uuid                      convert a pool name to pool UUID \r\n   \r\n   Storage Volume (help keyword ''volume'') \r\n      vol-clone                      clone a volume.  \r\n      vol-create-as                  create a volume from a set of args \r\n      vol-create                     create a vol from an XML file \r\n      vol-create-from                create a vol, using another volume as input \r\n      vol-delete                     delete a vol \r\n      vol-download                   Download a volume to a file \r\n      vol-dumpxml                    vol information in XML \r\n      vol-info                       storage vol information \r\n      vol-key                        returns the volume key for a given volume name or path \r\n      vol-list                       list vols \r\n      vol-name                       returns the volume name for a given volume key or path \r\n      vol-path                       returns the volume path for a given volume name or key \r\n      vol-pool                       returns the storage pool for a given volume key or path \r\n      vol-resize                     resize a vol \r\n      vol-upload                     upload a file into a volume \r\n      vol-wipe                       wipe a vol \r\n   \r\n   Virsh itself (help keyword ''virsh'') \r\n      cd                             change the current directory \r\n      connect                        (re)connect to hypervisor \r\n      echo                           echo arguments \r\n      exit                           quit this interactive terminal \r\n      help                           print help \r\n      pwd                            print the current directory \r\n      quit                           quit this interactive terminal \r\n   \r\n   \r\n  ########################################################################### \r\n  简单使用 \r\n   \r\n  virsh define xxx.xml 定义 \r\n  virsh create xxx.xml 创建 \r\n  virsh start uuid  运行 \r\n  virsh console uuid 进入虚拟机终端 \r\n  virsh destroy uuid 删除虚拟机 \r\n  virsh undefine uuid 删除定义 \r\n  virsh list 虚拟机列表 \r\n  \n', ''),
(166, 'docker', '##########################################################################\n\nUsage:	docker attach [OPTIONS] CONTAINER\n\nAttach to a running container\n\n  --detach-keys       Override the key sequence for detaching a container\n  --help              Print usage\n  --no-stdin          Do not attach STDIN\n  --sig-proxy=true    Proxy all received signals to the process\n##########################################################################\n\nUsage:	docker build [OPTIONS] PATH | URL | -\n\nBuild an image from a Dockerfile\n\n  --build-arg=[]                  Set build-time variables\n  --cpu-shares                    CPU shares (relative weight)\n  --cgroup-parent                 Optional parent cgroup for the container\n  --cpu-period                    Limit the CPU CFS (Completely Fair Scheduler) period\n  --cpu-quota                     Limit the CPU CFS (Completely Fair Scheduler) quota\n  --cpuset-cpus                   CPUs in which to allow execution (0-3, 0,1)\n  --cpuset-mems                   MEMs in which to allow execution (0-3, 0,1)\n  --disable-content-trust=true    Skip image verification\n  -f, --file                      Name of the Dockerfile (Default is ''PATH/Dockerfile'')\n  --force-rm                      Always remove intermediate containers\n  --help                          Print usage\n  --isolation                     Container isolation level\n  -m, --memory                    Memory limit\n  --memory-swap                   Swap limit equal to memory plus swap: ''-1'' to enable unlimited swap\n  --no-cache                      Do not use cache when building the image\n  --pull                          Always attempt to pull a newer version of the image\n  -q, --quiet                     Suppress the build output and print image ID on success\n  --rm=true                       Remove intermediate containers after a successful build\n  --shm-size                      Size of /dev/shm, default value is 64MB\n  -t, --tag=[]                    Name and optionally a tag in the ''name:tag'' format\n  --ulimit=[]                     Ulimit options\n##########################################################################\n\nUsage:	docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n\nCreate a new image from a container''s changes\n\n  -a, --author        Author (e.g., "John Hannibal Smith <hannibal@a-team.com>")\n  -c, --change=[]     Apply Dockerfile instruction to the created image\n  --help              Print usage\n  -m, --message       Commit message\n  -p, --pause=true    Pause container during commit\n##########################################################################\n\nUsage:	docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-\n	docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH\n\nCopy files/folders between a container and the local filesystem\nUse ''-'' as the source to read a tar archive from stdin\nand extract it to a directory destination in a container.\nUse ''-'' as the destination to stream a tar archive of a\ncontainer source to stdout.\n\n  --help               Print usage\n  -L, --follow-link    Always follow symbol link in SRC_PATH\n##########################################################################\n\nUsage:	docker create [OPTIONS] IMAGE [COMMAND] [ARG...]\n\nCreate a new container\n\n  -a, --attach=[]                 Attach to STDIN, STDOUT or STDERR\n  --add-host=[]                   Add a custom host-to-IP mapping (host:ip)\n  --blkio-weight                  Block IO (relative weight), between 10 and 1000\n  --blkio-weight-device=[]        Block IO weight (relative device weight)\n  --cpu-shares                    CPU shares (relative weight)\n  --cap-add=[]                    Add Linux capabilities\n  --cap-drop=[]                   Drop Linux capabilities\n  --cgroup-parent                 Optional parent cgroup for the container\n  --cidfile                       Write the container ID to the file\n  --cpu-period                    Limit CPU CFS (Completely Fair Scheduler) period\n  --cpu-quota                     Limit CPU CFS (Completely Fair Scheduler) quota\n  --cpuset-cpus                   CPUs in which to allow execution (0-3, 0,1)\n  --cpuset-mems                   MEMs in which to allow execution (0-3, 0,1)\n  --device=[]                     Add a host device to the container\n  --device-read-bps=[]            Limit read rate (bytes per second) from a device\n  --device-read-iops=[]           Limit read rate (IO per second) from a device\n  --device-write-bps=[]           Limit write rate (bytes per second) to a device\n  --device-write-iops=[]          Limit write rate (IO per second) to a device\n  --disable-content-trust=true    Skip image verification\n  --dns=[]                        Set custom DNS servers\n  --dns-opt=[]                    Set DNS options\n  --dns-search=[]                 Set custom DNS search domains\n  -e, --env=[]                    Set environment variables\n  --entrypoint                    Overwrite the default ENTRYPOINT of the image\n  --env-file=[]                   Read in a file of environment variables\n  --expose=[]                     Expose a port or a range of ports\n  --group-add=[]                  Add additional groups to join\n  -h, --hostname                  Container host name\n  --help                          Print usage\n  -i, --interactive               Keep STDIN open even if not attached\n  --ip                            Container IPv4 address (e.g. 172.30.100.104)\n  --ip6                           Container IPv6 address (e.g. 2001:db8::33)\n  --ipc                           IPC namespace to use\n  --isolation                     Container isolation level\n  --kernel-memory                 Kernel memory limit\n  -l, --label=[]                  Set meta data on a container\n  --label-file=[]                 Read in a line delimited file of labels\n  --link=[]                       Add link to another container\n  --log-driver                    Logging driver for container\n  --log-opt=[]                    Log driver options\n  -m, --memory                    Memory limit\n  --mac-address                   Container MAC address (e.g. 92:d0:c6:0a:29:33)\n  --memory-reservation            Memory soft limit\n  --memory-swap                   Swap limit equal to memory plus swap: ''-1'' to enable unlimited swap\n  --memory-swappiness=-1          Tune container memory swappiness (0 to 100)\n  --name                          Assign a name to the container\n  --net=default                   Connect a container to a network\n  --net-alias=[]                  Add network-scoped alias for the container\n  --oom-kill-disable              Disable OOM Killer\n  --oom-score-adj                 Tune host''s OOM preferences (-1000 to 1000)\n  -P, --publish-all               Publish all exposed ports to random ports\n  -p, --publish=[]                Publish a container''s port(s) to the host\n  --pid                           PID namespace to use\n  --privileged                    Give extended privileges to this container\n  --read-only                     Mount the container''s root filesystem as read only\n  --restart=no                    Restart policy to apply when a container exits\n  --security-opt=[]               Security Options\n  --shm-size                      Size of /dev/shm, default value is 64MB\n  --stop-signal=SIGTERM           Signal to stop a container, SIGTERM by default\n  -t, --tty                       Allocate a pseudo-TTY\n  --tmpfs=[]                      Mount a tmpfs directory\n  -u, --user                      Username or UID (format: <name|uid>[:<group|gid>])\n  --ulimit=[]                     Ulimit options\n  --uts                           UTS namespace to use\n  -v, --volume=[]                 Bind mount a volume\n  --volume-driver                 Optional volume driver for the container\n  --volumes-from=[]               Mount volumes from the specified container(s)\n  -w, --workdir                   Working directory inside the container\n##########################################################################\n\nUsage:	docker diff [OPTIONS] CONTAINER\n\nInspect changes on a container''s filesystem\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker events [OPTIONS]\n\nGet real time events from the server\n\n  -f, --filter=[]    Filter output based on conditions provided\n  --help             Print usage\n  --since            Show all events created since timestamp\n  --until            Stream events until this timestamp\n##########################################################################\n\nUsage:	docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n\nRun a command in a running container\n\n  -d, --detach         Detached mode: run command in the background\n  --detach-keys        Override the key sequence for detaching a container\n  --help               Print usage\n  -i, --interactive    Keep STDIN open even if not attached\n  --privileged         Give extended privileges to the command\n  -t, --tty            Allocate a pseudo-TTY\n  -u, --user           Username or UID (format: <name|uid>[:<group|gid>])\n##########################################################################\n\nUsage:	docker export [OPTIONS] CONTAINER\n\nExport a container''s filesystem as a tar archive\n\n  --help             Print usage\n  -o, --output       Write to a file, instead of STDOUT\n##########################################################################\n\nUsage:	docker history [OPTIONS] IMAGE\n\nShow the history of an image\n\n  -H, --human=true    Print sizes and dates in human readable format\n  --help              Print usage\n  --no-trunc          Don''t truncate output\n  -q, --quiet         Only show numeric IDs\n##########################################################################\n\nUsage:	docker images [OPTIONS] [REPOSITORY[:TAG]]\n\nList images\n\n  -a, --all          Show all images (default hides intermediate images)\n  --digests          Show digests\n  -f, --filter=[]    Filter output based on conditions provided\n  --format           Pretty-print images using a Go template\n  --help             Print usage\n  --no-trunc         Don''t truncate output\n  -q, --quiet        Only show numeric IDs\n##########################################################################\n\nUsage:	docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]\n\nImport the contents from a tarball to create a filesystem image\n\n  -c, --change=[]    Apply Dockerfile instruction to the created image\n  --help             Print usage\n  -m, --message      Set commit message for imported image\n##########################################################################\n\nUsage:	docker info [OPTIONS]\n\nDisplay system-wide information\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...]\n\nReturn low-level information on a container or image\n\n  -f, --format       Format the output using the given go template\n  --help             Print usage\n  -s, --size         Display total file sizes if the type is container\n  --type             Return JSON for specified type, (e.g image or container)\n##########################################################################\n\nUsage:	docker kill [OPTIONS] CONTAINER [CONTAINER...]\n\nKill a running container\n\n  --help               Print usage\n  -s, --signal=KILL    Signal to send to the container\n##########################################################################\n\nUsage:	docker load [OPTIONS]\n\nLoad an image from a tar archive or STDIN\n\n  --help             Print usage\n  -i, --input        Read from a tar archive file, instead of STDIN\n##########################################################################\n\nUsage:	docker login [OPTIONS] [SERVER]\n\nRegister or log in to a Docker registry.\nIf no server is specified, the default is defined by the daemon.\n\n  -e, --email        Email\n  --help             Print usage\n  -p, --password     Password\n  -u, --username     Username\n##########################################################################\n\nUsage:	docker logout [OPTIONS] [SERVER]\n\nLog out from a Docker registry.\nIf no server is specified, the default is defined by the daemon.\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker logs [OPTIONS] CONTAINER\n\nFetch the logs of a container\n\n  -f, --follow        Follow log output\n  --help              Print usage\n  --since             Show logs since timestamp\n  -t, --timestamps    Show timestamps\n  --tail=all          Number of lines to show from the end of the logs\n##########################################################################\n\nUsage:	docker network [OPTIONS] COMMAND [OPTIONS]\n\nCommands:\n  disconnect               Disconnect container from a network\n  inspect                  Display detailed network information\n  ls                       List all networks\n  rm                       Remove a network\n  create                   Create a network\n  connect                  Connect container to a network\n\nRun ''docker network COMMAND --help'' for more information on a command.\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker pause [OPTIONS] CONTAINER [CONTAINER...]\n\nPause all processes within a container\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker port [OPTIONS] CONTAINER [PRIVATE_PORT[/PROTO]]\n\nList port mappings or a specific mapping for the CONTAINER\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker ps [OPTIONS]\n\nList containers\n\n  -a, --all          Show all containers (default shows just running)\n  -f, --filter=[]    Filter output based on conditions provided\n  --format           Pretty-print containers using a Go template\n  --help             Print usage\n  -l, --latest       Show the latest created container (includes all states)\n  -n=-1              Show n last created containers (includes all states)\n  --no-trunc         Don''t truncate output\n  -q, --quiet        Only display numeric IDs\n  -s, --size         Display total file sizes\n##########################################################################\n\nUsage:	docker pull [OPTIONS] NAME[:TAG|@DIGEST]\n\nPull an image or a repository from a registry\n\n  -a, --all-tags                  Download all tagged images in the repository\n  --disable-content-trust=true    Skip image verification\n  --help                          Print usage\n##########################################################################\n\nUsage:	docker push [OPTIONS] NAME[:TAG]\n\nPush an image or a repository to a registry\n\n  --disable-content-trust=true    Skip image signing\n  --help                          Print usage\n##########################################################################\n\nUsage:	docker rename [OPTIONS] OLD_NAME NEW_NAME\n\nRename a container\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker restart [OPTIONS] CONTAINER [CONTAINER...]\n\nRestart a container\n\n  --help             Print usage\n  -t, --time=10      Seconds to wait for stop before killing the container\n##########################################################################\n\nUsage:	docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\nRemove one or more containers\n\n  -f, --force        Force the removal of a running container (uses SIGKILL)\n  --help             Print usage\n  -l, --link         Remove the specified link\n  -v, --volumes      Remove the volumes associated with the container\n##########################################################################\n\nUsage:	docker rmi [OPTIONS] IMAGE [IMAGE...]\n\nRemove one or more images\n\n  -f, --force        Force removal of the image\n  --help             Print usage\n  --no-prune         Do not delete untagged parents\n##########################################################################\n\nUsage:	docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n\nRun a command in a new container\n\n  -a, --attach=[]                 Attach to STDIN, STDOUT or STDERR\n  --add-host=[]                   Add a custom host-to-IP mapping (host:ip)\n  --blkio-weight                  Block IO (relative weight), between 10 and 1000\n  --blkio-weight-device=[]        Block IO weight (relative device weight)\n  --cpu-shares                    CPU shares (relative weight)\n  --cap-add=[]                    Add Linux capabilities\n  --cap-drop=[]                   Drop Linux capabilities\n  --cgroup-parent                 Optional parent cgroup for the container\n  --cidfile                       Write the container ID to the file\n  --cpu-period                    Limit CPU CFS (Completely Fair Scheduler) period\n  --cpu-quota                     Limit CPU CFS (Completely Fair Scheduler) quota\n  --cpuset-cpus                   CPUs in which to allow execution (0-3, 0,1)\n  --cpuset-mems                   MEMs in which to allow execution (0-3, 0,1)\n  -d, --detach                    Run container in background and print container ID\n  --detach-keys                   Override the key sequence for detaching a container\n  --device=[]                     Add a host device to the container\n  --device-read-bps=[]            Limit read rate (bytes per second) from a device\n  --device-read-iops=[]           Limit read rate (IO per second) from a device\n  --device-write-bps=[]           Limit write rate (bytes per second) to a device\n  --device-write-iops=[]          Limit write rate (IO per second) to a device\n  --disable-content-trust=true    Skip image verification\n  --dns=[]                        Set custom DNS servers\n  --dns-opt=[]                    Set DNS options\n  --dns-search=[]                 Set custom DNS search domains\n  -e, --env=[]                    Set environment variables\n  --entrypoint                    Overwrite the default ENTRYPOINT of the image\n  --env-file=[]                   Read in a file of environment variables\n  --expose=[]                     Expose a port or a range of ports\n  --group-add=[]                  Add additional groups to join\n  -h, --hostname                  Container host name\n  --help                          Print usage\n  -i, --interactive               Keep STDIN open even if not attached\n  --ip                            Container IPv4 address (e.g. 172.30.100.104)\n  --ip6                           Container IPv6 address (e.g. 2001:db8::33)\n  --ipc                           IPC namespace to use\n  --isolation                     Container isolation level\n  --kernel-memory                 Kernel memory limit\n  -l, --label=[]                  Set meta data on a container\n  --label-file=[]                 Read in a line delimited file of labels\n  --link=[]                       Add link to another container\n  --log-driver                    Logging driver for container\n  --log-opt=[]                    Log driver options\n  -m, --memory                    Memory limit\n  --mac-address                   Container MAC address (e.g. 92:d0:c6:0a:29:33)\n  --memory-reservation            Memory soft limit\n  --memory-swap                   Swap limit equal to memory plus swap: ''-1'' to enable unlimited swap\n  --memory-swappiness=-1          Tune container memory swappiness (0 to 100)\n  --name                          Assign a name to the container\n  --net=default                   Connect a container to a network\n  --net-alias=[]                  Add network-scoped alias for the container\n  --oom-kill-disable              Disable OOM Killer\n  --oom-score-adj                 Tune host''s OOM preferences (-1000 to 1000)\n  -P, --publish-all               Publish all exposed ports to random ports\n  -p, --publish=[]                Publish a container''s port(s) to the host\n  --pid                           PID namespace to use\n  --privileged                    Give extended privileges to this container\n  --read-only                     Mount the container''s root filesystem as read only\n  --restart=no                    Restart policy to apply when a container exits\n  --rm                            Automatically remove the container when it exits\n  --security-opt=[]               Security Options\n  --shm-size                      Size of /dev/shm, default value is 64MB\n  --sig-proxy=true                Proxy received signals to the process\n  --stop-signal=SIGTERM           Signal to stop a container, SIGTERM by default\n  -t, --tty                       Allocate a pseudo-TTY\n  --tmpfs=[]                      Mount a tmpfs directory\n  -u, --user                      Username or UID (format: <name|uid>[:<group|gid>])\n  --ulimit=[]                     Ulimit options\n  --uts                           UTS namespace to use\n  -v, --volume=[]                 Bind mount a volume\n  --volume-driver                 Optional volume driver for the container\n  --volumes-from=[]               Mount volumes from the specified container(s)\n  -w, --workdir                   Working directory inside the container\n##########################################################################\n\nUsage:	docker save [OPTIONS] IMAGE [IMAGE...]\n\nSave an image(s) to a tar archive (streamed to STDOUT by default)\n\n  --help             Print usage\n  -o, --output       Write to a file, instead of STDOUT\n##########################################################################\n\nUsage:	docker search [OPTIONS] TERM\n\nSearch the Docker Hub for images\n\n  --automated        Only show automated builds\n  --help             Print usage\n  --no-trunc         Don''t truncate output\n  -s, --stars        Only displays with at least x stars\n##########################################################################\n\nUsage:	docker start [OPTIONS] CONTAINER [CONTAINER...]\n\nStart one or more stopped containers\n\n  -a, --attach         Attach STDOUT/STDERR and forward signals\n  --detach-keys        Override the key sequence for detaching a container\n  --help               Print usage\n  -i, --interactive    Attach container''s STDIN\n##########################################################################\n\nUsage:	docker stats [OPTIONS] [CONTAINER...]\n\nDisplay a live stream of container(s) resource usage statistics\n\n  -a, --all          Show all containers (default shows just running)\n  --help             Print usage\n  --no-stream        Disable streaming stats and only pull the first result\n##########################################################################\n\nUsage:	docker stop [OPTIONS] CONTAINER [CONTAINER...]\n\nStop a running container.\nSending SIGTERM and then SIGKILL after a grace period\n\n  --help             Print usage\n  -t, --time=10      Seconds to wait for stop before killing it\n##########################################################################\n\nUsage:	docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]\n\nTag an image into a repository\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker top [OPTIONS] CONTAINER [ps OPTIONS]\n\nDisplay the running processes of a container\n\n  --help             Print usage\n##########################################################################\n\nUsage:	docker unpause [OPTIONS] CONTAINER [CONTAINER...]\n\nUnpause all processes within a container\n\n  --help             Print usage\n\nUsage:	docker update [OPTIONS] CONTAINER [CONTAINER...]\n\nUpdate resources of one or more containers\n\n  --blkio-weight          Block IO (relative weight), between 10 and 1000\n  --cpu-shares            CPU shares (relative weight)\n  --cpu-period            Limit CPU CFS (Completely Fair Scheduler) period\n  --cpu-quota             Limit CPU CFS (Completely Fair Scheduler) quota\n  --cpuset-cpus           CPUs in which to allow execution (0-3, 0,1)\n  --cpuset-mems           MEMs in which to allow execution (0-3, 0,1)\n  --help                  Print usage\n  --kernel-memory         Kernel memory limit\n  -m, --memory            Memory limit\n  --memory-reservation    Memory soft limit\n  --memory-swap           Swap limit equal to memory plus swap: ''-1'' to enable unlimited swap\n\nUsage:	docker version [OPTIONS]\n\nShow the Docker version information\n\n  -f, --format       Format the output using the given go template\n  --help             Print usage\n\nUsage:	docker volume [OPTIONS] [COMMAND]\n\nManage Docker volumes\n\nCommands:\n  create                   Create a volume\n  inspect                  Return low-level information on a volume\n  ls                       List volumes\n  rm                       Remove a volume\n\nRun ''docker volume COMMAND --help'' for more information on a command\n\n  --help             Print usage\n\nUsage:	docker wait [OPTIONS] CONTAINER [CONTAINER...]\n\nBlock until a container stops, then print its exit code\n\n  --help             Print usage\n', ''),
(164, 'test', ' sfdasdf asdfa df a ', '你好');
